<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-04-15T18:17:39Z</responseDate>
<request verb="ListRecords" until="2015-01-31" from="2010-01-01" metadataPrefix="arXiv" set="cs">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0062</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0062</id><created>2007-03-31</created><authors><author><keyname>Šrámek</keyname><forenames>Rastislav</forenames></author><author><keyname>Brejová</keyname><forenames>Broňa</forenames></author><author><keyname>Vinař</keyname><forenames>Tomáš</forenames></author></authors><title>On-line Viterbi Algorithm and Its Relationship to Random Walks</title><categories>cs.DS</categories><acm-class>G.3; E.1; F.1.2; J.3</acm-class><journal-ref>Algorithms in Bioinformatics: 7th International Workshop (WABI),
  4645 volume of Lecture Notes in Computer Science, pp. 240-251, Philadelphia,
  PA, USA, September 2007. Springer</journal-ref><doi>10.1007/978-3-540-74126-8_23</doi><abstract>  In this paper, we introduce the on-line Viterbi algorithm for decoding hidden
Markov models (HMMs) in much smaller than linear space. Our analysis on
two-state HMMs suggests that the expected maximum memory used to decode
sequence of length $n$ with $m$-state HMM can be as low as $\Theta(m\log n)$,
without a significant slow-down compared to the classical Viterbi algorithm.
Classical Viterbi algorithm requires $O(mn)$ space, which is impractical for
analysis of long DNA sequences (such as complete human genome chromosomes) and
for continuous data streams. We also experimentally demonstrate the performance
of the on-line Viterbi algorithm on a simple HMM for gene finding on both
simulated and real DNA sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0213</identifier>
 <datestamp>2012-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0213</id><created>2007-04-02</created><updated>2012-09-27</updated><authors><author><keyname>Narayanan</keyname><forenames>Ketan D. Mulmuley Hariharan</forenames></author></authors><title>Geometric Complexity Theory V: On deciding nonvanishing of a generalized
  Littlewood-Richardson coefficient</title><categories>cs.CC</categories><comments>This article has been withdrawn because it has been merged with the
  earlier article (GCT3) in the series, and a new article appears in this GCT5
  slot now as shown in the abstract</comments><abstract>  This article has been withdrawn because it has been merged with the earlier
article GCT3 (arXiv: CS/0501076 [cs.CC]) in the series. The merged article is
now available as:
  Geometric Complexity Theory III: on deciding nonvanishing of a
Littlewood-Richardson Coefficient, Journal of Algebraic Combinatorics, vol. 36,
issue 1, 2012, pp. 103-110. (Authors: Ketan Mulmuley, Hari Narayanan and Milind
Sohoni)
  The new article in this GCT5 slot in the series is:
  Geometric Complexity Theory V: Equivalence between blackbox derandomization
of polynomial identity testing and derandomization of Noether's Normalization
Lemma, in the Proceedings of FOCS 2012 (abstract), arXiv:1209.5993 [cs.CC]
(full version) (Author: Ketan Mulmuley)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0217</identifier>
 <datestamp>2010-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0217</id><created>2007-04-02</created><updated>2009-02-16</updated><authors><author><keyname>Santipach</keyname><forenames>Wiroonsak</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>Capacity of a Multiple-Antenna Fading Channel with a Quantized Precoding
  Matrix</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Trans. Inf. Theory, vol. 55, no. 3, pp. 1218--1234, March
  2009</journal-ref><doi>10.1109/TIT.2008.2011437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a multiple-input multiple-output (MIMO) channel, feedback from the
receiver can be used to specify a transmit precoding matrix, which selectively
activates the strongest channel modes. Here we analyze the performance of
Random Vector Quantization (RVQ), in which the precoding matrix is selected
from a random codebook containing independent, isotropically distributed
entries. We assume that channel elements are i.i.d. and known to the receiver,
which relays the optimal (rate-maximizing) precoder codebook index to the
transmitter using B bits. We first derive the large system capacity of
beamforming (rank-one precoding matrix) as a function of B, where large system
refers to the limit as B and the number of transmit and receive antennas all go
to infinity with fixed ratios. With beamforming RVQ is asymptotically optimal,
i.e., no other quantization scheme can achieve a larger asymptotic rate. The
performance of RVQ is also compared with that of a simpler reduced-rank scalar
quantization scheme in which the beamformer is constrained to lie in a random
subspace. We subsequently consider a precoding matrix with arbitrary rank, and
approximate the asymptotic RVQ performance with optimal and linear receivers
(matched filter and Minimum Mean Squared Error (MMSE)). Numerical examples show
that these approximations accurately predict the performance of finite-size
systems of interest. Given a target spectral efficiency, numerical examples
show that the amount of feedback required by the linear MMSE receiver is only
slightly more than that required by the optimal receiver, whereas the matched
filter can require significantly more feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0304</identifier>
 <datestamp>2013-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0304</id><created>2007-04-02</created><updated>2010-10-13</updated><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>The World as Evolving Information</title><categories>cs.IT cs.AI math.IT q-bio.PE</categories><comments>16 pages. Extended version, three more laws of information, two
  classifications, and discussion added. To be published (soon) in
  International Conference on Complex Systems 2007 Proceedings</comments><acm-class>H.1.1</acm-class><journal-ref>Minai, A., Braha, D., and Bar-Yam, Y., eds. Unifying Themes in
  Complex Systems VII, pp. 100-115. Springer, Berlin Heidelberg, 2012</journal-ref><doi>10.1007/978-3-642-18003-3_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the benefits of describing the world as information,
especially in the study of the evolution of life and cognition. Traditional
studies encounter problems because it is difficult to describe life and
cognition in terms of matter and energy, since their laws are valid only at the
physical scale. However, if matter and energy, as well as life and cognition,
are described in terms of information, evolution can be described consistently
as information becoming more complex.
  The paper presents eight tentative laws of information, valid at multiple
scales, which are generalizations of Darwinian, cybernetic, thermodynamic,
psychological, philosophical, and complexity principles. These are further used
to discuss the notions of life, cognition and their evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0309</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0309</id><created>2007-04-02</created><updated>2007-07-12</updated><authors><author><keyname>Zhu</keyname><forenames>Guohun</forenames></author></authors><title>The Complexity of HCP in Digraps with Degree Bound Two</title><categories>cs.CC cs.DM</categories><comments>10 pages, 4 figures, had been submitted to a Journal</comments><abstract>  The Hamiltonian cycle problem (HCP) in digraphs D with degree bound two is
solved by two mappings in this paper. The first bijection is between an
incidence matrix C_{nm} of simple digraph and an incidence matrix F of balanced
bipartite undirected graph G; The second mapping is from a perfect matching of
G to a cycle of D. It proves that the complexity of HCP in D is polynomial, and
finding a second non-isomorphism Hamiltonian cycle from a given Hamiltonian
digraph with degree bound two is also polynomial. Lastly it deduces P=NP base
on the results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0492</identifier>
 <datestamp>2010-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0492</id><created>2007-04-04</created><updated>2010-02-04</updated><authors><author><keyname>Su</keyname><forenames>Shenghui</forenames></author><author><keyname>Lu</keyname><forenames>Shuwang</forenames></author></authors><title>Refuting the Pseudo Attack on the REESSE1+ Cryptosystem</title><categories>cs.CR</categories><comments>14 pages, and 2 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We illustrate through example 1 and 2 that the condition at theorem 1 in [8]
dissatisfies necessity, and the converse proposition of fact 1.1 in [8] does
not hold, namely the condition Z/M - L/Ak &lt; 1/(2 Ak^2) is not sufficient for
f(i) + f(j) = f(k). Illuminate through an analysis and ex.3 that there is a
logic error during deduction of fact 1.2, which causes each of fact 1.2, 1.3, 4
to be invalid. Demonstrate through ex.4 and 5 that each or the combination of
qu+1 &gt; qu * D at fact 4 and table 1 at fact 2.2 is not sufficient for f(i) +
f(j) = f(k), property 1, 2, 3, 4, 5 each are invalid, and alg.1 based on fact 4
and alg.2 based on table 1 are disordered and wrong logically. Further,
manifest through a repeated experiment and ex.5 that the data at table 2 is
falsified, and the example in [8] is woven elaborately. We explain why Cx = Ax
* W^f(x) (% M) is changed to Cx = (Ax * W^f(x))^d (% M) in REESSE1+ v2.1. To
the signature fraud, we point out that [8] misunderstands the existence of T^-1
and Q^-1 % (M-1), and forging of Q can be easily avoided through moving H.
Therefore, the conclusion of [8] that REESSE1+ is not secure at all (which
connotes that [8] can extract a related private key from any public key in
REESSE1+) is fully incorrect, and as long as the parameter Omega is fitly
selected, REESSE1+ with Cx = Ax * W^f(x) (% M) is secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0499</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0499</id><created>2007-04-04</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Optimal Routing for Decode-and-Forward based Cooperation in Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>Accepted and to be presented at Fourth Annual IEEE Communications
  Society Conference on Sensor, Mesh, and Ad Hoc Communications and Networks
  (SECON 2007), San Diego, California, June 18-21 2007</comments><journal-ref>Proceedings of the 4th Annual IEEE Communications Society
  Conference on Sensor, Mesh, and Ad Hoc Communications and Networks (SECON
  2007), San Diego, CA, pp. 334-343, Jun. 18-21 2007.</journal-ref><doi>10.1109/SAHCN.2007.4292845</doi><abstract>  We investigate cooperative wireless relay networks in which the nodes can
help each other in data transmission. We study different coding strategies in
the single-source single-destination network with many relay nodes. Given the
myriad of ways in which nodes can cooperate, there is a natural routing
problem, i.e., determining an ordered set of nodes to relay the data from the
source to the destination. We find that for a given route, the
decode-and-forward strategy, which is an information theoretic cooperative
coding strategy, achieves rates significantly higher than that achievable by
the usual multi-hop coding strategy, which is a point-to-point non-cooperative
coding strategy. We construct an algorithm to find an optimal route (in terms
of rate maximizing) for the decode-and-forward strategy. Since the algorithm
runs in factorial time in the worst case, we propose a heuristic algorithm that
runs in polynomial time. The heuristic algorithm outputs an optimal route when
the nodes transmit independent codewords. We implement these coding strategies
using practical low density parity check codes to compare the performance of
the strategies on different routes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0802</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0802</id><created>2007-04-05</created><authors><author><keyname>Lo</keyname><forenames>Caleb K.</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Hybrid-ARQ in Multihop Networks with Opportunistic Relay Selection</title><categories>cs.IT math.IT</categories><comments>4 pages, 5 figures, to appear in Proceedings of the 2007
  International Conference on Acoustics, Speech, and Signal Processing in
  Honolulu, HI</comments><abstract>  This paper develops a contention-based opportunistic feedback technique
towards relay selection in a dense wireless network. This technique enables the
forwarding of additional parity information from the selected relay to the
destination. For a given network, the effects of varying key parameters such as
the feedback probability are presented and discussed. A primary advantage of
the proposed technique is that relay selection can be performed in a
distributed way. Simulation results find its performance to closely match that
of centralized schemes that utilize GPS information, unlike the proposed
method. The proposed relay selection method is also found to achieve throughput
gains over a point-to-point transmission strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.0805</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.0805</id><created>2007-04-05</created><authors><author><keyname>Lo</keyname><forenames>Caleb K.</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Opportunistic Relay Selection with Limited Feedback</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, to appear in Proceedings of 2007 IEEE Vehicular
  Technology Conference-Spring in Dublin, Ireland</comments><abstract>  It has been shown that a decentralized relay selection protocol based on
opportunistic feedback from the relays yields good throughput performance in
dense wireless networks. This selection strategy supports a hybrid-ARQ
transmission approach where relays forward parity information to the
destination in the event of a decoding error. Such an approach, however,
suffers a loss compared to centralized strategies that select relays with the
best channel gain to the destination. This paper closes the performance gap by
adding another level of channel feedback to the decentralized relay selection
problem. It is demonstrated that only one additional bit of feedback is
necessary for good throughput performance. The performance impact of varying
key parameters such as the number of relays and the channel feedback threshold
is discussed. An accompanying bit error rate analysis demonstrates the
importance of relay selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.1043</identifier>
 <datestamp>2010-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.1043</id><created>2007-04-08</created><updated>2010-12-16</updated><authors><author><keyname>Delahaye</keyname><forenames>Jean-Paul</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>On the Kolmogorov-Chaitin Complexity for short sequences</title><categories>cs.CC cs.IT math.IT</categories><comments>21 pages. Paper webpage: http://www.mathrix.org/experimentalAIT/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A drawback of Kolmogorov-Chaitin complexity (K) as a function from s to the
shortest program producing s is its noncomputability which limits its range of
applicability. Moreover, when strings are short, the dependence of K on a
particular universal Turing machine U can be arbitrary. In practice one can
approximate it by computable compression methods. However, such compression
methods do not always provide meaningful approximations--for strings shorter,
for example, than typical compiler lengths. In this paper we suggest an
empirical approach to overcome this difficulty and to obtain a stable
definition of the Kolmogorov-Chaitin complexity for short sequences.
Additionally, a correlation in terms of distribution frequencies was found
across the output of two models of abstract machines, namely unidimensional
cellular automata and deterministic Turing machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.1269</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.1269</id><created>2007-04-10</created><updated>2007-06-20</updated><authors><author><keyname>Zdeborová</keyname><forenames>Lenka</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author></authors><title>Phase Transitions in the Coloring of Random Graphs</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.CC</categories><comments>36 pages, 15 figures</comments><journal-ref>Phys. Rev. E 76, 031131 (2007)</journal-ref><doi>10.1103/PhysRevE.76.031131</doi><abstract>  We consider the problem of coloring the vertices of a large sparse random
graph with a given number of colors so that no adjacent vertices have the same
color. Using the cavity method, we present a detailed and systematic analytical
study of the space of proper colorings (solutions).
  We show that for a fixed number of colors and as the average vertex degree
(number of constraints) increases, the set of solutions undergoes several phase
transitions similar to those observed in the mean field theory of glasses.
First, at the clustering transition, the entropically dominant part of the
phase space decomposes into an exponential number of pure states so that beyond
this transition a uniform sampling of solutions becomes hard. Afterward, the
space of solutions condenses over a finite number of the largest states and
consequently the total entropy of solutions becomes smaller than the annealed
one. Another transition takes place when in all the entropically dominant
states a finite fraction of nodes freezes so that each of these nodes is
allowed a single color in all the solutions inside the state. Eventually, above
the coloring threshold, no more solutions are available. We compute all the
critical connectivities for Erdos-Renyi and regular random graphs and determine
their asymptotic values for large number of colors.
  Finally, we discuss the algorithmic consequences of our findings. We argue
that the onset of computational hardness is not associated with the clustering
transition and we suggest instead that the freezing transition might be the
relevant phenomenon. We also discuss the performance of a simple local Walk-COL
algorithm and of the belief propagation algorithm in the light of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.1274</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.1274</id><created>2007-04-10</created><authors><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Rajnarayan</keyname><forenames>Dev G.</forenames></author></authors><title>Parametric Learning and Monte Carlo Optimization</title><categories>cs.LG</categories><abstract>  This paper uncovers and explores the close relationship between Monte Carlo
Optimization of a parametrized integral (MCO), Parametric machine-Learning
(PL), and `blackbox' or `oracle'-based optimization (BO). We make four
contributions. First, we prove that MCO is mathematically identical to a broad
class of PL problems. This identity potentially provides a new application
domain for all broadly applicable PL techniques: MCO. Second, we introduce
immediate sampling, a new version of the Probability Collectives (PC) algorithm
for blackbox optimization. Immediate sampling transforms the original BO
problem into an MCO problem. Accordingly, by combining these first two
contributions, we can apply all PL techniques to BO. In our third contribution
we validate this way of improving BO by demonstrating that cross-validation and
bagging improve immediate sampling. Finally, conventional MC and MCO procedures
ignore the relationship between the sample point locations and the associated
values of the integrand; only the values of the integrand at those locations
are considered. We demonstrate that one can exploit the sample location
information using PL techniques, for example by forming a fit of the sample
locations to the associated values of the integrand. This provides an
additional way to apply PL techniques to improve MCO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.1409</identifier>
 <datestamp>2012-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.1409</id><created>2007-04-11</created><updated>2012-06-08</updated><authors><author><keyname>HengShuai</keyname><forenames>Yao</forenames></author></authors><title>Preconditioned Temporal Difference Learning</title><categories>cs.LG cs.AI</categories><comments>This paper has been withdrawn by the author. Look at the ICML version
  instead: http://icml2008.cs.helsinki.fi/papers/111.pdf</comments><abstract>  This paper has been withdrawn by the author. This draft is withdrawn for its
poor quality in english, unfortunately produced by the author when he was just
starting his science route. Look at the ICML version instead:
http://icml2008.cs.helsinki.fi/papers/111.pdf
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.1751</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.1751</id><created>2007-04-13</created><updated>2010-08-24</updated><authors><author><keyname>Rioul</keyname><forenames>Olivier</forenames></author></authors><title>Information Theoretic Proofs of Entropy Power Inequalities</title><categories>cs.IT math.IT</categories><comments>submitted for publication in the IEEE Transactions on Information
  Theory, revised version</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While most useful information theoretic inequalities can be deduced from the
basic properties of entropy or mutual information, up to now Shannon's entropy
power inequality (EPI) is an exception: Existing information theoretic proofs
of the EPI hinge on representations of differential entropy using either Fisher
information or minimum mean-square error (MMSE), which are derived from de
Bruijn's identity. In this paper, we first present an unified view of these
proofs, showing that they share two essential ingredients: 1) a data processing
argument applied to a covariance-preserving linear transformation; 2) an
integration over a path of a continuous Gaussian perturbation. Using these
ingredients, we develop a new and brief proof of the EPI through a mutual
information inequality, which replaces Stam and Blachman's Fisher information
inequality (FII) and an inequality for MMSE by Guo, Shamai and Verd\'u used in
earlier proofs. The result has the advantage of being very simple in that it
relies only on the basic properties of mutual information. These ideas are then
generalized to various extended versions of the EPI: Zamir and Feder's
generalized EPI for linear transformations of the random variables, Takano and
Johnson's EPI for dependent variables, Liu and Viswanath's
covariance-constrained EPI, and Costa's concavity inequality for the entropy
power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.1829</identifier>
 <datestamp>2011-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.1829</id><created>2007-04-13</created><updated>2011-02-19</updated><authors><author><keyname>Felsner</keyname><forenames>Stefan</forenames></author><author><keyname>Kloch</keyname><forenames>Kamil</forenames></author><author><keyname>Matecki</keyname><forenames>Grzegorz</forenames></author><author><keyname>Micek</keyname><forenames>Piotr</forenames></author></authors><title>On-line Chain Partitions of Up-growing Semi-orders</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On-line chain partition is a two-player game between Spoiler and Algorithm.
Spoiler presents a partially ordered set, point by point. Algorithm assigns
incoming points (immediately and irrevocably) to the chains which constitute a
chain partition of the order. The value of the game for orders of width $w$ is
a minimum number $\fVal(w)$ such that Algorithm has a strategy using at most
$\fVal(w)$ chains on orders of width at most $w$. We analyze the chain
partition game for up-growing semi-orders. Surprisingly, the golden ratio comes
into play and the value of the game is $\lfloor\frac{1+\sqrt{5}}{2}\; w
\rfloor$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.2452</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.2452</id><created>2007-04-18</created><authors><author><keyname>Yazdani</keyname><forenames>Raman</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>Optimum Linear LLR Calculation for Iterative Decoding on Fading Channels</title><categories>cs.IT math.IT</categories><comments>This paper will be presented in IEEE International Symposium on
  Information Theory (ISIT) 2007 in Nice, France</comments><doi>10.1109/ISIT.2007.4557204</doi><abstract>  On a fading channel with no channel state information at the receiver,
calculating true log-likelihood ratios (LLR) is complicated. Existing work
assume that the power of the additive noise is known and use the expected value
of the fading gain in a linear function of the channel output to find
approximate LLRs. In this work, we first assume that the power of the additive
noise is known and we find the optimum linear approximation of LLRs in the
sense of maximum achievable transmission rate on the channel. The maximum
achievable rate under this linear LLR calculation is almost equal to the
maximum achievable rate under true LLR calculation. We also observe that this
method appears to be the optimum in the sense of bit error rate performance
too. These results are then extended to the case that the noise power is
unknown at the receiver and a performance almost identical to the case that the
noise power is perfectly known is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.2596</identifier>
 <datestamp>2011-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.2596</id><created>2007-04-19</created><authors><author><keyname>Grassl</keyname><forenames>Markus</forenames></author></authors><title>Computing Extensions of Linear Codes</title><categories>cs.IT cs.DM math.IT</categories><comments>accepted for publication at ISIT 07</comments><journal-ref>Proceedings 2007 IEEE International Symposium on Information
  Theory (ISIT 2007), Nice, France, June 2007, pp. 476-480</journal-ref><doi>10.1109/ISIT.2007.4557095</doi><abstract>  This paper deals with the problem of increasing the minimum distance of a
linear code by adding one or more columns to the generator matrix. Several
methods to compute extensions of linear codes are presented. Many codes
improving the previously known lower bounds on the minimum distance have been
found.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.2725</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.2725</id><created>2007-04-20</created><updated>2007-12-06</updated><authors><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Cantador</keyname><forenames>Ivan</forenames></author></authors><title>Exploiting Heavy Tails in Training Times of Multilayer Perceptrons: A
  Case Study with the UCI Thyroid Disease Database</title><categories>cs.NE</categories><comments>8 pages, 4 figures, submitted for consideration to the "Statistics
  and Its Interface" journal</comments><abstract>  The random initialization of weights of a multilayer perceptron makes it
possible to model its training process as a Las Vegas algorithm, i.e. a
randomized algorithm which stops when some required training error is obtained,
and whose execution time is a random variable. This modeling is used to perform
a case study on a well-known pattern recognition benchmark: the UCI Thyroid
Disease Database. Empirical evidence is presented of the training time
probability distribution exhibiting a heavy tail behavior, meaning a big
probability mass of long executions. This fact is exploited to reduce the
training time cost by applying two simple restart strategies. The first assumes
full knowledge of the distribution yielding a 40% cut down in expected time
with respect to the training without restarts. The second, assumes null
knowledge, yielding a reduction ranging from 9% to 23%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.2926</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.2926</id><created>2007-04-23</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Optimal Routing for the Gaussian Multiple-Relay Channel with
  Decode-and-Forward</title><categories>cs.IT math.IT</categories><comments>Accepted and to be presented at the 2007 IEEE International Symposium
  on Information Theory (ISIT 2007), Acropolis Congress and Exhibition Center,
  Nice, France, June 24-29 2007</comments><journal-ref>Proceedings of the 2007 IEEE International Symposium on
  Information Theory (ISIT 2007), Acropolis Congress and Exhibition Center,
  Nice, France, pp. 1061-1065, Jun. 24-29 2007.</journal-ref><doi>10.1109/ISIT.2007.4557364</doi><abstract>  In this paper, we study a routing problem on the Gaussian multiple relay
channel, in which nodes employ a decode-and-forward coding strategy. We are
interested in routes for the information flow through the relays that achieve
the highest DF rate. We first construct an algorithm that provably finds
optimal DF routes. As the algorithm runs in factorial time in the worst case,
we propose a polynomial time heuristic algorithm that finds an optimal route
with high probability. We demonstrate that that the optimal (and near optimal)
DF routes are good in practice by simulating a distributed DF coding scheme
using low density parity check codes with puncturing and incremental
redundancy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.3238</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.3238</id><created>2007-04-24</created><authors><author><keyname>Balbiani</keyname><forenames>Philippe</forenames></author><author><keyname>Herzig</keyname><forenames>Andreas</forenames></author><author><keyname>Troquard</keyname><forenames>Nicolas</forenames></author></authors><title>Alternative axiomatics and complexity of deliberative STIT theories</title><categories>cs.LO</categories><comments>Submitted to the Journal of Philosophical Logic; 13 pages excluding
  annex</comments><doi>10.1007/s10992-007-9078-7</doi><abstract>  We propose two alternatives to Xu's axiomatization of the Chellas STIT. The
first one also provides an alternative axiomatization of the deliberative STIT.
The second one starts from the idea that the historic necessity operator can be
defined as an abbreviation of operators of agency, and can thus be eliminated
from the logic of the Chellas STIT. The second axiomatization also allows us to
establish that the problem of deciding the satisfiability of a STIT formula
without temporal operators is NP-complete in the single-agent case, and is
NEXPTIME-complete in the multiagent case, both for the deliberative and the
Chellas' STIT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.3395</identifier>
 <datestamp>2010-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.3395</id><created>2007-04-25</created><updated>2010-06-06</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>General-Purpose Computing on a Semantic Network Substrate</title><categories>cs.AI cs.PL</categories><report-no>LA-UR-07-2885</report-no><acm-class>I.2.4; I.2.5; H.3.7; H.3.4</acm-class><journal-ref>Emergent Web Intelligence: Advanced Semantic Technologies,
  Advanced Information and Knowledge Processing series, Springer-Verlag, pages
  57-104, ISBN:978-1-84996-076-2, June 2010</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This article presents a model of general-purpose computing on a semantic
network substrate. The concepts presented are applicable to any semantic
network representation. However, due to the standards and technological
infrastructure devoted to the Semantic Web effort, this article is presented
from this point of view. In the proposed model of computing, the application
programming interface, the run-time program, and the state of the computing
virtual machine are all represented in the Resource Description Framework
(RDF). The implementation of the concepts presented provides a practical
computing paradigm that leverages the highly-distributed and standardized
representational-layer of the Semantic Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.3662</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.3662</id><created>2007-04-27</created><authors><author><keyname>Jiang</keyname><forenames>Mike Tian-Jian</forenames></author><author><keyname>Zhan</keyname><forenames>James</forenames></author><author><keyname>Lin</keyname><forenames>Jaimie</forenames></author><author><keyname>Lin</keyname><forenames>Jerry</forenames></author><author><keyname>Hsu</keyname><forenames>Wen-Lien</forenames></author></authors><title>An Automated Evaluation Metric for Chinese Text Entry</title><categories>cs.HC cs.CL</categories><comments>8 pages</comments><journal-ref>Jiang, Mike Tian-Jian, et al. "Robustness analysis of adaptive
  chinese input methods." Advances in Text Input Methods (WTIM 2011) (2011): 53</journal-ref><abstract>  In this paper, we propose an automated evaluation metric for text entry. We
also consider possible improvements to existing text entry evaluation metrics,
such as the minimum string distance error rate, keystrokes per character, cost
per correction, and a unified approach proposed by MacKenzie, so they can
accommodate the special characteristics of Chinese text. Current methods lack
an integrated concern about both typing speed and accuracy for Chinese text
entry evaluation. Our goal is to remove the bias that arises due to human
factors. First, we propose a new metric, called the correction penalty (P),
based on Fitts' law and Hick's law. Next, we transform it into the approximate
amortized cost (AAC) of information theory. An analysis of the AAC of Chinese
text input methods with different context lengths is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.3746</identifier>
 <datestamp>2014-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.3746</id><created>2007-04-27</created><authors><author><keyname>Xi</keyname><forenames>Yufang</forenames></author><author><keyname>Yeh</keyname><forenames>Edmund M.</forenames></author></authors><title>Distributed Algorithms for Spectrum Allocation, Power Control, Routing,
  and Congestion Control in Wireless Networks</title><categories>cs.NI</categories><comments>14 pages, 5 figures, submitted to IEEE/ACM Transactions on Networking</comments><abstract>  We develop distributed algorithms to allocate resources in multi-hop wireless
networks with the aim of minimizing total cost. In order to observe the
fundamental duplexing constraint that co-located transmitters and receivers
cannot operate simultaneously on the same frequency band, we first devise a
spectrum allocation scheme that divides the whole spectrum into multiple
sub-bands and activates conflict-free links on each sub-band. We show that the
minimum number of required sub-bands grows asymptotically at a logarithmic rate
with the chromatic number of network connectivity graph. A simple distributed
and asynchronous algorithm is developed to feasibly activate links on the
available sub-bands. Given a feasible spectrum allocation, we then design
node-based distributed algorithms for optimally controlling the transmission
powers on active links for each sub-band, jointly with traffic routes and user
input rates in response to channel states and traffic demands. We show that
under specified conditions, the algorithms asymptotically converge to the
optimal operating point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0704.3780</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0704.3780</id><created>2007-04-28</created><authors><author><keyname>Collet</keyname><forenames>Pierre</forenames></author><author><keyname>Rennard</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Stochastic Optimization Algorithms</title><categories>cs.NE</categories><comments>16 pages, 4 figures, 2 tables</comments><acm-class>G.1.6</acm-class><journal-ref>Rennard, J.-P., Handbook of Research on Nature Inspired Computing
  for Economics and Management, IGR, 2006</journal-ref><abstract>  When looking for a solution, deterministic methods have the enormous
advantage that they do find global optima. Unfortunately, they are very
CPU-intensive, and are useless on untractable NP-hard problems that would
require thousands of years for cutting-edge computers to explore. In order to
get a result, one needs to revert to stochastic algorithms, that sample the
search space without exploring it thoroughly. Such algorithms can find very
good results, without any guarantee that the global optimum has been reached;
but there is often no other choice than using them. This chapter is a short
introduction to the main methods used in stochastic optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0017</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0017</id><created>2007-05-01</created><updated>2007-05-01</updated><authors><author><keyname>Viamontes</keyname><forenames>George F.</forenames></author><author><keyname>Markov</keyname><forenames>Igor L.</forenames></author><author><keyname>Hayes</keyname><forenames>John P.</forenames></author></authors><title>Checking Equivalence of Quantum Circuits and States</title><categories>quant-ph cs.ET</categories><comments>9 pages, 13 figures, 3 tables</comments><journal-ref>Proc. Int'l Conf. on Computer-Aided Design (ICCAD), pp. 69-74, San
  Jose, CA, November 2007.</journal-ref><abstract>  Quantum computing promises exponential speed-ups for important simulation and
optimization problems. It also poses new CAD problems that are similar to, but
more challenging, than the related problems in classical (non-quantum) CAD,
such as determining if two states or circuits are functionally equivalent.
While differences in classical states are easy to detect, quantum states, which
are represented by complex-valued vectors, exhibit subtle differences leading
to several notions of equivalence. This provides flexibility in optimizing
quantum circuits, but leads to difficult new equivalence-checking issues for
simulation and synthesis. We identify several different equivalence-checking
problems and present algorithms for practical benchmarks, including quantum
communication and search circuits, which are shown to be very fast and robust
for hundreds of qubits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0150</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0150</id><created>2007-05-01</created><updated>2007-08-24</updated><authors><author><keyname>Jorgensen</keyname><forenames>Palle E. T.</forenames></author><author><keyname>Song</keyname><forenames>Myung-Sin</forenames></author></authors><title>Comparison of Discrete and Continuous Wavelet Transforms</title><categories>cs.CE</categories><comments>22 pages, Springer Encyclopedia of Complexity and Systems Science,
  the full version with figures is available at
  http://www.siue.edu/~msong/Research/ency.pdf</comments><abstract>  In this paper we outline several points of view on the interplay between
discrete and continuous wavelet transforms; stressing both pure and applied
aspects of both. We outline some new links between the two transform
technologies based on the theory of representations of generators and
relations. By this we mean a finite system of generators which are represented
by operators in Hilbert space. We further outline how these representations
yield sub-band filter banks for signal and image processing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0315</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0315</id><created>2007-05-02</created><updated>2010-07-14</updated><authors><author><keyname>Amini</keyname><forenames>Omid</forenames></author><author><keyname>Havet</keyname><forenames>Frederic</forenames></author><author><keyname>Huc</keyname><forenames>Florian</forenames></author><author><keyname>Thomasse</keyname><forenames>Stephan</forenames></author></authors><title>WDM and Directed Star Arboricity</title><categories>cs.NI math.CO</categories><comments>18 pages, 2 figures. Final version</comments><journal-ref>Combinatorics, Probability and Computing, Volume 19, Issue 02,
  March 2010, pp 161-182</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A digraph is $m$-labelled if every arc is labelled by an integer in $\{1,
\dots,m\}$. Motivated by wavelength assignment for multicasts in optical
networks, we introduce and study $n$-fibre colourings of labelled digraphs.
These are colourings of the arcs of $D$ such that at each vertex $v$, and for
each colour $\alpha$, $in(v,\alpha)+out(v,\alpha)\leq n$ with $in(v,\alpha)$
the number of arcs coloured $\alpha$ entering $v$ and $out(v,\alpha)$ the
number of labels $l$ such that there is at least one arc of label $l$ leaving
$v$ and coloured with $\alpha$. The problem is to find the minimum number of
colours $\lambda_n(D)$ such that the $m$-labelled digraph $D$ has an $n$-fibre
colouring. In the particular case when $D$ is $1$-labelled, $\lambda_1(D)$ is
called the directed star arboricity of $D$, and is denoted by $dst(D)$. We
first show that $dst(D)\leq 2\Delta^-(D)+1$, and conjecture that if
$\Delta^-(D)\geq 2$, then $dst(D)\leq 2\Delta^-(D)$. We also prove that for a
subcubic digraph $D$, then $dst(D)\leq 3$, and that if $\Delta^+(D),
\Delta^-(D)\leq 2$, then $dst(D)\leq 4$. Finally, we study
$\lambda_n(m,k)=\max\{\lambda_n(D) \tq D \mbox{is $m$-labelled} \et
\Delta^-(D)\leq k\}$. We show that if $m\geq n$, then $\ds
\left\lceil\frac{m}{n}\left\lceil \frac{k}{n}\right\rceil + \frac{k}{n}
\right\rceil\leq \lambda_n(m,k) \leq\left\lceil\frac{m}{n}\left\lceil
\frac{k}{n}\right\rceil + \frac{k}{n} \right\rceil + C \frac{m^2\log k}{n}$ for
some constant $C$. We conjecture that the lower bound should be the right value
of $\lambda_n(m,k)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0423</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0423</id><created>2007-05-03</created><authors><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Kayhan</keyname><forenames>F.</forenames></author><author><keyname>Montorsi</keyname><forenames>G.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Encoding for the Blackwell Channel with Reinforced Belief Propagation</title><categories>cs.IT math.IT</categories><comments>5 pages, 8 figures, submitted to ISIT 2007</comments><journal-ref>IEEE International Symposium on Information Theory (ISIT07); 2007.
  p. 1891-5</journal-ref><abstract>  A key idea in coding for the broadcast channel (BC) is binning, in which the
transmitter encode information by selecting a codeword from an appropriate bin
(the messages are thus the bin indexes). This selection is normally done by
solving an appropriate (possibly difficult) combinatorial problem. Recently it
has been shown that binning for the Blackwell channel --a particular BC-- can
be done by iterative schemes based on Survey Propagation (SP). This method uses
decimation for SP and suffers a complexity of O(n^2). In this paper we propose
a new variation of the Belief Propagation (BP) algorithm, named Reinforced BP
algorithm, that turns BP into a solver. Our simulations show that this new
algorithm has complexity O(n log n). Using this new algorithm together with a
non-linear coding scheme, we can efficiently achieve rates close to the border
of the capacity region of the Blackwell channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0552</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0552</id><created>2007-05-04</created><authors><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Satti</keyname><forenames>Srinivasa Rao</forenames></author></authors><title>Succinct Indexable Dictionaries with Applications to Encoding $k$-ary
  Trees, Prefix Sums and Multisets</title><categories>cs.DS cs.DM cs.IT math.IT</categories><comments>Final version of SODA 2002 paper; supersedes Leicester Tech report
  2002/16</comments><acm-class>E.1; E.4; F.2.2</acm-class><journal-ref>ACM Transactions on Algorithms vol 3 (2007), Article 43, 25pp</journal-ref><doi>10.1145/1290672.1290680</doi><abstract>  We consider the {\it indexable dictionary} problem, which consists of storing
a set $S \subseteq \{0,...,m-1\}$ for some integer $m$, while supporting the
operations of $\Rank(x)$, which returns the number of elements in $S$ that are
less than $x$ if $x \in S$, and -1 otherwise; and $\Select(i)$ which returns
the $i$-th smallest element in $S$. We give a data structure that supports both
operations in O(1) time on the RAM model and requires ${\cal B}(n,m) + o(n) +
O(\lg \lg m)$ bits to store a set of size $n$, where ${\cal B}(n,m) = \ceil{\lg
{m \choose n}}$ is the minimum number of bits required to store any $n$-element
subset from a universe of size $m$. Previous dictionaries taking this space
only supported (yes/no) membership queries in O(1) time. In the cell probe
model we can remove the $O(\lg \lg m)$ additive term in the space bound,
answering a question raised by Fich and Miltersen, and Pagh.
  We present extensions and applications of our indexable dictionary data
structure, including:
  An information-theoretically optimal representation of a $k$-ary cardinal
tree that supports standard operations in constant time,
  A representation of a multiset of size $n$ from $\{0,...,m-1\}$ in ${\cal
B}(n,m+n) + o(n)$ bits that supports (appropriate generalizations of) $\Rank$
and $\Select$ operations in constant time, and
  A representation of a sequence of $n$ non-negative integers summing up to $m$
in ${\cal B}(n,m+n) + o(n)$ bits that supports prefix sum queries in constant
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0561</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0561</id><created>2007-05-03</created><updated>2011-05-10</updated><authors><author><keyname>Chen</keyname><forenames>Jing-Chao</forenames></author></authors><title>Iterative Rounding for the Closest String Problem</title><categories>cs.DS cs.CC</categories><comments>This paper has been published in abstract Booklet of CiE09</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The closest string problem is an NP-hard problem, whose task is to find a
string that minimizes maximum Hamming distance to a given set of strings. This
can be reduced to an integer program (IP). However, to date, there exists no
known polynomial-time algorithm for IP. In 2004, Meneses et al. introduced a
branch-and-bound (B &amp; B) method for solving the IP problem. Their algorithm is
not always efficient and has the exponential time complexity. In the paper, we
attempt to solve efficiently the IP problem by a greedy iterative rounding
technique. The proposed algorithm is polynomial time and much faster than the
existing B &amp; B IP for the CSP. If the number of strings is limited to 3, the
algorithm is provably at most 1 away from the optimum. The empirical results
show that in many cases we can find an exact solution. Even though we fail to
find an exact solution, the solution found is very close to exact solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0635</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0635</id><created>2007-05-04</created><updated>2007-09-28</updated><authors><author><keyname>Cardinal</keyname><forenames>J.</forenames></author><author><keyname>Collette</keyname><forenames>S.</forenames></author><author><keyname>Hurtado</keyname><forenames>F.</forenames></author><author><keyname>Langerman</keyname><forenames>S.</forenames></author><author><keyname>Palop</keyname><forenames>B.</forenames></author></authors><title>Moving Walkways, Escalators, and Elevators</title><categories>cs.CG</categories><comments>16 pages. Presented at XII Encuentros de Geometria Computacional,
  Valladolid, Spain</comments><abstract>  We study a simple geometric model of transportation facility that consists of
two points between which the travel speed is high. This elementary definition
can model shuttle services, tunnels, bridges, teleportation devices, escalators
or moving walkways. The travel time between a pair of points is defined as a
time distance, in such a way that a customer uses the transportation facility
only if it is helpful.
  We give algorithms for finding the optimal location of such a transportation
facility, where optimality is defined with respect to the maximum travel time
between two points in a given set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.0734</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.0734</id><created>2007-05-05</created><authors><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author><author><keyname>Ying</keyname><forenames>Mingsheng</forenames></author></authors><title>Soft constraint abstraction based on semiring homomorphism</title><categories>cs.AI</categories><comments>18 pages, 1 figure</comments><journal-ref>Theoretical Computer Science 403(2-3) 192-201, 2008</journal-ref><doi>10.1016/j.tcs.2008.03.029</doi><abstract>  The semiring-based constraint satisfaction problems (semiring CSPs), proposed
by Bistarelli, Montanari and Rossi \cite{BMR97}, is a very general framework of
soft constraints. In this paper we propose an abstraction scheme for soft
constraints that uses semiring homomorphism. To find optimal solutions of the
concrete problem, the idea is, first working in the abstract problem and
finding its optimal solutions, then using them to solve the concrete problem.
  In particular, we show that a mapping preserves optimal solutions if and only
if it is an order-reflecting semiring homomorphism. Moreover, for a semiring
homomorphism $\alpha$ and a problem $P$ over $S$, if $t$ is optimal in
$\alpha(P)$, then there is an optimal solution $\bar{t}$ of $P$ such that
$\bar{t}$ has the same value as $t$ in $\alpha(P)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.1025</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.1025</id><created>2007-05-08</created><updated>2011-07-19</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author></authors><title>Recognizing Partial Cubes in Quadratic Time</title><categories>cs.DS</categories><comments>25 pages, five figures. This version significantly expands previous
  versions, including a new report on an implementation of the algorithm and
  experiments with it</comments><acm-class>F.2.2</acm-class><journal-ref>Journal of Graph Algorithms and Applications 15(2) 269-293, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to test whether a graph with n vertices and m edges is a partial
cube, and if so how to find a distance-preserving embedding of the graph into a
hypercube, in the near-optimal time bound O(n^2), improving previous O(nm)-time
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.1442</identifier>
 <datestamp>2013-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.1442</id><created>2007-05-10</created><updated>2007-06-29</updated><authors><author><keyname>Gharibyan</keyname><forenames>Karlen Garnik</forenames></author></authors><title>Does P=NP?</title><categories>cs.CC</categories><journal-ref>Karlen Gharibyan, Does P=NP?, in Proceedings of the first
  international Arm Tech Congress 2007</journal-ref><abstract>  This paper has been withdrawn Abstract: This paper has been withdrawn by the
author due to the publication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.1617</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.1617</id><created>2007-05-11</created><authors><author><keyname>Song</keyname><forenames>Daegene</forenames></author></authors><title>Non-Computability of Consciousness</title><categories>quant-ph astro-ph cs.AI</categories><comments>10 pages, 2 figures, 1 table</comments><journal-ref>NeuroQuantology 5, 382 (2007).</journal-ref><abstract>  With the great success in simulating many intelligent behaviors using
computing devices, there has been an ongoing debate whether all conscious
activities are computational processes. In this paper, the answer to this
question is shown to be no. A certain phenomenon of consciousness is
demonstrated to be fully represented as a computational process using a quantum
computer. Based on the computability criterion discussed with Turing machines,
the model constructed is shown to necessarily involve a non-computable element.
The concept that this is solely a quantum effect and does not work for a
classical case is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.1750</identifier>
 <datestamp>2011-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.1750</id><created>2007-05-12</created><updated>2011-03-04</updated><authors><author><keyname>Cui</keyname><forenames>Peng</forenames></author></authors><title>A Tighter Analysis of Setcover Greedy Algorithm for Test Set</title><categories>cs.DS</categories><comments>12 pages, 3 figures, Revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Setcover greedy algorithm is a natural approximation algorithm for test set
problem. This paper gives a precise and tighter analysis of performance
guarantee of this algorithm. The author improves the performance guarantee
$2\ln n$ which derives from set cover problem to $1.1354\ln n$ by applying the
potential function technique. In addition, the author gives a nontrivial lower
bound $1.0004609\ln n$ of performance guarantee of this algorithm. This lower
bound, together with the matching bound of information content heuristic,
confirms the fact information content heuristic is slightly better than
setcover greedy algorithm in worst case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.1922</identifier>
 <datestamp>2011-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.1922</id><created>2007-05-14</created><authors><author><keyname>Morgenshtern</keyname><forenames>Veniamin I.</forenames></author><author><keyname>Boelcskei</keyname><forenames>Helmut</forenames></author></authors><title>Crystallization in large wireless networks</title><categories>cs.IT math.IT</categories><comments>30 pages, 6 figures, submitted to journal IEEE Transactions on
  Information Theory</comments><journal-ref>Information Theory, IEEE Transactions on , vol.53, no.10,
  pp.3319-3349, Oct. 2007</journal-ref><doi>10.1109/TIT.2007.904789</doi><abstract>  We analyze fading interference relay networks where M single-antenna
source-destination terminal pairs communicate concurrently and in the same
frequency band through a set of K single-antenna relays using half-duplex
two-hop relaying. Assuming that the relays have channel state information
(CSI), it is shown that in the large-M limit, provided K grows fast enough as a
function of M, the network "decouples" in the sense that the individual
source-destination terminal pair capacities are strictly positive. The
corresponding required rate of growth of K as a function of M is found to be
sufficient to also make the individual source-destination fading links converge
to nonfading links. We say that the network "crystallizes" as it breaks up into
a set of effectively isolated "wires in the air". A large-deviations analysis
is performed to characterize the "crystallization" rate, i.e., the rate (as a
function of M,K) at which the decoupled links converge to nonfading links. In
the course of this analysis, we develop a new technique for characterizing the
large-deviations behavior of certain sums of dependent random variables. For
the case of no CSI at the relay level, assuming amplify-and-forward relaying,
we compute the per source-destination terminal pair capacity for M,K converging
to infinity, with K/M staying fixed, using tools from large random matrix
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.2106</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.2106</id><created>2007-05-15</created><authors><author><keyname>Nielsen</keyname><forenames>Finn Aarup</forenames></author></authors><title>Scientific citations in Wikipedia</title><categories>cs.DL cs.IR</categories><comments>5 pages, 2 figures</comments><acm-class>H.3.7; H.3.5; H.3.1</acm-class><journal-ref>First Monday, 12(8), 2007 August</journal-ref><abstract>  The Internet-based encyclopaedia Wikipedia has grown to become one of the
most visited web-sites on the Internet. However, critics have questioned the
quality of entries, and an empirical study has shown Wikipedia to contain
errors in a 2005 sample of science entries. Biased coverage and lack of sources
are among the "Wikipedia risks". The present work describes a simple assessment
of these aspects by examining the outbound links from Wikipedia articles to
articles in scientific journals with a comparison against journal statistics
from Journal Citation Reports such as impact factors. The results show an
increasing use of structured citation markup and good agreement with the
citation pattern seen in the scientific literature though with a slight
tendency to cite articles in high-impact journals such as Nature and Science.
These results increase confidence in Wikipedia as an good information organizer
for science in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.2626</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.2626</id><created>2007-05-17</created><authors><author><keyname>Knyazev</keyname><forenames>A. V.</forenames></author><author><keyname>Argentati</keyname><forenames>M. E.</forenames></author><author><keyname>Lashuk</keyname><forenames>I.</forenames></author><author><keyname>Ovtchinnikov</keyname><forenames>E. E.</forenames></author></authors><title>Block Locally Optimal Preconditioned Eigenvalue Xolvers (BLOPEX) in
  hypre and PETSc</title><categories>cs.MS cs.NA</categories><comments>Submitted to SIAM Journal on Scientific Computing</comments><report-no>UCDHSC-CCM-251</report-no><acm-class>G.4; G.1.3; G.1.8</acm-class><journal-ref>SIAM Journal on Scientific Computing (SISC). 25(5): 2224-2239,
  2007</journal-ref><doi>10.1137/060661624</doi><abstract>  We describe our software package Block Locally Optimal Preconditioned
Eigenvalue Xolvers (BLOPEX) publicly released recently. BLOPEX is available as
a stand-alone serial library, as an external package to PETSc (``Portable,
Extensible Toolkit for Scientific Computation'', a general purpose suite of
tools for the scalable solution of partial differential equations and related
problems developed by Argonne National Laboratory), and is also built into {\it
hypre} (``High Performance Preconditioners'', scalable linear solvers package
developed by Lawrence Livermore National Laboratory). The present BLOPEX
release includes only one solver--the Locally Optimal Block Preconditioned
Conjugate Gradient (LOBPCG) method for symmetric eigenvalue problems. {\it
hypre} provides users with advanced high-quality parallel preconditioners for
linear systems, in particular, with domain decomposition and multigrid
preconditioners. With BLOPEX, the same preconditioners can now be efficiently
used for symmetric eigenvalue problems. PETSc facilitates the integration of
independently developed application modules with strict attention to component
interoperability, and makes BLOPEX extremely easy to compile and use with
preconditioners that are available via PETSc. We present the LOBPCG algorithm
in BLOPEX for {\it hypre} and PETSc. We demonstrate numerically the scalability
of BLOPEX by testing it on a number of distributed and shared memory parallel
systems, including a Beowulf system, SUN Fire 880, an AMD dual-core Opteron
workstation, and IBM BlueGene/L supercomputer, using PETSc domain decomposition
and {\it hypre} multigrid preconditioning. We test BLOPEX on a model problem,
the standard 7-point finite-difference approximation of the 3-D Laplacian, with
the problem size in the range $10^5-10^8$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.2862</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.2862</id><created>2007-05-20</created><updated>2010-11-04</updated><authors><author><keyname>Ruinskiy</keyname><forenames>Dima</forenames></author><author><keyname>Shamir</keyname><forenames>Adi</forenames></author><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>Cryptanalysis of group-based key agreement protocols using subgroup
  distance functions</title><categories>cs.CR</categories><journal-ref>Proceedings of the 10th International Conference on Practice and
  Theory in Public-Key Cryptography PKC07, Lecture Notes In Computer Science
  4450 (2007), 61--75</journal-ref><doi>10.1007/978-3-540-71677-8_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new approach for cryptanalysis of key agreement protocols
based on noncommutative groups. This approach uses functions that estimate the
distance of a group element to a given subgroup. We test it against the
Shpilrain-Ushakov protocol, which is based on Thompson's group F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.3227</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.3227</id><created>2007-05-22</created><updated>2007-08-08</updated><authors><author><keyname>Kumabe</keyname><forenames>Masahiro</forenames></author><author><keyname>Mihara</keyname><forenames>H. Reiju</forenames></author></authors><title>Computability of simple games: A characterization and application to the
  core</title><categories>cs.GT cs.CC cs.LO math.LO</categories><comments>35 pages; To appear in Journal of Mathematical Economics; Appendix
  added, Propositions, Remarks, etc. are renumbered</comments><acm-class>F.4.1; F.1.1</acm-class><journal-ref>Journal of Mathematical Economics, Volume 44, Issues 3-4, February
  2008, Pages 348-366</journal-ref><doi>10.1016/j.jmateco.2007.05.012</doi><abstract>  The class of algorithmically computable simple games (i) includes the class
of games that have finite carriers and (ii) is included in the class of games
that have finite winning coalitions. This paper characterizes computable games,
strengthens the earlier result that computable games violate anonymity, and
gives examples showing that the above inclusions are strict. It also extends
Nakamura's theorem about the nonemptyness of the core and shows that computable
games have a finite Nakamura number, implying that the number of alternatives
that the players can deal with rationally is restricted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.3693</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.3693</id><created>2007-05-25</created><updated>2007-08-23</updated><authors><author><keyname>Beezley</keyname><forenames>Jonathan D.</forenames></author><author><keyname>Mandel</keyname><forenames>Jan</forenames></author></authors><title>Morphing Ensemble Kalman Filters</title><categories>math.DS cs.CV math.ST physics.ao-ph stat.ME stat.TH</categories><comments>17 pages, 7 figures. Added DDDAS references to the introduction</comments><report-no>UCDHSC CCM Report 240</report-no><msc-class>65P99, 62F15, 94A08</msc-class><doi>10.1111/j.1600-0870.2007.00275.x</doi><abstract>  A new type of ensemble filter is proposed, which combines an ensemble Kalman
filter (EnKF) with the ideas of morphing and registration from image
processing. This results in filters suitable for nonlinear problems whose
solutions exhibit moving coherent features, such as thin interfaces in wildfire
modeling. The ensemble members are represented as the composition of one common
state with a spatial transformation, called registration mapping, plus a
residual. A fully automatic registration method is used that requires only
gridded data, so the features in the model state do not need to be identified
by the user. The morphing EnKF operates on a transformed state consisting of
the registration mapping and the residual. Essentially, the morphing EnKF uses
intermediate states obtained by morphing instead of linear combinations of the
states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.3748</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.3748</id><created>2007-05-25</created><updated>2007-12-14</updated><authors><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>On the Obfuscation Complexity of Planar Graphs</title><categories>cs.DM cs.CC</categories><comments>12 pages, 1 figure. The proof of Theorem 3 is simplified. An overview
  of a related work is added</comments><abstract>  Being motivated by John Tantalo's Planarity Game, we consider straight line
plane drawings of a planar graph $G$ with edge crossings and wonder how
obfuscated such drawings can be. We define $obf(G)$, the obfuscation complexity
of $G$, to be the maximum number of edge crossings in a drawing of $G$.
Relating $obf(G)$ to the distribution of vertex degrees in $G$, we show an
efficient way of constructing a drawing of $G$ with at least $obf(G)/3$ edge
crossings. We prove bounds $(\delta(G)^2/24-o(1))n^2 &lt; \obf G &lt;3 n^2$ for an
$n$-vertex planar graph $G$ with minimum vertex degree $\delta(G)\ge 2$.
  The shift complexity of $G$, denoted by $shift(G)$, is the minimum number of
vertex shifts sufficient to eliminate all edge crossings in an arbitrarily
obfuscated drawing of $G$ (after shifting a vertex, all incident edges are
supposed to be redrawn correspondingly). If $\delta(G)\ge 3$, then $shift(G)$
is linear in the number of vertices due to the known fact that the matching
number of $G$ is linear. However, in the case $\delta(G)\ge2$ we notice that
$shift(G)$ can be linear even if the matching number is bounded. As for
computational complexity, we show that, given a drawing $D$ of a planar graph,
it is NP-hard to find an optimum sequence of shifts making $D$ crossing-free.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.3820</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.3820</id><created>2007-05-25</created><updated>2009-10-12</updated><authors><author><keyname>Aichholzer</keyname><forenames>Oswin</forenames></author><author><keyname>Hackl</keyname><forenames>Thomas</forenames></author><author><keyname>Hoffmann</keyname><forenames>Michael</forenames></author><author><keyname>Huemer</keyname><forenames>Clemens</forenames></author><author><keyname>Por</keyname><forenames>Attila</forenames></author><author><keyname>Santos</keyname><forenames>Francisco</forenames></author><author><keyname>Speckmann</keyname><forenames>Bettina</forenames></author><author><keyname>Vogtenhuber</keyname><forenames>Birgit</forenames></author></authors><title>Maximizing Maximal Angles for Plane Straight-Line Graphs</title><categories>cs.CG cs.DM math.CO</categories><comments>15 pages, 14 figures. Apart of minor corrections, some proofs that
  were omitted in the previous version are now included</comments><acm-class>G.2.2; I.3.5</acm-class><journal-ref>In "Algorithms and Data Structures, WADS 2007, Halifax, Canada,
  August 15-17, 2007", Frank Dehne et al. (Eds.), LNCS 4619, Springer-Verlag,
  2007, pp. 458-469</journal-ref><doi>10.1007/978-3-540-73951-7_40</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G=(S, E)$ be a plane straight-line graph on a finite point set
$S\subset\R^2$ in general position. The incident angles of a vertex $p \in S$
of $G$ are the angles between any two edges of $G$ that appear consecutively in
the circular order of the edges incident to $p$.
  A plane straight-line graph is called $\phi$-open if each vertex has an
incident angle of size at least $\phi$. In this paper we study the following
type of question: What is the maximum angle $\phi$ such that for any finite set
$S\subset\R^2$ of points in general position we can find a graph from a certain
class of graphs on $S$ that is $\phi$-open? In particular, we consider the
classes of triangulations, spanning trees, and paths on $S$ and give tight
bounds in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0705.4485</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0705.4485</id><created>2007-05-30</created><authors><author><keyname>Airoldi</keyname><forenames>Edoardo M</forenames></author><author><keyname>Blei</keyname><forenames>David M</forenames></author><author><keyname>Fienberg</keyname><forenames>Stephen E</forenames></author><author><keyname>Xing</keyname><forenames>Eric P</forenames></author></authors><title>Mixed membership stochastic blockmodels</title><categories>stat.ME cs.LG math.ST physics.soc-ph stat.ML stat.TH</categories><comments>46 pages, 14 figures, 3 tables</comments><journal-ref>Journal of Machine Learning Research, 9, 1981-2014.</journal-ref><abstract>  Observations consisting of measurements on relationships for pairs of objects
arise in many settings, such as protein interaction and gene regulatory
networks, collections of author-recipient email, and social networks. Analyzing
such data with probabilisic models can be delicate because the simple
exchangeability assumptions underlying many boilerplate models no longer hold.
In this paper, we describe a latent variable model of such data called the
mixed membership stochastic blockmodel. This model extends blockmodels for
relational data to ones which capture mixed membership latent relational
structure, thus providing an object-specific low-dimensional representation. We
develop a general variational inference algorithm for fast approximate
posterior inference. We explore applications to social and protein interaction
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.0103</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.0103</id><created>2007-06-01</created><updated>2008-10-12</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Many concepts and two logics of algorithmic reduction</title><categories>cs.LO math.LO</categories><comments>To appear in Studia Logica in the Spring of 2009</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Studia Logica 91 (2009), pp. 1-24</journal-ref><doi>10.1007/s11225-009-9164-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the program of finding axiomatizations for various parts of
computability logic, it was proved earlier that the logic of interactive Turing
reduction is exactly the implicative fragment of Heyting's intuitionistic
calculus. That sort of reduction permits unlimited reusage of the computational
resource represented by the antecedent. An at least equally basic and natural
sort of algorithmic reduction, however, is the one that does not allow such
reusage. The present article shows that turning the logic of the first sort of
reduction into the logic of the second sort of reduction takes nothing more
than just deleting the contraction rule from its Gentzen-style axiomatization.
The first (Turing) sort of interactive reduction is also shown to come in three
natural versions. While those three versions are very different from each
other, their logical behaviors (in isolation) turn out to be indistinguishable,
with that common behavior being precisely captured by implicative
intuitionistic logic. Among the other contributions of the present article is
an informal introduction of a series of new -- finite and bounded -- versions
of recurrence operations and the associated reduction operations. An online
source on computability logic can be found at
http://www.cis.upenn.edu/~giorgi/cl.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.0489</identifier>
 <datestamp>2010-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.0489</id><created>2007-06-04</created><updated>2010-10-25</updated><authors><author><keyname>Jalsenius</keyname><forenames>Markus</forenames></author></authors><title>Sampling Colourings of the Triangular Lattice</title><categories>math-ph cs.DM cs.DS math.MP</categories><comments>42 pages. Added appendix that describes implementation. Added
  ancillary files</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Glauber dynamics on proper 9-colourings of the triangular
lattice is rapidly mixing, which allows for efficient sampling. Consequently,
there is a fully polynomial randomised approximation scheme (FPRAS) for
counting proper 9-colourings of the triangular lattice. Proper colourings
correspond to configurations in the zero-temperature anti-ferromagnetic Potts
model. We show that the spin system consisting of proper 9-colourings of the
triangular lattice has strong spatial mixing. This implies that there is a
unique infinite-volume Gibbs distribution, which is an important property
studied in statistical physics. Our results build on previous work by Goldberg,
Martin and Paterson, who showed similar results for 10 colours on the
triangular lattice. Their work was preceded by Salas and Sokal's 11-colour
result. Both proofs rely on computational assistance, and so does our 9-colour
proof. We have used a randomised heuristic to guide us towards rigourous
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.0507</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.0507</id><created>2007-06-04</created><authors><author><keyname>Geryville</keyname><forenames>Hichem</forenames><affiliation>LIESP</affiliation></author><author><keyname>Ouzrout</keyname><forenames>Yacine</forenames><affiliation>LIESP</affiliation></author><author><keyname>Bouras</keyname><forenames>Abdelaziz</forenames><affiliation>LIESP</affiliation></author><author><keyname>Sapidis</keyname><forenames>Nikolaos</forenames></author></authors><title>A collaborative framework to exchange and share product information
  within a supply chain context</title><categories>cs.HC</categories><proxy>ccsd hal-00151633</proxy><abstract>  The new requirement for "collaboration" between multidisciplinary
collaborators induces to exchange and share adequate information on the
product, processes throughout the products' lifecycle. Thus, effective capture
of information, and also its extraction, recording, exchange, sharing, and
reuse become increasingly critical. These lead companies to adopt new improved
methodologies in managing the exchange and sharing of information. The aim of
this paper is to describe a collaborative framework system to exchange and
share information, which is based on: (i) The Product Process Collaboration
Organization model (PPCO) which defines product and process information, and
the various collaboration methods for the organizations involved in the supply
chain. (ii) Viewpoint model describes relationships between each actor and the
comprehensive Product/Process model, defining each actor's "domain of interest"
within the evolving product definition. (iii) A layer which defines the
comprehensive organization and collaboration relationships between the actors
within the supply chain. (iv) Based on the above relationships, the last layer
proposes a typology of exchanged messages. A communication method, based on
XML, is developed that supports optimal exchange/sharing of information. To
illustrate the proposed framework system, an example is presented related to
collaborative design of a new piston for an automotive engine. The focus is on
user-viewpoint integration to ensure that the adequate information is retrieved
from the PPCO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.0534</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.0534</id><created>2007-06-04</created><updated>2008-01-11</updated><authors><author><keyname>Zhou</keyname><forenames>Shuheng</forenames></author><author><keyname>Lafferty</keyname><forenames>John</forenames></author><author><keyname>Wasserman</keyname><forenames>Larry</forenames></author></authors><title>Compressed Regression</title><categories>stat.ML cs.IT math.IT</categories><comments>59 pages, 5 figure, Submitted for review</comments><journal-ref>IEEE Transactions on Information Theory, Volume 55, No.2, pp
  846--866, 2009</journal-ref><abstract>  Recent research has studied the role of sparsity in high dimensional
regression and signal reconstruction, establishing theoretical limits for
recovering sparse models from sparse data. This line of work shows that
$\ell_1$-regularized least squares regression can accurately estimate a sparse
linear model from $n$ noisy examples in $p$ dimensions, even if $p$ is much
larger than $n$. In this paper we study a variant of this problem where the
original $n$ input variables are compressed by a random linear transformation
to $m \ll n$ examples in $p$ dimensions, and establish conditions under which a
sparse linear model can be successfully recovered from the compressed data. A
primary motivation for this compression procedure is to anonymize the data and
preserve privacy by revealing little information about the original data. We
characterize the number of random projections that are required for
$\ell_1$-regularized compressed regression to identify the nonzero coefficients
in the true model with probability approaching one, a property called
``sparsistence.'' In addition, we show that $\ell_1$-regularized compressed
regression asymptotically predicts as well as an oracle linear model, a
property called ``persistence.'' Finally, we characterize the privacy
properties of the compression procedure in information-theoretic terms,
establishing upper bounds on the mutual information between the compressed and
uncompressed data that decay to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.0564</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.0564</id><created>2007-06-04</created><updated>2010-06-20</updated><authors><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>Yu</keyname><forenames>Josephine</forenames></author></authors><title>Tropical Implicitization and Mixed Fiber Polytopes</title><categories>cs.SC math.AG math.CO</categories><comments>21 pages, 2 figures; Typo fixed in Theorem 5.2</comments><msc-class>14Q10, 52B20, 52B55, 65D18</msc-class><journal-ref>Software for algebraic geometry, 111--131, IMA Vol. Math. Appl.,
  148, Springer, New York, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The software TrIm offers implementations of tropical implicitization and
tropical elimination, as developed by Tevelev and the authors. Given a
polynomial map with generic coefficients, TrIm computes the tropical variety of
the image. When the image is a hypersurface, the output is the Newton polytope
of the defining polynomial. TrIm can thus be used to compute mixed fiber
polytopes, including secondary polytopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.0580</identifier>
 <datestamp>2011-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.0580</id><created>2007-06-05</created><updated>2010-06-20</updated><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author></authors><title>Efficient Batch Update of Unique Identifiers in a Distributed Hash Table
  for Resources in a Mobile Host</title><categories>cs.NI</categories><comments>To be presented at the 2010 International Workshop on Cloud
  Computing, Applications and Technologies</comments><acm-class>E.1</acm-class><doi>10.1109/ISPA.2010.73</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Resources in a distributed system can be identified using identifiers based
on random numbers. When using a distributed hash table to resolve such
identifiers to network locations, the straightforward approach is to store the
network location directly in the hash table entry associated with an
identifier. When a mobile host contains a large number of resources, this
requires that all of the associated hash table entries must be updated when its
network address changes.
  We propose an alternative approach where we store a host identifier in the
entry associated with a resource identifier and the actual network address of
the host in a separate host entry. This can drastically reduce the time
required for updating the distributed hash table when a mobile host changes its
network address. We also investigate under which circumstances our approach
should or should not be used. We evaluate and confirm the usefulness of our
approach with experiments run on top of OpenDHT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.1119</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.1119</id><created>2007-06-08</created><updated>2011-01-24</updated><authors><author><keyname>Stefanov</keyname><forenames>Stefan Z.</forenames></author></authors><title>Cointegration of the Daily Electric Power System Load and the Weather</title><categories>cs.CE</categories><comments>8 pages, extended version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper makes a thermal predictive analysis of the electric power system
security for a day ahead. This predictive analysis is set as a thermal
computation of the expected security. This computation is obtained by
cointegrating the daily electric power systen load and the weather, by finding
the daily electric power system thermodynamics and by introducing tests for
this thermodynamics. The predictive analysis made shows the electricity
consumers' wisdom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.1141</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.1141</id><created>2007-06-08</created><authors><author><keyname>Andronache</keyname><forenames>Adrian</forenames></author><author><keyname>Brust</keyname><forenames>Matthias R.</forenames></author><author><keyname>Rothkugel</keyname><forenames>Steffen</forenames></author></authors><title>Multimedia Content Distribution in Hybrid Wireless Networks using
  Weighted Clustering</title><categories>cs.MM cs.NI</categories><comments>2nd ACM Workshop on Wireless Multimedia Networking and Performance
  Modeling 2006 (ISBN 1-59593-485)</comments><abstract>  Fixed infrastructured networks naturally support centralized approaches for
group management and information provisioning. Contrary to infrastructured
networks, in multi-hop ad-hoc networks each node acts as a router as well as
sender and receiver. Some applications, however, requires hierarchical
arrangements that-for practical reasons-has to be done locally and
self-organized. An additional challenge is to deal with mobility that causes
permanent network partitioning and re-organizations. Technically, these
problems can be tackled by providing additional uplinks to a backbone network,
which can be used to access resources in the Internet as well as to inter-link
multiple ad-hoc network partitions, creating a hybrid wireless network. In this
paper, we present a prototypically implemented hybrid wireless network system
optimized for multimedia content distribution. To efficiently manage the ad-hoc
communicating devices a weighted clustering algorithm is introduced. The
proposed localized algorithm deals with mobility, but does not require
geographical information or distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.1409</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.1409</id><created>2007-06-11</created><updated>2008-04-01</updated><authors><author><keyname>Borwein</keyname><forenames>Jonathan M.</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A Proof of a Recursion for Bessel Moments</title><categories>cs.SC math.CA</categories><proxy>ccsd inria-00152799</proxy><doi>10.1080/10586458.2008.10129032</doi><abstract>  We provide a proof of a conjecture in (Bailey, Borwein, Borwein, Crandall
2007) on the existence and form of linear recursions for moments of powers of
the Bessel function $K_0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.1588</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.1588</id><created>2007-06-11</created><updated>2010-06-08</updated><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Detection of Gauss-Markov Random Fields with Nearest-Neighbor Dependency</title><categories>cs.IT math.IT</categories><comments>Information Theory, IEEE Transactions</comments><journal-ref>vol. 55, no. 2, Feb. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of hypothesis testing against independence for a Gauss-Markov
random field (GMRF) is analyzed. Assuming an acyclic dependency graph, an
expression for the log-likelihood ratio of detection is derived. Assuming
random placement of nodes over a large region according to the Poisson or
uniform distribution and nearest-neighbor dependency graph, the error exponent
of the Neyman-Pearson detector is derived using large-deviations theory. The
error exponent is expressed as a dependency-graph functional and the limit is
evaluated through a special law of large numbers for stabilizing graph
functionals. The exponent is analyzed for different values of the variance
ratio and correlation. It is found that a more correlated GMRF has a higher
exponent at low values of the variance ratio whereas the situation is reversed
at high values of the variance ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.1860</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.1860</id><created>2007-06-13</created><updated>2007-08-31</updated><authors><author><keyname>Cucurull</keyname><forenames>Jordi</forenames></author><author><keyname>Marti</keyname><forenames>Ramon</forenames></author><author><keyname>Robles</keyname><forenames>Sergi</forenames></author><author><keyname>Borrell</keyname><forenames>Joan</forenames></author><author><keyname>Navarro</keyname><forenames>Guillermo</forenames></author></authors><title>FIPA-based Interoperable Agent Mobility Proposal</title><categories>cs.MA cs.NI</categories><comments>10 pages, agent migration architecture proposal</comments><abstract>  This paper presents a proposal for a flexible agent mobility architecture
based on IEEE-FIPA standards and intended to be one of them. This proposal is a
first step towards interoperable mobility mechanisms, which are needed for
future agent migration between different kinds of platforms. Our proposal is
presented as a flexible and robust architecture that has been successfully
implemented in the JADE and AgentScape platforms. It is based on an open set of
protocols, allowing new protocols and future improvements to be accommodated in
the architecture. With this proposal we demonstrate that a standard
architecture for agent mobility capable of supporting several agent platforms
can be defined and implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.2040</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.2040</id><created>2007-06-14</created><updated>2007-11-10</updated><authors><author><keyname>Airoldi</keyname><forenames>Edoardo M</forenames></author></authors><title>Getting started in probabilistic graphical models</title><categories>q-bio.QM cs.LG physics.soc-ph stat.ME stat.ML</categories><comments>12 pages, 1 figure</comments><journal-ref>Airoldi EM (2007) Getting started in probabilistic graphical
  models. PLoS Comput Biol 3(12): e252</journal-ref><doi>10.1371/journal.pcbi.0030252</doi><abstract>  Probabilistic graphical models (PGMs) have become a popular tool for
computational analysis of biological data in a variety of domains. But, what
exactly are they and how do they work? How can we use PGMs to discover patterns
that are biologically relevant? And to what extent can PGMs help us formulate
new hypotheses that are testable at the bench? This note sketches out some
answers and illustrates the main ideas behind the statistical approach to
biological pattern discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.2153</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.2153</id><created>2007-06-14</created><updated>2007-06-18</updated><authors><author><keyname>Chazal</keyname><forenames>Frédéric</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Cohen-Steiner</keyname><forenames>David</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mérigot</keyname><forenames>Quentin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Stability of boundary measures</title><categories>cs.CG math.CA math.MG</categories><journal-ref>Boundary measures for geometric inference, Found. Comput. Math.,
  10 (2), pp. 221-240, 2010</journal-ref><doi>10.1007/s10208-009-9056-2</doi><abstract>  We introduce the boundary measure at scale r of a compact subset of the
n-dimensional Euclidean space. We show how it can be computed for point clouds
and suggest these measures can be used for feature detection. The main
contribution of this work is the proof a quantitative stability theorem for
boundary measures using tools of convex analysis and geometric measure theory.
As a corollary we obtain a stability result for Federer's curvature measures of
a compact, allowing to compute them from point-cloud approximations of the
compact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.2434</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.2434</id><created>2007-06-16</created><authors><author><keyname>Ganti</keyname><forenames>RadhaKrishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Interference and Outage in Clustered Wireless Ad Hoc Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><doi>10.1109/TIT.2009.2025543</doi><abstract>  In the analysis of large random wireless networks, the underlying node
distribution is almost ubiquitously assumed to be the homogeneous Poisson point
process. In this paper, the node locations are assumed to form a Poisson
clustered process on the plane. We derive the distributional properties of the
interference and provide upper and lower bounds for its CCDF. We consider the
probability of successful transmission in an interference limited channel when
fading is modeled as Rayleigh. We provide a numerically integrable expression
for the outage probability and closed-form upper and lower bounds.We show that
when the transmitter-receiver distance is large, the success probability is
greater than that of a Poisson arrangement. These results characterize the
performance of the system under geographical or MAC-induced clustering. We
obtain the maximum intensity of transmitting nodes for a given outage
constraint, i.e., the transmission capacity (of this spatial arrangement) and
show that it is equal to that of a Poisson arrangement of nodes. For the
analysis, techniques from stochastic geometry are used, in particular the
probability generating functional of Poisson cluster processes, the Palm
characterization of Poisson cluster processes and the Campbell-Mecke theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3129</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3129</id><created>2007-06-21</created><updated>2008-06-19</updated><authors><author><keyname>Kazakopoulos</keyname><forenames>Pavlos</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author></authors><title>Closed-Form Density of States and Localization Length for a
  Non-Hermitian Disordered System</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT nlin.SI</categories><comments>5 pages, 1 figure</comments><doi>10.1103/PhysRevE.78.016603</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We calculate the Lyapunov exponent for the non-Hermitian Zakharov-Shabat
eigenvalue problem corresponding to the attractive non-linear Schroedinger
equation with a Gaussian random pulse as initial value function. Using an
extension of the Thouless formula to non-Hermitian random operators, we
calculate the corresponding average density of states. We analyze two cases,
one with circularly symmetric complex Gaussian pulses and the other with real
Gaussian pulses. We discuss the implications in the context of the information
transmission through non-linear optical fibers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3305</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3305</id><created>2007-06-22</created><updated>2011-01-24</updated><authors><author><keyname>Mahalanobis</keyname><forenames>Ayan</forenames></author></authors><title>A simple generalization of the ElGamal cryptosystem to non-abelian
  groups II</title><categories>cs.CR math.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a study of the MOR cryptosystem using the special linear group over
finite fields. The automorphism group of the special linear group is analyzed
for this purpose. At our current state of knowledge, I show that the MOR
cryptosystem has better security than the ElGamal cryptosystem over finite
fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3479</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3479</id><created>2007-06-23</created><authors><author><keyname>Love</keyname><forenames>David</forenames></author></authors><title>Hypocomputation</title><categories>cs.OH</categories><comments>34 pages</comments><abstract>  Hypercomputational formal theories will, clearly, be both structurally and
foundationally different from the formal theories underpinning computational
theories. However, many of the maps that might guide us into this strange realm
have been lost. So little work has been done recently in the area of
metamathematics, and so many of the previous results have been folded into
other theories, that we are in danger of loosing an appreciation of the broader
structure of formal theories. As an aid to those looking to develop
hypercomputational theories, we will briefly survey the known landmarks both
inside and outside the borders of computational theory. We will not focus in
this paper on why the structure of formal theory looks the way it does. Instead
we will focus on what this structure looks like, moving from hypocomputational,
through traditional computational theories, and then beyond to
hypercomputational theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3480</identifier>
 <datestamp>2012-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3480</id><created>2007-06-23</created><authors><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author></authors><title>Tight Bounds on the Average Length, Entropy, and Redundancy of
  Anti-Uniform Huffman Codes</title><categories>cs.IT math.IT</categories><comments>9 pages, 2 figures</comments><journal-ref>IET Communications, vol. 5, no. 9, pp. 1213-1219, 2011</journal-ref><abstract>  In this paper we consider the class of anti-uniform Huffman codes and derive
tight lower and upper bounds on the average length, entropy, and redundancy of
such codes in terms of the alphabet size of the source. The Fibonacci
distributions are introduced which play a fundamental role in AUH codes. It is
shown that such distributions maximize the average length and the entropy of
the code for a given alphabet size. Another previously known bound on the
entropy for given average length follows immediately from our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3546</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3546</id><created>2007-06-24</created><updated>2007-11-23</updated><authors><author><keyname>Kiswany</keyname><forenames>Samer Al</forenames></author><author><keyname>Ripeanu</keyname><forenames>Matei</forenames></author><author><keyname>Vazhkudai</keyname><forenames>Sudharshan S.</forenames></author><author><keyname>Gharaibeh</keyname><forenames>Abdullah</forenames></author></authors><title>stdchk: A Checkpoint Storage System for Desktop Grid Computing</title><categories>cs.DC</categories><comments>13 pages, 8 figures</comments><abstract>  Checkpointing is an indispensable technique to provide fault tolerance for
long-running high-throughput applications like those running on desktop grids.
This paper argues that a dedicated checkpoint storage system, optimized to
operate in these environments, can offer multiple benefits: reduce the load on
a traditional file system, offer high-performance through specialization, and,
finally, optimize data management by taking into account checkpoint application
semantics. Such a storage system can present a unifying abstraction to
checkpoint operations, while hiding the fact that there are no dedicated
resources to store the checkpoint data. We prototype stdchk, a checkpoint
storage system that uses scavenged disk space from participating desktops to
build a low-cost storage system, offering a traditional file system interface
for easy integration with applications. This paper presents the stdchk
architecture, key performance optimizations, support for incremental
checkpointing, and increased data availability. Our evaluation confirms that
the stdchk approach is viable in a desktop grid setting and offers a low cost
storage system with desirable performance characteristics: high write
throughput and reduced storage space and network effort to save checkpoint
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3812</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3812</id><created>2007-06-26</created><updated>2007-07-27</updated><authors><author><keyname>Parrend</keyname><forenames>Pierre</forenames><affiliation>INRIA Rhône-Alpes</affiliation></author><author><keyname>Frénot</keyname><forenames>Stéphane</forenames><affiliation>INRIA Rhône-Alpes</affiliation></author></authors><title>Java Components Vulnerabilities - An Experimental Classification
  Targeted at the OSGi Platform</title><categories>cs.CR cs.OS</categories><abstract>  The OSGi Platform finds a growing interest in two different applications
domains: embedded systems, and applications servers. However, the security
properties of this platform are hardly studied, which is likely to hinder its
use in production systems. This is all the more important that the dynamic
aspect of OSGi-based applications, that can be extended at runtime, make them
vulnerable to malicious code injection. We therefore perform a systematic audit
of the OSGi platform so as to build a vulnerability catalog that intends to
reference OSGi Vulnerabilities originating in the Core Specification, and in
behaviors related to the use of the Java language. Standard Services are not
considered. To support this audit, a Semi-formal Vulnerability Pattern is
defined, that enables to uniquely characterize fundamental properties for each
vulnerability, to include verbose description in the pattern, to reference
known security protections, and to track the implementation status of the
proof-of-concept OSGi Bundles that exploit the vulnerability. Based on the
analysis of the catalog, a robust OSGi Platform is built, and recommendations
are made to enhance the OSGi Specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.3856</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.3856</id><created>2007-06-26</created><authors><author><keyname>Marichal</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Mathonet</keyname><forenames>Pierre</forenames></author></authors><title>Approximations of Lovasz extensions and their induced interaction index</title><categories>math.CO cs.DM</categories><comments>19 pages</comments><msc-class>90B50, 91A12 (Primary) 41A30 (Secondary).</msc-class><journal-ref>Discrete Applied Mathematics 156 (1) (2008) 11-24</journal-ref><abstract>  The Lovasz extension of a pseudo-Boolean function $f : \{0,1\}^n \to R$ is
defined on each simplex of the standard triangulation of $[0,1]^n$ as the
unique affine function $\hat f : [0,1]^n \to R$ that interpolates $f$ at the
$n+1$ vertices of the simplex. Its degree is that of the unique multilinear
polynomial that expresses $f$. In this paper we investigate the least squares
approximation problem of an arbitrary Lovasz extension $\hat f$ by Lovasz
extensions of (at most) a specified degree. We derive explicit expressions of
these approximations. The corresponding approximation problem for
pseudo-Boolean functions was investigated by Hammer and Holzman (1992) and then
solved explicitly by Grabisch, Marichal, and Roubens (2000), giving rise to an
alternative definition of Banzhaf interaction index. Similarly we introduce a
new interaction index from approximations of $\hat f$ and we present some of
its properties. It turns out that its corresponding power index identifies with
the power index introduced by Grabisch and Labreuche (2001).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.4044</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.4044</id><created>2007-06-27</created><authors><author><keyname>Schröder</keyname><forenames>Lutz</forenames></author><author><keyname>Pattinson</keyname><forenames>Dirk</forenames></author></authors><title>PSPACE Bounds for Rank-1 Modal Logics</title><categories>cs.LO cs.CC</categories><report-no>Imperial College TR 2007/4</report-no><acm-class>F.4.1; F.2.2</acm-class><journal-ref>ACM Transactions on Computational Logic 10 (2:13), pp. 1-33, 2009</journal-ref><doi>10.1145/1462179.1462185</doi><abstract>  For lack of general algorithmic methods that apply to wide classes of logics,
establishing a complexity bound for a given modal logic is often a laborious
task. The present work is a step towards a general theory of the complexity of
modal logics. Our main result is that all rank-1 logics enjoy a shallow model
property and thus are, under mild assumptions on the format of their
axiomatisation, in PSPACE. This leads to a unified derivation of tight
PSPACE-bounds for a number of logics including K, KD, coalition logic, graded
modal logic, majority logic, and probabilistic modal logic. Our generic
algorithm moreover finds tableau proofs that witness pleasant proof-theoretic
properties including a weak subformula property. This generality is made
possible by a coalgebraic semantics, which conveniently abstracts from the
details of a given model class and thus allows covering a broad range of logics
in a uniform way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0706.4440</identifier>
 <datestamp>2011-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0706.4440</id><created>2007-06-29</created><updated>2011-12-09</updated><authors><author><keyname>Feinstein</keyname><forenames>Craig Alan</forenames></author></authors><title>2-State 3-Symbol Universal Turing Machines Do Not Exist</title><categories>cs.OH</categories><comments>1 page</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this brief note, we give a simple information-theoretic proof that 2-state
3-symbol universal Turing machines cannot possibly exist, unless one loosens
the definition of "universal".
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.0556</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.0556</id><created>2007-07-04</created><updated>2008-02-11</updated><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Dogguy</keyname><forenames>Mehdi</forenames><affiliation>PPS</affiliation></author></authors><title>Determinacy in a synchronous pi-calculus</title><categories>cs.LO</categories><comments>To appear in the book `From semantics to computer science: essays in
  honor of Gilles Kahn', Cambridge University Press</comments><proxy>ccsd hal-00159764</proxy><journal-ref>From semantics to computer science: essays in honor of Gilles
  Kahn, Y. Bertot et al. (Ed.) (2009) 1-27</journal-ref><abstract>  The S-pi-calculus is a synchronous pi-calculus which is based on the SL
model. The latter is a relaxation of the Esterel model where the reaction to
the absence of a signal within an instant can only happen at the next instant.
In the present work, we present and characterise a compositional semantics of
the S-pi-calculus based on suitable notions of labelled transition system and
bisimulation. Based on this semantic framework, we explore the notion of
determinacy and the related one of (local) confluence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.0705</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.0705</id><created>2007-07-04</created><updated>2007-11-09</updated><authors><author><keyname>d'Aspremont</keyname><forenames>Alexandre</forenames></author><author><keyname>Bach</keyname><forenames>Francis</forenames></author><author><keyname>Ghaoui</keyname><forenames>Laurent El</forenames></author></authors><title>Optimal Solutions for Sparse Principal Component Analysis</title><categories>cs.AI cs.LG</categories><comments>Revised journal version. More efficient optimality conditions and new
  examples in subset selection and sparse recovery. Original version is in ICML
  proceedings</comments><abstract>  Given a sample covariance matrix, we examine the problem of maximizing the
variance explained by a linear combination of the input variables while
constraining the number of nonzero coefficients in this combination. This is
known as sparse principal component analysis and has a wide array of
applications in machine learning and engineering. We formulate a new
semidefinite relaxation to this problem and derive a greedy algorithm that
computes a full set of good solutions for all target numbers of non zero
coefficients, with total complexity O(n^3), where n is the number of variables.
We then use the same relaxation to derive sufficient conditions for global
optimality of a solution, which can be tested in O(n^3) per pattern. We discuss
applications in subset selection and sparse recovery and show on artificial
examples and biological data that our algorithm does provide globally optimal
solutions in many cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.0805</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.0805</id><created>2007-07-05</created><updated>2011-06-24</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A New Generalization of Chebyshev Inequality for Random Vectors</title><categories>math.ST cs.LG math.PR stat.AP stat.TH</categories><comments>7 pages, 1 figure; added some references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we derive a new generalization of Chebyshev inequality for
random vectors. We demonstrate that the new generalization is much less
conservative than the classical generalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.0808</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.0808</id><created>2007-07-05</created><authors><author><keyname>Bartolo</keyname><forenames>Alexandra</forenames></author><author><keyname>McGuire</keyname><forenames>Patrick C.</forenames></author><author><keyname>Camilleri</keyname><forenames>Kenneth P.</forenames></author><author><keyname>Spiteri</keyname><forenames>Christopher</forenames></author><author><keyname>Borg</keyname><forenames>Jonathan C.</forenames></author><author><keyname>Farrugia</keyname><forenames>Philip J.</forenames></author><author><keyname>Ormo</keyname><forenames>Jens</forenames></author><author><keyname>Gomez-Elvira</keyname><forenames>Javier</forenames></author><author><keyname>Rodriguez-Manfredi</keyname><forenames>Jose Antonio</forenames></author><author><keyname>Diaz-Martinez</keyname><forenames>Enrique</forenames></author><author><keyname>Ritter</keyname><forenames>Helge</forenames></author><author><keyname>Haschke</keyname><forenames>Robert</forenames></author><author><keyname>Oesker</keyname><forenames>Markus</forenames></author><author><keyname>Ontrup</keyname><forenames>Joerg</forenames></author></authors><title>The Cyborg Astrobiologist: Porting from a wearable computer to the
  Astrobiology Phone-cam</title><categories>cs.CV astro-ph cs.AI cs.CE cs.HC cs.NI cs.RO cs.SE</categories><comments>15 pages, 4 figures, accepted for publication in the International
  Journal of Astrobiology</comments><journal-ref>International Journal of Astrobiology, vol. 6, issue 4, pp.
  255-261 (2007)</journal-ref><doi>10.1017/S1473550407003862</doi><abstract>  We have used a simple camera phone to significantly improve an `exploration
system' for astrobiology and geology. This camera phone will make it much
easier to develop and test computer-vision algorithms for future planetary
exploration. We envision that the `Astrobiology Phone-cam' exploration system
can be fruitfully used in other problem domains as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.0878</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.0878</id><created>2007-07-05</created><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author><author><keyname>Aravena</keyname><forenames>Jorge</forenames></author><author><keyname>Zhou</keyname><forenames>Kemin</forenames></author></authors><title>Risk Analysis in Robust Control -- Making the Case for Probabilistic
  Robust Control</title><categories>math.OC cs.SY math.ST stat.TH</categories><comments>22 pages, 2 figures</comments><journal-ref>Proceedings of American Control Conference, pp. 1533-1538,
  Portland, June 2005.</journal-ref><abstract>  This paper offers a critical view of the "worst-case" approach that is the
cornerstone of robust control design. It is our contention that a blind
acceptance of worst-case scenarios may lead to designs that are actually more
dangerous than designs based on probabilistic techniques with a built-in risk
factor. The real issue is one of modeling. If one accepts that no mathematical
model of uncertainties is perfect then a probabilistic approach can lead to
more reliable control even if it cannot guarantee stability for all possible
cases. Our presentation is based on case analysis. We first establish that
worst-case is not necessarily "all-encompassing." In fact, we show that for
some uncertain control problems to have a conventional robust control solution
it is necessary to make assumptions that leave out some feasible cases. Once we
establish that point, we argue that it is not uncommon for the risk of
unaccounted cases in worst-case design to be greater than that of the accepted
risk in a probabilistic approach. With an example, we quantify the risks and
show that worst-case can be significantly more risky. Finally, we join our
analysis with existing results on computational complexity and probabilistic
robustness to argue that the deterministic worst-case analysis is not
necessarily the better tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.1053</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.1053</id><created>2007-07-06</created><updated>2007-11-02</updated><authors><author><keyname>Singh</keyname><forenames>Sudhir Kumar</forenames></author><author><keyname>Roychowdhury</keyname><forenames>Vwani P.</forenames></author><author><keyname>Bradonjić</keyname><forenames>Milan</forenames></author><author><keyname>Rezaei</keyname><forenames>Behnam A.</forenames></author></authors><title>Exploration via design and the cost of uncertainty in keyword auctions</title><categories>cs.GT</categories><comments>19 pages, presentation improved, references added, title changed</comments><abstract>  We present a deterministic exploration mechanism for sponsored search
auctions, which enables the auctioneer to learn the relevance scores of
advertisers, and allows advertisers to estimate the true value of clicks
generated at the auction site. This exploratory mechanism deviates only
minimally from the mechanism being currently used by Google and Yahoo! in the
sense that it retains the same pricing rule, similar ranking scheme, as well
as, similar mathematical structure of payoffs. In particular, the estimations
of the relevance scores and true-values are achieved by providing a chance to
lower ranked advertisers to obtain better slots. This allows the search engine
to potentially test a new pool of advertisers, and correspondingly, enables new
advertisers to estimate the value of clicks/leads generated via the auction.
Both these quantities are unknown a priori, and their knowledge is necessary
for the auction to operate efficiently. We show that such an exploration policy
can be incorporated without any significant loss in revenue for the auctioneer.
We compare the revenue of the new mechanism to that of the standard mechanism
at their corresponding symmetric Nash equilibria and compute the cost of
uncertainty, which is defined as the relative loss in expected revenue per
impression. We also bound the loss in efficiency, as well as, in user
experience due to exploration, under the same solution concept (i.e. SNE). Thus
the proposed exploration mechanism learns the relevance scores while
incorporating the incentive constraints from the advertisers who are selfish
and are trying to maximize their own profits, and therefore, the exploration is
essentially achieved via mechanism design. We also discuss variations of the
new mechanism such as truthful implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.1176</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.1176</id><created>2007-07-09</created><updated>2007-07-11</updated><authors><author><keyname>Chermakani</keyname><forenames>Deepak</forenames></author></authors><title>Expressing an NP-Complete Problem as the Solvability of a Polynomial
  Equation</title><categories>cs.CC cs.DM</categories><comments>7 pages</comments><abstract>  We demonstrate a polynomial approach to express the decision version of the
directed Hamiltonian Cycle Problem (HCP), which is NP-Complete, as the
Solvability of a Polynomial Equation with a constant number of variables,
within a bounded real space. We first introduce four new Theorems for a set of
periodic Functions with irrational periods, based on which we then use a
trigonometric substitution, to show how the HCP can be expressed as the
Solvability of a single polynomial Equation with a constant number of
variables. The feasible solution of each of these variables is bounded within
two real numbers. We point out what future work is necessary to prove that
P=NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.2191</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.2191</id><created>2007-07-15</created><authors><author><keyname>Lambiotte</keyname><forenames>R.</forenames></author><author><keyname>Ausloos</keyname><forenames>M.</forenames></author><author><keyname>Thelwall</keyname><forenames>M.</forenames></author></authors><title>Word statistics in Blogs and RSS feeds: Towards empirical universal
  evidence</title><categories>cs.IT math.IT</categories><comments>16 pages, 6 figures</comments><journal-ref>J. Informetrics 1 (2007) 277-286</journal-ref><abstract>  We focus on the statistics of word occurrences and of the waiting times
between such occurrences in Blogs. Due to the heterogeneity of words'
frequencies, the empirical analysis is performed by studying classes of
"frequently-equivalent" words, i.e. by grouping words depending on their
frequencies. Two limiting cases are considered: the dilute limit, i.e. for
those words that are used less than once a day, and the dense limit for
frequent words. In both cases, extreme events occur more frequently than
expected from the Poisson hypothesis. These deviations from Poisson statistics
reveal non-trivial time correlations between events that are associated with
bursts of activities. The distribution of waiting times is shown to behave like
a stretched exponential and to have the same shape for different sets of words
sharing a common frequency, thereby revealing universal features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.2265</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.2265</id><created>2007-07-16</created><authors><author><keyname>Padakandla</keyname><forenames>Arun</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Separable convex optimization problems with linear ascending constraints</title><categories>cs.IT math.IT math.OC</categories><comments>15 pages, Submitted to SIAM J. on Opt</comments><journal-ref>SIAM J. on Optim., vol. 20, no. 3, pp. 1185-1204, online version
  19 August 2009</journal-ref><doi>10.1137/07069729X</doi><abstract>  Separable convex optimization problems with linear ascending inequality and
equality constraints are addressed in this paper. Under an ordering condition
on the slopes of the functions at the origin, an algorithm that determines the
optimum point in a finite number of steps is described. The optimum value is
shown to be monotone with respect to a partial order on the constraint
parameters. Moreover, the optimum value is convex with respect to these
parameters. Examples motivated by optimizations for communication systems are
used to illustrate the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.2792</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.2792</id><created>2007-07-18</created><updated>2008-02-05</updated><authors><author><keyname>Avis</keyname><forenames>David</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Savov</keyname><forenames>Ivan</forenames></author></authors><title>Distributed Compression and Multiparty Squashed Entanglement</title><categories>quant-ph cs.IT math.IT</categories><comments>26 pages, 6 figures thanks to jPicEdt. In v2 we fixed some typos and
  made minor clarifications and updates</comments><journal-ref>J. Phys. A 41 (2008) 115301</journal-ref><doi>10.1088/1751-8113/41/11/115301</doi><abstract>  We study a protocol in which many parties use quantum communication to
transfer a shared state to a receiver without communicating with each other.
This protocol is a multiparty version of the fully quantum Slepian-Wolf
protocol for two senders and arises through the repeated application of the
two-sender protocol. We describe bounds on the achievable rate region for the
distributed compression problem. The inner bound arises by expressing the
achievable rate region for our protocol in terms of its vertices and extreme
rays and, equivalently, in terms of facet inequalities. We also prove an outer
bound on all possible rates for distributed compression based on the multiparty
squashed entanglement, a measure of multiparty entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3043</identifier>
 <datestamp>2010-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3043</id><created>2007-07-20</created><authors><author><keyname>Dragovich</keyname><forenames>Branko</forenames></author><author><keyname>Dragovich</keyname><forenames>Alexandra</forenames></author></authors><title>p-Adic Modelling of the Genome and the Genetic Code</title><categories>q-bio.OT cs.IT math.IT physics.bio-ph</categories><comments>26 pages. Submitted to the Computer Journal for a special issue</comments><journal-ref>The Computer Journal 53 (2010) 432-442</journal-ref><doi>10.1093/comjnl/bxm083</doi><abstract>  The present paper is devoted to foundations of p-adic modelling in genomics.
Considering nucleotides, codons, DNA and RNA sequences, amino acids, and
proteins as information systems, we have formulated the corresponding p-adic
formalisms for their investigations. Each of these systems has its
characteristic prime number used for construction of the related information
space. Relevance of this approach is illustrated by some examples. In
particular, it is shown that degeneration of the genetic code is a p-adic
phenomenon. We have also put forward a hypothesis on evolution of the genetic
code assuming that primitive code was based on single nucleotides and
chronologically first four amino acids. This formalism of p-adic genomic
information systems can be implemented in computer programs and applied to
various concrete cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3236</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3236</id><created>2007-07-21</created><authors><author><keyname>Tskhvaradze</keyname><forenames>Vladimir</forenames></author></authors><title>RS-232 Led Board</title><categories>cs.OH</categories><abstract>  This article demonstrates how to develop a Microchip PIC16F84 based device
that supports RS-232 interface with PC. Circuit (LED Board) design and software
development will be discussed. PicBasic Pro Compiler from microEngineering
Labs, Inc. is used for PIC programming. Development of LED Board Control
Console using C/C++ is also briefly discussed. The project requires basic work
experience with Microchip PICs, serial communication and programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3407</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3407</id><created>2007-07-23</created><updated>2008-01-18</updated><authors><author><keyname>Tiskin</keyname><forenames>Alexander</forenames></author></authors><title>Faster subsequence recognition in compressed strings</title><categories>cs.DS cs.CC cs.DM</categories><abstract>  Computation on compressed strings is one of the key approaches to processing
massive data sets. We consider local subsequence recognition problems on
strings compressed by straight-line programs (SLP), which is closely related to
Lempel--Ziv compression. For an SLP-compressed text of length $\bar m$, and an
uncompressed pattern of length $n$, C{\'e}gielski et al. gave an algorithm for
local subsequence recognition running in time $O(\bar mn^2 \log n)$. We improve
the running time to $O(\bar mn^{1.5})$. Our algorithm can also be used to
compute the longest common subsequence between a compressed text and an
uncompressed pattern in time $O(\bar mn^{1.5})$; the same problem with a
compressed pattern is known to be NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3462</identifier>
 <datestamp>2010-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3462</id><created>2007-07-24</created><authors><author><keyname>Stein</keyname><forenames>Noah D.</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author></authors><title>Separable and Low-Rank Continuous Games</title><categories>cs.GT math.OC</categories><journal-ref>International Journal of Game Theory, Vol. 37, No. 4, pp. 457-474,
  2008.</journal-ref><doi>10.1007/s00182-008-0129-2</doi><abstract>  In this paper, we study nonzero-sum separable games, which are continuous
games whose payoffs take a sum-of-products form. Included in this subclass are
all finite games and polynomial games. We investigate the structure of
equilibria in separable games. We show that these games admit finitely
supported Nash equilibria. Motivated by the bounds on the supports of mixed
equilibria in two-player finite games in terms of the ranks of the payoff
matrices, we define the notion of the rank of an n-player continuous game and
use this to provide bounds on the cardinality of the support of equilibrium
strategies. We present a general characterization theorem that states that a
continuous game has finite rank if and only if it is separable. Using our rank
results, we present an efficient algorithm for computing approximate equilibria
of two-player separable games with fixed strategy spaces in time polynomial in
the rank of the game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3540</identifier>
 <datestamp>2010-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3540</id><created>2007-07-24</created><authors><author><keyname>Bradley</keyname><forenames>Patrick Erik</forenames></author></authors><title>Mumford dendrograms</title><categories>cs.DM</categories><comments>16 pages, 7 figures; Incorporating Special Issue: Ultrametric and
  p-Adic Applications in Computer Science</comments><journal-ref>The Computer Journal, Vol. 53, No. 4 (2010), 393-404</journal-ref><doi>10.1093/comjnl/bxm088</doi><abstract>  An effective $p$-adic encoding of dendrograms is presented through an
explicit embedding into the Bruhat-Tits tree for a $p$-adic number field. This
field depends on the number of children of a vertex and is a finite extension
of the field of $p$-adic numbers. It is shown that fixing $p$-adic
representatives of the residue field allows a natural way of encoding strings
by identifying a given alphabet with such representatives. A simple $p$-adic
hierarchic classification algorithm is derived for $p$-adic numbers, and is
applied to strings over finite alphabets. Examples of DNA coding are presented
and discussed. Finally, new geometric and combinatorial invariants of time
series of $p$-adic dendrograms are developped.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3584</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3584</id><created>2007-07-24</created><authors><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>The effect of fading, channel inversion, and threshold scheduling on ad
  hoc networks</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Trans. Inform. Theory, 24 pages</comments><journal-ref>IEEE Trans. Information Theory, Vol. 53, No. 11, pp. 4127-4149,
  Nov. 2007</journal-ref><abstract>  This paper addresses three issues in the field of ad hoc network capacity:
the impact of i)channel fading, ii) channel inversion power control, and iii)
threshold-based scheduling on capacity. Channel inversion and threshold
scheduling may be viewed as simple ways to exploit channel state information
(CSI) without requiring cooperation across transmitters. We use the
transmission capacity (TC) as our metric, defined as the maximum spatial
intensity of successful simultaneous transmissions subject to a constraint on
the outage probability (OP). By assuming the nodes are located on the infinite
plane according to a Poisson process, we are able to employ tools from
stochastic geometry to obtain asymptotically tight bounds on the distribution
of the signal-to-interference (SIR) level, yielding in turn tight bounds on the
OP (relative to a given SIR threshold) and the TC. We demonstrate that in the
absence of CSI, fading can significantly reduce the TC and somewhat
surprisingly, channel inversion only makes matters worse. We develop a
threshold-based transmission rule where transmitters are active only if the
channel to their receiver is acceptably strong, obtain expressions for the
optimal threshold, and show that this simple, fully distributed scheme can
significantly reduce the effect of fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.3622</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.3622</id><created>2007-07-24</created><authors><author><keyname>Markov</keyname><forenames>Igor</forenames><affiliation>University of Michigan</affiliation></author><author><keyname>Shi</keyname><forenames>Yaoyun</forenames><affiliation>University of Michigan</affiliation></author></authors><title>Constant-degree graph expansions that preserve the treewidth</title><categories>cs.DM cs.DS math.CO quant-ph</categories><comments>12 pages, 6 figures, the main result used by quant-ph/0511070</comments><acm-class>F.2.2; G.2.2</acm-class><journal-ref>Algorithmica, Volume 59, Number 4, 461-470,2011</journal-ref><doi>10.1007/s00453-009-9312-5</doi><abstract>  Many hard algorithmic problems dealing with graphs, circuits, formulas and
constraints admit polynomial-time upper bounds if the underlying graph has
small treewidth. The same problems often encourage reducing the maximal degree
of vertices to simplify theoretical arguments or address practical concerns.
Such degree reduction can be performed through a sequence of splittings of
vertices, resulting in an _expansion_ of the original graph. We observe that
the treewidth of a graph may increase dramatically if the splittings are not
performed carefully. In this context we address the following natural question:
is it possible to reduce the maximum degree to a constant without substantially
increasing the treewidth?
  Our work answers the above question affirmatively. We prove that any simple
undirected graph G=(V, E) admits an expansion G'=(V', E') with the maximum
degree &lt;= 3 and treewidth(G') &lt;= treewidth(G)+1. Furthermore, such an expansion
will have no more than 2|E|+|V| vertices and 3|E| edges; it can be computed
efficiently from a tree-decomposition of G. We also construct a family of
examples for which the increase by 1 in treewidth cannot be avoided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0707.4255</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0707.4255</id><created>2007-07-28</created><authors><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames></author><author><keyname>Tzameret</keyname><forenames>Iddo</forenames></author></authors><title>Complexity of Propositional Proofs under a Promise</title><categories>cs.CC cs.LO</categories><comments>32 pages; a preliminary version appeared in the Proceedings of
  ICALP'07</comments><acm-class>F.2.2; F.4.1</acm-class><journal-ref>ACM Transactions on Computational Logic, 11(3):1-29, 2010;</journal-ref><abstract>  We study -- within the framework of propositional proof complexity -- the
problem of certifying unsatisfiability of CNF formulas under the promise that
any satisfiable formula has many satisfying assignments, where ``many'' stands
for an explicitly specified function $\Lam$ in the number of variables $n$. To
this end, we develop propositional proof systems under different measures of
promises (that is, different $\Lam$) as extensions of resolution. This is done
by augmenting resolution with axioms that, roughly, can eliminate sets of truth
assignments defined by Boolean circuits. We then investigate the complexity of
such systems, obtaining an exponential separation in the average-case between
resolution under different size promises:
  1. Resolution has polynomial-size refutations for all unsatisfiable 3CNF
formulas when the promise is $\eps\cd2^n$, for any constant $0&lt;\eps&lt;1$.
  2. There are no sub-exponential size resolution refutations for random 3CNF
formulas, when the promise is $2^{\delta n}$ (and the number of clauses is
$o(n^{3/2})$), for any constant $0&lt;\delta&lt;1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.0242</identifier>
 <datestamp>2013-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.0242</id><created>2007-08-01</created><updated>2008-02-25</updated><authors><author><keyname>Khan</keyname><forenames>Usman A.</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Distributing the Kalman Filter for Large-Scale Systems</title><categories>cs.IT math.IT</categories><journal-ref>U. A. Khan and J. M. F. Moura, "Distributing the Kalman filter for
  large-scale systems," IEEE Transactions on Signal Processing, vol. 56, Part
  1, no. 10, pp. 4919-4935, Oct. 2008</journal-ref><doi>10.1109/TSP.2008.927480</doi><abstract>  This paper derives a \emph{distributed} Kalman filter to estimate a sparsely
connected, large-scale, $n-$dimensional, dynamical system monitored by a
network of $N$ sensors. Local Kalman filters are implemented on the
($n_l-$dimensional, where $n_l\ll n$) sub-systems that are obtained after
spatially decomposing the large-scale system. The resulting sub-systems
overlap, which along with an assimilation procedure on the local Kalman
filters, preserve an $L$th order Gauss-Markovian structure of the centralized
error processes. The information loss due to the $L$th order Gauss-Markovian
approximation is controllable as it can be characterized by a divergence that
decreases as $L\uparrow$. The order of the approximation, $L$, leads to a lower
bound on the dimension of the sub-systems, hence, providing a criterion for
sub-system selection. The assimilation procedure is carried out on the local
error covariances with a distributed iterate collapse inversion (DICI)
algorithm that we introduce. The DICI algorithm computes the (approximated)
centralized Riccati and Lyapunov equations iteratively with only local
communication and low-order computation. We fuse the observations that are
common among the local Kalman filters using bipartite fusion graphs and
consensus averaging algorithms. The proposed algorithm achieves full
distribution of the Kalman filter that is coherent with the centralized Kalman
filter with an $L$th order Gaussian-Markovian structure on the centralized
error processes. Nowhere storage, communication, or computation of
$n-$dimensional vectors and matrices is needed; only $n_l \ll n$ dimensional
vectors and matrices are communicated or used in the computation at the
sensors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.0580</identifier>
 <datestamp>2010-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.0580</id><created>2007-08-03</created><updated>2010-08-05</updated><authors><author><keyname>Pritchard</keyname><forenames>David</forenames></author></authors><title>Efficient Divide-and-Conquer Implementations Of Symmetric FSAs</title><categories>cs.FL cs.DM</categories><journal-ref>Journal of Cellular Automata 5(6) (special issue for Automata
  2007, H. Fuks &amp; A. T. Lawniczak, eds), pages 481-490, 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A deterministic finite-state automaton (FSA) is an abstract sequential
machine that reads the symbols comprising an input word one at a time. An FSA
is symmetric if its output is independent of the order in which the input
symbols are read, i.e., if the output is invariant under permutations of the
input. We show how to convert a symmetric FSA A into an automaton-like
divide-and-conquer process whose intermediate results are no larger than the
size of A's memory. In comparison, a similar result for general FSA's has been
long known via functional composition, but entails an exponential increase in
memory size. The new result has applications to parallel processing and
symmetric FSA networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.0741</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.0741</id><created>2007-08-06</created><authors><author><keyname>Zhou</keyname><forenames>Shi</forenames></author><author><keyname>Cox</keyname><forenames>Ingemar</forenames></author><author><keyname>Petricek</keyname><forenames>Vaclav</forenames></author></authors><title>Characterising Web Site Link Structure</title><categories>cs.IR</categories><comments>To appear at IEEE/WSE07</comments><acm-class>H.5.4; C.2.1; D.2.8</acm-class><abstract>  The topological structures of the Internet and the Web have received
considerable attention. However, there has been little research on the
topological properties of individual web sites. In this paper, we consider
whether web sites (as opposed to the entire Web) exhibit structural
similarities. To do so, we exhaustively crawled 18 web sites as diverse as
governmental departments, commercial companies and university departments in
different countries. These web sites consisted of as little as a few thousand
pages to millions of pages. Statistical analysis of these 18 sites revealed
that the internal link structure of the web sites are significantly different
when measured with first and second-order topological properties, i.e.
properties based on the connectivity of an individual or a pairs of nodes.
However, examination of a third-order topological property that consider the
connectivity between three nodes that form a triangle, revealed a strong
correspondence across web sites, suggestive of an invariant. Comparison with
the Web, the AS Internet, and a citation network, showed that this third-order
property is not shared across other types of networks. Nor is the property
exhibited in generative network models such as that of Barabasi and Albert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.0977</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.0977</id><created>2007-08-07</created><authors><author><keyname>Lucarini</keyname><forenames>Valerio</forenames></author></authors><title>From symmetry break to Poisson point process in 2D Voronoi
  tessellations: the generic nature of hexagons</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CG math-ph math.MP physics.data-an</categories><comments>14 pages, 4 figures</comments><journal-ref>J. Stat. Phys., 130, 1047-1062 (2008)</journal-ref><doi>10.1007/s10955-007-9475-x</doi><abstract>  We bridge the properties of the regular square and honeycomb Voronoi
tessellations of the plane to those of the Poisson-Voronoi case, thus analyzing
in a common framework symmetry-break processes and the approach to uniformly
random distributions of tessellation-generating points. We consider ensemble
simulations of tessellations generated by points whose regular positions are
perturbed through a Gaussian noise controlled by the parameter alpha. We study
the number of sides, the area, and the perimeter of the Voronoi cells. For
alpha&gt;0, hexagons are the most common class of cells, and 2-parameter gamma
distributions describe well the statistics of the geometrical characteristics.
The symmetry break due to noise destroys the square tessellation, whereas the
honeycomb hexagonal tessellation is very stable and all Voronoi cells are
hexagon for small but finite noise with alpha&lt;0.1. For a moderate amount of
Gaussian noise, memory of the specific unperturbed tessellation is lost,
because the statistics of the two perturbed tessellations is indistinguishable.
When alpha&gt;2, results converge to those of Poisson-Voronoi tessellations. The
properties of n-sided cells change with alpha until the Poisson-Voronoi limit
is reached for alpha&gt;2. The Desch law for perimeters is confirmed to be not
valid and a square root dependence on n is established. The ensemble mean of
the cells area and perimeter restricted to the hexagonal cells coincides with
the full ensemble mean; this might imply that the number of sides acts as a
thermodynamic state variable fluctuating about n=6; this reinforces the idea
that hexagons, beyond their ubiquitous numerical prominence, can be taken as
generic polygons in 2D Voronoi tessellations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.1491</identifier>
 <datestamp>2010-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.1491</id><created>2007-08-10</created><authors><author><keyname>Marichal</keyname><forenames>Jean-Luc</forenames></author></authors><title>On perfect, amicable, and sociable chains</title><categories>math.CO cs.DM math.NT</categories><comments>10 pages</comments><msc-class>05A17, 11B83, 11P81</msc-class><abstract>  Let $x = (x_0,...,x_{n-1})$ be an n-chain, i.e., an n-tuple of non-negative
integers $&lt; n$. Consider the operator $s: x \mapsto x' = (x'_0,...,x'_{n-1})$,
where x'_j represents the number of $j$'s appearing among the components of x.
An n-chain x is said to be perfect if $s(x) = x$. For example, (2,1,2,0,0) is a
perfect 5-chain. Analogously to the theory of perfect, amicable, and sociable
numbers, one can define from the operator s the concepts of amicable pair and
sociable group of chains. In this paper we give an exhaustive list of all the
perfect, amicable, and sociable chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.1529</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.1529</id><created>2007-08-10</created><authors><author><keyname>Raz</keyname><forenames>Ran</forenames></author><author><keyname>Tzameret</keyname><forenames>Iddo</forenames></author></authors><title>Resolution over Linear Equations and Multilinear Proofs</title><categories>cs.CC cs.LO</categories><comments>44 pages</comments><acm-class>F.2.2; F.4.1</acm-class><journal-ref>Annals of Pure and Applied Logic , 155(3):194-224, 2008;</journal-ref><doi>10.1016/j.apal.2008.04.001</doi><abstract>  We develop and study the complexity of propositional proof systems of varying
strength extending resolution by allowing it to operate with disjunctions of
linear equations instead of clauses. We demonstrate polynomial-size refutations
for hard tautologies like the pigeonhole principle, Tseitin graph tautologies
and the clique-coloring tautologies in these proof systems. Using the
(monotone) interpolation by a communication game technique we establish an
exponential-size lower bound on refutations in a certain, considerably strong,
fragment of resolution over linear equations, as well as a general polynomial
upper bound on (non-monotone) interpolants in this fragment.
  We then apply these results to extend and improve previous results on
multilinear proofs (over fields of characteristic 0), as studied in
[RazTzameret06]. Specifically, we show the following:
  1. Proofs operating with depth-3 multilinear formulas polynomially simulate a
certain, considerably strong, fragment of resolution over linear equations.
  2. Proofs operating with depth-3 multilinear formulas admit polynomial-size
refutations of the pigeonhole principle and Tseitin graph tautologies. The
former improve over a previous result that established small multilinear proofs
only for the \emph{functional} pigeonhole principle. The latter are different
than previous proofs, and apply to multilinear proofs of Tseitin mod p graph
tautologies over any field of characteristic 0.
  We conclude by connecting resolution over linear equations with extensions of
the cutting planes proof system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.1580</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.1580</id><created>2007-08-11</created><updated>2010-08-19</updated><authors><author><keyname>Still</keyname><forenames>Susanne</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author></authors><title>Optimal Causal Inference: Estimating Stored Information and
  Approximating Causal Architecture</title><categories>cs.IT cond-mat.stat-mech cs.LG math.IT math.ST stat.TH</categories><comments>14 pages, 13 figures;
  http://cse.ucdavis.edu/~cmg/compmech/pubs/oci.htm; Updated figures and
  citations; added corrections and clarifications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an approach to inferring the causal architecture of stochastic
dynamical systems that extends rate distortion theory to use causal
shielding---a natural principle of learning. We study two distinct cases of
causal inference: optimal causal filtering and optimal causal estimation.
  Filtering corresponds to the ideal case in which the probability distribution
of measurement sequences is known, giving a principled method to approximate a
system's causal structure at a desired level of representation. We show that,
in the limit in which a model complexity constraint is relaxed, filtering finds
the exact causal architecture of a stochastic dynamical system, known as the
causal-state partition. From this, one can estimate the amount of historical
information the process stores. More generally, causal filtering finds a graded
model-complexity hierarchy of approximations to the causal architecture. Abrupt
changes in the hierarchy, as a function of approximation, capture distinct
scales of structural organization.
  For nonideal cases with finite data, we show how the correct number of
underlying causal states can be found by optimal causal estimation. A
previously derived model complexity control term allows us to correct for the
effect of statistical fluctuations in probability estimates and thereby avoid
over-fitting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.2078</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.2078</id><created>2007-08-15</created><authors><author><keyname>Levandovskyy</keyname><forenames>Viktor</forenames></author><author><keyname>Zerz</keyname><forenames>Eva</forenames></author></authors><title>Obstructions to Genericity in Study of Parametric Problems in Control
  Theory</title><categories>math.OC cs.SC math.RA</categories><comments>20 pages</comments><msc-class>13P10; 93B25</msc-class><abstract>  We investigate systems of equations, involving parameters from the point of
view of both control theory and computer algebra. The equations might involve
linear operators such as partial (q-)differentiation, (q-)shift, (q-)difference
as well as more complicated ones, which act trivially on the parameters. Such a
system can be identified algebraically with a certain left module over a
non-commutative algebra, where the operators commute with the parameters. We
develop, implement and use in practice the algorithm for revealing all the
expressions in parameters, for which e.g. homological properties of a system
differ from the generic properties. We use Groebner bases and Groebner basics
in rings of solvable type as main tools. In particular, we demonstrate an
optimized algorithm for computing the left inverse of a matrix over a ring of
solvable type. We illustrate the article with interesting examples. In
particular, we provide a complete solution to the "two pendula, mounted on a
cart" problem from the classical book of Polderman and Willems, including the
case, where the friction at the joints is essential . To the best of our
knowledge, the latter example has not been solved before in a complete way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.2575</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.2575</id><created>2007-08-19</created><updated>2011-06-03</updated><authors><author><keyname>Erez</keyname><forenames>Uri</forenames></author><author><keyname>Trott</keyname><forenames>Mitchell D.</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory W.</forenames></author></authors><title>Rateless Coding for Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rateless code-i.e., a rate-compatible family of codes-has the property that
codewords of the higher rate codes are prefixes of those of the lower rate
ones. A perfect family of such codes is one in which each of the codes in the
family is capacity-achieving. We show by construction that perfect rateless
codes with low-complexity decoding algorithms exist for additive white Gaussian
noise channels. Our construction involves the use of layered encoding and
successive decoding, together with repetition using time-varying layer weights.
As an illustration of our framework, we design a practical three-rate code
family. We further construct rich sets of near-perfect rateless codes within
our architecture that require either significantly fewer layers or lower
complexity than their perfect counterparts. Variations of the basic
construction are also developed, including one for time-varying channels in
which there is no a priori stochastic model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.2584</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.2584</id><created>2007-08-20</created><updated>2008-03-03</updated><authors><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author></authors><title>Claw Finding Algorithms Using Quantum Walk</title><categories>quant-ph cs.CC</categories><comments>12 pages. Introduction revised. A reference added. Weak lower bound
  deleted</comments><journal-ref>Theoretical Computer Science, 410(50): 5285-5297 (2009)</journal-ref><doi>10.1016/j.tcs.2009.08.030</doi><abstract>  The claw finding problem has been studied in terms of query complexity as one
of the problems closely connected to cryptography. For given two functions, f
and g, as an oracle which have domains of size N and M (N&lt;=M), respectively,
and the same range, the goal of the problem is to find x and y such that
f(x)=g(y). This paper describes an optimal algorithm using quantum walk that
solves this problem. Our algorithm can be generalized to find a claw of k
functions for any constant integer k&gt;1, where the domains of the functions may
have different size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.2668</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.2668</id><created>2007-08-19</created><updated>2011-07-25</updated><authors><author><keyname>Reem</keyname><forenames>Daniel</forenames></author><author><keyname>Reich</keyname><forenames>Simeon</forenames></author></authors><title>Zone and double zone diagrams in abstract spaces</title><categories>math.MG cs.CG math.CO</categories><comments>17 pages, 5 figures; slight modifications and additions (including
  thanks); Theorem 5.5 was slightly improved. This version is essentially from
  the beginning of 2009 and it does not take into account several developments
  which have occurred since then</comments><msc-class>06B23, 47H10, 51K99, 54E35</msc-class><journal-ref>Colloquium Mathematicum, 115 (2009), 129-145</journal-ref><doi>10.4064/cm115-1-11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A zone diagram is a relatively new concept which was first defined and
studied by T. Asano, J. Matousek and T. Tokuyama. It can be interpreted as a
state of equilibrium between several mutually hostile kingdoms. Formally, it is
a fixed point of a certain mapping. These authors considered the Euclidean
plane and proved the existence and uniqueness of zone diagrams there. In the
present paper we generalize this concept in various ways. We consider general
sites in m-spaces (a simple generalization of metric spaces) and prove several
existence and (non)uniqueness results in this setting. In contrast to previous
works, our (rather simple) proofs are based on purely order theoretic
arguments. Many explicit examples are given, and some of them illustrate new
phenomena which occur in the general case. We also re-interpret zone diagrams
as a stable configuration in a certain combinatorial game, and provide an
algorithm for finding this configuration in a particular case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.2843</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.2843</id><created>2007-08-21</created><updated>2007-12-14</updated><authors><author><keyname>Colbeck</keyname><forenames>Roger</forenames></author></authors><title>The Impossibility Of Secure Two-Party Classical Computation</title><categories>quant-ph cs.CR</categories><comments>10 pages</comments><journal-ref>Physical Review A 76, 062308 (2007)</journal-ref><doi>10.1103/PhysRevA.76.062308</doi><abstract>  We present attacks that show that unconditionally secure two-party classical
computation is impossible for many classes of function. Our analysis applies to
both quantum and relativistic protocols. We illustrate our results by showing
the impossibility of oblivious transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.3220</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.3220</id><created>2007-08-23</created><authors><author><keyname>Delvenne</keyname><forenames>Jean-Charles</forenames></author><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Zampieri</keyname><forenames>Sandro</forenames></author></authors><title>Optimal strategies in the average consensus problem</title><categories>cs.MA cs.NI math.OC</categories><comments>9 pages; extended preprint with proofs of a CDC 2007 (Conference on
  decision and Control) paper</comments><abstract>  We prove that for a set of communicating agents to compute the average of
their initial positions (average consensus problem), the optimal topology of
communication is given by a de Bruijn's graph. Consensus is then reached in a
finitely many steps. A more general family of strategies, constructed by block
Kronecker products, is investigated and compared to Cayley strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.3226</identifier>
 <datestamp>2010-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.3226</id><created>2007-08-23</created><updated>2010-04-04</updated><authors><author><keyname>Takhanov</keyname><forenames>Rustem</forenames></author></authors><title>A Dichotomy Theorem for General Minimum Cost Homomorphism Problem</title><categories>cs.LG cs.CC</categories><comments>23 pages</comments><acm-class>F.4.1; G.2.2; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the constraint satisfaction problem ($CSP$), the aim is to find an
assignment of values to a set of variables subject to specified constraints. In
the minimum cost homomorphism problem ($MinHom$), one is additionally given
weights $c_{va}$ for every variable $v$ and value $a$, and the aim is to find
an assignment $f$ to the variables that minimizes $\sum_{v} c_{vf(v)}$. Let
$MinHom(\Gamma)$ denote the $MinHom$ problem parameterized by the set of
predicates allowed for constraints. $MinHom(\Gamma)$ is related to many
well-studied combinatorial optimization problems, and concrete applications can
be found in, for instance, defence logistics and machine learning. We show that
$MinHom(\Gamma)$ can be studied by using algebraic methods similar to those
used for CSPs. With the aid of algebraic techniques, we classify the
computational complexity of $MinHom(\Gamma)$ for all choices of $\Gamma$. Our
result settles a general dichotomy conjecture previously resolved only for
certain classes of directed graphs, [Gutin, Hell, Rafiey, Yeo, European J. of
Combinatorics, 2008].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.3446</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.3446</id><created>2007-08-25</created><updated>2007-09-14</updated><authors><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>Multi and Independent Block Approach in Public Cluster</title><categories>cs.DC</categories><comments>3 pages, Proceeding of the 3rd Information and Communication
  Technology Seminar 2007</comments><report-no>FISIKALIPI-07012</report-no><abstract>  We present extended multi block approach in the LIPI Public Cluster. The
multi block approach enables a cluster to be divided into several independent
blocks which run jobs owned by different users simultaneously. Previously, we
have maintained the blocks using single master node for all blocks due to
efficiency and resource limitations. Following recent advancements and
expansion of node\'s number, we have modified the multi block approach with
multiple master nodes, each of them is responsible for a single block. We argue
that this approach improves the overall performance significantly, for
especially data intensive computational works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.3522</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.3522</id><created>2007-08-26</created><updated>2008-06-24</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Pasechnik</keyname><forenames>Dmitrii V.</forenames></author><author><keyname>Roy</keyname><forenames>Marie-Francoise</forenames></author></authors><title>Bounding the Betti numbers and computing the Euler-Poincar\'e
  characteristic of semi-algebraic sets defined by partly quadratic systems of
  polynomials</title><categories>math.AG cs.SC math.AT math.GT</categories><comments>23 pages, 1 figure. Shortened revised version to appear in the J.
  Eur. Math. Soc</comments><msc-class>14P10, 14P25 (Primary), 68W30 (Secondary)</msc-class><journal-ref>J. European Math. Soc. 12(2010), 529-553</journal-ref><doi>10.1137/070711141</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\R$ be a real closed field, $ {\mathcal Q} \subset
\R[Y_1,...,Y_\ell,X_1,...,X_k], $ with $ \deg_{Y}(Q) \leq 2, \deg_{X}(Q) \leq
d, Q \in {\mathcal Q}, #({\mathcal Q})=m,$ and $ {\mathcal P} \subset
\R[X_1,...,X_k] $ with $\deg_{X}(P) \leq d, P \in {\mathcal P}, #({\mathcal
P})=s$, and $S \subset \R^{\ell+k}$ a semi-algebraic set defined by a Boolean
formula without negations, with atoms $P=0, P \geq 0, P \leq 0, P \in {\mathcal
P} \cup {\mathcal Q}$. We prove that the sum of the Betti numbers of $S$ is
bounded by \[ \ell^2 (O(s+\ell+m)\ell d)^{k+2m}. \] This is a common
generalization of previous results on bounding the Betti numbers of closed
semi-algebraic sets defined by polynomials of degree $d$ and 2, respectively.
  We also describe an algorithm for computing the Euler-Poincar\'e
characteristic of such sets, generalizing similar algorithms known before. The
complexity of the algorithm is bounded by $(\ell s m d)^{O(m(m+k))}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.3699</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.3699</id><created>2007-08-27</created><updated>2007-09-19</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Krovi</keyname><forenames>Hari</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author></authors><title>Convolutional Entanglement Distillation</title><categories>quant-ph cs.IT math.IT</categories><comments>17 pages, 7 figures, 1 table - minor corrections to text and figures</comments><report-no>CSI-07-08-02</report-no><journal-ref>Proceedings of the 2010 IEEE International Symposium on
  Information Theory, pp. 2657-2661, Austin, Texas, USA</journal-ref><doi>10.1109/ISIT.2010.5513666</doi><abstract>  We develop a theory of entanglement distillation that exploits a
convolutional coding structure. We provide a method for converting an arbitrary
classical binary or quaternary convolutional code into a convolutional
entanglement distillation protocol. The imported classical convolutional code
does not have to be dual-containing or self-orthogonal. The yield and
error-correcting properties of such a protocol depend respectively on the rate
and error-correcting properties of the imported classical convolutional code. A
convolutional entanglement distillation protocol has several other benefits.
Two parties sharing noisy ebits can distill noiseless ebits ``online'' as they
acquire more noisy ebits. Distillation yield is high and decoding complexity is
simple for a convolutional entanglement distillation protocol. Our theory of
convolutional entanglement distillation reduces the problem of finding a good
convolutional entanglement distillation protocol to the well-established
problem of finding a good classical convolutional code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4324</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4324</id><created>2007-08-31</created><updated>2013-12-04</updated><authors><author><keyname>Caro</keyname><forenames>Stéphane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bennis</keyname><forenames>Fouad</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Sensitivity Analysis of the Orthoglide, a 3-DOF Translational Parallel
  Kinematic Machine</title><categories>cs.RO</categories><proxy>ccsd</proxy><journal-ref>Journal of Mechanical Design 128 (2006) 392-402</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a sensitivity analysis of the Orthoglide, a 3-DOF
translational Parallel Kinematic Machine. Two complementary methods are
developed to analyze its sensitivity to its dimensional and angular variations.
First, a linkage kinematic analysis method is used to have a rough idea of the
influence of the dimensional variations on the location of the end-effector.
Besides, this method shows that variations in the design parameters of the same
type from one leg to the other have the same influence on the end-effector.
However, this method does not take into account the variations in the
parallelograms. Thus, a differential vector method is used to study the
influence of the dimensional and angular variations in the parts of the
manipulator on the position and orientation of the end-effector, and
particularly the influence of the variations in the parallelograms. It turns
out that the kinematic isotropic configuration of the manipulator is the least
sensitive one to its dimensional and angular variations. On the contrary, the
closest configurations to its kinematic singular configurations are the most
sensitive ones to geometrical variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4387</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4387</id><created>2007-08-31</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author></authors><title>Conjugates of characteristic Sturmian words generated by morphisms</title><categories>math.CO cs.DM</categories><comments>11 pages</comments><msc-class>68R15; 11A55</msc-class><journal-ref>European Journal of Combinatorics 25 (2004) 1025-1037</journal-ref><doi>10.1016/j.ejc.2003.12.012</doi><abstract>  This article is concerned with characteristic Sturmian words of slope
$\alpha$ and $1-\alpha$ (denoted by $c_\alpha$ and $c_{1-\alpha}$
respectively), where $\alpha \in (0,1)$ is an irrational number such that
$\alpha = [0;1+d_1,\bar{d_2,...,d_n}]$ with $d_n \geq d_1 \geq 1$. It is known
that both $c_\alpha$ and $c_{1-\alpha}$ are fixed points of non-trivial
(standard) morphisms $\sigma$ and $\hat{\sigma}$, respectively, if and only if
$\alpha$ has a continued fraction expansion as above. Accordingly, such words
$c_\alpha$ and $c_{1-\alpha}$ are generated by the respective morphisms
$\sigma$ and $\hat{\sigma}$. For the particular case when $\alpha =
[0;2,\bar{r}]$ ($r\geq1$), we give a decomposition of each conjugate of
$c_\alpha$ (and hence $c_{1-\alpha}$) into generalized adjoining singular
words, by considering conjugates of powers of the standard morphism $\sigma$ by
which it is generated. This extends a recent result of Lev\'{e} and S\ee bold
on conjugates of the infinite Fibonacci word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4389</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4389</id><created>2007-08-31</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author></authors><title>Occurrences of palindromes in characteristic Sturmian words</title><categories>math.CO cs.DM</categories><comments>17 pages</comments><msc-class>68R15; 11A55</msc-class><journal-ref>Theoretical Computer Science 352 (2006) 31-46</journal-ref><doi>10.1016/j.tcs.2005.09.075</doi><abstract>  This paper is concerned with palindromes occurring in characteristic Sturmian
words $c_\alpha$ of slope $\alpha$, where $\alpha \in (0,1)$ is an irrational.
As $c_\alpha$ is a uniformly recurrent infinite word, any (palindromic) factor
of $c_\alpha$ occurs infinitely many times in $c_\alpha$ with bounded gaps. Our
aim is to completely describe where palindromes occur in $c_\alpha$. In
particular, given any palindromic factor $u$ of $c_\alpha$, we shall establish
a decomposition of $c_\alpha$ with respect to the occurrences of $u$. Such a
decomposition shows precisely where $u$ occurs in $c_\alpha$, and this is
directly related to the continued fraction expansion of $\alpha$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4400</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4400</id><created>2007-08-31</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author></authors><title>Powers in a class of A-strict standard episturmian words</title><categories>math.CO cs.DM</categories><comments>26 pages; extended version of a paper presented at the 5th
  International Conference on Words, Montreal, Canada, September 13-17, 2005</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 380 (2007) 330-354</journal-ref><doi>10.1016/j.tcs.2007.03.023</doi><abstract>  This paper concerns a specific class of strict standard episturmian words
whose directive words resemble those of characteristic Sturmian words. In
particular, we explicitly determine all integer powers occurring in such
infinite words, extending recent results of Damanik and Lenz (2003), who
studied powers in Sturmian words. The key tools in our analysis are canonical
decompositions and a generalization of singular words, which were originally
defined for the ubiquitous Fibonacci word. Our main results are demonstrated
via some examples, including the $k$-bonacci word: a generalization of the
Fibonacci word to a $k$-letter alphabet ($k\geq2$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4406</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4406</id><created>2007-08-31</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author></authors><title>A characterization of fine words over a finite alphabet</title><categories>math.CO cs.DM</categories><comments>16 pages; presented at the conference on "Combinatorics, Automata and
  Number Theory", Liege, Belgium, May 8-19, 2006 (to appear in a special issue
  of Theoretical Computer Science)</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 391 (2008) 51-60</journal-ref><doi>10.1016/j.tcs.2007.10.029</doi><abstract>  To any infinite word w over a finite alphabet A we can associate two infinite
words min(w) and max(w) such that any prefix of min(w) (resp. max(w)) is the
lexicographically smallest (resp. greatest) amongst the factors of w of the
same length. We say that an infinite word w over A is "fine" if there exists an
infinite word u such that, for any lexicographic order, min(w) = au where a =
min(A). In this paper, we characterize fine words; specifically, we prove that
an infinite word w is fine if and only if w is either a "strict episturmian
word" or a strict "skew episturmian word''. This characterization generalizes a
recent result of G. Pirillo, who proved that a fine word over a 2-letter
alphabet is either an (aperiodic) Sturmian word, or an ultimately periodic (but
not periodic) infinite word, all of whose factors are (finite) Sturmian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4407</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4407</id><created>2007-08-31</created><updated>2007-11-23</updated><authors><author><keyname>Rajan</keyname><forenames>G. Susinder</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Algebraic Distributed Differential Space-Time Codes with Low Decoding
  Complexity</title><categories>cs.IT cs.DM math.IT math.RA</categories><comments>To appear in IEEE Transactions on Wireless Communications. 10 pages,
  5 figures</comments><abstract>  The differential encoding/decoding setup introduced by Kiran et al,
Oggier-Hassibi and Jing-Jafarkhani for wireless relay networks that use
codebooks consisting of unitary matrices is extended to allow codebooks
consisting of scaled unitary matrices. For such codebooks to be usable in the
Jing-Hassibi protocol for cooperative diversity, the conditions involving the
relay matrices and the codebook that need to be satisfied are identified. Using
the algebraic framework of extended Clifford algebras, a new class of
Distributed Differential Space-Time Codes satisfying these conditions for power
of two number of relays and also achieving full cooperative diversity with a
low complexity sub-optimal receiver is proposed. Simulation results indicate
that the proposed codes outperform both the cyclic codes as well as the
circulant codes. Furthermore, these codes can also be applied as Differential
Space-Time codes for non-coherent communication in classical point to point
multiple antenna systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0708.4409</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0708.4409</id><created>2007-08-31</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Justin</keyname><forenames>Jacques</forenames></author><author><keyname>Pirillo</keyname><forenames>Giuseppe</forenames></author></authors><title>Characterizations of finite and infinite episturmian words via
  lexicographic orderings</title><categories>math.CO cs.DM</categories><comments>18 pages; to appear in the European Journal of Combinatorics</comments><msc-class>68R15</msc-class><journal-ref>European Journal of Combinatorics 29 (2008) 45-58</journal-ref><doi>10.1016/j.ejc.2007.01.002</doi><abstract>  In this paper, we characterize by lexicographic order all finite Sturmian and
episturmian words, i.e., all (finite) factors of such infinite words.
Consequently, we obtain a characterization of infinite episturmian words in a
"wide sense" (episturmian and episkew infinite words). That is, we characterize
the set of all infinite words whose factors are (finite) episturmian.
Similarly, we characterize by lexicographic order all balanced infinite words
over a 2-letter alphabet; in other words, all Sturmian and skew infinite words,
the factors of which are (finite) Sturmian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0099</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0099</id><created>2007-09-02</created><updated>2007-12-21</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author></authors><title>The road coloring problem</title><categories>cs.DM</categories><comments>9 pages, correct typos</comments><abstract>  The synchronizing word of deterministic automaton is a word in the alphabet
of colors (considered as letters) of its edges that maps the automaton to a
single state. A coloring of edges of a directed graph is synchronizing if the
coloring turns the graph into deterministic finite automaton possessing a
synchronizing word.
  The road coloring problem is a problem of synchronizing coloring of directed
finite strongly connected graph with constant outdegree of all its vertices if
the greatest common divisor of lengths of all its cycles is one. The problem
was posed by Adler, Goodwyn and Weiss over 30 years ago and evoked a noticeable
interest among the specialists in theory of graphs, deterministic automata and
symbolic dynamics. The problem is described even in "Wikipedia" - the popular
Internet Encyclopedia. The positive solution of the road coloring problem is
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0116</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0116</id><created>2007-09-02</created><updated>2007-09-29</updated><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>On Ultrametric Algorithmic Information</title><categories>cs.AI cs.CL</categories><comments>Forthcoming, Computer Journal. Minor corrections 29 Oct. 2007</comments><acm-class>I.2.0</acm-class><journal-ref>Computer Journal, 53, 405-416, 2010</journal-ref><doi>10.1093/comjnl/bxm084</doi><abstract>  How best to quantify the information of an object, whether natural or
artifact, is a problem of wide interest. A related problem is the computability
of an object. We present practical examples of a new way to address this
problem. By giving an appropriate representation to our objects, based on a
hierarchical coding of information, we exemplify how it is remarkably easy to
compute complex objects. Our algorithmic complexity is related to the length of
the class of objects, rather than to the length of the object.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0223</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0223</id><created>2007-09-03</created><authors><author><keyname>Kostakos</keyname><forenames>Vassilis</forenames></author><author><keyname>O'Neill</keyname><forenames>Eamonn</forenames></author><author><keyname>Penn</keyname><forenames>Alan</forenames></author></authors><title>Brief encounter networks</title><categories>cs.CY</categories><comments>8 pages, 6 figures</comments><journal-ref>ACM Transactions on Computer Human Interaction, 17(1):1-38, 2010</journal-ref><doi>10.1145/1721831.1721833</doi><abstract>  Many complex human and natural phenomena can usefully be represented as
networks describing the relationships between individuals. While these
relationships are typically intermittent, previous research has used network
representations that aggregate the relationships at discrete intervals.
However, such an aggregation discards important temporal information, thus
inhibiting our understanding of the networks dynamic behaviour and evolution.
We have recorded patterns of human urban encounter using Bluetooth technology
thus retaining the temporal properties of this network. Here we show how this
temporal information influences the structural properties of the network. We
show that the temporal properties of human urban encounter are scale-free,
leading to an overwhelming proportion of brief encounters between individuals.
While previous research has shown preferential attachment to result in
scale-free connectivity in aggregated network data, we found that scale-free
connectivity results from the temporal properties of the network. In addition,
we show that brief encounters act as weak social ties in the diffusion of
non-expiring information, yet persistent encounters provide the means for
sustaining time-expiring information through a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0355</identifier>
 <datestamp>2014-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0355</id><created>2007-09-04</created><authors><author><keyname>Bodard</keyname><forenames>Nicolas</forenames></author><author><keyname>Bouffanais</keyname><forenames>Roland</forenames></author><author><keyname>Deville</keyname><forenames>Michel O.</forenames></author></authors><title>Solution of moving-boundary problems by the spectral element method</title><categories>cs.CE cs.NA</categories><comments>Applied Numerical Mathematics, In Press, 2008</comments><journal-ref>Applied Numerial Mathematics, Volume 58, Issue 7, July 2008, Pages
  968-984</journal-ref><doi>10.1016/j.apnum.2007.04.009</doi><abstract>  This paper describes a novel numerical model aiming at solving
moving-boundary problems such as free-surface flows or fluid-structure
interaction. This model uses a moving-grid technique to solve the
Navier--Stokes equations expressed in the arbitrary Lagrangian--Eulerian
kinematics. The discretization in space is based on the spectral element
method. The coupling of the fluid equations and the moving-grid equations is
essentially done through the conditions on the moving boundaries. Two- and
three-dimensional simulations are presented: translation and rotation of a
cylinder in a fluid, and large-amplitude sloshing in a rectangular tank. The
accuracy and robustness of the present numerical model is studied and
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0670</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0670</id><created>2007-09-05</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Using Data Compressors to Construct Rank Tests</title><categories>cs.DS cs.IT math.IT</categories><journal-ref>Applied Mathematics Letters, 22:7, 1029-1032, 2009</journal-ref><abstract>  Nonparametric rank tests for homogeneity and component independence are
proposed, which are based on data compressors. For homogeneity testing the idea
is to compress the binary string obtained by ordering the two joint samples and
writing 0 if the element is from the first sample and 1 if it is from the
second sample and breaking ties by randomization (extension to the case of
multiple samples is straightforward). $H_0$ should be rejected if the string is
compressed (to a certain degree) and accepted otherwise. We show that such a
test obtained from an ideal data compressor is valid against all alternatives.
Component independence is reduced to homogeneity testing by constructing two
samples, one of which is the first half of the original and the other is the
second half with one of the components randomly permuted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0746</identifier>
 <datestamp>2014-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0746</id><created>2007-09-05</created><authors><author><keyname>Mulmuley</keyname><forenames>Ketan D.</forenames></author><author><keyname>Sohoni</keyname><forenames>Milind</forenames></author></authors><title>Geometric Complexity Theory: Introduction</title><categories>cs.CC</categories><comments>161 pages</comments><report-no>TR-2007-16, comp. sci. dept., The University Of Chicago</report-no><abstract>  These are lectures notes for the introductory graduate courses on geometric
complexity theory (GCT) in the computer science department, the university of
Chicago. Part I consists of the lecture notes for the course given by the first
author in the spring quarter, 2007. It gives introduction to the basic
structure of GCT. Part II consists of the lecture notes for the course given by
the second author in the spring quarter, 2003. It gives introduction to
invariant theory with a view towards GCT. No background in algebraic geometry
or representation theory is assumed. These lecture notes in conjunction with
the article \cite{GCTflip1}, which describes in detail the basic plan of GCT
based on the principle called the flip, should provide a high level picture of
GCT assuming familiarity with only basic notions of algebra, such as groups,
rings, fields etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0883</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0883</id><created>2007-09-06</created><updated>2011-07-07</updated><authors><author><keyname>Herman</keyname><forenames>Joshua Jay</forenames></author></authors><title>Liquid State Machines in Adbiatic Quantum Computers for General
  Computation</title><categories>cs.CC cs.NE</categories><comments>Totally wrong</comments><acm-class>C.1.3; F.1.3</acm-class><abstract>  Major mistakes do not read
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0961</identifier>
 <datestamp>2010-03-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0961</id><created>2007-09-07</created><updated>2009-11-13</updated><authors><author><keyname>Sethu</keyname><forenames>Harish</forenames></author><author><keyname>Gerety</keyname><forenames>Thomas</forenames></author></authors><title>A New Distributed Topology Control Algorithm for Wireless Environments
  with Non-Uniform Path Loss and Multipath Propagation</title><categories>cs.NI</categories><comments>To appear in Ad Hoc Networks</comments><journal-ref>Ad Hoc Networks, May 2010, volume 8, issue 3, pages 280-294.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Each node in a wireless multi-hop network can adjust the power level at which
it transmits and thus change the topology of the network to save energy by
choosing the neighbors with which it directly communicates. Many previous
algorithms for distributed topology control have assumed an ability at each
node to deduce some location-based information such as the direction and the
distance of its neighbor nodes with respect to itself. Such a deduction of
location-based information, however, cannot be relied upon in real environments
where the path loss exponents vary greatly leading to significant errors in
distance estimates. Also, multipath effects may result in different signal
paths with different loss characteristics, and none of these paths may be
line-of-sight, making it difficult to estimate the direction of a neighboring
node. In this paper, we present Step Topology Control (STC), a simple
distributed topology control algorithm which reduces energy consumption while
preserving the connectivity of a heterogeneous sensor network without use of
any location-based information. We show that the STC algorithm achieves the
same or better order of communication and computational complexity when
compared to other known algorithms that also preserve connectivity without the
use of location-based information. We also present a detailed simulation-based
comparative analysis of the energy savings and interference reduction achieved
by the algorithms. The results show that, in spite of not incurring a higher
communication or computational complexity, the STC algorithm performs better
than other algorithms in uniform wireless environments and especially better
when path loss characteristics are non-uniform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.0993</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.0993</id><created>2007-09-07</created><authors><author><keyname>Shro</keyname><forenames>O. I.</forenames></author></authors><title>The Description of Information in 4-Dimensional Pseudo-Euclidean
  Information Space</title><categories>cs.IT math.IT nlin.AO physics.soc-ph</categories><comments>40 pages. This is conceptual article from information theory. This
  article contains original results received by the author</comments><abstract>  This article is presented new method of description information systems in
abstract 4-dimensional pseudo-Euclidean information space (4-DPIES) with using
special relativity (SR) methods. This purpose core postulates of existence
4-DPIES are formulated. The theorem setting existence criteria of the invariant
velocity of the information transference is formulated and proved. One more
theorem allowed relating discrete parameters of information and continuous
space-time treating and also row of supplementary theorems is formulated and
proved. For description of dynamics and interaction of information, in article
is introduced general parameter of information - generalized information
emotion (GIE), reminding simultaneously on properties the mass and the charge.
At performing calculation of information observable parameters in the
information space is introduced continual integration methods of Feynman. The
applying idea about existence of GIE as measures of the information inertness
and the interaction carrier, and using continual integration methods of Feynman
can be calculated probability of information process in 4-DPIES. In this frame
presented approach has allowed considering information systems when interest is
presented with information processes, their related with concrete definition
without necessity. The relation between 4-DPIES and real systems parameters is
set at modelling of matching between observable processes and real phenomena
from information interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.1308</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.1308</id><created>2007-09-10</created><updated>2008-04-01</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Cirquent calculus deepened</title><categories>cs.LO math.LO</categories><comments>Significant improvements over the previous versions</comments><acm-class>F.4.1</acm-class><journal-ref>Journal of Logic and Computation 18 (2008), pp. 983-1028</journal-ref><doi>10.1093/logcom/exn019</doi><abstract>  Cirquent calculus is a new proof-theoretic and semantic framework, whose main
distinguishing feature is being based on circuits, as opposed to the more
traditional approaches that deal with tree-like objects such as formulas or
sequents. Among its advantages are greater efficiency, flexibility and
expressiveness. This paper presents a detailed elaboration of a deep-inference
cirquent logic, which is naturally and inherently resource conscious. It shows
that classical logic, both syntactically and semantically, is just a special,
conservative fragment of this more general and, in a sense, more basic logic --
the logic of resources in the form of cirquent calculus. The reader will find
various arguments in favor of switching to the new framework, such as arguments
showing the insufficiency of the expressive power of linear logic or other
formula-based approaches to developing resource logics, exponential
improvements over the traditional approaches in both representational and proof
complexities offered by cirquent calculus, and more. Among the main purposes of
this paper is to provide an introductory-style starting point for what, as the
author wishes to hope, might have a chance to become a new line of research in
proof theory -- a proof theory based on circuits instead of formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.1433</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.1433</id><created>2007-09-10</created><updated>2014-07-08</updated><authors><author><keyname>Kante</keyname><forenames>Mamadou Moustapha</forenames></author><author><keyname>Rao</keyname><forenames>Michael</forenames></author></authors><title>The Rank-Width of Edge-Colored Graphs</title><categories>cs.DM math.CO</categories><comments>It is an update of the last version generalising all the results to
  edge-colored graphs and answering some of the raised questions</comments><msc-class>68R05, 68R10, 05C20, 05C75</msc-class><acm-class>F.0; F.2.2; G.2.2</acm-class><journal-ref>Theory of Computing Systems 52(4):599-644(2013)</journal-ref><doi>10.1007/s00224-012-9399-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clique-width is a complexity measure of directed as well as undirected
graphs. Rank-width is an equivalent complexity measure for undirected graphs
and has good algorithmic and structural properties. It is in particular related
to the vertex-minor relation. We discuss an extension of the notion of
rank-width to edge-colored graphs. A C-colored graph is a graph where the arcs
are colored with colors from the set C. There is not a natural notion of
rank-width for C-colored graphs. We define two notions of rank-width for them,
both based on a coding of C-colored graphs by edge-colored graphs where each
edge has exactly one color from a field F and named respectively F-rank-width
and F-bi-rank-width. The two notions are equivalent to clique-width. We then
present a notion of vertex-minor for F-colored graphs and prove that F-colored
graphs of bounded F-rank-width are characterised by a finite list of F-colored
graphs to exclude as vertex-minors. A cubic-time algorithm to decide whether a
F-colored graph has F-rank-width (resp. F-bi-rank-width) at most k, for fixed
k, is also given. Graph operations to check MSOL-definable properties on
F-colored graphs of bounded rank-width are presented. A specialisation of all
these notions to (directed) graphs without edge colors is presented, which
shows that our results generalise the ones in undirected graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.1500</identifier>
 <datestamp>2010-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.1500</id><created>2007-09-10</created><updated>2007-11-22</updated><authors><author><keyname>Berstein</keyname><forenames>Yael</forenames></author><author><keyname>Onn</keyname><forenames>Shmuel</forenames></author></authors><title>The Graver Complexity of Integer Programming</title><categories>math.CO cs.CC cs.DM math.AC</categories><comments>Improved Bound $\Omega(2^m)$</comments><msc-class>05A, 15A, 51M, 52A, 52B, 52C, 62H, 68Q, 68R, 68U, 68W, 90B, 90C</msc-class><journal-ref>Annals of Combinatorics, 13:289--296, 2009</journal-ref><abstract>  In this article we establish an exponential lower bound on the Graver
complexity of integer programs. This provides new type of evidence supporting
the presumable intractability of integer programming. Specifically, we show
that the Graver complexity of the incidence matrix of the complete bipartite
graph $K_{3,m}$ satisfies $g(m)=\Omega(2^m)$, with $g(m)\geq 17\cdot 2^{m-3}-7$
for every $m&gt;3$ .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.1920</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.1920</id><created>2007-09-12</created><updated>2007-09-14</updated><authors><author><keyname>Bugeau</keyname><forenames>Aurelie</forenames><affiliation>IRISA</affiliation></author><author><keyname>Pérez</keyname><forenames>Patrick</forenames><affiliation>IRISA</affiliation></author></authors><title>Bandwidth selection for kernel estimation in mixed multi-dimensional
  spaces</title><categories>cs.CV</categories><proxy>ccsd inria-00171686</proxy><abstract>  Kernel estimation techniques, such as mean shift, suffer from one major
drawback: the kernel bandwidth selection. The bandwidth can be fixed for all
the data set or can vary at each points. Automatic bandwidth selection becomes
a real challenge in case of multidimensional heterogeneous features. This paper
presents a solution to this problem. It is an extension of \cite{Comaniciu03a}
which was based on the fundamental property of normal distributions regarding
the bias of the normalized density gradient. The selection is done iteratively
for each type of features, by looking for the stability of local bandwidth
estimates across a predefined range of bandwidths. A pseudo balloon mean shift
filtering and partitioning are introduced. The validity of the method is
demonstrated in the context of color image segmentation based on a
5-dimensional space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2065</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2065</id><created>2007-09-13</created><authors><author><keyname>Khrennikov</keyname><forenames>Andrei</forenames></author></authors><title>Toward Psycho-robots</title><categories>cs.AI</categories><journal-ref>Paladyn Volume 1, Number 2, 99-108, 2010</journal-ref><doi>10.2478/s13230-010-0014-0</doi><abstract>  We try to perform geometrization of psychology by representing mental states,
&lt;&lt;ideas&gt;&gt;, by points of a metric space, &lt;&lt;mental space&gt;&gt;. Evolution of ideas is
described by dynamical systems in metric mental space. We apply the mental
space approach for modeling of flows of unconscious and conscious information
in the human brain. In a series of models, Models 1-4, we consider cognitive
systems with increasing complexity of psychological behavior determined by
structure of flows of ideas. Since our models are in fact models of the
AI-type, one immediately recognizes that they can be used for creation of
AI-systems, which we call psycho-robots, exhibiting important elements of human
psyche. Creation of such psycho-robots may be useful improvement of domestic
robots. At the moment domestic robots are merely simple working devices (e.g.
vacuum cleaners or lawn mowers) . However, in future one can expect demand in
systems which be able not only perform simple work tasks, but would have
elements of human self-developing psyche. Such AI-psyche could play an
important role both in relations between psycho-robots and their owners as well
as between psycho-robots. Since the presence of a huge numbers of
psycho-complexes is an essential characteristic of human psychology, it would
be interesting to model them in the AI-framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2201</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2201</id><created>2007-09-14</created><updated>2010-07-29</updated><authors><author><keyname>Gilbert</keyname><forenames>Jesse</forenames></author></authors><title>A complete proof of The Graceful Tree Conjecture using the concept of
  Edge Degree</title><categories>cs.DM</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show the Graceful Tree Conjecture holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2512</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2512</id><created>2007-09-16</created><updated>2007-09-21</updated><authors><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Freedman</keyname><forenames>Daniel</forenames></author></authors><title>Quantifying Homology Classes II: Localization and Stability</title><categories>cs.CG cs.CC math.AT</categories><comments>The "companion paper" referred in this paper is another version of
  the paper "Measuring and localizing homology classes" by the same authors.
  Sept. 21st: authors name fixed</comments><acm-class>F.2.2; G.2.1</acm-class><abstract>  In the companion paper, we measured homology classes and computed the optimal
homology basis. This paper addresses two related problems, namely, localization
and stability. We localize a class with the cycle minimizing a certain
objective function. We explore three different objective functions, namely,
volume, diameter and radius. We show that it is NP-hard to compute the smallest
cycle using the former two. We also prove that the measurement defined in the
companion paper is stable with regard to small changes of the geometry of the
concerned space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2525</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2525</id><created>2007-09-17</created><updated>2010-07-29</updated><authors><author><keyname>Gilbert</keyname><forenames>Jesse</forenames></author></authors><title>H-Decompositions</title><categories>cs.DM</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for all graphs H of size n, the complete graph $K_{2n+1}$ has an
$H$-decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2618</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2618</id><created>2007-09-17</created><updated>2012-02-27</updated><authors><author><keyname>Picu</keyname><forenames>Andreea</forenames><affiliation>CITI, INRIA Rhône-Alpes</affiliation></author><author><keyname>Fraboulet</keyname><forenames>Antoine</forenames><affiliation>CITI, INRIA Rhône-Alpes</affiliation></author><author><keyname>Fleury</keyname><forenames>Eric</forenames><affiliation>CITI, INRIA Rhône-Alpes</affiliation></author></authors><title>On Frequency Optimisation for Power Saving in WSNs: Finding Optimum
  Hardware Timers Frequencies</title><categories>cs.NI</categories><proxy>ccsd inria-00172015</proxy><report-no>RR-6290</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks research and demand are now in full expansion, since
people came to understand these are the key to a large number of issues in
industry, commerce, home automation, healthcare, agriculture and environment,
monitoring, public safety etc. One of the most challenging research problems in
sensor networks research is power awareness and power-saving techniques. In
this master's thesis, we have studied one particular power-saving technique,
i.e. frequency scaling. In particular, we analysed the close relationship
between clock frequencies in a microcontroller and several types of constraints
imposed on these frequencies, e.g. by other components of the microcontroller,
by protocol specifications, by external factors etc. Among these constraints,
we were especially interested in the ones imposed by the timer service and by
the serial ports' transmission rates. Our efforts resulted in a microcontroller
configuration management tool which aims at assisting application programmers
in choosing microcontroller configurations, in function of the particular needs
and constraints of their application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2689</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2689</id><created>2007-09-17</created><updated>2007-09-21</updated><authors><author><keyname>Kettani</keyname><forenames>Omar</forenames></author></authors><title>An algorithm for solving the Independent Set problem</title><categories>cs.DM</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn by the author, due an error in claim 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2831</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2831</id><created>2007-09-18</created><updated>2007-12-14</updated><authors><author><keyname>Aanjaneya</keyname><forenames>Mridul</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Teillaud</keyname><forenames>Monique</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Triangulating the Real Projective Plane</title><categories>cs.CG</categories><proxy>ccsd inria-00172999</proxy><abstract>  We consider the problem of computing a triangulation of the real projective
plane P2, given a finite point set S={p1, p2,..., pn} as input. We prove that a
triangulation of P2 always exists if at least six points in S are in general
position, i.e., no three of them are collinear. We also design an algorithm for
triangulating P2 if this necessary condition holds. As far as we know, this is
the first computational result on the real projective plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.2962</identifier>
 <datestamp>2010-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.2962</id><created>2007-09-19</created><updated>2009-01-22</updated><authors><author><keyname>Esik</keyname><forenames>Zoltan</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>Algebraic characterization of logically defined tree languages</title><categories>cs.LO math.LO</categories><comments>46 pages. Version 3: various local improvements (more typos
  corrected, and "intuitive" explanations added)</comments><proxy>ccsd hal-00173125</proxy><acm-class>F.4.3; F.4.1</acm-class><journal-ref>International Journal of Algebra and Computation 20 (2010) 195-239</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algebraic characterization of the tree languages that are defined
by logical formulas using certain Lindstr\"om quantifiers. An important
instance of our result concerns first-order definable tree languages. Our
characterization relies on the usage of preclones, an algebraic structure
introduced by the authors in a previous paper, and of the block product
operation on preclones. Our results generalize analogous results on finite word
languages, but it must be noted that, as they stand, they do not yield an
algorithm to decide whether a given regular tree language is first-order
definable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.3283</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.3283</id><created>2007-09-20</created><authors><author><keyname>Kettner</keyname><forenames>Michael</forenames></author></authors><title>Algorithmic and topological aspects of semi-algebraic sets defined by
  quadratic polynomial</title><categories>math.AG cs.CG math.AT math.GT</categories><comments>PhD thesis, final version, 109 pages, 9 figures</comments><abstract>  In this thesis, we consider semi-algebraic sets over a real closed field $R$
defined by quadratic polynomials. Semi-algebraic sets of $R^k$ are defined as
the smallest family of sets in $R^k$ that contains the algebraic sets as well
as the sets defined by polynomial inequalities, and which is also closed under
the boolean operations (complementation, finite unions and finite
intersections). We prove new bounds on the Betti numbers as well as on the
number of different stable homotopy types of certain fibers of semi-algebraic
sets over a real closed field $R$ defined by quadratic polynomials, in terms of
the parameters of the system of polynomials defining them, which improve the
known results. We conclude the thesis with presenting two new algorithms along
with their implementations. The first algorithm computes the number of
connected components and the first Betti number of a semi-algebraic set defined
by compact objects in $\mathbb{R}^k$ which are simply connected. This algorithm
improves the well-know method using a triangulation of the semi-algebraic set.
Moreover, the algorithm has been efficiently implemented which was not possible
before. The second algorithm computes efficiently the real intersection of
three quadratic surfaces in $\mathbb{R}^3$ using a semi-numerical approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.3334</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.3334</id><created>2007-09-20</created><updated>2011-05-17</updated><authors><author><keyname>Wang</keyname><forenames>Yong</forenames></author></authors><title>Mistake Analyses on Proof about Perfect Secrecy of One-time-pad</title><categories>cs.CR</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.3590</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.3590</id><created>2007-09-24</created><updated>2010-07-29</updated><authors><author><keyname>Gilbert</keyname><forenames>Jesse</forenames></author></authors><title>An extension of a result concerning convex geometric graphs</title><categories>cs.DM</categories><comments>This paper has been withdrawn by the author. This paper was presented
  at Discrete Math Days in Fort Collins Colorado</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a general result known as the Erdos_Sos Conjecture: if
$E(G)&gt;{1/2}(k-1)n$ where $G$ has order $n$ then $G$ contains every tree of
order $k+1$ as a subgraph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.4303</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.4303</id><created>2007-09-26</created><updated>2011-05-17</updated><authors><author><keyname>Wang</keyname><forenames>Yong</forenames></author></authors><title>Security Analyses of One-time System</title><categories>cs.CR</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.4420</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.4420</id><created>2007-09-27</created><updated>2011-05-17</updated><authors><author><keyname>Wang</keyname><forenames>Yong</forenames></author></authors><title>Confirmation of Shannon's Mistake about Perfect Secrecy of One-time-pad</title><categories>cs.CR</categories><comments>This paper has been withdrawn</comments><abstract>  This paper has been withdrawn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0709.4669</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0709.4669</id><created>2007-09-28</created><authors><author><keyname>Fuad</keyname><forenames>Muhammad Marwan Muhammad</forenames><affiliation>VALORIA</affiliation></author><author><keyname>Marteau</keyname><forenames>Pierre-François</forenames><affiliation>VALORIA</affiliation></author></authors><title>The Extended Edit Distance Metric</title><categories>cs.IR</categories><comments>Technical report</comments><proxy>ccsd hal-00175552</proxy><acm-class>H.3</acm-class><journal-ref>Content-Based Multimedia Indexing, CBMI 2008, london : United
  Kingdom (2008)</journal-ref><doi>10.1109/CBMI.2008.4564953</doi><abstract>  Similarity search is an important problem in information retrieval. This
similarity is based on a distance. Symbolic representation of time series has
attracted many researchers recently, since it reduces the dimensionality of
these high dimensional data objects. We propose a new distance metric that is
applied to symbolic data objects and we test it on time series data bases in a
classification task. We compare it to other distances that are well known in
the literature for symbolic data objects. We also prove, mathematically, that
our distance is metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.0262</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.0262</id><created>2007-10-01</created><updated>2007-11-01</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Incomplete Lineage Sorting: Consistent Phylogeny Estimation From
  Multiple Loci</title><categories>q-bio.PE cs.CE cs.DS math.PR math.ST stat.TH</categories><comments>Added a section on more general distance-based methods</comments><abstract>  We introduce a simple algorithm for reconstructing phylogenies from multiple
gene trees in the presence of incomplete lineage sorting, that is, when the
topology of the gene trees may differ from that of the species tree. We show
that our technique is statistically consistent under standard stochastic
assumptions, that is, it returns the correct tree given sufficiently many
unlinked loci. We also show that it can tolerate moderate estimation errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.0528</identifier>
 <datestamp>2012-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.0528</id><created>2007-10-02</created><updated>2009-07-28</updated><authors><author><keyname>Amato</keyname><forenames>Gianluca</forenames></author><author><keyname>Scozzari</keyname><forenames>Francesca</forenames></author></authors><title>On the interaction between sharing and linearity</title><categories>cs.PL cs.LO</categories><journal-ref>Theory and Practice of Logic Programming, volume 10, issue 01, pp.
  49-112, 2010</journal-ref><doi>10.1017/S1471068409990160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the analysis of logic programs, abstract domains for detecting sharing and
linearity information are widely used. Devising abstract unification algorithms
for such domains has proved to be rather hard. At the moment, the available
algorithms are correct but not optimal, i.e., they cannot fully exploit the
information conveyed by the abstract domains. In this paper, we define a new
(infinite) domain ShLin-w which can be thought of as a general framework from
which other domains can be easily derived by abstraction. ShLin-w makes the
interaction between sharing and linearity explicit. We provide a constructive
characterization of the optimal abstract unification operator on ShLin-w and we
lift it to two well-known abstractions of ShLin-w. Namely, to the classical
Sharing X Lin abstract domain and to the more precise ShLin-2 abstract domain
by Andy King. In the case of single binding substitutions, we obtain optimal
abstract unification algorithms for such domains.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.0531</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.0531</id><created>2007-10-02</created><authors><author><keyname>Daneshgaran</keyname><forenames>Fred</forenames></author><author><keyname>Laddomada</keyname><forenames>Massimiliano</forenames></author><author><keyname>Mondin</keyname><forenames>Marina</forenames></author></authors><title>The Problem of Localization in Networks of Randomly Deployed Nodes:
  Asymptotic and Finite Analysis, and Thresholds</title><categories>cs.DM cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE transactions on information theory (Submission date
  October 1, 2007)</comments><abstract>  We derive the probability that a randomly chosen NL-node over $S$ gets
localized as a function of a variety of parameters. Then, we derive the
probability that the whole network of NL-nodes over $S$ gets localized. In
connection with the asymptotic thresholds, we show the presence of asymptotic
thresholds on the network localization probability in two different scenarios.
The first refers to dense networks, which arise when the domain $S$ is bounded
and the densities of the two kinds of nodes tend to grow unboundedly. The
second kind of thresholds manifest themselves when the considered domain
increases but the number of nodes grow in such a way that the L-node density
remains constant throughout the investigated domain. In this scenario, what
matters is the minimum value of the maximum transmission range averaged over
the fading process, denoted as $d_{max}$, above which the network of NL-nodes
almost surely gets asymptotically localized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.0556</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.0556</id><created>2007-10-02</created><updated>2007-12-28</updated><authors><author><keyname>Dai</keyname><forenames>Xianhua</forenames></author><author><keyname>Belavkin</keyname><forenames>V. P.</forenames></author></authors><title>A Game Theoretic Approach to Quantum Information</title><categories>quant-ph cs.GT cs.IT math.IT</categories><comments>35 pages</comments><abstract>  This work is an application of game theory to quantum information. In a state
estimate, we are given observations distributed according to an unknown
distribution $P_{\theta}$ (associated with award $Q$), which Nature chooses at
random from the set $\{P_{\theta}: \theta \in \Theta \}$ according to a known
prior distribution $\mu$ on $\Theta$, we produce an estimate $M$ for the
unknown distribution $P_{\theta}$, and in the end, we will suffer a relative
entropy cost $\mathcal{R}(P;M)$, measuring the quality of this estimate,
therefore the whole utility is taken as $P \cdot Q -\mathcal{R}(P; M)$.
  In an introduction to strategic game, a sufficient condition for minimax
theorem is obtained; An estimate is explored in the frame of game theory, and
in the view of convex conjugate, we reach one new approach to quantum relative
entropy, correspondingly quantum mutual entropy, and quantum channel capacity,
which are more general, in the sense, without Radon-Nikodym (RN) derivatives.
Also the monotonicity of quantum relative entropy and the additivity of quantum
channel capacity are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.0672</identifier>
 <datestamp>2011-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.0672</id><created>2007-10-03</created><updated>2007-10-04</updated><authors><author><keyname>Vieira</keyname><forenames>Fabio R. J.</forenames></author><author><keyname>Barbosa</keyname><forenames>Valmir C.</forenames></author></authors><title>Optimization of supply diversity for the self-assembly of simple objects
  in two and three dimensions</title><categories>cs.NE</categories><comments>Minor typos corrected</comments><journal-ref>Natural Computing 10 (2011), 551-581</journal-ref><doi>10.1007/s11047-010-9209-x</doi><abstract>  The field of algorithmic self-assembly is concerned with the design and
analysis of self-assembly systems from a computational perspective, that is,
from the perspective of mathematical problems whose study may give insight into
the natural processes through which elementary objects self-assemble into more
complex ones. One of the main problems of algorithmic self-assembly is the
minimum tile set problem (MTSP), which asks for a collection of types of
elementary objects (called tiles) to be found for the self-assembly of an
object having a pre-established shape. Such a collection is to be as concise as
possible, thus minimizing supply diversity, while satisfying a set of stringent
constraints having to do with the termination and other properties of the
self-assembly process from its tile types. We present a study of what we think
is the first practical approach to MTSP. Our study starts with the introduction
of an evolutionary heuristic to tackle MTSP and includes results from extensive
experimentation with the heuristic on the self-assembly of simple objects in
two and three dimensions. The heuristic we introduce combines classic elements
from the field of evolutionary computation with a problem-specific variant of
Pareto dominance into a multi-objective approach to MTSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.0736</identifier>
 <datestamp>2014-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.0736</id><created>2007-10-03</created><authors><author><keyname>Kay</keyname><forenames>David A</forenames><affiliation>Oxford University Computational Laboratory</affiliation></author><author><keyname>Tomasi</keyname><forenames>Alessandro</forenames><affiliation>University of Sussex</affiliation></author></authors><title>Colour image segmentation by the vector-valued Allen-Cahn phase-field
  model: a multigrid solution</title><categories>cs.CV cs.NA</categories><comments>17 pages, 9 figures</comments><acm-class>I.4.6; G.1.8</acm-class><doi>10.1109/TIP.2009.2026678</doi><abstract>  We propose a new method for the numerical solution of a PDE-driven model for
colour image segmentation and give numerical examples of the results. The
method combines the vector-valued Allen-Cahn phase field equation with initial
data fitting terms. This method is known to be closely related to the
Mumford-Shah problem and the level set segmentation by Chan and Vese. Our
numerical solution is performed using a multigrid splitting of a finite element
space, thereby producing an efficient and robust method for the segmentation of
large images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.1418</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.1418</id><created>2007-10-07</created><authors><author><keyname>Anashin</keyname><forenames>Vladimir</forenames></author></authors><title>Non-Archimedean Ergodic Theory and Pseudorandom Generators</title><categories>math.DS cs.IT math.IT</categories><comments>Submitted to The Computer Journal</comments><msc-class>37A25 (Primary) 11K45, 26E30, 94A60 (Secondary)</msc-class><journal-ref>The Computer Journal, 53(4):370--392, 2010</journal-ref><doi>10.1093/comjnl/bxm101</doi><abstract>  The paper develops techniques in order to construct computer programs,
pseudorandom number generators (PRNG), that produce uniformly distributed
sequences. The paper exploits an approach that treats standard processor
instructions (arithmetic and bitwise logical ones) as continuous functions on
the space of 2-adic integers. Within this approach, a PRNG is considered as a
dynamical system and is studied by means of the non-Archimedean ergodic theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.1435</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.1435</id><created>2007-10-07</created><updated>2010-09-26</updated><authors><author><keyname>Drineas</keyname><forenames>Petros</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author><author><keyname>Sarlos</keyname><forenames>Tamas</forenames></author></authors><title>Faster Least Squares Approximation</title><categories>cs.DS</categories><comments>25 pages; minor changes from previous version; this version will
  appear in Numerische Mathematik</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Least squares approximation is a technique to find an approximate solution to
a system of linear equations that has no exact solution. In a typical setting,
one lets $n$ be the number of constraints and $d$ be the number of variables,
with $n \gg d$. Then, existing exact methods find a solution vector in
$O(nd^2)$ time. We present two randomized algorithms that provide very accurate
relative-error approximations to the optimal value and the solution vector of a
least squares approximation problem more rapidly than existing exact
algorithms. Both of our algorithms preprocess the data with the Randomized
Hadamard Transform. One then uniformly randomly samples constraints and solves
the smaller problem on those constraints, and the other performs a sparse
random projection and solves the smaller problem on those projected
coordinates. In both cases, solving the smaller problem provides relative-error
approximations, and, if $n$ is sufficiently larger than $d$, the approximate
solution can be computed in $O(nd \log d)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.1641</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.1641</id><created>2007-10-09</created><updated>2007-11-30</updated><authors><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>A polynomial bound for untangling geometric planar graphs</title><categories>cs.CG cs.DM math.CO</categories><comments>14 pages, 7 figures</comments><journal-ref>Discrete &amp; Computational Geometry 42(4):570-585, 2009</journal-ref><doi>10.1007/s00454-008-9125-3</doi><abstract>  To untangle a geometric graph means to move some of the vertices so that the
resulting geometric graph has no crossings. Pach and Tardos [Discrete Comput.
Geom., 2002] asked if every n-vertex geometric planar graph can be untangled
while keeping at least n^\epsilon vertices fixed. We answer this question in
the affirmative with \epsilon=1/4. The previous best known bound was
\Omega((\log n / \log\log n)^{1/2}). We also consider untangling geometric
trees. It is known that every n-vertex geometric tree can be untangled while
keeping at least (n/3)^{1/2} vertices fixed, while the best upper bound was
O(n\log n)^{2/3}. We answer a question of Spillner and Wolff [arXiv:0709.0170
2007] by closing this gap for untangling trees. In particular, we show that for
infinitely many values of n, there is an n-vertex geometric tree that cannot be
untangled while keeping more than 3(n^{1/2}-1) vertices fixed. Moreover, we
improve the lower bound to (n/2)^{1/2}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.1976</identifier>
 <datestamp>2012-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.1976</id><created>2007-10-10</created><authors><author><keyname>Ishimoto</keyname><forenames>Yukitaka</forenames></author></authors><title>Solving Infinite Kolam in Knot Theory</title><categories>cs.DM cond-mat.stat-mech</categories><comments>13 pages, 2 figures, the final version for FORMA with typo fixed</comments><report-no>OIQP-06-15</report-no><journal-ref>Forma 22 (2007) 15-30</journal-ref><abstract>  In south India, there are traditional patterns of line-drawings encircling
dots, called ``Kolam'', among which one-line drawings or the ``infinite Kolam''
provide very interesting questions in mathematics. For example, we address the
following simple question: how many patterns of infinite Kolam can we draw for
a given grid pattern of dots? The simplest way is to draw possible patterns of
Kolam while judging if it is infinite Kolam. Such a search problem seems to be
NP complete. However, it is certainly not. In this paper, we focus on
diamond-shaped grid patterns of dots, (1-3-5-3-1) and (1-3-5-7-5-3-1) in
particular. By using the knot-theory description of the infinite Kolam, we show
how to find the solution, which inevitably gives a sketch of the proof for the
statement ``infinite Kolam is not NP complete.'' Its further discussion will be
given in the final section.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.3603</identifier>
 <datestamp>2014-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.3603</id><created>2007-10-18</created><updated>2009-07-07</updated><authors><author><keyname>Burke</keyname><forenames>Edmund K.</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author><author><keyname>Parkes</keyname><forenames>Andrew J.</forenames></author><author><keyname>Rudova</keyname><forenames>Hana</forenames></author></authors><title>On a Clique-Based Integer Programming Formulation of Vertex Colouring
  with Applications in Course Timetabling</title><categories>cs.DM cs.DS math.CO</categories><report-no>NOTTCS-TR-2007-10</report-no><acm-class>G.1.6; G.2.2; G.2.3</acm-class><journal-ref>Annals of Operations Research (2010) 179(1), 105-130</journal-ref><doi>10.1007/s10479-010-0716-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vertex colouring is a well-known problem in combinatorial optimisation, whose
alternative integer programming formulations have recently attracted
considerable attention. This paper briefly surveys seven known formulations of
vertex colouring and introduces a formulation of vertex colouring using a
suitable clique partition of the graph. This formulation is applicable in
timetabling applications, where such a clique partition of the conflict graph
is given implicitly. In contrast with some alternatives, the presented
formulation can also be easily extended to accommodate complex performance
indicators (``soft constraints'') imposed in a number of real-life course
timetabling applications. Its performance depends on the quality of the clique
partition, but encouraging empirical results for the Udine Course Timetabling
problem are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.3979</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.3979</id><created>2007-10-22</created><updated>2007-10-26</updated><authors><author><keyname>Yurcik</keyname><forenames>William</forenames></author><author><keyname>Woolam</keyname><forenames>Clay</forenames></author><author><keyname>Hellings</keyname><forenames>Greg</forenames></author><author><keyname>Khan</keyname><forenames>Latifur</forenames></author><author><keyname>Thuraisingham</keyname><forenames>Bhavani</forenames></author></authors><title>Toward Trusted Sharing of Network Packet Traces Using Anonymization:
  Single-Field Privacy/Analysis Tradeoffs</title><categories>cs.CR cs.NI</categories><comments>8 pages,1 figure, 4 tables</comments><acm-class>C.2.0; C.2.3; C.2.m; D.3.4; K.6.5</acm-class><abstract>  Network data needs to be shared for distributed security analysis.
Anonymization of network data for sharing sets up a fundamental tradeoff
between privacy protection versus security analysis capability. This
privacy/analysis tradeoff has been acknowledged by many researchers but this is
the first paper to provide empirical measurements to characterize the
privacy/analysis tradeoff for an enterprise dataset. Specifically we perform
anonymization options on single-fields within network packet traces and then
make measurements using intrusion detection system alarms as a proxy for
security analysis capability. Our results show: (1) two fields have a zero sum
tradeoff (more privacy lessens security analysis and vice versa) and (2) eight
fields have a more complex tradeoff (that is not zero sum) in which both
privacy and analysis can both be simultaneously accomplished.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4031</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4031</id><created>2007-10-22</created><authors><author><keyname>Blondin-Massé</keyname><forenames>Alexandre</forenames></author><author><keyname>Brlek</keyname><forenames>Srecko</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Labbé</keyname><forenames>Sébastien</forenames></author></authors><title>On the critical exponent of generalized Thue-Morse words</title><categories>math.CO cs.DM</categories><comments>13 pages; to appear in Discrete Mathematics and Theoretical Computer
  Science (accepted October 15, 2007)</comments><msc-class>68R15; 11B85</msc-class><journal-ref>Discrete Mathematics and Theoretical Computer Science 9 (2007)
  293-304</journal-ref><abstract>  For certain generalized Thue-Morse words t, we compute the "critical
exponent", i.e., the supremum of the set of rational numbers that are exponents
of powers in t, and determine exactly the occurrences of powers realizing it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4051</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4051</id><created>2007-10-22</created><updated>2010-07-09</updated><authors><author><keyname>Dumont</keyname><forenames>Julien</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Hachem</keyname><forenames>W.</forenames><affiliation>LTCI</affiliation></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Loubaton</keyname><forenames>Philippe</forenames><affiliation>IGM-LabInfo</affiliation></author><author><keyname>Najim</keyname><forenames>Jamal</forenames><affiliation>LTCI</affiliation></author></authors><title>On the capacity achieving covariance matrix for Rician MIMO channels: an
  asymptotic approach</title><categories>math.PR cs.IT math.IT</categories><comments>56 pp. Extended version of the published article in IEEE Inf. Th.
  (march 2010) with more proofs</comments><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Information Theory 56, 3 (2010) 1048--1069</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity-achieving input covariance matrices for coherent block-fading
correlated MIMO Rician channels are determined. In this case, no closed-form
expressions for the eigenvectors of the optimum input covariance matrix are
available. An approximation of the average mutual information is evaluated in
this paper in the asymptotic regime where the number of transmit and receive
antennas converge to $+\infty$. New results related to the accuracy of the
corresponding large system approximation are provided. An attractive
optimization algorithm of this approximation is proposed and we establish that
it yields an effective way to compute the capacity achieving covariance matrix
for the average mutual information. Finally, numerical simulation results show
that, even for a moderate number of transmit and receive antennas, the new
approach provides the same results as direct maximization approaches of the
average mutual information, while being much more computationally attractive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4180</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4180</id><created>2007-10-22</created><authors><author><keyname>Kimura</keyname><forenames>Akisato</forenames></author><author><keyname>Kashino</keyname><forenames>Kunio</forenames></author><author><keyname>Kurozumi</keyname><forenames>Takayuki</forenames></author><author><keyname>Murase</keyname><forenames>Hiroshi</forenames></author></authors><title>A quick search method for audio signals based on a piecewise linear
  representation of feature trajectories</title><categories>cs.MM cs.DB</categories><comments>20 pages, to appear in IEEE Transactions on Audio, Speech and
  Language Processing</comments><journal-ref>IEEE Transactions on Audio, Speech and Language Processing,
  Vol.16, No.2, pp.396-407, February 2008.</journal-ref><doi>10.1109/TASL.2007.912362</doi><abstract>  This paper presents a new method for a quick similarity-based search through
long unlabeled audio streams to detect and locate audio clips provided by
users. The method involves feature-dimension reduction based on a piecewise
linear representation of a sequential feature trajectory extracted from a long
audio stream. Two techniques enable us to obtain a piecewise linear
representation: the dynamic segmentation of feature trajectories and the
segment-based Karhunen-L\'{o}eve (KL) transform. The proposed search method
guarantees the same search results as the search method without the proposed
feature-dimension reduction method in principle. Experiment results indicate
significant improvements in search speed. For example the proposed method
reduced the total search time to approximately 1/12 that of previous methods
and detected queries in approximately 0.3 seconds from a 200-hour audio
database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4231</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4231</id><created>2007-10-23</created><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author><author><keyname>Ohsawa</keyname><forenames>Yukio</forenames></author></authors><title>Analyzing covert social network foundation behind terrorism disaster</title><categories>cs.AI</categories><comments>17pages, 10 figures, submitted to Int. J. Services Sciences</comments><journal-ref>International Journal of Services Sciences Vol.2, pp.125-141
  (2009)</journal-ref><doi>10.1504/IJSSCI.2009.024936</doi><abstract>  This paper addresses a method to analyze the covert social network foundation
hidden behind the terrorism disaster. It is to solve a node discovery problem,
which means to discover a node, which functions relevantly in a social network,
but escaped from monitoring on the presence and mutual relationship of nodes.
The method aims at integrating the expert investigator's prior understanding,
insight on the terrorists' social network nature derived from the complex graph
theory, and computational data processing. The social network responsible for
the 9/11 attack in 2001 is used to execute simulation experiment to evaluate
the performance of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4410</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4410</id><created>2007-10-24</created><authors><author><keyname>Brent</keyname><forenames>Richard</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Zimmermann</keyname><forenames>Paul</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>A Multi-level Blocking Distinct Degree Factorization Algorithm</title><categories>cs.DS</categories><proxy>ccsd inria-00181029</proxy><report-no>INRIA Tech. Report RR-6331, Oct. 2007</report-no><journal-ref>Contemporary Mathematics 461 (2008) 47-58</journal-ref><abstract>  We give a new algorithm for performing the distinct-degree factorization of a
polynomial P(x) over GF(2), using a multi-level blocking strategy. The coarsest
level of blocking replaces GCD computations by multiplications, as suggested by
Pollard (1975), von zur Gathen and Shoup (1992), and others. The novelty of our
approach is that a finer level of blocking replaces multiplications by
squarings, which speeds up the computation in GF(2)[x]/P(x) of certain interval
polynomials when P(x) is sparse. As an application we give a fast algorithm to
search for all irreducible trinomials x^r + x^s + 1 of degree r over GF(2),
while producing a certificate that can be checked in less time than the full
search. Naive algorithms cost O(r^2) per trinomial, thus O(r^3) to search over
all trinomials of given degree r. Under a plausible assumption about the
distribution of factors of trinomials, the new algorithm has complexity O(r^2
(log r)^{3/2}(log log r)^{1/2}) for the search over all trinomials of degree r.
Our implementation achieves a speedup of greater than a factor of 560 over the
naive algorithm in the case r = 24036583 (a Mersenne exponent). Using our
program, we have found two new primitive trinomials of degree 24036583 over
GF(2) (the previous record degree was 6972593).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4508</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4508</id><created>2007-10-24</created><updated>2008-03-19</updated><authors><author><keyname>Cucker</keyname><forenames>Felipe</forenames></author><author><keyname>Krick</keyname><forenames>Teresa</forenames></author><author><keyname>Malajovich</keyname><forenames>Gregorio</forenames></author><author><keyname>Wschebor</keyname><forenames>Mario</forenames></author></authors><title>A Numerical Algorithm for Zero Counting. I: Complexity and Accuracy</title><categories>cs.CC cs.NA cs.SC math.NA</categories><comments>We made minor but necessary improvements in the presentation</comments><acm-class>F.2.1; G.1; I.1.2</acm-class><journal-ref>Journal of Complexity 24 Issues 5-6, pp 582-605 (Oct-Dec 2008)</journal-ref><doi>10.1016/j.jco.2008.03.001</doi><abstract>  We describe an algorithm to count the number of distinct real zeros of a
polynomial (square) system f. The algorithm performs O(n D kappa(f)) iterations
where n is the number of polynomials (as well as the dimension of the ambient
space), D is a bound on the polynomials' degree, and kappa(f) is a condition
number for the system. Each iteration uses an exponential number of operations.
The algorithm uses finite-precision arithmetic and a polynomial bound for the
precision required to ensure the returned output is correct is exhibited. This
bound is a major feature of our algorithm since it is in contrast with the
exponential precision required by the existing (symbolic) algorithms for
counting real zeros. The algorithm parallelizes well in the sense that each
iteration can be computed in parallel polynomial time with an exponential
number of processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4629</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4629</id><created>2007-10-25</created><authors><author><keyname>Katz</keyname><forenames>Jacob</forenames></author><author><keyname>Hanna</keyname><forenames>Ziyad</forenames></author><author><keyname>Dershowitz</keyname><forenames>Nachum</forenames></author></authors><title>Space-Efficient Bounded Model Checking</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181188</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><doi>10.1109/DATE.2005.276</doi><abstract>  Current algorithms for bounded model checking use SAT methods for checking
satisfiability of Boolean formulae. These methods suffer from the potential
memory explosion problem. Methods based on the validity of Quantified Boolean
Formulae (QBF) allow an exponentially more succinct representation of formulae
to be checked, because no "unrolling" of the transition relation is required.
These methods have not been widely used, because of the lack of an efficient
decision procedure for QBF. We evaluate the usage of QBF in bounded model
checking (BMC), using general-purpose SAT and QBF solvers. We develop a
special-purpose decision procedure for QBF used in BMC, and compare our
technique with the methods using general-purpose SAT and QBF solvers on
real-life industrial benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4630</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4630</id><created>2007-10-25</created><authors><author><keyname>Mcconaghy</keyname><forenames>Trent</forenames></author><author><keyname>Eeckelaert</keyname><forenames>Tom</forenames></author><author><keyname>Gielen</keyname><forenames>Georges</forenames></author></authors><title>CAFFEINE: Template-Free Symbolic Model Generation of Analog Circuits via
  Canonical Form Functions and Genetic Programming</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181274</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents a method to automatically generate compact symbolic
performance models of analog circuits with no prior specification of an
equation template. The approach takes SPICE simulation data as input, which
enables modeling of any nonlinear circuits and circuit characteristics. Genetic
programming is applied as a means of traversing the space of possible symbolic
expressions. A grammar is specially designed to constrain the search to a
canonical form for functions. Novel evolutionary search operators are designed
to exploit the structure of the grammar. The approach generates a set of
symbolic models which collectively provide a tradeoff between error and model
complexity. Experimental results show that the symbolic models generated are
compact and easy to understand, making this an effective method for aiding
understanding in analog design. The models also demonstrate better prediction
quality than posynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4632</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4632</id><created>2007-10-25</created><authors><author><keyname>Kavvadias</keyname><forenames>Nikolaos</forenames></author><author><keyname>Nikolaidis</keyname><forenames>Spiridon</forenames></author></authors><title>Hardware Support for Arbitrarily Complex Loop Structures in Embedded
  Applications</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181271</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, the program control unit of an embedded RISC processor is
enhanced with a novel zero-overhead loop controller (ZOLC) supporting arbitrary
loop structures with multiple-entry/exit nodes. The ZOLC has been incorporated
to an open RISC processor core to evaluate the performance of the proposed unit
for alternative configurations of the selected processor. It is proven that
speed improvements of 8.4% to 48.2% are feasible for the used benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4633</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4633</id><created>2007-10-25</created><authors><author><keyname>Sukhwani</keyname><forenames>Bharat</forenames></author><author><keyname>Padmanabhan</keyname><forenames>Uday</forenames></author><author><keyname>Wang</keyname><forenames>Janet M.</forenames></author></authors><title>Nano-Sim: A Step Wise Equivalent Conductance based Statistical Simulator
  for Nanotechnology Circuit Design</title><categories>cs.PF</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181202</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><doi>10.1109/DATE.2005.221</doi><abstract>  New nanotechnology based devices are replacing CMOS devices to overcome CMOS
technology's scaling limitations. However, many such devices exhibit
non-monotonic I-V characteristics and uncertain properties which lead to the
negative differential resistance (NDR) problem and the chaotic performance.
This paper proposes a new circuit simulation approach that can effectively
simulate nanotechnology devices with uncertain input sources and negative
differential resistance (NDR) problem. The experimental results show a 20-30
times speedup comparing with existing simulators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4634</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4634</id><created>2007-10-25</created><authors><author><keyname>Kumar</keyname><forenames>Y. Satish</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author><author><keyname>Talarico</keyname><forenames>Claudio</forenames></author><author><keyname>Wang</keyname><forenames>Janet</forenames></author></authors><title>A Probabilistic Collocation Method Based Statistical Gate Delay Model
  Considering Process Variations and Multiple Input Switching</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181207</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><doi>10.1109/DATE.2005.31</doi><abstract>  Since the advent of new nanotechnologies, the variability of gate delay due
to process variations has become a major concern. This paper proposes a new
gate delay model that includes impact from both process variations and multiple
input switching. The proposed model uses orthogonal polynomial based
probabilistic collocation method to construct a delay analytical equation from
circuit timing performance. From the experimental results, our approach has
less that 0.2% error on the mean delay of gates and less than 3% error on the
standard deviation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4635</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4635</id><created>2007-10-25</created><authors><author><keyname>Takeuchi</keyname><forenames>Tadashi</forenames></author></authors><title>OS Debugging Method Using a Lightweight Virtual Machine Monitor</title><categories>cs.OS</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181270</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Demands for implementing original OSs that can achieve high I/O performance
on PC/AT compatible hardware have recently been increasing, but conventional OS
debugging environments have not been able to simultaneously assure their
stability, be easily customized to new OSs and new I/O devices, and assure
efficient execution of I/O operations. We therefore developed a novel OS
debugging method using a lightweight virtual machine. We evaluated this
debugging method experimentally and confirmed that it can transfer data about
5.4 times as fast as the conventional virtual machine monitor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4636</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4636</id><created>2007-10-25</created><authors><author><keyname>Mellor</keyname><forenames>Stephen J.</forenames></author><author><keyname>Wolfe</keyname><forenames>John R.</forenames></author><author><keyname>Mccausland</keyname><forenames>Campbell</forenames></author></authors><title>Why Systems-on-Chip Needs More UML like a Hole in the Head</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181221</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Let's be clear from the outset: SoC can most certainly make use of UML; SoC
just doesn't need more UML, or even all of it. The advent of model mappings,
coupled with marks that indicate which mapping rule to apply, enable a major
simplification of the use of UML in SoC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4637</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4637</id><created>2007-10-25</created><authors><author><keyname>Pomeranz</keyname><forenames>Irith</forenames></author><author><keyname>Reddy</keyname><forenames>Sudhakar M.</forenames></author></authors><title>The Accidental Detection Index as a Fault Ordering Heuristic for
  Full-Scan Circuits</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181262</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We investigate a new fault ordering heuristic for test generation in
full-scan circuits. The heuristic is referred to as the accidental detection
index. It associates a value ADI (f) with every circuit fault f. The heuristic
estimates the number of faults that will be detected by a test generated for f.
Fault ordering is done such that a fault with a higher accidental detection
index appears earlier in the ordered fault set and targeted earlier during test
generation. This order is effective for generating compact test sets, and for
obtaining a test set with a steep fault coverage curve. Such a test set has
several applications. We present experimental results to demonstrate the
effectiveness of the heuristic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4638</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4638</id><created>2007-10-25</created><authors><author><keyname>Kallakuri</keyname><forenames>Sankalp S.</forenames></author><author><keyname>Doboli</keyname><forenames>Alex</forenames></author><author><keyname>Feinberg</keyname><forenames>Eugene A.</forenames></author></authors><title>Buffer Insertion for Bridges and Optimal Buffer Sizing for Communication
  Sub-System of Systems-on-Chip</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181217</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We have presented an optimal buffer sizing and buffer insertion methodology
which uses stochastic models of the architecture and Continuous Time Markov
Decision Processes CTMDPs. Such a methodology is useful in managing the scarce
buffer resources available on chip as compared to network based data
communication which can have large buffer space. The modeling of this problem
in terms of a CT-MDP framework lead to a nonlinear formulation due to usage of
bridges in the bus architecture. We present a methodology to split the problem
into several smaller though linear systems and we then solve these subsystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4639</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4639</id><created>2007-10-25</created><authors><author><keyname>Forzan</keyname><forenames>Cristiano</forenames></author><author><keyname>Pandini</keyname><forenames>Davide</forenames></author></authors><title>Modeling the Non-Linear Behavior of Library Cells for an Accurate Static
  Noise Analysis</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181255</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In signal integrity analysis, the joint effect of propagated noise through
library cells, and of the noise injected on a quiet net by neighboring
switching nets through coupling capacitances, must be considered in order to
accurately estimate the overall noise impact on design functionality and
performances. In this work the impact of the cell non-linearity on the noise
glitch waveform is analyzed in detail, and a new macromodel that allows to
accurately and efficiently modeling the non-linear effects of the victim driver
in noise analysis is presented. Experimental results demonstrate the
effectiveness of our method, and confirm that existing noise analysis
approaches based on linear superposition of the propagated and
crosstalk-injected noise can be highly inaccurate, thus impairing the sign-off
functional verification phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4640</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4640</id><created>2007-10-25</created><authors><author><keyname>Issenin</keyname><forenames>Ilya</forenames></author><author><keyname>Dutt</keyname><forenames>Nikil</forenames></author></authors><title>FORAY-GEN: Automatic Generation of Affine Functions for Memory
  Optimizations</title><categories>cs.PL</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181214</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In today's embedded applications a significant portion of energy is spent in
the memory subsystem. Several approaches have been proposed to minimize this
energy, including the use of scratch pad memories, with many based on static
analysis of a program. However, often it is not possible to perform static
analysis and optimization of a program's memory access behavior unless the
program is specifically written for this purpose. In this paper we introduce
the FORAY model of a program that permits aggressive analysis of the
application's memory behavior that further enables such optimizations since it
consists of 'for' loops and array accesses which are easily analyzable. We
present FORAY-GEN: an automated profile-based approach for extraction of the
FORAY model from the original program. We also demonstrate how FORAY-GEN
enhances applicability of other memory subsystem optimization approaches,
resulting in an average of two times increase in the number of memory
references that can be analyzed by existing static approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4641</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4641</id><created>2007-10-25</created><authors><author><keyname>Schattkowsky</keyname><forenames>Tim</forenames></author></authors><title>UML 2.0 - Overview and Perspectives in SoC Design</title><categories>cs.SE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181220</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The design productivity gap requires more efficient design methods. Software
systems have faced the same challenge and seem to have mastered it with the
introduction of more abstract design methods. The UML has become the standard
for software systems modeling and thus the foundation of new design methods.
Although the UML is defined as a general purpose modeling language, its
application to hardware and hardware/software codesign is very limited. In
order to successfully apply the UML at these fields, it is essential to
understand its capabilities and to map it to a new domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4642</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4642</id><created>2007-10-25</created><authors><author><keyname>Nazarian</keyname><forenames>Shahin</forenames></author><author><keyname>Pedram</keyname><forenames>Massoud</forenames></author><author><keyname>Tuncer</keyname><forenames>Emre</forenames></author><author><keyname>Lin</keyname><forenames>Tao</forenames></author><author><keyname>Ajami</keyname><forenames>Amir H.</forenames></author></authors><title>Modeling and Propagation of Noisy Waveforms in Static Timing Analysis</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181208</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><doi>10.1109/DATE.2005.211</doi><abstract>  A technique based on the sensitivity of the output to input waveform is
presented for accurate propagation of delay information through a gate for the
purpose of static timing analysis (STA) in the presence of noise. Conventional
STA tools represent a waveform by its arrival time and slope. However, this is
not an accurate way of modeling the waveform for the purpose of noise analysis.
The key contribution of our work is the development of a method that allows
efficient propagation of equivalent waveforms throughout the circuit.
Experimental results demonstrate higher accuracy of the proposed
sensitivity-based gate delay propagation technique, SGDP, compared to the best
of existing approaches. SGDP is compatible with the current level of gate
characterization in conventional ASIC cell libraries, and as a result, it can
be easily incorporated into commercial STA tools to improve their accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4643</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4643</id><created>2007-10-25</created><authors><author><keyname>Reshadi</keyname><forenames>Mehrdad</forenames></author><author><keyname>Dutt</keyname><forenames>Nikil</forenames></author></authors><title>Generic Pipelined Processor Modeling and High Performance Cycle-Accurate
  Simulator Generation</title><categories>cs.AR cs.PF</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181210</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><doi>10.1109/DATE.2005.166</doi><abstract>  Detailed modeling of processors and high performance cycle-accurate
simulators are essential for today's hardware and software design. These
problems are challenging enough by themselves and have seen many previous
research efforts. Addressing both simultaneously is even more challenging, with
many existing approaches focusing on one over another. In this paper, we
propose the Reduced Colored Petri Net (RCPN) model that has two advantages:
first, it offers a very simple and intuitive way of modeling pipelined
processors; second, it can generate high performance cycle-accurate simulators.
RCPN benefits from all the useful features of Colored Petri Nets without
suffering from their exponential growth in complexity. RCPN processor models
are very intuitive since they are a mirror image of the processor pipeline
block diagram. Furthermore, in our experiments on the generated cycle-accurate
simulators for XScale and StrongArm processor models, we achieved an order of
magnitude (~15 times) speedup over the popular SimpleScalar ARM simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4644</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4644</id><created>2007-10-25</created><authors><author><keyname>Schnerr</keyname><forenames>Jurgen</forenames></author><author><keyname>Bringmann</keyname><forenames>Oliver</forenames></author><author><keyname>Rosenstiel</keyname><forenames>Wolfgang</forenames></author></authors><title>Cycle Accurate Binary Translation for Simulation Acceleration in Rapid
  Prototyping of SoCs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181211</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, the application of a cycle accurate binary translator for
rapid prototyping of SoCs will be presented. This translator generates code to
run on a rapid prototyping system consisting of a VLIW processor and FPGAs. The
generated code is annotated with information that triggers cycle generation for
the hardware in parallel to the execution of the translated program. The VLIW
processor executes the translated program whereas the FPGAs contain the
hardware for the parallel cycle generation and the bus interface that adapts
the bus of the VLIW processor to the SoC bus of the emulated processor core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4645</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4645</id><created>2007-10-25</created><authors><author><keyname>Cheon</keyname><forenames>B.</forenames></author><author><keyname>Lee</keyname><forenames>E.</forenames></author><author><keyname>Wang</keyname><forenames>L. -T.</forenames></author><author><keyname>Wen</keyname><forenames>X.</forenames></author><author><keyname>Hsu</keyname><forenames>P.</forenames></author><author><keyname>Cho</keyname><forenames>J.</forenames></author><author><keyname>Park</keyname><forenames>J.</forenames></author><author><keyname>Chao</keyname><forenames>H.</forenames></author><author><keyname>Wu</keyname><forenames>S.</forenames></author></authors><title>At-Speed Logic BIST for IP Cores</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181226</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper describes a flexible logic BIST scheme that features high fault
coverage achieved by fault-simulation guided test point insertion, real
at-speed test capability for multi-clock designs without clock frequency
manipulation, and easy physical implementation due to the use of a low-speed SE
signal. Application results of this scheme to two widely used IP cores are also
reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4646</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4646</id><created>2007-10-25</created><authors><author><keyname>Villa</keyname><forenames>O.</forenames></author><author><keyname>Schaumont</keyname><forenames>P.</forenames></author><author><keyname>Verbauwhede</keyname><forenames>I.</forenames></author><author><keyname>Monchiero</keyname><forenames>M.</forenames></author><author><keyname>Palermo</keyname><forenames>G.</forenames></author></authors><title>Fast Dynamic Memory Integration in Co-Simulation Frameworks for
  Multiprocessor System on-Chip</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181213</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper is proposed a technique to integrate and simulate a dynamic
memory in a multiprocessor framework based on C/C++/SystemC. Using host
machine's memory management capabilities, dynamic data processing is supported
without compromising speed and accuracy of the simulation. A first prototype in
a shared memory context is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4649</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4649</id><created>2007-10-25</created><authors><author><keyname>Ghanta</keyname><forenames>Praveen</forenames></author><author><keyname>Vrudhula</keyname><forenames>Sarma</forenames></author><author><keyname>Panda</keyname><forenames>Rajendran</forenames></author><author><keyname>Wang</keyname><forenames>Janet</forenames></author></authors><title>Stochastic Power Grid Analysis Considering Process Variations</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181252</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, we investigate the impact of interconnect and device process
variations on voltage fluctuations in power grids. We consider random
variations in the power grid's electrical parameters as spatial stochastic
processes and propose a new and efficient method to compute the stochastic
voltage response of the power grid. Our approach provides an explicit
analytical representation of the stochastic voltage response using orthogonal
polynomials in a Hilbert space. The approach has been implemented in a
prototype software called OPERA (Orthogonal Polynomial Expansions for Response
Analysis). Use of OPERA on industrial power grids demonstrated speed-ups of up
to two orders of magnitude. The results also show a significant variation of
about $\pm$ 35% in the nominal voltage drops at various nodes of the power
grids and demonstrate the need for variation-aware power grid analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4652</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4652</id><created>2007-10-25</created><authors><author><keyname>Kandemir</keyname><forenames>Mahmut</forenames></author><author><keyname>Chen</keyname><forenames>Guilin</forenames></author></authors><title>Locality-Aware Process Scheduling for Embedded MPSoCs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181228</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Utilizing on-chip caches in embedded multiprocessor-system-on-a-chip (MPSoC)
based systems is critical from both performance and power perspectives. While
most of the prior work that targets at optimizing cache behavior are performed
at hardware and compilation levels, operating system (OS) can also play major
role as it sees the global access pattern information across applications. This
paper proposes a cache-conscious OS process scheduling strategy based on data
reuse. The proposed scheduler implements two complementary approaches. First,
the processes that do not share any data between them are scheduled at
different cores if it is possible to do so. Second, the processes that could
not be executed at the same time (due to dependences) but share data among each
other are mapped to the same processor core so that they share the cache
contents. Our experimental results using this new data locality aware OS
scheduling strategy are promising, and show significant improvements in task
completion times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4653</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4653</id><created>2007-10-25</created><authors><author><keyname>Sharifi</keyname><forenames>Shervin</forenames></author><author><keyname>Jaffari</keyname><forenames>Javid</forenames></author><author><keyname>Hosseinabady</keyname><forenames>Mohammad</forenames></author><author><keyname>Afzali-Kusha</keyname><forenames>Ali</forenames></author><author><keyname>Navabi</keyname><forenames>Zainalabedin</forenames></author></authors><title>Simultaneous Reduction of Dynamic and Static Power in Scan Structures</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181223</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Power dissipation during test is a major challenge in testing integrated
circuits. Dynamic power has been the dominant part of power dissipation in CMOS
circuits, however, in future technologies the static portion of power
dissipation will outreach the dynamic portion. This paper proposes an efficient
technique to reduce both dynamic and static power dissipation in scan
structures. Scan cell outputs which are not on the critical path(s) are
multiplexed to fixed values during scan mode. These constant values and primary
inputs are selected such that the transitions occurred on non-multiplexed scan
cells are suppressed and the leakage current during scan mode is decreased. A
method for finding these vectors is also proposed. Effectiveness of this
technique is proved by experiments performed on ISCAS89 benchmark circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4654</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4654</id><created>2007-10-25</created><authors><author><keyname>Li</keyname><forenames>Peng</forenames></author><author><keyname>Liu</keyname><forenames>Frank</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author><author><keyname>Pileggi</keyname><forenames>Lawrence T.</forenames></author><author><keyname>Nassif</keyname><forenames>Sani R.</forenames></author></authors><title>Modeling Interconnect Variability Using Efficient Parametric Model Order
  Reduction</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181249</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Assessing IC manufacturing process fluctuations and their impacts on IC
interconnect performance has become unavoidable for modern DSM designs.
However, the construction of parametric interconnect models is often hampered
by the rapid increase in computational cost and model complexity. In this paper
we present an efficient yet accurate parametric model order reduction algorithm
for addressing the variability of IC interconnect performance. The efficiency
of the approach lies in a novel combination of low-rank matrix approximation
and multi-parameter moment matching. The complexity of the proposed parametric
model order reduction is as low as that of a standard Krylov subspace method
when applied to a nominal system. Under the projection-based framework, our
algorithm also preserves the passivity of the resulting parametric models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4655</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4655</id><created>2007-10-25</created><authors><author><keyname>Wang</keyname><forenames>Baosheng</forenames></author><author><keyname>Wu</keyname><forenames>Yuejian</forenames></author><author><keyname>Ivanov</keyname><forenames>Andre</forenames></author></authors><title>A Fast Diagnosis Scheme for Distributed Small Embedded SRAMs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181224</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper proposes a diagnosis scheme aimed at reducing diagnosis time of
distributed small embedded SRAMs (e-SRAMs). This scheme improves the one
proposed in [A parallel built-in self-diagnostic method for embedded memory
buffers, A parallel built-in self-diagnostic method for embedded memory
arrays]. The improvements are mainly two-fold. On one hand, the diagnosis of
time-consuming Data Retention Faults (DRFs), which is neglected by the
diagnosis architecture in [A parallel built-in self-diagnostic method for
embedded memory buffers, A parallel built-in self-diagnostic method for
embedded memory arrays], is now considered and performed via a DFT technique
referred to as the "No Write Recovery Test Mode (NWRTM)". On the other hand, a
pair comprising a Serial to Parallel Converter (SPC) and a Parallel to Serial
Converter (PSC) is utilized to replace the bi-directional serial interface, to
avoid the problems of serial fault masking and defect rate dependent diagnosis.
Results from our evaluations show that the proposed diagnosis scheme achieves
an increased diagnosis coverage and reduces diagnosis time compared to those
obtained in [A parallel built-in self-diagnostic method for embedded memory
buffers, A parallel built-in self-diagnostic method for embedded memory
arrays], with neglectable extra area cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4656</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4656</id><created>2007-10-25</created><authors><author><keyname>Dasygenis</keyname><forenames>Minas</forenames></author><author><keyname>Brockmeyer</keyname><forenames>Erik</forenames></author><author><keyname>Durinck</keyname><forenames>Bart</forenames></author><author><keyname>Catthoor</keyname><forenames>Francky</forenames></author><author><keyname>Soudris</keyname><forenames>Dimitrios</forenames></author><author><keyname>Thanailakis</keyname><forenames>Antonios</forenames></author></authors><title>A Memory Hierarchical Layer Assigning and Prefetching Technique to
  Overcome the Memory Performance/Energy Bottleneck</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181245</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The memory subsystem has always been a bottleneck in performance as well as
significant power contributor in memory intensive applications. Many
researchers have presented multi-layered memory hierarchies as a means to
design energy and performance efficient systems. However, most of the previous
work do not explore trade-offs systematically. We fill this gap by proposing a
formalized technique that takes into consideration data reuse, limited lifetime
of the arrays of an application and application specific prefetching
opportunities, and performs a thorough trade-off exploration for different
memory layer sizes. This technique has been implemented on a prototype tool,
which was tested successfully using nine real-life applications of industrial
relevance. Following this approach we have able to reduce execution time up to
60%, and energy consumption up to 70%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4657</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4657</id><created>2007-10-25</created><authors><author><keyname>Bodean</keyname><forenames>Gh.</forenames></author><author><keyname>Bodean</keyname><forenames>D.</forenames></author><author><keyname>Labunetz</keyname><forenames>A.</forenames></author></authors><title>New Schemes for Self-Testing RAM</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181225</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper gives an overview of a new technique, named pseudo-ring testing
(PRT). PRT can be applied for testing wide type of random access memories
(RAM): bit- or word-oriented and single- or dual-port RAM's. An essential
particularity of the proposed methodology is the emulation of a linear
automaton over Galois field by memory own components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4658</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4658</id><created>2007-10-25</created><authors><author><keyname>Molnos</keyname><forenames>A. M.</forenames></author><author><keyname>Heijligers</keyname><forenames>M. J. M.</forenames></author><author><keyname>Cotofana</keyname><forenames>S. D.</forenames></author><author><keyname>Van Eijndhoven</keyname><forenames>J. T. J.</forenames></author></authors><title>Compositional Memory Systems for Multimedia Communicating Tasks</title><categories>cs.AR cs.MM</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181239</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Conventional cache models are not suited for real-time parallel processing
because tasks may flush each other's data out of the cache in an unpredictable
manner. In this way the system is not compositional so the overall performance
is difficult to predict and the integration of new tasks expensive. This paper
proposes a new method that imposes compositionality to the system?s performance
and makes different memory hierarchy optimizations possible for multimedia
communicating tasks when running on embedded multiprocessor architectures. The
method is based on a cache allocation strategy that assigns sets of the unified
cache exclusively to tasks and to the communication buffers. We also
analytically formulate the problem and describe a method to compute the cache
partitioning ratio for optimizing the throughput and the consumed power. When
applied to a multiprocessor with memory hierarchy our technique delivers also
performance gain. Compared to the shared cache case, for an application
consisting of two jpeg decoders and one edge detection algorithm 5 times less
misses are experienced and for an mpeg2 decoder 6.5 times less misses are
experienced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4659</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4659</id><created>2007-10-25</created><authors><author><keyname>Bomel</keyname><forenames>Pierre</forenames><affiliation>LESTER</affiliation></author><author><keyname>Martin</keyname><forenames>Eric</forenames><affiliation>LESTER</affiliation></author><author><keyname>Boutillon</keyname><forenames>Emmanuel</forenames><affiliation>LESTER</affiliation></author></authors><title>Synchronization Processor Synthesis for Latency Insensitive Systems</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181231</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper we present our contribution in terms of synchronization
processor for a SoC design methodology based on the theory of the latency
insensitive systems (LIS) of Carloni et al. Our contribution consists in IP
encapsulation into a new wrapper model which speed and area are optimized and
synthetizability guarantied. The main benefit of our approach is to preserve
the local IP performances when encapsulating them and reduce SoC silicon area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4660</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4660</id><created>2007-10-25</created><authors><author><keyname>Hung</keyname><forenames>W. -L.</forenames></author><author><keyname>Xie</keyname><forenames>Y.</forenames></author><author><keyname>Vijaykrishnan</keyname><forenames>N.</forenames></author><author><keyname>Kandemir</keyname><forenames>M.</forenames></author><author><keyname>Irwin</keyname><forenames>M. J.</forenames></author></authors><title>Thermal-Aware Task Allocation and Scheduling for Embedded Systems</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181232</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Temperature affects not only the reliability but also the performance, power,
and cost of the embedded system. This paper proposes a thermal-aware task
allocation and scheduling algorithm for embedded systems. The algorithm is used
as a sub-routine for hardware/software co-synthesis to reduce the peak
temperature and achieve a thermally even distribution while meeting real time
constraints. The paper investigates both power-aware and thermal-aware
approaches to task allocation and scheduling. The experimental results show
that the thermal-aware approach outperforms the power-aware schemes in terms of
maximal and average temperature reductions. To the best of our knowledge, this
is the first task allocation and scheduling algorithm that takes temperature
into consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4661</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4661</id><created>2007-10-25</created><authors><author><keyname>Chiang</keyname><forenames>C.</forenames></author><author><keyname>Kahng</keyname><forenames>A.</forenames></author><author><keyname>Sinha</keyname><forenames>S.</forenames></author><author><keyname>Xu</keyname><forenames>X.</forenames></author><author><keyname>Zelikovsky</keyname><forenames>A.</forenames></author></authors><title>Bright-Field AAPSM Conflict Detection and Correction</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181234</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As feature sizes shrink, it will be necessary to use AAPSM
(Alternating-Aperture Phase Shift Masking) to image critical features,
especially on the polysilicon layer. This imposes additional constraints on the
layouts beyond traditional design rules. Of particular note is the requirement
that all critical features be flanked by opposite-phase shifters, while the
shifters obey minimum width and spacing requirements. A layout is called
phase-assignable if it satisfies this requirement. If a layout is not
phase-assignable, the phase conflicts have to removed to enable the use of
AAPSM for the layout. Previous work has sought to detect a suitable set of
phase Conflicts to be removed, as well as correct them. The contribution of
this paper are the following: (1) a new approach to detect a minimal set of
phase conflicts (also referred to as AAPSM conflicts), which when corrected
will produce a phase-assignable layout; (2) a novel layout modification scheme
for correcting these AAPSM conflicts. The proposed approach for conflict
detection shows significant improvements in the quality of results and runtime
for real industrial circuits, when compared to previous methods. To the best of
our knowledge, this is the first time layout modification results are presented
for bright-field AAPSM. Our experiments show that the percentage area increase
for making a layout phase-assignable ranges from 0.7-11.8%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4663</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4663</id><created>2007-10-25</created><authors><author><keyname>Datta</keyname><forenames>Animesh</forenames></author><author><keyname>Bhunia</keyname><forenames>Swarup</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Saibal</forenames></author><author><keyname>Banerjee</keyname><forenames>Nilanjan</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Statistical Modeling of Pipeline Delay and Design of Pipeline under
  Process Variation to Enhance Yield in sub-100nm Technologies</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181238</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Operating frequency of a pipelined circuit is determined by the delay of the
slowest pipeline stage. However, under statistical delay variation in sub-100nm
technology regime, the slowest stage is not readily identifiable and the
estimation of the pipeline yield with respect to a target delay is a
challenging problem. We have proposed analytical models to estimate yield for a
pipelined design based on delay distributions of individual pipe stages. Using
the proposed models, we have shown that change in logic depth and imbalance
between the stage delays can improve the yield of a pipeline. A statistical
methodology has been developed to optimally design a pipeline circuit for
enhancing yield. Optimization results show that, proper imbalance among the
stage delays in a pipeline improves design yield by 9% for the same area and
performance (and area reduction by about 8.4% under a yield constraint) over a
balanced design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4665</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4665</id><created>2007-10-25</created><authors><author><keyname>Manaresi</keyname><forenames>Nicolo</forenames></author><author><keyname>Medoro</keyname><forenames>Gianni</forenames></author><author><keyname>Abonnenc</keyname><forenames>Melanie</forenames></author><author><keyname>Auger</keyname><forenames>Vincent</forenames></author><author><keyname>Vulto</keyname><forenames>Paul</forenames></author><author><keyname>Romani</keyname><forenames>Aldo</forenames></author><author><keyname>Altomare</keyname><forenames>Luigi</forenames></author><author><keyname>Tartagni</keyname><forenames>Marco</forenames></author><author><keyname>Guerrieri</keyname><forenames>Roberto</forenames></author></authors><title>New Perspectives and Opportunities From the Wild West of Microelectronic
  Biochips</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181276</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Application of Microelectronic to bioanalysis is an emerging field which
holds great promise. From the standpoint of electronic and system design,
biochips imply a radical change of perspective, since new, completely different
constraints emerge while other usual constraints can be relaxed. While
electronic parts of the system can rely on the usual established design-flow,
fluidic and packaging design, calls for a new approach which relies
significantly on experiments. We hereby make some general considerations based
on our experience in the development of biochips for cell analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4666</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4666</id><created>2007-10-25</created><authors><author><keyname>Ganai</keyname><forenames>Malay K.</forenames></author><author><keyname>Gupta</keyname><forenames>Aarti</forenames></author><author><keyname>Ashar</keyname><forenames>Pranav</forenames></author></authors><title>Verification of Embedded Memory Systems using Efficient Memory Modeling</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181278</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We describe verification techniques for embedded memory systems using
efficient memory modeling (EMM), without explicitly modeling each memory bit.
We extend our previously proposed approach of EMM in Bounded Model Checking
(BMC) for a single read/write port single memory system, to more commonly
occurring systems with multiple memories, having multiple read and write ports.
More importantly, we augment such EMM to providing correctness proofs, in
addition to finding real bugs as before. The novelties of our verification
approach are in a) combining EMM with proof-based abstraction that preserves
the correctness of a property up to a certain analysis depth of SAT-based BMC,
and b) modeling arbitrary initial memory state precisely and thereby, providing
inductive proofs using SAT-based BMC for embedded memory systems. Similar to
the previous approach, we construct a verification model by eliminating memory
arrays, but retaining the memory interface signals with their control logic and
adding constraints on those signals at every analysis depth to preserve the
data forwarding semantics. The size of these EMM constraints depends
quadratically on the number of memory accesses and the number of read and write
ports; and linearly on the address and data widths and the number of memories.
We show the effectiveness of our approach on several industry designs and
software programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4667</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4667</id><created>2007-10-25</created><authors><author><keyname>Chen</keyname><forenames>Chien-Liang</forenames></author><author><keyname>Lin</keyname><forenames>Jiing-Yuan</forenames></author><author><keyname>Lin</keyname><forenames>Youn-Long</forenames></author></authors><title>Integration, Verification and Layout of a Complex Multimedia SOC</title><categories>cs.AR cs.MM</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181281</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We present our experience of designing a single-chip controller for advanced
digital still camera from specification all the way to mass production. The
process involves collaboration with camera system designer, IP vendors, EDA
vendors, silicon wafer foundry, package and testing houses, and camera maker.
We also co-work with academic research groups to develop a JPEG codec IP and
memory BIST and SOC testing methodology. In this presentation, we cover the
problems encountered, our solutions, and lessons learned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4669</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4669</id><created>2007-10-25</created><authors><author><keyname>Wu</keyname><forenames>Cheng-Wen</forenames></author></authors><title>SOC Testing Methodology and Practice</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181282</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  On a commercial digital still camera (DSC) controller chip we practice a
novel SOC test integration platform, solving real problems in test scheduling,
test IO reduction, timing of functional test, scan IO sharing, embedded memory
built-in self-test (BIST), etc. The chip has been fabricated and tested
successfully by our approach. Test results justify that short test integration
cost, short test time, and small area overhead can be achieved. To support SOC
testing, a memory BIST compiler and an SOC testing integration system have been
developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4670</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4670</id><created>2007-10-25</created><authors><author><keyname>Polian</keyname><forenames>Ilia</forenames></author><author><keyname>Czutro</keyname><forenames>Alejandro</forenames></author><author><keyname>Becker</keyname><forenames>Bernd</forenames></author></authors><title>Evolutionary Optimization in Code-Based Test Compression</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181283</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We provide a general formulation for the code-based test compression problem
with fixed-length input blocks and propose a solution approach based on
Evolutionary Algorithms. In contrast to existing code-based methods, we allow
unspecified values in matching vectors, which allows encoding of arbitrary test
sets using a relatively small number of code-words. Experimental results for
both stuck-at and path delay fault test sets for ISCAS circuits demonstrate an
improvement compared to existing techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4671</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4671</id><created>2007-10-25</created><authors><author><keyname>Murali</keyname><forenames>Srinivasan</forenames></author><author><keyname>De Micheli</keyname><forenames>Giovanni</forenames></author></authors><title>An Application-Specific Design Methodology for STbus Crossbar Generation</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181290</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As the communication requirements of current and future Multiprocessor
Systems on Chips (MPSoCs) continue to increase, scalable communication
architectures are needed to support the heavy communication demands of the
system. This is reflected in the recent trend that many of the standard bus
products such as STbus, have now introduced the capability of designing a
crossbar with multiple buses operating in parallel. The crossbar configuration
should be designed to closely match the application traffic characteristics and
performance requirements. In this work we address this issue of
application-specific design of optimal crossbar (using STbus crossbar
architecture), satisfying the performance requirements of the application and
optimal binding of cores onto the crossbar resources. We present a simulation
based design approach that is based on analysis of actual traffic trace of the
application, considering local variations in traffic rates, temporal overlap
among traffic streams and criticality of traffic streams. Our methodology is
applied to several MPSoC designs and the resulting crossbar platforms are
validated for performance by cycle-accurate SystemC simulation of the designs.
The experimental case studies show large reduction in packet latencies (up to
7x) and large crossbar component savings (up to 3.5x) compared to traditional
design approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4672</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4672</id><created>2007-10-25</created><authors><author><keyname>Su</keyname><forenames>Fei</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Krishnendu</forenames></author><author><keyname>Pamula</keyname><forenames>Vamsee K.</forenames></author></authors><title>Yield Enhancement of Digital Microfluidics-Based Biochips Using Space
  Redundancy and Local Reconfiguration</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181293</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As microfluidics-based biochips become more complex, manufacturing yield will
have significant influence on production volume and product cost. We propose an
interstitial redundancy approach to enhance the yield of biochips that are
based on droplet-based microfluidics. In this design method, spare cells are
placed in the interstitial sites within the microfluidic array, and they
replace neighboring faulty cells via local reconfiguration. The proposed design
method is evaluated using a set of concurrent real-life bioassays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4673</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4673</id><created>2007-10-25</created><authors><author><keyname>Su</keyname><forenames>Fei</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Krishnendu</forenames></author></authors><title>Design of Fault-Tolerant and Dynamically-Reconfigurable Microfluidic
  Biochips</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181294</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Microfluidics-based biochips are soon expected to revolutionize clinical
diagnosis, DNA sequencing, and other laboratory procedures involving molecular
biology. Most microfluidic biochips are based on the principle of continuous
fluid flow and they rely on permanently-etched microchannels, micropumps, and
microvalves. We focus here on the automated design of "digital" droplet-based
microfluidic biochips. In contrast to continuous-flow systems, digital
microfluidics offers dynamic reconfigurability; groups of cells in a
microfluidics array can be reconfigured to change their functionality during
the concurrent execution of a set of bioassays. We present a simulated
annealing-based technique for module placement in such biochips. The placement
procedure not only addresses chip area, but it also considers fault tolerance,
which allows a microfluidic module to be relocated elsewhere in the system when
a single cell is detected to be faulty. Simulation results are presented for a
case study involving the polymerase chain reaction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4678</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4678</id><created>2007-10-25</created><authors><author><keyname>Thewes</keyname><forenames>R.</forenames></author><author><keyname>Paulus</keyname><forenames>C.</forenames></author><author><keyname>Schienle</keyname><forenames>M.</forenames></author><author><keyname>Hofmann</keyname><forenames>F.</forenames></author><author><keyname>Frey</keyname><forenames>A.</forenames></author><author><keyname>Brederlow</keyname><forenames>R.</forenames></author><author><keyname>Augustyniak</keyname><forenames>M.</forenames></author><author><keyname>Jenkner</keyname><forenames>M.</forenames></author><author><keyname>Eversmann</keyname><forenames>B.</forenames></author><author><keyname>Schindler-Bauer</keyname><forenames>P.</forenames></author><author><keyname>Atzesberger</keyname><forenames>M.</forenames></author><author><keyname>Holzapfl</keyname><forenames>B.</forenames></author><author><keyname>Beer</keyname><forenames>G.</forenames></author><author><keyname>Haneder</keyname><forenames>T.</forenames></author><author><keyname>Hanke</keyname><forenames>H. -C.</forenames></author></authors><title>CMOS-Based Biosensor Arrays</title><categories>cs.AR</categories><proxy>ccsd hal-00181297</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  CMOS-based sensor array chips provide new and attractive features as compared
to today's standard tools for medical, diagnostic, and biotechnical
applications. Examples for molecule- and cell-based approaches and related
circuit design issues are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4679</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4679</id><created>2007-10-25</created><authors><author><keyname>Kaul</keyname><forenames>Himanshu</forenames></author><author><keyname>Sylvester</keyname><forenames>Dennis</forenames></author><author><keyname>Blaauw</keyname><forenames>David</forenames></author><author><keyname>Mudge</keyname><forenames>Trevor</forenames></author><author><keyname>Austin</keyname><forenames>Todd</forenames></author></authors><title>DVS for On-Chip Bus Designs Based on Timing Error Correction</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181499</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  On-chip buses are typically designed to meet performance constraints at
worst-case conditions, including process corner, temperature, IR-drop, and
neighboring net switching pattern. This can result in significant performance
slack at more typical operating conditions. In this paper, we propose a dynamic
voltage scaling (DVS) technique for buses, based on a double sampling latch
which can detect and correct for delay errors without the need for
retransmission. The proposed approach recovers the available slack at
non-worst-case operating points through more aggressive voltage scaling and
tracks changing conditions by monitoring the error recovery rate. Voltage
margins needed in traditional designs to accommodate worst-case performance
conditions are therefore eliminated, resulting in a significant improvement in
energy efficiency. The approach was implemented for a 6mm memory read bus
operating at 1.5GHz (0.13 $\mu$m technology node) and was simulated for a
number of benchmark programs. Even at the worst-case process and environment
conditions, energy gains of up to 17% are achieved, with error recovery rates
under 2.3%. At more typical process and environment conditions, energy gains
range from 35% to 45%, with a performance degradation under 2%. An analysis of
optimum interconnect architectures for maximizing energy gains with this
approach shows that the proposed approach performs well with technology
scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4680</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4680</id><created>2007-10-25</created><authors><author><keyname>Marculescu</keyname><forenames>Diana</forenames></author></authors><title>Energy Bounds for Fault-Tolerant Nanoscale Designs</title><categories>cs.CC cs.IT math.IT</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181498</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The problem of determining lower bounds for the energy cost of a given
nanoscale design is addressed via a complexity theory-based approach. This
paper provides a theoretical framework that is able to assess the trade-offs
existing in nanoscale designs between the amount of redundancy needed for a
given level of resilience to errors and the associated energy cost. Circuit
size, logic depth and error resilience are analyzed and brought together in a
theoretical framework that can be seamlessly integrated with automated
synthesis tools and can guide the design process of nanoscale systems comprised
of failure prone devices. The impact of redundancy addition on the switching
energy and its relationship with leakage energy is modeled in detail. Results
show that 99% error resilience is possible for fault-tolerant designs, but at
the expense of at least 40% more energy if individual gates fail independently
with probability of 1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4681</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4681</id><created>2007-10-25</created><authors><author><keyname>Weber</keyname><forenames>Wolf-Dietrich</forenames></author><author><keyname>Chou</keyname><forenames>Joe</forenames></author><author><keyname>Swarbrick</keyname><forenames>Ian</forenames></author><author><keyname>Wingard</keyname><forenames>Drew</forenames></author></authors><title>A Quality-of-Service Mechanism for Interconnection Networks in
  System-on-Chips</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181299</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As Moore's Law continues to fuel the ability to build ever increasingly
complex system-on-chips (SoCs), achieving performance goals is rising as a
critical challenge to completing designs. In particular, the system
interconnect must efficiently service a diverse set of data flows with widely
ranging quality-of-service (QoS) requirements. However, the known solutions for
off-chip interconnects such as large-scale networks are not necessarily
applicable to the on-chip environment. Latency and memory constraints for
on-chip interconnects are quite different from larger-scale interconnects. This
paper introduces a novel on-chip interconnect arbitration scheme. We show how
this scheme can be distributed across a chip for high-speed implementation. We
compare the performance of the arbitration scheme with other known interconnect
arbitration schemes. Existing schemes typically focus heavily on either low
latency of service for some initiators, or alternatively on guaranteed
bandwidth delivery for other initiators. Our scheme allows service latency on
some initiators to be traded off smoothly against jitter bounds on other
initiators, while still delivering bandwidth guarantees. This scheme is a
subset of the QoS controls that are available in the SonicsMX? (SMX) product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4682</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4682</id><created>2007-10-25</created><authors><author><keyname>Oliver</keyname><forenames>Ian</forenames></author></authors><title>Applying UML and MDA to Real Systems Design</title><categories>cs.SE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181497</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Traditionally system design has been made from a black box/functionality only
perspective which forces the developer to concentrate on how the functionality
can be decomposed and recomposed into so called components. While this
technique is well established and well known it does suffer fromsome drawbacks;
namely that the systems produced can often be forced into certain, incompatible
architectures, difficult to maintain or reuse and the code itself difficult to
debug. Now that ideas such as the OMG's Model Based Architecture (MDA) or Model
Based Engineering (MBE) and the ubiquitous modelling language UML are being
used (allegedly) and desired we face a number of challenges to existing
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4683</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4683</id><created>2007-10-25</created><authors><author><keyname>Edwards</keyname><forenames>Stephen A.</forenames></author></authors><title>The Challenges of Hardware Synthesis from C-Like Languages</title><categories>cs.PL</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181495</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  MANY TECHNIQUES for synthesizing digital hardware from C-like languages have
been proposed, but none have emerged as successful as Verilog or VHDL for
register-transfer-level design. This paper looks at two of the fundamental
challenges: concurrency and timing control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4684</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4684</id><created>2007-10-25</created><authors><author><keyname>Tosun</keyname><forenames>S.</forenames></author><author><keyname>Mansouri</keyname><forenames>N.</forenames></author><author><keyname>Arvas</keyname><forenames>E.</forenames></author><author><keyname>Kandemir</keyname><forenames>M.</forenames></author><author><keyname>Xie</keyname><forenames>Yuan</forenames></author></authors><title>Reliability-Centric High-Level Synthesis</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181301</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Importance of addressing soft errors in both safety critical applications and
commercial consumer products is increasing, mainly due to ever shrinking
geometries, higher-density circuits, and employment of power-saving techniques
such as voltage scaling and component shut-down. As a result, it is becoming
necessary to treat reliability as a first-class citizen in system design. In
particular, reliability decisions taken early in system design can have
significant benefits in terms of design quality. Motivated by this observation,
this paper presents a reliability-centric high-level synthesis approach that
addresses the soft error problem. The proposed approach tries to maximize
reliability of the design while observing the bounds on area and performance,
and makes use of our reliability characterization of hardware components such
as adders and multipliers. We implemented the proposed approach, performed
experiments with several designs, and compared the results with those obtained
by a prior proposal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4685</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4685</id><created>2007-10-25</created><authors><author><keyname>Bolchini</keyname><forenames>C.</forenames></author><author><keyname>Salice</keyname><forenames>F.</forenames></author><author><keyname>Sciuto</keyname><forenames>D.</forenames></author><author><keyname>Pomante</keyname><forenames>L.</forenames></author></authors><title>Reliable System Specification for Self-Checking Data-Paths</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181304</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The design of reliable circuits has received a lot of attention in the past,
leading to the definition of several design techniques introducing fault
detection and fault tolerance properties in systems for critical
applications/environments. Such design methodologies tackled the problem at
different abstraction levels, from switch-level to logic, RT level, and more
recently to system level. Aim of this paper is to introduce a novel
system-level technique based on the redefinition of the operators functionality
in the system specification. This technique provides reliability properties to
the system data path, transparently with respect to the designer. Feasibility,
fault coverage, performance degradation and overheads are investigated on a FIR
circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4686</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4686</id><created>2007-10-25</created><authors><author><keyname>Sehgal</keyname><forenames>Anuja</forenames></author><author><keyname>Liu</keyname><forenames>Fang</forenames></author><author><keyname>Ozev</keyname><forenames>Sule</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Krishnendu</forenames></author></authors><title>Test Planning for Mixed-Signal SOCs with Wrapped Analog Cores</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181494</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Many SOCs today contain both digital and analog embedded cores. Even though
the test cost for such mixed-signal SOCs is significantly higher than that for
digital SOCs, most prior research in this area has focused exclusively on
digital cores. We propose a low-cost test development methodology for
mixed-signal SOCs that allows the analog and digital cores to be tested in a
unified manner, thereby minimizing the overall test cost. The analog cores in
the SOC are wrapped such that they can be accessed using a digital test access
mechanism (TAM). We evaluate the impact of the use of analog test wrappers on
area overhead and test time. To reduce area overhead, we present an analog test
wrapper optimization technique, which is then combined with TAM optimization in
a cost-oriented heuristic approach for test scheduling. We also demonstrate the
feasibility of using analog wrappers by presenting transistor-level simulations
for an analog wrapper and a representative core. We present experimental
results on test scheduling for an ITC'02 benchmark SOC that has been augmented
with five analog cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4687</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4687</id><created>2007-10-25</created><authors><author><keyname>Goel</keyname><forenames>Sandeep Kumar</forenames></author><author><keyname>Marinissen</keyname><forenames>Erik Jan</forenames></author></authors><title>On-Chip Test Infrastructure Design for Optimal Multi-Site Testing of
  System Chips</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181493</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Multi-site testing is a popular and effective way to increase test throughput
and reduce test costs. We present a test throughput model, in which we focus on
wafer testing, and consider parameters like test time, index time,
abort-on-fail, and contact yield. Conventional multi-site testing requires
sufficient ATE resources, such as ATE channels, to allow to test multiple SOCs
in parallel. In this paper, we design and optimize on-chip DfT, in order to
maximize the test throughput for a given SOC and ATE. The on-chip DfT consists
of an E-RPCT wrapper, and, for modular SOCs, module wrappers and TAMs. We
present experimental results for a Philips SOC and several ITC'02 SOC Test
Benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4688</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4688</id><created>2007-10-25</created><authors><author><keyname>Kastensmidt</keyname><forenames>F. Lima</forenames></author><author><keyname>Sterpone</keyname><forenames>L.</forenames></author><author><keyname>Carro</keyname><forenames>L.</forenames></author><author><keyname>Reorda</keyname><forenames>M. Sonza</forenames></author></authors><title>On the Optimal Design of Triple Modular Redundancy Logic for SRAM-based
  FPGAs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181306</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Triple Modular Redundancy (TMR) is a suitable fault tolerant technique for
SRAM-based FPGA. However, one of the main challenges in achieving 100%
robustness in designs protected by TMR running on programmable platforms is to
prevent upsets in the routing from provoking undesirable connections between
signals from distinct redundant logic parts, which can generate an error in the
output. This paper investigates the optimal design of the TMR logic (e.g., by
cleverly inserting voters) to ensure robustness. Four different versions of a
TMR digital filter were analyzed by fault injection. Faults were randomly
inserted straight into the bitstream of the FPGA. The experimental results
presented in this paper demonstrate that the number and placement of voters in
the TMR design can directly affect the fault tolerance, ranging from 4.03% to
0.98% the number of upsets in the routing able to cause an error in the TMR
circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4689</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4689</id><created>2007-10-25</created><authors><author><keyname>Shashidhar</keyname><forenames>K. C.</forenames></author><author><keyname>Bruynooghe</keyname><forenames>Maurice</forenames></author><author><keyname>Catthoor</keyname><forenames>Francky</forenames></author><author><keyname>Janssens</keyname><forenames>Gerda</forenames></author></authors><title>Functional Equivalence Checking for Verification of Algebraic
  Transformations on Array-Intensive Source Code</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181308</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Development of energy and performance-efficient embedded software is
increasingly relying on application of complex transformations on the critical
parts of the source code. Designers applying such nontrivial source code
transformations are often faced with the problem of ensuring functional
equivalence of the original and transformed programs. Currently they have to
rely on incomplete and time-consuming simulation. Formal automatic verification
of the transformed program against the original is instead desirable. This
calls for equivalence checking tools similar to the ones available for
comparing digital circuits. We present such a tool to compare array-intensive
programs related through a combination of important global transformations like
expression propagations, loop and algebraic transformations. When the
transformed program fails to pass the equivalence check, the tool provides
specific feedback on the possible locations of errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4690</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4690</id><created>2007-10-25</created><authors><author><keyname>Liu</keyname><forenames>Xun</forenames></author><author><keyname>Peng</keyname><forenames>Yuantao</forenames></author><author><keyname>Papaefthymiou</keyname><forenames>Marios C.</forenames></author></authors><title>RIP: An Efficient Hybrid Repeater Insertion Scheme for Low Power</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181311</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents a novel repeater insertion algorithm for interconnect
power minimization. The novelty of our approach is in the judicious integration
of an analytical solver and a dynamic programming based method. Specifically,
the analytical solver chooses a concise repeater library and a small set of
repeater location candidates such that the dynamic programming algorithm can be
performed fast with little degradation of the solution quality. In comparison
with previously reported repeater insertion schemes, within comparable
runtimes, our approach achieves up to 37% higher power savings. Moreover, for
the same design quality, our scheme attains a speedup of two orders of
magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4691</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4691</id><created>2007-10-25</created><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>Shi</keyname><forenames>Weiping</forenames></author></authors><title>An O(bn^2) Time Algorithm for Optimal Buffer Insertion with b Buffer
  Types</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181310</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Buffer insertion is a popular technique to reduce the interconnect delay. The
classic buffer insertion algorithm of van Ginneken has time complexity O(n^2),
where n is the number of buffer positions. Lillis, Cheng and Lin extended van
Ginneken's algorithm to allow b buffer types in time O (b^2 n^2). For modern
design libraries that contain hundreds of buffers, it is a serious challenge to
balance the speed and performance of the buffer insertion algorithm. In this
paper, we present a new algorithm that computes the optimal buffer insertion in
O (bn^2) time. The reduction is achieved by the observation that the (Q, C)
pairs of the candidates that generate the new candidates must form a convex
hull. On industrial test cases, the new algorithm is faster than the previous
best buffer insertion algorithms by orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4692</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4692</id><created>2007-10-25</created><authors><author><keyname>Kirstein</keyname><forenames>K. -U.</forenames></author><author><keyname>Li</keyname><forenames>Y.</forenames></author><author><keyname>Zimmermann</keyname><forenames>M.</forenames></author><author><keyname>Vancura</keyname><forenames>C.</forenames></author><author><keyname>Volden</keyname><forenames>T.</forenames></author><author><keyname>Song</keyname><forenames>W. H.</forenames></author><author><keyname>Lichtenberg</keyname><forenames>J.</forenames></author><author><keyname>Hierlemannn</keyname><forenames>A.</forenames></author></authors><title>Cantilever-Based Biosensors in CMOS Technology</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181313</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Single-chip CMOS-based biosensors that feature microcantilevers as transducer
elements are presented. The cantilevers are functionalized for the capturing of
specific analytes, e.g., proteins or DNA. The binding of the analyte changes
the mechanical properties of the cantilevers such as surface stress and
resonant frequency, which can be detected by an integrated Wheatstone bridge.
The monolithic integrated readout allows for a high signal-to-noise ratio,
lowers the sensitivity to external interference and enables autonomous device
operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4693</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4693</id><created>2007-10-25</created><authors><author><keyname>Majhi</keyname><forenames>Ananta K.</forenames></author><author><keyname>Azimane</keyname><forenames>Mohamed</forenames></author><author><keyname>Gronthoud</keyname><forenames>Guido</forenames></author><author><keyname>Lousberg</keyname><forenames>Maurice</forenames></author><author><keyname>Eichenberger</keyname><forenames>Stefan</forenames></author><author><keyname>Bowen</keyname><forenames>Fred</forenames></author></authors><title>Memory Testing Under Different Stress Conditions: An Industrial
  Evaluation</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181553</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents the effectiveness of various stress conditions (mainly
voltage and frequency) on detecting the resistive shorts and open defects in
deep sub-micron embedded memories in an industrial environment. Simulation
studies on very-low voltage, high voltage and at-speed testing show the need of
the stress conditions for high quality products; i.e., low defect-per-million
(DPM) level, which is driving the semiconductor market today. The above test
conditions have been validated to screen out bad devices on real silicon (a
test-chip) built on CMOS 0.18 um technology. IFA (inductive fault analysis)
based simulation technique leads to an efficient fault coverage and DPM
estimator, which helps the customers upfront to make decisions on test
algorithm implementations under different stress conditions in order to reduce
the number of test escapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4694</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4694</id><created>2007-10-25</created><authors><author><keyname>Yang</keyname><forenames>Guowu</forenames></author><author><keyname>Hung</keyname><forenames>William N. N.</forenames></author><author><keyname>Song</keyname><forenames>Xiaoyu</forenames></author><author><keyname>Perkowski</keyname><forenames>Marek</forenames></author></authors><title>Exact Synthesis of 3-Qubit Quantum Circuits from Non-Binary Quantum
  Gates Using Multiple-Valued Logic and Group Theory</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181552</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We propose an approach to optimally synthesize quantum circuits from
non-permutative quantum gates such as Controlled-Square-Root-of-Not (i.e.
Controlled-V). Our approach reduces the synthesis problem to multiple-valued
optimization and uses group theory. We devise a novel technique that transforms
the quantum logic synthesis problem from a multi-valued constrained
optimization problem to a group permutation problem. The transformation enables
us to utilize group theory to exploit the properties of the synthesis problem.
Assuming a cost of one for each two-qubit gate, we found all reversible
circuits with quantum costs of 4, 5, 6, etc, and give another algorithm to
realize these reversible circuits with quantum gates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4695</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4695</id><created>2007-10-25</created><authors><author><keyname>Mishchenko</keyname><forenames>Alan</forenames></author><author><keyname>Brayton</keyname><forenames>Robert K.</forenames></author></authors><title>SAT-Based Complete Don't-Care Computation for Network Optimization</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181549</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper describes an improved approach to Boolean network optimization
using internal don't-cares. The improvements concern the type of don't-cares
computed, their scope, and the computation method. Instead of the traditionally
used compatible observability don't-cares (CODCs), we introduce and justify the
use of complete don't-cares (CDC). To ensure the robustness of the don't-care
computation for very large industrial networks, a optional windowing scheme is
implemented that computes substantial subsets of the CDCs in reasonable time.
Finally, we give a SAT-based don't-care computation algorithm that is more
efficient than BDD-based algorithms. Experimental results confirm that these
improvements work well in practice. Complete don't-cares allow for a reduction
in the number of literals compared to the CODCs. Windowing guarantees
robustness, even for very large benchmarks on which previous methods could not
be applied. SAT reduces the runtime and enhances robustness, making don't-cares
affordable for a variety of other Boolean methods applied to the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4697</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4697</id><created>2007-10-25</created><authors><author><keyname>Agarwal</keyname><forenames>Aseem</forenames></author><author><keyname>Chopra</keyname><forenames>Kaviraj</forenames></author><author><keyname>Blaauw</keyname><forenames>David</forenames></author></authors><title>Statistical Timing Based Optimization using Gate Sizing</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181547</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The increased dominance of intra-die process variations has motivated the
field of Statistical Static Timing Analysis (SSTA) and has raised the need for
SSTA-based circuit optimization. In this paper, we propose a new sensitivity
based, statistical gate sizing method. Since brute-force computation of the
change in circuit delay distribution to gate size change is computationally
expensive, we propose an efficient and exact pruning algorithm. The pruning
algorithm is based on a novel theory of perturbation bounds which are shown to
decrease as they propagate through the circuit. This allows pruning of gate
sensitivities without complete propagation of their perturbations. We apply our
proposed optimization algorithm to ISCAS benchmark circuits and demonstrate the
accuracy and efficiency of the proposed method. Our results show an improvement
of up to 10.5% in the 99-percentile circuit delay for the same circuit area,
using the proposed statistical optimizer and a run time improvement of up to
56x compared to the brute-force approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4698</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4698</id><created>2007-10-25</created><authors><author><keyname>Gadkari</keyname><forenames>Ambar A.</forenames></author><author><keyname>Ramesh</keyname><forenames>S.</forenames></author></authors><title>Automated Synthesis of Assertion Monitors using Visual Specifications</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181545</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Automated synthesis of monitors from high-level properties plays a
significant role in assertion-based verification. We present here a methodology
to synthesize assertion monitors from visual specifications given in CESC
(Clocked Event Sequence Chart). CESC is a visual language designed for
specifying system level interactions involving single and multiple clock
domains. It has well-defined graphical and textual syntax and formal semantics
based on synchronous language paradigm enabling formal analysis of
specifications. In this paper we provide an overview of CESC language with few
illustrative examples. The algorithm for automated synthesis of assertion
monitors from CESC specifications is described. A few examples from standard
bus protocols (OCP-IP and AMBA) are presented to demonstrate the application of
monitor synthesis algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4700</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4700</id><created>2007-10-25</created><authors><author><keyname>Stitt</keyname><forenames>Greg</forenames></author><author><keyname>Vahid</keyname><forenames>Frank</forenames></author></authors><title>A Decompilation Approach to Partitioning Software for
  Microprocessor/FPGA Platforms</title><categories>cs.SE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181546</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, we present a software compilation approach for
microprocessor/FPGA platforms that partitions a software binary onto custom
hardware implemented in the FPGA. Our approach imposes less restrictions on
software tool flow than previous compiler approaches, allowing software
designers to use any software language and compiler. Our approach uses a
back-end partitioning tool that utilizes decompilation techniques to recover
important high-level information, resulting in performance comparable to
high-level compiler-based approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4701</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4701</id><created>2007-10-25</created><authors><author><keyname>Lee</keyname><forenames>Jae-Gon</forenames></author><author><keyname>Chung</keyname><forenames>Moo-Kyoung</forenames></author><author><keyname>Ahn</keyname><forenames>Ki-Yong</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Heon</forenames></author><author><keyname>Kyung</keyname><forenames>Chong-Min</forenames></author></authors><title>A Prediction Packetizing Scheme for Reducing Channel Traffic in
  Transaction-Level Hardware/Software Co-Emulation</title><categories>cs.PF</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181544</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents a scheme for efficient channel usage between simulator
and accelerator where the accelerator models some RTL sub-blocks in the
accelerator-based hardware/software co-simulation while the simulator runs
transaction-level model of the remaining part of the whole chip being verified.
With conventional simulation accelerator, evaluations of simulator and
accelerator alternate at every valid simulation time, which results in poor
simulation performance due to startup overhead of simulator-accelerator channel
access. The startup overhead can be reduced by merging multiple transactions on
the channel into a single burst traffic. We propose a predictive packetizing
scheme for reducing channel traffic by merging as many transactions into a
burst traffic as possible based on 'prediction and rollback.' Under ideal
condition with 100% prediction accuracy, the proposed method shows a
performance gain of 1500% compared to the conventional one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4702</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4702</id><created>2007-10-25</created><authors><author><keyname>Baradaran</keyname><forenames>Nastaran</forenames></author><author><keyname>Diniz</keyname><forenames>Pedro C.</forenames></author></authors><title>A Register Allocation Algorithm in the Presence of Scalar Replacement
  for Fine-Grain Configurable Architectures</title><categories>cs.PL</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181487</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The aggressive application of scalar replacement to array references
substantially reduces the number of memory operations at the expense of a
possibly very large number of registers. In this paper we describe a register
allocation algorithm that assigns registers to scalar replaced array references
along the critical paths of a computation, in many cases exploiting the
opportunity for concurrent memory accesses. Experimental results, for a set of
image/signal processing code kernels, reveal that the proposed algorithm leads
to a substantial reduction of the number of execution cycles for the
corresponding hardware implementation on a contemporary
Field-Programmable-Gate-Array (FPGA) when compared to other greedy allocation
algorithms, in some cases, using even fewer number of registers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4703</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4703</id><created>2007-10-25</created><authors><author><keyname>Ishihara</keyname><forenames>Tohru</forenames></author><author><keyname>Fallah</keyname><forenames>Farzan</forenames></author></authors><title>A Way Memoization Technique for Reducing Power Consumption of Caches in
  Application Specific Integrated Processors</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181541</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents a technique for eliminating redundant cache-tag and
cache-way accesses to reduce power consumption. The basic idea is to keep a
small number of Most Recently Used (MRU) addresses in a Memory Address Buffer
(MAB) and to omit redundant tag and way accesses when there is a MAB-hit. Since
the approach keeps only tag and set-index values in the MAB, the energy and
area overheads are relatively small even for a MAB with a large number of
entries. Furthermore, the approach does not sacrifice the performance. In other
words, neither the cycle time nor the number of executed cycles increases. The
proposed technique has been applied to Fujitsu VLIW processor (FR-V) and its
power saving has been estimated using NanoSim. Experiments for 32kB 2-way set
associative caches show the power consumption of I-cache and D-cache can be
reduced by 40% and 50%, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4704</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4704</id><created>2007-10-25</created><authors><author><keyname>Kim</keyname><forenames>Yoonjin</forenames></author><author><keyname>Kiemb</keyname><forenames>Mary</forenames></author><author><keyname>Park</keyname><forenames>Chulsoo</forenames></author><author><keyname>Jung</keyname><forenames>Jinyong</forenames></author><author><keyname>Choi</keyname><forenames>Kiyoung</forenames></author></authors><title>Resource Sharing and Pipelining in Coarse-Grained Reconfigurable
  Architecture for Domain-Specific Optimization</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181488</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Coarse-grained reconfigurable architectures aim to achieve both goals of high
performance and flexibility. However, existing reconfigurable array
architectures require many resources without considering the specific
application domain. Functional resources that take long latency and/or large
area can be pipelined and/or shared among the processing elements. Therefore
the hardware cost and the delay can be effectively reduced without any
performance degradation for some application domains. We suggest such
reconfigurable array architecture template and design space exploration flow
for domain-specific optimization. Experimental results show that our approach
is much more efficient both in performance and area compared to existing
reconfigurable architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4705</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4705</id><created>2007-10-25</created><authors><author><keyname>Lysecky</keyname><forenames>Roman</forenames></author><author><keyname>Vahid</keyname><forenames>Frank</forenames></author></authors><title>A Study of the Speedups and Competitiveness of FPGA Soft Processor Cores
  using Dynamic Hardware/Software Partitioning</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181489</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Field programmable gate arrays (FPGAs) provide designers with the ability to
quickly create hardware circuits. Increases in FPGA configurable logic capacity
and decreasing FPGA costs have enabled designers to more readily incorporate
FPGAs in their designs. FPGA vendors have begun providing configurable soft
processor cores that can be synthesized onto their FPGA products. While FPGAs
with soft processor cores provide designers with increased flexibility, such
processors typically have degraded performance and energy consumption compared
to hard-core processors. Previously, we proposed warp processing, a technique
capable of optimizing a software application by dynamically and transparently
re-implementing critical software kernels as custom circuits in on-chip
configurable logic. In this paper, we study the potential of a MicroBlaze
soft-core based warp processing system to eliminate the performance and energy
overhead of a soft-core processor compared to a hard-core processor. We
demonstrate that the soft-core based warp processor achieves average speedups
of 5.8 and energy reductions of 57% compared to the soft core alone. Our data
shows that a soft-core based warp processor yields performance and energy
consumption competitive with existing hard-core processors, thus expanding the
usefulness of soft processor cores on FPGAs to a broader range of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4706</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4706</id><created>2007-10-25</created><authors><author><keyname>Rodrigues</keyname><forenames>Rui</forenames></author><author><keyname>Cardoso</keyname><forenames>Joao M. P.</forenames></author></authors><title>An Infrastructure to Functionally Test Designs Generated by Compilers
  Targeting FPGAs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181490</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents an infrastructure to test the functionality of the
specific architectures output by a high-level compiler targeting dynamically
reconfigurable hardware. It results in a suitable scheme to verify the
architectures generated by the compiler, each time new optimization techniques
are included or changes in the compiler are performed. We believe this kind of
infrastructure is important to verify, by functional simulation, further
research techniques, as far as compilation to Field-Programmable Gate Array
(FPGA) platforms is concerned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4707</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4707</id><created>2007-10-25</created><authors><author><keyname>Ogras</keyname><forenames>Umit Y.</forenames></author><author><keyname>Marculescu</keyname><forenames>Radu</forenames></author></authors><title>Energy- and Performance-Driven NoC Communication Architecture Synthesis
  Using a Decomposition Approach</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181540</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, we present a methodology for customized communication
architecture synthesis that matches the communication requirements of the
target application. This is an important problem, particularly for
network-based implementations of complex applications. Our approach is based on
using frequently encountered generic communication primitives as an alphabet
capable of characterizing any given communication pattern. The proposed
algorithm searches through the entire design space for a solution that
minimizes the system total energy consumption, while satisfying the other
design constraints. Compared to the standard mesh architecture, the customized
architecture generated by the newly proposed approach shows about 36%
throughput increase and 51% reduction in the energy required to encrypt 128
bits of data with a standard encryption algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4709</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4709</id><created>2007-10-25</created><authors><author><keyname>Gielen</keyname><forenames>Georges</forenames></author><author><keyname>Dehaene</keyname><forenames>Wim</forenames></author><author><keyname>Christie</keyname><forenames>Phillip</forenames></author><author><keyname>Draxelmayr</keyname><forenames>Dieter</forenames></author><author><keyname>Janssens</keyname><forenames>Edmond</forenames></author><author><keyname>Maex</keyname><forenames>Karen</forenames></author><author><keyname>Vucurevich</keyname><forenames>Ted</forenames></author></authors><title>Analog and Digital Circuit Design in 65 nm CMOS: End of the Road?</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181492</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This special session adresses the problems that designers face when
implementing analog and digital circuits in nanometer technologies. An
introductory embedded tutorial will give an overview of the design problems at
hand : the leakage power and process variability and their implications for
digital circuits and memories, and the reducing supply voltages, the design
productivity and signal integrity problems for embedded analog blocks. Next, a
panel of experts from both industrial semiconductor houses and design
companies, EDA vendors and research institutes will present and discuss with
the audience their opinions on whether the design road ends at marker "65nm" or
not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4710</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4710</id><created>2007-10-25</created><authors><author><keyname>Iranli</keyname><forenames>Ali</forenames></author><author><keyname>Fatemi</keyname><forenames>Hanif</forenames></author><author><keyname>Pedram</keyname><forenames>Massoud</forenames></author></authors><title>HEBS: Histogram Equalization for Backlight Scaling</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181539</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, a method is proposed for finding a pixel transformation
function that maximizes backlight dimming while maintaining a pre-specified
image distortion level for a liquid crystal display. This is achieved by
finding a pixel transformation function, which maps the original image
histogram to a new histogram with lower dynamic range. Next the contrast of the
transformed image is enhanced so as to compensate for brightness loss that
would arise from backlight dimming. The proposed approach relies on an accurate
definition of the image distortion which takes into account both the pixel
value differences and a model of the human visual system and is amenable to
highly efficient hardware realization. Experimental results show that the
histogram equalization for backlight scaling method results in about 45% power
saving with an effective distortion rate of 5% and 65% power saving for a 20%
distortion rate. This is significantly higher power savings compared to
previously reported backlight dimming approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4711</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4711</id><created>2007-10-25</created><authors><author><keyname>Huot</keyname><forenames>N.</forenames><affiliation>TIMA</affiliation></author><author><keyname>Dubreuil</keyname><forenames>H.</forenames><affiliation>TIMA</affiliation></author><author><keyname>Fesquet</keyname><forenames>L.</forenames><affiliation>TIMA</affiliation></author><author><keyname>Renaudin</keyname><forenames>M.</forenames><affiliation>TIMA</affiliation></author></authors><title>FPGA Architecture for Multi-Style Asynchronous Logic</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181491</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents a novel FPGA architecture for implementing various styles
of asynchronous logic. The main objective is to break the dependency between
the FPGA architecture dedicated to asynchronous logic and the logic style. The
innovative aspects of the architecture are described. Moreover the structure is
well suited to be rebuilt and adapted to fit with further asynchronous logic
evolutions thanks to the architecture genericity. A full-adder was implemented
in different styles of logic to show the architecture flexibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4712</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4712</id><created>2007-10-25</created><authors><author><keyname>Asadi</keyname><forenames>Ghazanfar</forenames></author><author><keyname>Tahoori</keyname><forenames>Mehdi B.</forenames></author></authors><title>An Accurate SER Estimation Method Based on Propagation Probability</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181534</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, we present an accurate but very fast soft error rate (SER)
estimation technique for digital circuits based on error propagation
probability (EPP) computation. Experiments results and comparison of the
results with the random simulation technique show that our proposed method is
on average within 6% of the random simulation method and four to five orders of
magnitude faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4713</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4713</id><created>2007-10-25</created><authors><author><keyname>Neiroukh</keyname><forenames>Osama</forenames></author><author><keyname>Song</keyname><forenames>Xiaoyu</forenames></author></authors><title>Improving the Process-Variation Tolerance of Digital Circuits Using Gate
  Sizing and Statistical Techniques</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181532</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  A new approach for enhancing the process-variation tolerance of digital
circuits is described. We extend recent advances in statistical timing analysis
into an optimization framework. Our objective is to reduce the performance
variance of a technology-mapped circuit where delays across elements are
represented by random variables which capture the manufacturing variations. We
introduce the notion of statistical critical paths, which account for both
means and variances of performance variation. An optimization engine is used to
size gates with a goal of reducing the timing variance along the statistical
critical paths. We apply a pair of nested statistical analysis methods
deploying a slower more accurate approach for tracking statistical critical
paths and a fast engine for evaluation of gate size assignments. We derive a
new approximation for the max operation on random variables which is deployed
for the faster inner engine. Circuit optimization is carried out using a
gain-based algorithm that terminates when constraints are satisfied or no
further improvements can be made. We show optimization results that demonstrate
an average of 72% reduction in performance variation at the expense of average
20% increase in design area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4714</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4714</id><created>2007-10-25</created><authors><author><keyname>Yu</keyname><forenames>Jia</forenames></author><author><keyname>Wu</keyname><forenames>Wei</forenames></author><author><keyname>Chen</keyname><forenames>Xi</forenames></author><author><keyname>Hsieh</keyname><forenames>Harry</forenames></author><author><keyname>Yang</keyname><forenames>Jun</forenames></author><author><keyname>Balarin</keyname><forenames>Felice</forenames></author></authors><title>Assertion-Based Design Exploration of DVS in Network Processor
  Architectures</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181501</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  With the scaling of technology and higher requirements on performance and
functionality, power dissipation is becoming one of the major design
considerations in the development of network processors. In this paper, we use
an assertion-based methodology for system-level power/performance analysis to
study two dynamic voltage scaling (DVS) techniques, traffic-based DVS and
execution-based DVS, in a network processor model. Using the automatically
generated distribution analyzers, we analyze the power and performance
distributions and study their trade-offs for the two DVS policies with
different parameter settings such as threshold values and window sizes. We
discuss the optimal configurations of the two DVS policies under different
design requirements. By a set of experiments, we show that the assertion-based
trace analysis methodology is an efficient tool that can help a designer easily
compare and study optimal architectural configurations in a large design space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4715</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4715</id><created>2007-10-25</created><authors><author><keyname>Carter</keyname><forenames>Jonathan R.</forenames></author><author><keyname>Ozev</keyname><forenames>Sule</forenames></author><author><keyname>Sorin</keyname><forenames>Daniel J.</forenames></author></authors><title>Circuit-Level Modeling for Concurrent Testing of Operational Defects due
  to Gate Oxide Breakdown</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181533</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As device sizes shrink and current densities increase, the probability of
device failures due to gate oxide breakdown (OBD) also increases. To provide
designs that are tolerant to such failures, we must investigate and understand
the manifestations of this physical phenomenon at the circuit and system level.
In this paper, we develop a model for operational OBD defects, and we explore
how to test for faults due to OBD. For a NAND gate, we derive the necessary
input conditions that excite and detect errors due to OBD defects at the gate
level. We show that traditional pattern generators fail to exercise all of
these defects. Finally, we show that these test patterns can be propagated and
justified for a combinational circuit in a manner similar to traditional ATPG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4716</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4716</id><created>2007-10-25</created><authors><author><keyname>Guo</keyname><forenames>Zhi</forenames></author><author><keyname>Buyukkurt</keyname><forenames>Betul</forenames></author><author><keyname>Najjar</keyname><forenames>Walid</forenames></author><author><keyname>Vissers</keyname><forenames>Kees</forenames></author></authors><title>Optimized Generation of Data-Path from C Codes for FPGAs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181503</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  FPGAs, as computing devices, offer significant speedup over microprocessors.
Furthermore, their configurability offers an advantage over traditional ASICs.
However, they do not yet enjoy high-level language programmability, as
microprocessors do. This has become the main obstacle for their wider
acceptance by application designers. ROCCC is a compiler designed to generate
circuits from C source code to execute on FPGAs, more specifically on CSoCs. It
generates RTL level HDLs from frequently executing kernels in an application.
In this paper, we describe ROCCC's system overview and focus on its data path
generation. We compare the performance of ROCCC-generated VHDL code with that
of Xilinx IPs. The synthesis result shows that ROCCC-generated circuit takes
around 2x ~ 3x area and runs at comparable clock rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4717</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4717</id><created>2007-10-25</created><authors><author><keyname>Badaoui</keyname><forenames>Raoul F.</forenames></author><author><keyname>Vemuri</keyname><forenames>Ranga</forenames></author></authors><title>Multi-Placement Structures for Fast and Optimized Placement in Analog
  Circuit Synthesis</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181507</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents the novel idea of multi-placement structures, for a fast
and optimized placement instantiation in analog circuit synthesis. These
structures need to be generated only once for a specific circuit topology. When
used in synthesis, these pre-generated structures instantiate various layout
floorplans for various sizes and parameters of a circuit. Unlike procedural
layout generators, they enable fast placement of circuits while keeping the
quality of the placements at a high level during a synthesis process. The fast
placement is a result of high speed instantiation resulting from the efficiency
of the multi-placement structure. The good quality of placements derive from
the extensive and intelligent search process that is used to build the
multi-placement structure. The target benchmarks of these structures are analog
circuits in the vicinity of 25 modules. An algorithm for the generation of such
multi-placement structures is presented. Experimental results show placement
execution times with an average of a few milliseconds making them usable during
layout-aware synthesis for optimized placements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4718</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4718</id><created>2007-10-25</created><authors><author><keyname>Negreiros</keyname><forenames>Marcelo</forenames></author><author><keyname>Carro</keyname><forenames>Luigi</forenames></author><author><keyname>Susin</keyname><forenames>Altamiro A.</forenames></author></authors><title>Noise Figure Evaluation Using Low Cost BIST</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181509</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  A technique for evaluating noise figure suitable for BIST implementation is
described. It is based on a low cost single-bit digitizer, which allows the
simultaneous evaluation of noise figure in several test points of the analog
circuit. The method is also able to benefit from SoC resources, like memory and
processing power. Theoretical background and experimental results are presented
in order to demonstrate the feasibility of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4719</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4719</id><created>2007-10-25</created><authors><author><keyname>Biswas</keyname><forenames>Sounil</forenames><affiliation>shawn</affiliation></author><author><keyname>Li</keyname><forenames>Peng</forenames><affiliation>shawn</affiliation></author><author><keyname>D.</keyname><forenames>R.</forenames><affiliation>shawn</affiliation></author><author><keyname>Blanton</keyname></author><author><keyname>Pileggi</keyname><forenames>Larry T.</forenames></author></authors><title>Specification Test Compaction for Analog Circuits and MEMS</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181510</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Testing a non-digital integrated system against all of its specifications can
be quite expensive due to the elaborate test application and measurement setup
required. We propose to eliminate redundant tests by employing e-SVM based
statistical learning. Application of the proposed methodology to an operational
amplifier and a MEMS accelerometer reveal that redundant tests can be
statistically identified from a complete set of specification-based tests with
negligible error. Specifically, after eliminating five of eleven
specification-based tests for an operational amplifier, the defect escape and
yield loss is small at 0.6% and 0.9%, respectively. For the accelerometer,
defect escape of 0.2% and yield loss of 0.1% occurs when the hot and colt tests
are eliminated. For the accelerometer, this level of Compaction would reduce
test cost by more than half.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4720</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4720</id><created>2007-10-25</created><authors><author><keyname>Dhillon</keyname><forenames>Yuvraj Singh</forenames></author><author><keyname>Diril</keyname><forenames>Abdulkadir Utku</forenames></author><author><keyname>Chatterjee</keyname><forenames>Abhijit</forenames></author></authors><title>Soft-Error Tolerance Analysis and Optimization of Nanometer Circuits</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181531</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Nanometer circuits are becoming increasingly susceptible to soft-errors due
to alpha-particle and atmospheric neutron strikes as device scaling reduces
node capacitances and supply/threshold voltage scaling reduces noise margins.
It is becoming crucial to add soft-error tolerance estimation and optimization
to the design flow to handle the increasing susceptibility. The first part of
this paper presents a tool for accurate soft-error tolerance analysis of
nanometer circuits (ASERTA) that can be used to estimate the soft-error
tolerance of nanometer circuits consisting of millions of gates. The tolerance
estimates generated by the tool match SPICE generated estimates closely while
taking orders of magnitude less computation time. The second part of the paper
presents a tool for soft-error tolerance optimization of nanometer circuits
(SERTOPT) using the tolerance estimates generated by ASERTA. The tool finds
optimal sizes, channel lengths, supply voltages and threshold voltages to be
assigned to gates in a combinational circuit such that the soft-error tolerance
is increased while meeting the timing constraint. Experiments on ISCAS'85
benchmark circuits showed that soft-error rate of the optimized circuit
decreased by as much as 47% with marginal increase in circuit delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4721</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4721</id><created>2007-10-25</created><authors><author><keyname>Syri</keyname><forenames>Pekka</forenames></author><author><keyname>Hakkinen</keyname><forenames>Juha</forenames></author><author><keyname>Moilanen</keyname><forenames>Markku</forenames></author></authors><title>IEEE 1149.4 Compatible ABMs for Basic RF Measurements</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181511</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  An analogue testing standard IEEE 1149.4 is mainly targeted for low-frequency
testing. The problem studied in this paper is extending the standard also for
radio frequency testing. IEEE 1149.4 compatible measurement structures (ABMs)
developed in this study extract the information one is measuring from the radio
frequency signal and represent the result as a DC voltage level. The ABMs
presented in this paper are targeted for power and frequency measurements
operating in frequencies from 1 GHz to 2 GHz. The power measurement error
caused by temperature, supply voltage and process variations is roughly 2 dB
and the frequency measurement error is 0.1 GHz, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4722</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4722</id><created>2007-10-25</created><authors><author><keyname>Chien</keyname><forenames>Yu-Tsun</forenames></author><author><keyname>Chen</keyname><forenames>Dong</forenames></author><author><keyname>Lou</keyname><forenames>Jea-Hong</forenames></author><author><keyname>Ma</keyname><forenames>Gin-Kou</forenames></author><author><keyname>Rutenbar</keyname><forenames>Rob A.</forenames></author><author><keyname>Mukherjee</keyname><forenames>Tamal</forenames></author></authors><title>Designer-Driven Topology Optimization for Pipelined Analog to Digital
  Converters</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181529</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper suggests a practical "hybrid" synthesis methodology which
integrates designer-derived analytical models for system-level description with
simulation-based models at the circuit level. We show how to optimize
stage-resolution to minimize the power in a pipelined ADC. Exploration (via
detailed synthesis) of several ADC configurations is used to show that a
4-3-2... resolution distribution uses the least power for a 13-bit 40 MSPS
converter in a 0.25 $\mu$m CMOS process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4723</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4723</id><created>2007-10-25</created><authors><author><keyname>Soens</keyname><forenames>C.</forenames></author><author><keyname>Van Der Plas</keyname><forenames>G.</forenames></author><author><keyname>Wambacq</keyname><forenames>P.</forenames></author><author><keyname>Donnay</keyname><forenames>S.</forenames></author></authors><title>Simulation Methodology for Analysis of Substrate Noise Impact on Analog
  / RF Circuits Including Interconnect Resistance</title><categories>cs.PF</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181527</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper reports a novel simulation methodology for analysis and prediction
of substrate noise impact on analog / RF circuits taking into account the role
of the parasitic resistance of the on-chip interconnect in the impact
mechanism. This methodology allows investigation of the role of the separate
devices (also parasitic devices) in the analog / RF circuit in the overall
impact. This way is revealed which devices have to be taken care of (shielding,
topology change) to protect the circuit against substrate noise. The developed
methodology is used to analyze impact of substrate noise on a 3 GHz LC-tank
Voltage Controlled Oscillator (VCO) designed in a high-ohmic 0.18 $\mu$m 1PM6
CMOS technology. For this VCO (in the investigated frequency range from DC to
15 MHz) impact is mainly caused by resistive coupling of noise from the
substrate to the non-ideal on-chip ground interconnect, resulting in analog
ground bounce and frequency modulation. Hence, the presented test-case reveals
the important role of the on-chip interconnect in the phenomenon of substrate
noise impact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4724</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4724</id><created>2007-10-25</created><authors><author><keyname>Barrandon</keyname><forenames>L.</forenames><affiliation>IETR</affiliation></author><author><keyname>Crand</keyname><forenames>S.</forenames><affiliation>IETR</affiliation></author><author><keyname>Houzet</keyname><forenames>D.</forenames><affiliation>IETR</affiliation></author></authors><title>Systematic Figure of Merit Computation for the Design of Pipeline ADC</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181528</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The emerging concept of SoC-AMS leads to research new top-down methodologies
to aid systems designers in sizing analog and mixed devices. This work applies
this idea to the high-level optimization of pipeline ADC. Considering a given
technology, it consists in comparing different configurations according to
their imperfections and their architectures without FFT computation or
time-consuming simulations. The final selection is based on a figure of merit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4725</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4725</id><created>2007-10-25</created><authors><author><keyname>Savioli</keyname><forenames>Carlos Eduardo</forenames></author><author><keyname>Czendrodi</keyname><forenames>Claudio C.</forenames></author><author><keyname>Calvano</keyname><forenames>Jose Vicente</forenames></author><author><keyname>Filho</keyname><forenames>Antonio Carneiro De Mesquita</forenames></author></authors><title>Fault-Trajectory Approach for Fault Diagnosis on Analog Circuits</title><categories>cs.NE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181512</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This issue discusses the fault-trajectory approach suitability for fault
diagnosis on analog networks. Recent works have shown promising results
concerning a method based on this concept for ATPG for diagnosing faults on
analog networks. Such method relies on evolutionary techniques, where a generic
algorithm (GA) is coded to generate a set of optimum frequencies capable to
disclose faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4727</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4727</id><created>2007-10-25</created><authors><author><keyname>Muller</keyname><forenames>Paul</forenames></author><author><keyname>Tajalli</keyname><forenames>Armin</forenames></author><author><keyname>Atarodi</keyname><forenames>Mojtaba</forenames></author><author><keyname>Leblebici</keyname><forenames>Yusuf</forenames></author></authors><title>Top-Down Design of a Low-Power Multi-Channel 2.5-Gbit/s/Channel Gated
  Oscillator Clock-Recovery Circuit</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181525</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  We present a complete top-down design of a low-power multi-channel clock
recovery circuit based on gated current-controlled oscillators. The flow
includes several tools and methods used to specify block constraints, to design
and verify the topology down to the transistor level, as well as to achieve a
power consumption as low as 5mW/Gbit/s. Statistical simulation is used to
estimate the achievable bit error rate in presence of phase and frequency
errors and to prove the feasibility of the concept. VHDL modeling provides
extensive verification of the topology. Thermal noise modeling based on
well-known concepts delivers design parameters for the device sizing and
biasing. We present two practical examples of possible design improvements
analyzed and implemented with this methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4728</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4728</id><created>2007-10-25</created><authors><author><keyname>Kao</keyname><forenames>Jung-Chun</forenames></author><author><keyname>Marculescu</keyname><forenames>Radu</forenames></author></authors><title>Energy-Aware Routing for E-Textile Applications</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181514</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As the scale of electronic devices shrinks, "electronic textiles"
(e-textiles) will make possible a wide variety of novel applications which are
currently unfeasible. Due to the wearability concerns, low-power techniques are
critical for e-textile applications. In this paper, we address the issue of the
energy-aware routing for e-textile platforms and propose an efficient algorithm
to solve it. The platform we consider consists of dedicated components for
e-textiles, including computational modules, dedicated transmission lines and
thin-film batteries on fiber substrates. Furthermore, we derive an analytical
upper bound for the achievable number of jobs completed over all possible
routing strategies. From a practical standpoint, for the Advanced Encryption
Standard (AES) cipher, the routing technique we propose achieves about fifty
percent of this analytical upper bound. Moreover, compared to the
non-energy-aware counterpart, our routing technique increases the number of
encryption jobs completed by one order of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4729</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4729</id><created>2007-10-25</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Saibal</forenames></author><author><keyname>Bhunia</keyname><forenames>Swarup</forenames></author><author><keyname>Roy</keyname><forenames>Kaushik</forenames></author></authors><title>Modeling and Analysis of Loading Effect in Leakage of Nano-Scaled
  Bulk-CMOS Logic Circuits</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181519</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In nanometer scaled CMOS devices significant increase in the subthreshold,
the gate and the reverse biased junction band-to-band-tunneling (BTBT) leakage,
results in the large increase of total leakage power in a logic circuit.
Leakage components interact with each other in device level (through device
geometry, doping profile) and also in the circuit level (through node
voltages). Due to the circuit level interaction of the different leakage
components, the leakage of a logic gate strongly depends on the circuit
topology i.e. number and nature of the other logic gates connected to its input
and output. In this paper, for the first time, we have analyzed loading effect
on leakage and proposed a method to accurately estimate the total leakage in a
logic circuit, from its logic level description considering the impact of
loading and transistor stacking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4731</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4731</id><created>2007-10-25</created><authors><author><keyname>Tsai</keyname><forenames>Yuh-Fang</forenames></author><author><keyname>Narayaynan</keyname><forenames>Vijaykrishnan</forenames></author><author><keyname>Xie</keyname><forenames>Yuan</forenames></author><author><keyname>Irwin</keyname><forenames>Mary Jane</forenames></author></authors><title>Leakage-Aware Interconnect for On-Chip Network</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181520</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  On-chip networks have been proposed as the interconnect fabric for future
systems-on-chip and multi-processors on chip. Power is one of the main
constraints of these systems and interconnect consumes a significant portion of
the power budget. In this paper, we propose four leakage-aware interconnect
schemes. Our schemes achieve 10.13%~63.57% active leakage savings and
12.35%~95.96% standby leakage savings across schemes while the delay penalty
ranges from 0% to 4.69%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4732</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4732</id><created>2007-10-25</created><authors><author><keyname>Bougard</keyname><forenames>Bruno</forenames></author><author><keyname>Catthoor</keyname><forenames>Francky</forenames></author><author><keyname>Daly</keyname><forenames>Denis C.</forenames></author><author><keyname>Chandrakasan</keyname><forenames>Anantha</forenames></author><author><keyname>Dehaene</keyname><forenames>Wim</forenames></author></authors><title>Energy Efficiency of the IEEE 802.15.4 Standard in Dense Wireless
  Microsensor Networks: Modeling and Improvement Perspectives</title><categories>cs.NI</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181516</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Wireless microsensor networks, which have been the topic of intensive
research in recent years, are now emerging in industrial applications. An
important milestone in this transition has been the release of the IEEE
802.15.4 standard that specifies interoperable wireless physical and medium
access control layers targeted to sensor node radios. In this paper, we
evaluate the potential of an 802.15.4 radio for use in an ultra low power
sensor node operating in a dense network. Starting from measurements carried
out on the off-the-shelf radio, effective radio activation and link adaptation
policies are derived. It is shown that, in a typical sensor network scenario,
the average power per node can be reduced down to 211m mm mW. Next, the energy
consumption breakdown between the different phases of a packet transmission is
presented, indicating which part of the transceiver architecture can most
effectively be optimized in order to further reduce the radio power, enabling
self-powered wireless microsensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4733</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4733</id><created>2007-10-25</created><authors><author><keyname>Bota</keyname><forenames>S. A.</forenames></author><author><keyname>Rosales</keyname><forenames>M.</forenames></author><author><keyname>Rossello</keyname><forenames>J. L.</forenames></author><author><keyname>Segura</keyname><forenames>J.</forenames></author></authors><title>Smart Temperature Sensor for Thermal Testing of Cell-Based ICs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181652</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper we present a simple and efficient built-in temperature sensor
for thermal monitoring of standard-cell based VLSI circuits. The proposed smart
temperature sensor uses a ring-oscillator composed of complex gates instead of
inverters to optimize their linearity. Simulation results from a 0.18$\mu$m
CMOS technology show that the non-linearity error of the sensor can be reduced
when an adequate set of standard logic gates is selected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4734</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4734</id><created>2007-10-25</created><authors><author><keyname>Liau</keyname><forenames>Eric</forenames></author><author><keyname>Schmitt-Landsiedel</keyname><forenames>Doris</forenames></author></authors><title>Computational Intelligence Characterization Method of Semiconductor
  Device</title><categories>cs.AI cs.NE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181555</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Characterization of semiconductor devices is used to gather as much data
about the device as possible to determine weaknesses in design or trends in the
manufacturing process. In this paper, we propose a novel multiple trip point
characterization concept to overcome the constraint of single trip point
concept in device characterization phase. In addition, we use computational
intelligence techniques (e.g. neural network, fuzzy and genetic algorithm) to
further manipulate these sets of multiple trip point values and tests based on
semiconductor test equipments, Our experimental results demonstrate an
excellent design parameter variation analysis in device characterization phase,
as well as detection of a set of worst case tests that can provoke the worst
case variation, while traditional approach was not capable of detecting them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4735</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4735</id><created>2007-10-25</created><authors><author><keyname>Pomeranz</keyname><forenames>Irith</forenames></author><author><keyname>Reddy</keyname><forenames>Sudhakar M.</forenames></author></authors><title>Worst-Case and Average-Case Analysis of n-Detection Test Sets</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181554</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Test sets that detect each target fault n times (n-detection test sets) are
typically generated for restricted values of n due to the increase in test set
size with n. We perform both a worst-case analysis and an average-case analysis
to check the effect of restricting n on the unmodeled fault coverage of an
(arbitrary) n-detection test set. Our analysis is independent of any particular
test set or test generation approach. It is based on a specific set of target
faults and a specific set of untargeted faults. It shows that, depending on the
circuit, very large values of n may be needed to guarantee the detection of all
the untargeted faults. We discuss the implications of these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4736</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4736</id><created>2007-10-25</created><authors><author><keyname>Lopez</keyname><forenames>L.</forenames><affiliation>L2MP</affiliation></author><author><keyname>Portal</keyname><forenames>J. M.</forenames><affiliation>L2MP</affiliation></author><author><keyname>Nee</keyname><forenames>D.</forenames><affiliation>ST-Rousset</affiliation></author></authors><title>A New Embedded Measurement Structure for eDRAM Capacitor</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181649</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The embedded DRAM (eDRAM) is more and more used in System On Chip (SOC). The
integration of the DRAM capacitor process into a logic process is challenging
to get satisfactory yields. The specific process of DRAM capacitor and the low
capacitance value (~30F) of this device induce problems of process monitoring
and failure analysis. We propose a new test structure to measure the
capacitance value of each DRAM cell capacitor in a DRAM array. This concept has
been validated by simulation on a 0.18$\mu$m eDRAM technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4737</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4737</id><created>2007-10-25</created><authors><author><keyname>Albers</keyname><forenames>Karsten</forenames></author><author><keyname>Slomka</keyname><forenames>Frank</forenames></author></authors><title>Efficient Feasibility Analysis for Real-Time Systems with EDF Scheduling</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181560</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents new fast exact feasibility tests for uniprocessor
real-time systems using preemptive EDF scheduling. Task sets which are accepted
by previously described sufficient tests will be evaluated in nearly the same
time as with the old tests by the new algorithms. Many task sets are not
accepted by the earlier tests despite them beeing feasible. These task sets
will be evaluated by the new algorithms a lot faster than with known exact
feasibility tests. Therefore it is possible to use them for many applications
for which only sufficient test are suitable. Additionally this paper shows that
the best previous known sufficient test, the best known feasibility bound and
the best known approximation algorithm can be derived from these new tests. In
result this leads to an integrated schedulability theory for EDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4738</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4738</id><created>2007-10-25</created><authors><author><keyname>Marcon</keyname><forenames>Cesar</forenames></author><author><keyname>Calazans</keyname><forenames>Ney</forenames></author><author><keyname>Moraes</keyname><forenames>Fernando</forenames></author><author><keyname>Susin</keyname><forenames>Altamiro</forenames></author><author><keyname>Reis</keyname><forenames>Igor</forenames></author><author><keyname>Hessel</keyname><forenames>Fabiano</forenames></author></authors><title>Exploring NoC Mapping Strategies: An Energy and Timing Aware Technique</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181561</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Complex applications implemented as Systems on Chip (SoCs) demand extensive
use of system level modeling and validation. Their implementation gathers a
large number of complex IP cores and advanced interconnection schemes, such as
hierarchical bus architectures or networks on chip (NoCs). Modeling
applications involves capturing its computation and communication
characteristics. Previously proposed communication weighted models (CWM)
consider only the application communication aspects. This work proposes a
communication dependence and computation model (CDCM) that can simultaneously
consider both aspects of an application. It presents a solution to the problem
of mapping applications on regular NoCs while considering execution time and
energy consumption. The use of CDCM is shown to provide estimated average
reductions of 40% in execution time, and 20% in energy consumption, for current
technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4739</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4739</id><created>2007-10-25</created><authors><author><keyname>Li</keyname><forenames>Min</forenames></author><author><keyname>Wu</keyname><forenames>Xiaobo</forenames></author><author><keyname>Yao</keyname><forenames>Richard</forenames></author><author><keyname>Yan</keyname><forenames>Xiaolang</forenames></author></authors><title>Q-DPM: An Efficient Model-Free Dynamic Power Management Technique</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181564</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  When applying Dynamic Power Management (DPM) technique to pervasively
deployed embedded systems, the technique needs to be very efficient so that it
is feasible to implement the technique on low end processor and tight-budget
memory. Furthermore, it should have the capability to track time varying
behavior rapidly because the time varying is an inherent characteristic of real
world system. Existing methods, which are usually model-based, may not satisfy
the aforementioned requirements. In this paper, we propose a model-free DPM
technique based on Q-Learning. Q-DPM is much more efficient because it removes
the overhead of parameter estimator and mode-switch controller. Furthermore,
its policy optimization is performed via consecutive online trialing, which
also leads to very rapid response to time varying behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4740</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4740</id><created>2007-10-25</created><authors><author><keyname>Brinkmeyer</keyname><forenames>Horst</forenames></author></authors><title>A New Approach to Component Testing</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181566</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Carefully tested electric/electronic components are a requirement for
effective hardware-in-the-loop tests and vehicle tests in automotive industry.
A new method for definition and execution of component tests is described. The
most important advantage of this method is independance from the test stand. It
therefore offers the oppportunity to build up knowledge over a long period of
time and the ability to share this knowledge with different partners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4742</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4742</id><created>2007-10-25</created><authors><author><keyname>Coburn</keyname><forenames>Joel</forenames></author><author><keyname>Ravi</keyname><forenames>Srivaths</forenames></author><author><keyname>Raghunathan</keyname><forenames>Anand</forenames></author></authors><title>Hardware Accelerated Power Estimation</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181565</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, we present power emulation, a novel design paradigm that
utilizes hardware acceleration for the purpose of fast power estimation. Power
emulation is based on the observation that the functions necessary for power
estimation (power model evaluation, aggregation, etc.) can be implemented as
hardware circuits. Therefore, we can enhance any given design with "power
estimation hardware", map it to a prototyping platform, and exercise it with
any given test stimuli to obtain power consumption estimates. Our empirical
studies with industrial designs reveal that power emulation can achieve
significant speedups (10X to 500X) over state-of-the-art commercial
register-transfer level (RTL) power estimation tools.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4743</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4743</id><created>2007-10-25</created><authors><author><keyname>Mishchenko</keyname><forenames>Alan</forenames></author><author><keyname>Brayton</keyname><forenames>Robert</forenames></author><author><keyname>Jiang</keyname><forenames>Roland</forenames></author><author><keyname>Villa</keyname><forenames>Tiziano</forenames></author><author><keyname>Yevtushenko</keyname><forenames>Nina</forenames></author></authors><title>Efficient Solution of Language Equations Using Partitioned
  Representations</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181647</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  A class of discrete event synthesis problems can be reduced to solving
language equations f . X &amp;sube; S, where F is the fixed component and S the
specification. Sequential synthesis deals with FSMs when the automata for F and
S are prefix closed, and are naturally represented by multi-level networks with
latches. For this special case, we present an efficient computation, using
partitioned representations, of the most general prefix-closed solution of the
above class of language equations. The transition and the output relations of
the FSMs for F and S in their partitioned form are represented by the sets of
output and next state functions of the corresponding networks. Experimentally,
we show that using partitioned representations is much faster than using
monolithic representations, as well as applicable to larger problem instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4745</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4745</id><created>2007-10-25</created><authors><author><keyname>Langenwalter</keyname><forenames>Joachim</forenames></author></authors><title>Embedded Automotive System Development Process</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181567</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Model based design enables the automatic generation of final-build software
from models for high-volume automotive embedded systems. This paper presents a
framework of processes, methods and tools for the design of automotive embedded
systems. A steer-by-wire system serves as an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4746</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4746</id><created>2007-10-25</created><authors><author><keyname>Hassan</keyname><forenames>M. Abdelsalam</forenames></author><author><keyname>Sakanushi</keyname><forenames>Keishi</forenames></author><author><keyname>Takeuchi</keyname><forenames>Yoshinori</forenames></author><author><keyname>Imai</keyname><forenames>Masaharu</forenames></author></authors><title>RTK-Spec TRON: A Simulation Model of an ITRON Based RTOS Kernel in
  SystemC</title><categories>cs.OS</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181570</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents the methodology and the modeling constructs we have
developed to capture the real time aspects of RTOS simulation models in a
System Level Design Language (SLDL) like SystemC. We describe these constructs
and show how they are used to build a simulation model of an RTOS kernel
targeting the $\mu$-ITRON OS specification standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4747</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4747</id><created>2007-10-25</created><authors><author><keyname>Li</keyname><forenames>Jin-Fu</forenames></author><author><keyname>Tseng</keyname><forenames>Tsu-Wei</forenames></author><author><keyname>Wey</keyname><forenames>Chin-Long</forenames></author></authors><title>An Efficient Transparent Test Scheme for Embedded Word-Oriented Memories</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181573</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Memory cores are usually the densest portion with the smallest feature size
in system-on-chip (SOC) designs. The reliability of memory cores thus has heavy
impact on the reliability of SOCs. Transparent test is one of useful technique
for improving the reliability of memories during life time. This paper presents
a systematic algorithm used for transforming a bit-oriented march test into a
transparent word-oriented march test. The transformed transparent march test
has shorter test complexity compared with that proposed in the previous works
[Theory of transparent BIST for RAMs, A transparent online memory test for
simultaneous detection of functional faults and soft errors in memories]. For
example, if a memory with 32-bit words is tested with March C-, time complexity
of the transparent word-oriented test transformed by the proposed scheme is
only about 56% or 19% time complexity of the transparent word-oriented test
converted by the scheme reported in [Theory of transparent BIST for RAMs] or [A
transparent online memory test for simultaneous detection of functional faults
and soft errors in memories], respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4748</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4748</id><created>2007-10-25</created><authors><author><keyname>Klingauf</keyname><forenames>Wolfgang</forenames></author></authors><title>Systematic Transaction Level Modeling of Embedded Systems with SystemC</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181572</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper gives an overview of a transaction level modeling (TLM) design
flow for straightforward embedded system design with SystemC. The goal is to
systematically develop both application-specific HW and SW components of an
embedded system using the TLM approach, thus allowing for fast communication
architecture exploration, rapid prototyping and early embedded SW development.
To this end, we specify the lightweight transaction-based communication
protocol SHIP and present a methodology for automatic mapping of the
communication part of a system to a given architecture, including HW/SW
interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4750</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4750</id><created>2007-10-25</created><authors><author><keyname>Schiano</keyname><forenames>L.</forenames></author><author><keyname>Ottavi</keyname><forenames>M.</forenames></author><author><keyname>Lombardi</keyname><forenames>F.</forenames></author><author><keyname>Pontarelli</keyname><forenames>S.</forenames></author><author><keyname>Salsano</keyname><forenames>A.</forenames></author></authors><title>On the Analysis of Reed Solomon Coding for Resilience to
  Transient/Permanent Faults in Highly Reliable Memories</title><categories>cs.IT math.IT</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181574</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Single Event Upsets (SEU) as well as permanent faults can significantly
affect the correct on-line operation of digital systems, such as memories and
microprocessors; a memory can be made resilient to permanent and transient
faults by using modular redundancy and coding. In this paper, different memory
systems are compared: these systems utilize simplex and duplex arrangements
with a combination of Reed Solomon coding and scrubbing. The memory systems and
their operations are analyzed by novel Markov chains to characterize
performance for dynamic reconfiguration as well as error detection and
correction under the occurrence of permanent and transient faults. For a
specific Reed Solomon code, the duplex arrangement allows to efficiently cope
with the occurrence of permanent faults, while the use of scrubbing allows to
cope with transient faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4751</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4751</id><created>2007-10-25</created><authors><author><keyname>Wehmeyer</keyname><forenames>Lars</forenames></author><author><keyname>Marwedel</keyname><forenames>Peter</forenames></author></authors><title>Influence of Memory Hierarchies on Predictability for Time Constrained
  Embedded Software</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181576</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Safety-critical embedded systems having to meet real-time constraints are
expected to be highly predictable in order to guarantee at design time that
certain timing deadlines will always be met. This requirement usually prevents
designers from utilizing caches due to their highly dynamic, thus hardly
predictable behavior. The integration of scratchpad memories represents an
alternative approach which allows the system to benefit from a performance gain
comparable to that of caches while at the same time maintaining predictability.
In this work, we compare the impact of scratchpad memories and caches on worst
case execution time (WCET) analysis results. We show that caches, despite
requiring complex techniques, can have a negative impact on the predicted WCET,
while the estimated WCET for scratchpad memories scales with the achieved
Performance gain at no extra analysis cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4752</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4752</id><created>2007-10-25</created><authors><author><keyname>Khan</keyname><forenames>Jawad</forenames></author><author><keyname>Vemuri</keyname><forenames>Ranga</forenames></author></authors><title>An Iterative Algorithm for Battery-Aware Task Scheduling on Portable
  Computing Platforms</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181578</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this work we consider battery powered portable systems which either have
Field Programmable Gate Arrays (FPGA) or voltage and frequency scalable
processors as their main processing element. An application is modeled in the
form of a precedence task graph at a coarse level of granularity. We assume
that for each task in the task graph several unique design-points are available
which correspond to different hardware implementations for FPGAs and different
voltage-frequency combinations for processors. It is assumed that performance
and total power consumption estimates for each design-point are available for
any given portable platfrom, including the peripheral components such as memory
and display power usage. We present an iterative heuristic algorithm which
finds a sequence of tasks along with an appropriate design-point for each task,
such that a deadline is met and the amount of battery energy used is as small
as possible. A detailed illustrative example along with a case study of a
real-world application of a robotic arm controller which demonstrates the
usefulness of our algorithm is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4753</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4753</id><created>2007-10-25</created><authors><author><keyname>Heckmann</keyname><forenames>Reinhold</forenames></author><author><keyname>Ferdinand</keyname><forenames>Christian</forenames></author></authors><title>Verifying Safety-Critical Timing and Memory-Usage Properties of Embedded
  Software by Abstract Interpretation</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181577</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Static program analysis by abstract interpretation is an efficient method to
determine properties of embedded software. One example is value analysis, which
determines the values stored in the processor registers. Its results are used
as input to more advanced analyses, which ultimately yield information about
the stack usage and the timing behavior of embedded software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4754</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4754</id><created>2007-10-25</created><authors><author><keyname>Martin</keyname><forenames>Philippe</forenames></author></authors><title>Design of a Virtual Component Neutral Network-on-Chip Transaction Layer</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181645</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Research studies have demonstrated the feasibility and advantages of
Network-on-Chip (NoC) over traditional bus-based architectures but have not
focused on compatibility communication standards. This paper describes a number
of issues faced when designing a VC-neutral NoC, i.e. compatible with standards
such as AHB 2.0, AXI, VCI, OCP, and various other proprietary protocols, and
how a layered approach to communication helps solve these issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4755</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4755</id><created>2007-10-25</created><authors><author><keyname>Rincon</keyname><forenames>Fernando</forenames></author><author><keyname>Moya</keyname><forenames>Francisco</forenames></author><author><keyname>Barba</keyname><forenames>Jesus</forenames></author><author><keyname>Lopez</keyname><forenames>Juan Carlos</forenames></author></authors><title>Model Reuse through Hardware Design Patterns</title><categories>cs.SE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181644</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Increasing reuse opportunities is a well-known problem for software designers
as well as for hardware designers. Nonetheless, current software and hardware
engineering practices have embraced different approaches to this problem.
Software designs are usually modelled after a set of proven solutions to
recurrent problems called design patterns. This approach differs from the
component-based reuse usually found in hardware designs: design patterns do not
specify unnecessary implementation details. Several authors have already
proposed translating structural design patterns concepts to hardware design. In
this paper we extend the discussion to behavioural design patterns.
Specifically, we describe how the hardware version of the Iterator can be used
to enhance model reuse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4756</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4756</id><created>2007-10-25</created><authors><author><keyname>Tiri</keyname><forenames>Kris</forenames></author><author><keyname>Verbauwhede</keyname><forenames>Ingrid</forenames></author></authors><title>Design Method for Constant Power Consumption of Differential Logic
  Circuits</title><categories>cs.CR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181579</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Side channel attacks are a major security concern for smart cards and other
embedded devices. They analyze the variations on the power consumption to find
the secret key of the encryption algorithm implemented within the security IC.
To address this issue, logic gates that have a constant power dissipation
independent of the input signals, are used in security ICs. This paper presents
a design methodology to create fully connected differential pull down networks.
Fully connected differential pull down networks are transistor networks that
for any complementary input combination connect all the internal nodes of the
network to one of the external nodes of the network. They are memoryless and
for that reason have a constant load capacitance and power consumption. This
type of networks is used in specialized logic gates to guarantee a constant
contribution of the internal nodes into the total power consumption of the
logic gate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4757</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4757</id><created>2007-10-25</created><authors><author><keyname>Lopez-Ongil</keyname><forenames>Celia</forenames></author><author><keyname>Garcia-Valderas</keyname><forenames>Mario</forenames></author><author><keyname>Portela-Garcia</keyname><forenames>Marta</forenames></author><author><keyname>Entrena-Arrontes</keyname><forenames>Luis</forenames></author></authors><title>Techniques for Fast Transient Fault Grading Based on Autonomous
  Emulation</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181643</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Very deep submicron and nanometer technologies have increased notably
integrated circuit (IC) sensitiveness to radiation. Soft errors are currently
appearing into ICs working at earth surface. Hardened circuits are currently
required in many applications where Fault Tolerance (FT) was not a requirement
in the very near past. The use of platform FPGAs for the emulation of
single-event upset effects (SEU) is gaining attention in order to speed up the
FT evaluation. In this work, a new emulation system for FT evaluation with
respect to SEU effects is proposed, providing shorter evaluation times by
performing all the evaluation process in the FPGA and avoiding emulator-host
communication bottlenecks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4758</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4758</id><created>2007-10-25</created><authors><author><keyname>Leung</keyname><forenames>Lap-Fai</forenames></author><author><keyname>Tsui</keyname><forenames>Chi-Ying</forenames></author><author><keyname>Hu</keyname><forenames>Xiaobo Sharon</forenames></author></authors><title>Exploiting Dynamic Workload Variation in Low Energy Preemptive Task
  Scheduling</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181580</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  A novel energy reduction strategy to maximally exploit the dynamic workload
variation is proposed for the offline voltage scheduling of preemptive systems.
The idea is to construct a fully-preemptive schedule that leads to minimum
energy consumption when the tasks take on approximately the average execution
cycles yet still guarantees no deadline violation during the worst-case
scenario. End-time for each sub-instance of the tasks obtained from the
schedule is used for the on-line dynamic voltage scaling (DVS) of the tasks.
For the tasks that normally require a small number of cycles but occasionally a
large number of cycles to complete, such a schedule provides more opportunities
for slack utilization and hence results in larger energy saving. The concept is
realized by formulating the problem as a Non-Linear Programming (NLP)
optimization problem. Experimental results show that, by using the proposed
scheme, the total energy consumption at runtime is reduced by as high as 60%
for randomly generated task sets when comparing with the static scheduling
approach only using worst case workload.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4759</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4759</id><created>2007-10-25</created><authors><author><keyname>Rossello</keyname><forenames>J. L.</forenames></author><author><keyname>Canals</keyname><forenames>V.</forenames></author><author><keyname>Bota</keyname><forenames>S. A.</forenames></author><author><keyname>Keshavarzi</keyname><forenames>A.</forenames></author><author><keyname>Segura</keyname><forenames>J.</forenames></author></authors><title>A Fast Concurrent Power-Thermal Model for Sub-100nm Digital ICs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181641</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As technology scales down, the static power is expected to become a
significant fraction of the total power. The exponential dependence of static
power with the operating temperature makes the thermal profile estimation of
high-performance ICs a key issue to compute the total power dissipated in
next-generations. In this paper we present accurate and compact analytical
models to estimate the static power dissipation and the temperature of
operation of CMOS gates. The models are the fundamentals of a performance
estimation tool in which numerical procedures are avoided for any computation
to set a faster estimation and optimization. The models developed are compared
to measurements and SPICE simulations for a 0.12mm technology showing excellent
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4760</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4760</id><created>2007-10-25</created><authors><author><keyname>Verle</keyname><forenames>A.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Michel</keyname><forenames>X.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Azemard</keyname><forenames>N.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Maurine</keyname><forenames>P.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Auvergne</keyname><forenames>D.</forenames><affiliation>LIRMM</affiliation></author></authors><title>Low Power Oriented CMOS Circuit Optimization Protocol</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181581</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Low power oriented circuit optimization consists in selecting the best
alternative between gate sizing, buffer insertion and logic structure
transformation, for satisfying a delay constraint at minimum area cost. In this
paper we used a closed form model of delay in CMOS structures to define metrics
for a deterministic selection of the optimization alternative. The target is
delay constraint satisfaction with minimum area cost. We validate the design
space exploration method, defining maximum and minimum delay bounds on logical
paths. Then we adapt this method to a "constant sensitivity method" allowing to
size a circuit at minimum area under a delay constraint. An optimisation
protocol is finally defined to manage the trade-off performance constraint -
circuit structure. These methods are implemented in an optimization tool (POPS)
and validated by comparing on a 0.25$\mu$m process, the optimization efficiency
obtained on various benchmarks (ISCAS?85) to that resulting from an industrial
tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4761</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4761</id><created>2007-10-25</created><authors><author><keyname>Keezer</keyname><forenames>D. C.</forenames></author><author><keyname>Gray</keyname><forenames>C.</forenames></author><author><keyname>Majid</keyname><forenames>A.</forenames></author><author><keyname>Taher</keyname><forenames>N.</forenames></author></authors><title>Low-Cost Multi-Gigahertz Test Systems Using CMOS FPGAs and PECL</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181640</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper describes two research projects that develop new low-cost
techniques for testing devices with multiple high-speed (2 to 5 Gbps) signals.
Each project uses commercially available components to keep costs low, yet
achieves performance characteristics comparable to (and in some ways exceeding)
more expensive ATE. A common CMOS FPGA-based logic core provides flexibility,
adaptability, and communication with controlling computers while customized
positive emitter-coupled logic (PECL) achieves multi-gigahertz data rates with
about $\pm$25ps timing accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4762</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4762</id><created>2007-10-25</created><authors><author><keyname>Kitahara</keyname><forenames>Takeshi</forenames></author><author><keyname>Kawabe</keyname><forenames>Naoyuki</forenames></author><author><keyname>Minami</keyname><forenames>Fimihiro</forenames></author><author><keyname>Seta</keyname><forenames>Katsuhiro</forenames></author><author><keyname>Furusawa</keyname><forenames>Toshiyuki</forenames></author></authors><title>Area-Efficient Selective Multi-Threshold CMOS Design Methodology for
  Standby Leakage Power Reduction</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181582</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper presents a design flow for an improved selective
multi-threshold(Selective-MT) circuit. The Selective-MT circuit is improved so
that plural MT-cells can share one switch transistor. We propose the design
methodology from RTL(Register Transfer Level) to final layout with optimizing
switch transistor structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4763</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4763</id><created>2007-10-25</created><authors><author><keyname>Beck</keyname><forenames>Matthias</forenames></author><author><keyname>Barondeau</keyname><forenames>Olivier</forenames></author><author><keyname>Kaibel</keyname><forenames>Martin</forenames></author><author><keyname>Poehl</keyname><forenames>Frank</forenames></author><author><keyname>Lin</keyname><forenames>Xijiang</forenames></author><author><keyname>Press</keyname><forenames>Ron</forenames></author></authors><title>Logic Design for On-Chip Test Clock Generation - Implementation Details
  and Impact on Delay Test Quality</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181638</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  This paper addresses delay test for SOC devices with high frequency clock
domains. A logic design for on-chip high-speed clock generation, implemented to
avoid expensive test equipment, is described in detail. Techniques for on-chip
clock generation, meant to reduce test vector count and to increase test
quality, are discussed. ATPG results for the proposed techniques are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4764</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4764</id><created>2007-10-25</created><authors><author><keyname>Link</keyname><forenames>G. M.</forenames></author><author><keyname>Vijaykrishnan</keyname><forenames>N.</forenames></author></authors><title>Hotspot Prevention Through Runtime Reconfiguration in Network-On-Chip</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181583</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Many existing thermal management techniques focus on reducing the overall
power consumption of the chip, and do not address location-specific temperature
problems referred to as hotspots. We propose the use of dynamic runtime
reconfiguration to shift the hotspot-inducing computation periodically and make
the thermal profile more uniform. Our analysis shows that dynamic
reconfiguration is an effective technique in reducing hotspots for NoCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4793</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4793</id><created>2007-10-25</created><authors><author><keyname>Hai</keyname><forenames>He</forenames></author><author><keyname>Yi-Fang</keyname><forenames>Zhong</forenames></author><author><keyname>Chi-Lan</keyname><forenames>Cai</forenames></author></authors><title>Unified Modeling of Complex Real-Time Control Systems</title><categories>cs.SE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181653</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Complex real-time control system is a software dense and algorithms dense
system, which needs modern software engineering techniques to design. UML is an
object-oriented industrial standard modeling language, used more and more in
real-time domain. This paper first analyses the advantages and problems of
using UML for real-time control systems design. Then, it proposes an extension
of UML-RT to support time-continuous subsystems modeling. So we can unify
modeling of complex real-time control systems on UML-RT platform, from
requirement analysis, model design, simulation, until generation code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4794</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4794</id><created>2007-10-25</created><authors><author><keyname>Bai</keyname><forenames>Robert</forenames></author><author><keyname>Kim</keyname><forenames>Nam-Sung</forenames></author><author><keyname>Kgil</keyname><forenames>Tae Ho</forenames></author><author><keyname>Sylvester</keyname><forenames>Dennis</forenames></author><author><keyname>Mudge</keyname><forenames>Trevor</forenames></author></authors><title>Power-Performance Trade-Offs in Nanometer-Scale Multi-Level Caches
  Considering Total Leakage</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181660</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  In this paper, we investigate the impact of T_{ox} and Vth on power
performance trade-offs for on-chip caches. We start by examining the
optimization of the various components of a single level cache and then extend
this to two level cache systems. In addition to leakage, our studies also
account for the dynamic power expanded as a result of cache misses. Our results
show that one can often reduce overall power by increasing the size of the L2
cache if we only allow one pair of Vth/T_{ox} in L2. However, if we allow the
memory cells and the peripherals to have their own Vth's and T_{ox}'s, we show
that a two-level cache system with smaller L2's will yield less total leakage.
We further show that two Vth's and two T_{ox}'s are sufficient to get close to
an optimal solution, and that Vth is generally a better design knob than T_{ox}
for leakage optimization, thus it is better to restrict the number of T_{ox}'s
rather than Vth's if cost is a concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4795</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4795</id><created>2007-10-25</created><authors><author><keyname>Amory</keyname><forenames>Alexandre M.</forenames></author><author><keyname>Lubaszewski</keyname><forenames>Marcelo</forenames></author><author><keyname>Moraes</keyname><forenames>Fernando G.</forenames></author><author><keyname>Moreno</keyname><forenames>Edson I.</forenames></author></authors><title>Test Time Reduction Reusing Multiple Processors in a Network-on-Chip
  Based Architecture</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181665</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The increasing complexity and the short life cycles of embedded systems are
pushing the current system-on-chip designs towards a rapid increasing on the
number of programmable processing units, while decreasing the gate count for
custom logic. Considering this trend, this work proposes a test planning method
capable of reusing available processors as test sources and sinks, and the
on-chip network as the test access mechanism. Experimental results are based on
ITC'02 benchmarks and on two open core processors compliant with MIPS and SPARC
instruction set. The results show that the cooperative use of both the on-chip
network and the embedded processors can increase the test parallelism and
reduce the test time without additional cost in area and pins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4796</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4796</id><created>2007-10-25</created><authors><author><keyname>Resano</keyname><forenames>Javier</forenames></author><author><keyname>Mozos</keyname><forenames>Daniel</forenames></author><author><keyname>Catthoor</keyname><forenames>Francky</forenames></author></authors><title>A Hybrid Prefetch Scheduling Heuristic to Minimize at Run-Time the
  Reconfiguration Overhead of Dynamically Reconfigurable Hardware</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181666</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Due to the emergence of highly dynamic multimedia applications there is a
need for flexible platforms and run-time scheduling support for embedded
systems. Dynamic Reconfigurable Hardware (DRHW) is a promising candidate to
provide this flexibility but, currently, not sufficient run-time scheduling
support to deal with the run-time reconfigurations exists. Moreover, executing
at run-time a complex scheduling heuristic to provide this support may generate
an excessive run-time penalty. Hence, we have developed a hybrid
design/run-time prefetch heuristic that schedules the reconfigurations at
run-time, but carries out the scheduling computations at design-time by
carefully identifying a set of near-optimal schedules that can be selected at
run-time. This approach provides run-time flexibility with a negligible
penalty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4797</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4797</id><created>2007-10-25</created><authors><author><keyname>Rosinger</keyname><forenames>Paul</forenames></author><author><keyname>Al-Hashimi</keyname><forenames>Bashir</forenames></author><author><keyname>Chakrabarty</keyname><forenames>Krishnendu</forenames></author></authors><title>Rapid Generation of Thermal-Safe Test Schedules</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181676</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Overheating has been acknowledged as a major issue in testing complex SOCs.
Several power constrained system-level DFT solutions (power constrained test
scheduling) have recently been proposed to tackle this problem. However, as it
will be shown in this paper, imposing a chip-level maximum power constraint
doesn't necessarily avoid local overheating due to the non-uniform distribution
of power across the chip. This paper proposes a new approach for dealing with
overheating during test, by embedding thermal awareness into test scheduling.
The proposed approach facilitates rapid generation of thermal-safer test
schedules without requiring time-consuming thermal simulations. This is
achieved by employing a low-complexity test session thermal model used to guide
the test schedule generation algorithm. This approach reduces the chances of a
design re-spin due to potential overheating during test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4798</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4798</id><created>2007-10-25</created><authors><author><keyname>Mannion</keyname><forenames>Ryan</forenames></author><author><keyname>Hsieh</keyname><forenames>Harry</forenames></author><author><keyname>Cotterell</keyname><forenames>Susan</forenames></author><author><keyname>Vahid</keyname><forenames>Frank</forenames></author></authors><title>System Synthesis for Networks of Programmable Blocks</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181678</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  The advent of sensor networks presents untapped opportunities for synthesis.
We examine the problem of synthesis of behavioral specifications into networks
of programmable sensor blocks. The particular behavioral specification we
consider is an intuitive user-created network diagram of sensor blocks, each
block having a pre-defined combinational or sequential behavior. We synthesize
this specification to a new network that utilizes a minimum number of
programmable blocks in place of the pre-defined blocks, thus reducing network
size and hence network cost and power. We focus on the main task of this
synthesis problem, namely partitioning pre-defined blocks onto a minimum number
of programmable blocks, introducing the efficient but effective PareDown
decomposition algorithm for the task. We describe the synthesis and simulation
tools we developed. We provide results showing excellent network size
reductions through such synthesis, and significant speedups of our algorithm
over exhaustive search while obtaining near-optimal results for 15 real network
designs as well as nearly 10,000 randomly generated designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4799</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4799</id><created>2007-10-25</created><authors><author><keyname>Ozturk</keyname><forenames>O.</forenames></author><author><keyname>Saputra</keyname><forenames>H.</forenames></author><author><keyname>Kandemir</keyname><forenames>M.</forenames></author><author><keyname>Kolcu</keyname><forenames>I.</forenames></author></authors><title>Access Pattern-Based Code Compression for Memory-Constrained Embedded
  Systems</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181677</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  As compared to a large spectrum of performance optimizations, relatively
little effort has been dedicated to optimize other aspects of embedded
applications such as memory space requirements, power, real-time
predictability, and reliability. In particular, many modern embedded systems
operate under tight memory space constraints. One way of satisfying these
constraints is to compress executable code and data as much as possible. While
research on code compression have studied efficient hardware and software based
code strategies, many of these techniques do not take application behavior into
account, that is, the same compression/decompression strategy is used
irrespective of the application being optimized. This paper presents a code
compression strategy based on control flow graph (CFG) representation of the
embedded program. The idea is to start with a memory image wherein all basic
blocks are compressed, and decompress only the blocks that are predicted to be
needed in the near future. When the current access to a basic block is over,
our approach also decides the point at which the block could be compressed. We
propose several compression and decompression strategies that try to reduce
memory requirements without excessively increasing the original instruction
cycle counts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4800</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4800</id><created>2007-10-25</created><authors><author><keyname>Farouk</keyname><forenames>Hala A.</forenames></author><author><keyname>Saeb</keyname><forenames>Magdy</forenames></author></authors><title>An Improved FPGA Implementation of the Modified Hybrid Hiding Encryption
  Algorithm (MHHEA) for Data Communication Security</title><categories>cs.CR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181824</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The hybrid hiding encryption algorithm, as its name implies, embraces
concepts from both steganography and cryptography. In this exertion, an
improved micro-architecture Field Programmable Gate Array (FPGA) implementation
of this algorithm is presented. This design overcomes the observed limitations
of a previously-designed micro-architecture. These observed limitations are: no
exploitation of the possibility of parallel bit replacement, and the fact that
the input plaintext was encrypted serially, which caused a dependency between
the throughput and the nature of the used secret key. This dependency can be
viewed by some as vulnerability in the security of the implemented
micro-architecture. The proposed modified micro-architecture is constructed
using five basic modules. These modules are; the message cache, the message
alignment module, the key cache, the comparator, and at last the encryption
module. In this work, we provide comprehensive simulation and implementation
results. These are: the timing diagrams, the post-implementation timing and
routing reports, and finally the floor plan. Moreover, a detailed comparison
with other FPGA implementations is made available and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4801</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4801</id><created>2007-10-25</created><authors><author><keyname>Ruiz-Sautua</keyname><forenames>R.</forenames></author><author><keyname>Molina</keyname><forenames>M. C.</forenames></author><author><keyname>Mendias</keyname><forenames>J. M.</forenames></author><author><keyname>Hermida</keyname><forenames>R.</forenames></author></authors><title>Behavioural Transformation to Improve Circuit Performance in High-Level
  Synthesis</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181686</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Early scheduling algorithms usually adjusted the clock cycle duration to the
execution time of the slowest operation. This resulted in large slack times
wasted in those cycles executing faster operations. To reduce the wasted times
multi-cycle and chaining techniques have been employed. While these techniques
have produced successful designs, its effectiveness is often limited due to the
area increment that may derive from chaining, and the extra latencies that may
derive from multicycling. In this paper we present an optimization method that
solves the time-constrained scheduling problem by transforming behavioural
specifications into new ones whose subsequent synthesis substantially improves
circuit performance. Our proposal breaks up some of the specification
operations, allowing their execution during several possibly unconsecutive
cycles, and also the calculation of several data-dependent operation fragments
in the same cycle. To do so, it takes into account the circuit latency and the
execution time of every specification operation. The experimental results
carried out show that circuits obtained from the optimized specification are on
average 60% faster than those synthesized from the original specification, with
only slight increments in the circuit area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4802</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4802</id><created>2007-10-25</created><authors><author><keyname>Scholive</keyname><forenames>M.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Beroulle</keyname><forenames>V.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Robach</keyname><forenames>C.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Flottes</keyname><forenames>M. L.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Rouzeyre</keyname><forenames>B.</forenames><affiliation>LIRMM</affiliation></author></authors><title>Mutation Sampling Technique for the Generation of Structural Test Data</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181680</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Our goal is to produce validation data that can be used as an efficient (pre)
test set for structural stuck-at faults. In this paper, we detail an original
test-oriented mutation sampling technique used for generating such data and we
present a first evaluation on these validation data with regard to a structural
test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4803</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4803</id><created>2007-10-25</created><authors><author><keyname>Elbaz</keyname><forenames>R.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Torres</keyname><forenames>L.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Sassatelli</keyname><forenames>G.</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Guillemin</keyname><forenames>P.</forenames></author><author><keyname>Anguille</keyname><forenames>C.</forenames></author><author><keyname>Bardouillet</keyname><forenames>M.</forenames></author><author><keyname>Buatois</keyname><forenames>C.</forenames></author><author><keyname>Rigaud</keyname><forenames>J. B.</forenames></author></authors><title>Hardware Engines for Bus Encryption: A Survey of Existing Techniques</title><categories>cs.CR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181818</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The widening spectrum of applications and services provided by portable and
embedded devices bring a new dimension of concerns in security. Most of those
embedded systems (pay-TV, PDAs, mobile phones, etc...) make use of external
memory. As a result, the main problem is that data and instructions are
constantly exchanged between memory (RAM) and CPU in clear form on the bus.
This memory may contain confidential data like commercial software or private
contents, which either the end-user or the content provider is willing to
protect. The goal of this paper is to clearly describe the problem of
processor-memory bus communications in this regard and the existing techniques
applied to secure the communication channel through encryption - Performance
overheads implied by those solutions will be extensively discussed in this
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4805</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4805</id><created>2007-10-25</created><authors><author><keyname>Heusala</keyname><forenames>Hannu</forenames></author><author><keyname>Liedes</keyname><forenames>Jussi</forenames></author></authors><title>Modeling of a Reconfigurable OFDM IP Block Family For an RF System
  Simulator</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181836</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The idea of design domain specific Mother Model of IP block family as a base
of modeling of system integration is presented here. A common reconfigurable
Mother Model for ten different standardized digital OFDM transmitters has been
developed. By means of a set of parameters, the mother model can be
reconfigured to any of the ten selected standards. So far the applicability of
the proposed reconfiguration and analog-digital co-modeling methods have been
proved by modeling the function of the digital parts of three, 802.11a, ADSL
and DRM, transmitters in an RF system simulator. The model is intended to be
used as signal source template in RF system simulations. The concept is not
restricted to signal sources, it can be applied to any IP block development.
The idea of the Mother Model will be applied in other design domains to prove
that in certain application areas, OFDM transceivers in this case, the design
process can progress simultaneously in different design domains - mixed signal,
system and RTL-architectural - without the need of high-level synthesis. Only
the Mother Models of three design domains are needed to be formally proved to
function as specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4806</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4806</id><created>2007-10-25</created><authors><author><keyname>Tiri</keyname><forenames>Kris</forenames></author><author><keyname>Verbauwhede</keyname><forenames>Ingrid</forenames></author></authors><title>A VLSI Design Flow for Secure Side-Channel Attack Resistant ICs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181821</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper presents a digital VLSI design flow to create secure, side-channel
attack (SCA) resistant integrated circuits. The design flow starts from a
normal design in a hardware description language such as VHDL or Verilog and
provides a direct path to a SCA resistant layout. Instead of a full custom
layout or an iterative design process with extensive simulations, a few key
modifications are incorporated in a regular synchronous CMOS standard cell
design flow. We discuss the basis for side-channel attack resistance and adjust
the library databases and constraints files of the synthesis and place &amp; route
procedures accordingly. Experimental results show that a DPA attack on a
regular single ended CMOS standard cell implementation of a module of the DES
algorithm discloses the secret key after 200 measurements. The same attack on a
secure version still does not disclose the secret key after more than 2000
measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4807</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4807</id><created>2007-10-25</created><authors><author><keyname>Chen</keyname><forenames>G.</forenames></author><author><keyname>Kandemir</keyname><forenames>M.</forenames></author><author><keyname>Karakoy</keyname><forenames>M.</forenames></author></authors><title>A Constraint Network Based Approach to Memory Layout Optimization</title><categories>cs.PL</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181684</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  While loop restructuring based code optimization for array intensive
applications has been successful in the past, it has several problems such as
the requirement of checking dependences (legality issues) and transformation of
all of the array references within the loop body indiscriminately (while some
of the references can benefit from the transformation, others may not). As a
result, data transformations, i.e., transformations that modify memory layout
of array data instead of loop structure have been proposed. One of the problems
associated with data transformations is the difficulty of selecting a memory
layout for an array that is acceptable to the entire program (not just to a
single loop). In this paper, we formulate the problem of determining the memory
layouts of arrays as a constraint network, and explore several methods of
solution in a systematic way. Our experiments provide strong support in favor
of employing constraint processing, and point out future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4808</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4808</id><created>2007-10-25</created><authors><author><keyname>Kim</keyname><forenames>Young-Taek</forenames></author><author><keyname>Kim</keyname><forenames>Taehun</forenames></author><author><keyname>Kim</keyname><forenames>Youngduk</forenames></author><author><keyname>Shin</keyname><forenames>Chulho</forenames></author><author><keyname>Chung</keyname><forenames>Eui-Young</forenames></author><author><keyname>Choi</keyname><forenames>Kyu-Myung</forenames></author><author><keyname>Kong</keyname><forenames>Jeong-Taek</forenames></author><author><keyname>Eo</keyname><forenames>Soo-Kwan</forenames></author></authors><title>Fast and Accurate Transaction Level Modeling of an Extended AMBA2.0 Bus
  Architecture</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181837</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Transaction Level Modeling (TLM) approach is used to meet the simulation
speed as well as cycle accuracy for large scale SoC performance analysis. We
implemented a transaction-level model of a proprietary bus called AHB+ which
supports an extended AMBA2.0 protocol. The AHB+ transaction-level model shows
353 times faster than pin-accurate RTL model while maintaining 97% of accuracy
on average. We also present the development procedure of TLM of a bus
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4809</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4809</id><created>2007-10-25</created><authors><author><keyname>Takach</keyname><forenames>Andres</forenames></author><author><keyname>Bowyer</keyname><forenames>Bryan</forenames></author><author><keyname>Bollaert</keyname><forenames>Thomas</forenames></author></authors><title>C Based Hardware Design for Wireless Applications</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181834</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The algorithms used in wireless applications are increasingly more
sophisticated and consequently more challenging to implement in hardware.
Traditional design flows require developing the micro architecture, coding the
RTL, and verifying the generated RTL against the original functional C or
MATLAB specification. This paper describes a C-based design flow that is well
suited for the hardware implementation of DSP algorithms commonly found in
wireless applications. The C design flow relies on guided synthesis to generate
the RTL directly from the untimed C algorithm. The specifics of the C-based
design flow are described using a simple DSP filtering algorithm consisting of
a forward adaptive equalizer, a 64-QAM slicer and an adaptive decision feedback
equalizer. The example illustrates some of the capabilities and advantages
offered by this flow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4810</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4810</id><created>2007-10-25</created><authors><author><keyname>Dyka</keyname><forenames>Zoya</forenames></author><author><keyname>Langendoerfer</keyname><forenames>Peter</forenames></author></authors><title>Area Efficient Hardware Implementation of Elliptic Curve Cryptography by
  Iteratively Applying Karatsuba's Method</title><categories>cs.CR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181823</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Securing communication channels is especially needed in wireless
environments. But applying cipher mechanisms in software is limited by the
calculation and energy resources of the mobile devices. If hardware is applied
to realize cryptographic operations cost becomes an issue. In this paper we
describe an approach which tackles all these three points. We implemented a
hardware accelerator for polynomial multiplication in extended Galois fields
(GF) applying Karatsuba's method iteratively. With this approach the area
consumption is reduced to 2.1 mm^2 in comparison to. 6.2 mm^2 for the standard
application of Karatsuba's method i.e. for recursive application. Our approach
also reduces the energy consumption to 60 per cent of the original approach.
The price we have to pay for these achievement is the increased execution time.
In our implementation a polynomial multiplication takes 3 clock cycles whereas
the recurisve Karatsuba approach needs only one clock cycle. But considering
area, energy and calculation speed we are convinced that the benefits of our
approach outweigh its drawback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4811</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4811</id><created>2007-10-25</created><authors><author><keyname>Conti</keyname><forenames>Massimo</forenames></author><author><keyname>Moretti</keyname><forenames>Daniele</forenames></author></authors><title>System Level Analysis of the Bluetooth Standard</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181833</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The SystemC modules of the Link Manager Layer and Baseband Layer have been
designed in this work at behavioral level to analyze the performances of the
Bluetooth standard. In particular the probability of the creation of a piconet
in presence of noise in the channel and the power reduction using the sniff and
hold mode have been investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4812</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4812</id><created>2007-10-25</created><authors><author><keyname>Silva</keyname><forenames>Sandro V.</forenames></author><author><keyname>Bampi</keyname><forenames>Sergio</forenames></author></authors><title>Area and Throughput Trade-Offs in the Design of Pipelined Discrete
  Wavelet Transform Architectures</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181817</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The JPEG2000 standard defines the discrete wavelet transform (DWT) as a
linear space-to-frequency transform of the image domain in an irreversible
compression. This irreversible discrete wavelet transform is implemented by FIR
filter using 9/7 Daubechies coefficients or a lifting scheme of factorizated
coefficients from 9/7 Daubechies coefficients. This work investigates the
tradeoffs between area, power and data throughput (or operating frequency) of
several implementations of the Discrete Wavelet Transform using the lifting
scheme in various pipeline designs. This paper shows the results of five
different architectures synthesized and simulated in FPGAs. It concludes that
the descriptions with pipelined operators provide the best area-power-operating
frequency trade-off over non-pipelined operators descriptions. Those
descriptions require around 40% more hardware to increase the maximum operating
frequency up to 100% and reduce power consumption to less than 50%. Starting
from behavioral HDL descriptions provide the best area-power-operating
frequency trade-off, improving hardware cost and maximum operating frequency
around 30% in comparison to structural descriptions for the same power
requirement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4813</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4813</id><created>2007-10-25</created><authors><author><keyname>Papaefstathiou</keyname><forenames>I.</forenames></author><author><keyname>Orphanoudakis</keyname><forenames>T.</forenames></author><author><keyname>Kornaros</keyname><forenames>G.</forenames></author><author><keyname>Kachris</keyname><forenames>C.</forenames></author><author><keyname>Mavroidis</keyname><forenames>I.</forenames></author><author><keyname>Nikologiannis</keyname><forenames>A.</forenames></author></authors><title>Queue Management in Network Processors</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181832</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  One of the main bottlenecks when designing a network processing system is
very often its memory subsystem. This is mainly due to the state-of-the-art
network links operating at very high speeds and to the fact that in order to
support advanced Quality of Service (QoS), a large number of independent queues
is desirable. In this paper we analyze the performance bottlenecks of various
data memory managers integrated in typical Network Processing Units (NPUs). We
expose the performance limitations of software implementations utilizing the
RISC processing cores typically found in most NPU architectures and we identify
the requirements for hardware assisted memory management in order to achieve
wire-speed operation at gigabit per second rates. Furthermore, we describe the
architecture and performance of a hardware memory manager that fulfills those
requirements. This memory manager, although it is implemented in a
reconfigurable technology, it can provide up to 6.2Gbps of aggregate
throughput, while handling 32K independent queues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4814</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4814</id><created>2007-10-25</created><authors><author><keyname>Duller</keyname><forenames>Andrew</forenames></author><author><keyname>Towner</keyname><forenames>Daniel</forenames></author><author><keyname>Panesar</keyname><forenames>Gajinder</forenames></author><author><keyname>Gray</keyname><forenames>Alan</forenames></author><author><keyname>Robbins</keyname><forenames>Will</forenames></author></authors><title>picoArray Technology: The Tool's Story</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181831</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper briefly describes the picoArray? architecture, and in particular
the deterministic internal communication fabric. The methods that have been
developed for debugging and verifying systems using devices from the picoArray
family are explained. In order to maximize the computational ability of these
devices, hardware debugging support has been kept to a minimum and the methods
and tools developed to take this into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4815</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4815</id><created>2007-10-25</created><authors><author><keyname>Blazquez</keyname><forenames>Raul</forenames></author><author><keyname>Lee</keyname><forenames>Fred</forenames></author><author><keyname>Wentzloff</keyname><forenames>David</forenames></author><author><keyname>Ginsburg</keyname><forenames>Brian</forenames></author><author><keyname>Powell</keyname><forenames>Johnna</forenames></author><author><keyname>Chandrakasan</keyname><forenames>Anantha</forenames></author></authors><title>Direct Conversion Pulsed UWB Transceiver Architecture</title><categories>cs.NI</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181828</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Ultra-wideband (UWB) communication is an emerging wireless technology that
promises high data rates over short distances and precise locationing. The
large available bandwidth and the constraint of a maximum power spectral
density drives a unique set of system challenges. This paper addresses these
challenges using two UWB transceivers and a discrete prototype platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4816</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4816</id><created>2007-10-25</created><authors><author><keyname>Simunic</keyname><forenames>T.</forenames></author></authors><title>Power Saving Techniques for Wireless LANs</title><categories>cs.NI</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181829</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Fast wireless access has rapidly become commonplace. Wireless access points
and Hotspot servers are sprouting everywhere. Battery lifetime continues to be
a critical issue in mobile computing. This paper first gives an overview of
WLAN energy saving strategies, followed by an illustration of a system-level
methodology for saving power in heterogeneous wireless environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4817</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4817</id><created>2007-10-25</created><authors><author><keyname>Thull</keyname><forenames>Daniel</forenames></author><author><keyname>Sannino</keyname><forenames>Roberto</forenames></author></authors><title>Performance Considerations for an Embedded Implementation of OMA DRM 2</title><categories>cs.CR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181819</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  As digital content services gain importance in the mobile world, Digital
Rights Management (DRM) applications will become a key component of mobile
terminals. This paper examines the effect dedicated hardware macros for
specific cryptographic functions have on the performance of a mobile terminal
that supports version 2 of the open standard for Digital Rights Management
defined by the Open Mobile Alliance (OMA). Following a general description of
the standard, the paper contains a detailed analysis of the cryptographic
operations that have to be carried out before protected content can be
accessed. The combination of this analysis with data on execution times for
specific algorithms realized in hardware and software has made it possible to
build a model which has allowed us to assert that hardware acceleration for
specific cryptographic algorithms can significantly reduce the impact DRM has
on a mobile terminal's processing performance and battery life.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4818</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4818</id><created>2007-10-25</created><authors><author><keyname>Holt</keyname><forenames>Keith</forenames></author></authors><title>Wireless LAN: Past, Present, and Future</title><categories>cs.NI</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181827</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper retraces the historical development of wireless LAN technology in
the context of the pursuit of ever higher data rate, describes the significant
technical breakthroughs that are now occurring, and speculates on future
directions that the technology may take over the remainder of the decade. The
challenges that these developments have created for low power operation are
considered, as well as some of the opportunities that are presented to mitigate
them. The importance of MIMO as an emerging technology for 802.11 is
specifically highlighted, both in terms of the significant increase in data
rate and range that it enables as well as the considerable challenge that it
presents for the development of low power wireless LAN products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4819</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4819</id><created>2007-10-25</created><authors><author><keyname>Lopez</keyname><forenames>S.</forenames></author><author><keyname>Callico</keyname><forenames>G. M.</forenames></author><author><keyname>Lopez</keyname><forenames>J. F.</forenames></author><author><keyname>Sarmiento</keyname><forenames>R.</forenames></author></authors><title>A High Quality/Low Computational Cost Technique for Block Matching
  Motion Estimation</title><categories>cs.MM</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181812</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Motion estimation is the most critical process in video coding systems. First
of all, it has a definitive impact on the rate-distortion performance given by
the video encoder. Secondly, it is the most computationally intensive process
within the encoding loop. For these reasons, the design of high-performance
low-cost motion estimators is a crucial task in the video compression field. An
adaptive cost block matching (ACBM) motion estimation technique is presented in
this paper, featuring an excellent tradeoff between the quality of the
reconstructed video sequences and the computational effort. Simulation results
demonstrate that the ACBM algorithm achieves a slight better rate-distortion
performance than the one given by the well-known full search algorithm block
matching algorithm with reductions of up to 95% in the computational load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4820</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4820</id><created>2007-10-25</created><authors><author><keyname>Biswas</keyname><forenames>Partha</forenames></author><author><keyname>Banerjee</keyname><forenames>Sudarshan</forenames></author><author><keyname>Dutt</keyname><forenames>Nikil</forenames></author><author><keyname>Pozzi</keyname><forenames>Laura</forenames></author><author><keyname>Ienne</keyname><forenames>Paolo</forenames></author></authors><title>ISEGEN: Generation of High-Quality Instruction Set Extensions by
  Iterative Improvement</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181685</proxy><journal-ref>Dans Design, Automation and Test in Europe - DATE'05, Munich :
  Allemagne (2005)</journal-ref><abstract>  Customization of processor architectures through Instruction Set Extensions
(ISEs) is an effective way to meet the growing performance demands of embedded
applications. A high-quality ISE generation approach needs to obtain results
close to those achieved by experienced designers, particularly for complex
applications that exhibit regularity: expert designers are able to exploit
manually such regularity in the data flow graphs to generate high-quality ISEs.
In this paper, we present ISEGEN, an approach that identifies high-quality ISEs
by iterative improvement following the basic principles of the well-known
Kernighan-Lin (K-L) min-cut heuristic. Experimental results on a number of
MediaBench, EEMBC and cryptographic applications show that our approach matches
the quality of the optimal solution obtained by exhaustive search. We also show
that our ISEGEN technique is on average 20x faster than a genetic formulation
that generates equivalent solutions. Furthermore, the ISEs identified by our
technique exhibit 35% more speedup than the genetic solution on a large
cryptographic application (AES) by effectively exploiting its regular
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4821</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4821</id><created>2007-10-25</created><authors><author><keyname>Wolf</keyname><forenames>Wayne</forenames></author></authors><title>Multimedia Applications of Multiprocessor Systems-on-Chips</title><categories>cs.MM</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181826</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper surveys the characteristics of multimedia systems. Multimedia
applications today are dominated by compression and decompression, but
multimedia devices must also implement many other functions such as security
and file management. We introduce some basic concepts of multimedia algorithms
and the larger set of functions that multimedia systems-on-chips must
implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4823</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4823</id><created>2007-10-25</created><authors><author><keyname>Stechele</keyname><forenames>W.</forenames></author><author><keyname>Carcel</keyname><forenames>L. Alvado</forenames></author><author><keyname>Herrmann</keyname><forenames>S.</forenames></author><author><keyname>Simon</keyname><forenames>J. Lidon</forenames></author></authors><title>A Coprocessor for Accelerating Visual Information Processing</title><categories>cs.MM</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181816</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Visual information processing will play an increasingly important role in
future electronics systems. In many applications, e.g. video surveillance
cameras, data throughput of microprocessors is not sufficient and power
consumption is too high. Instruction profiling on a typical test algorithm has
shown that pixel address calculations are the dominant operations to be
optimized. Therefore AddressLib, a structured scheme for pixel addressing was
developed, that can be accelerated by AddressEngine, a coprocessor for visual
information processing. In this paper, the architectural design of
AddressEngine is described, which in the first step supports a subset of the
AddressLib. Dataflow and memory organization are optimized during architectural
design. AddressEngine was implemented in a FPGA and was tested with MPEG-7
Global Motion Estimation algorithm. Results on processing speed and circuit
complexity are given and compared to a pure software implementation. The next
step will be the support for the full AddressLib, including segment addressing.
An outlook on further investigations on dynamic reconfiguration capabilities is
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4824</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4824</id><created>2007-10-25</created><authors><author><keyname>Pradeep</keyname><forenames>R.</forenames></author><author><keyname>Vinay</keyname><forenames>S.</forenames></author><author><keyname>Burman</keyname><forenames>Sanjay</forenames></author><author><keyname>Kamakoti</keyname><forenames>V.</forenames></author></authors><title>FPGA based Agile Algorithm-On-Demand Co-Processor</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181825</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  With growing computational needs of many real-world applications, frequently
changing specifications of standards, and the high design and NRE costs of
ASICs, an algorithm-agile FPGA based co-processor has become a viable
alternative. In this article, we report about the general design of an
algorith-agile co-processor and the proof-of-concept implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4825</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4825</id><created>2007-10-25</created><authors><author><keyname>Lyons</keyname><forenames>Wayne</forenames></author></authors><title>Meeting the Embedded Design Needs of Automotive Applications</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181838</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The importance of embedded systems in driving innovation in automotive
applications continues to grow. Understanding the specific needs of developers
targeting this market is also helping to drive innovation in RISC core design.
This paper describes how a RISC instruction set architecture has evolved to
better meet those needs, and the key implementation features in two very
different RISC cores are used to demonstrate the challenges of designing for
real-time automotive systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4826</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4826</id><created>2007-10-25</created><authors><author><keyname>Jeffrey</keyname><forenames>C.</forenames></author><author><keyname>Cutajar</keyname><forenames>R.</forenames></author><author><keyname>Prosser</keyname><forenames>S.</forenames></author><author><keyname>Lickess</keyname><forenames>M.</forenames></author><author><keyname>Richardson</keyname><forenames>A.</forenames></author><author><keyname>Riches</keyname><forenames>S.</forenames></author></authors><title>The Integration of On-Line Monitoring and Reconfiguration Functions
  using EDAA - European design and Automation Association1149.4 Into a Safety
  Critical Automotive Electronic Control Unit</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181840</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper presents an innovative application of EDAA - European design and
Automation Association 1149.4 and the Integrated Diagnostic Reconfiguration
(IDR) as tools for the implementation of an embedded test solution for an
Automotive Electronic Control Unit implemented as a fully integrated mixed
signal system. The paper described how the test architecture can be used for
fault avoidance with results from a hardware prototype presented. The paper
concludes that fault avoidance can be integrated into mixed signal electronic
systems to handle key failure modes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4827</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4827</id><created>2007-10-25</created><authors><author><keyname>Mayer</keyname><forenames>A.</forenames></author><author><keyname>Siebert</keyname><forenames>H.</forenames></author><author><keyname>Mcdonald-Maier</keyname><forenames>K. D.</forenames></author></authors><title>Debug Support, Calibration and Emulation for Multiple Processor and
  Powertrain Control SoCs</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181839</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The introduction of complex SoCs with multiple processor cores presents new
development challenges, such that development support is now a decisive factor
when choosing a System-on-Chip (SoC). The presented developments support
strategy addresses the challenges using both architecture and technology
approaches. The Multi-Core Debug Support (MCDS) architecture provides flexible
triggering using cross triggers and a multiple core break and suspend switch.
Temporal trace ordering is guaranteed down to cycle level by on-chip time
stamping. The Package Sized-ICE (PSI) approach is a novel method of including
trace buffers, overlay memories, processing resources and communication
interfaces without changing device behavior. PSI requires no external emulation
box, as the debug host interfaces directly with the SoC using a standard
interface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4829</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4829</id><created>2007-10-25</created><authors><author><keyname>Ziegenbein</keyname><forenames>Dirk</forenames></author><author><keyname>Braun</keyname><forenames>Peter</forenames></author><author><keyname>Freund</keyname><forenames>Ulrich</forenames></author><author><keyname>Bauer</keyname><forenames>Andreas</forenames></author><author><keyname>Romberg</keyname><forenames>Jan</forenames></author><author><keyname>Schatz</keyname><forenames>Bernhard</forenames></author></authors><title>AutoMoDe - Model-Based Development of Automotive Software</title><categories>cs.SE</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181843</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper describes first results from the AutoMoDe (Automotive Model-Based
Development) project. The overall goal of the project is to develop an
integrated methodology for model-based development of automotive control
software, based on problem-specific design notations with an explicit formal
foundation. Based on the existing AutoFOCUS framework, a tool prototype is
being developed in order to illustrate and validate the key elements of our
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4831</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4831</id><created>2007-10-25</created><authors><author><keyname>Horsky</keyname><forenames>Pavel</forenames></author></authors><title>LC Oscillator Driver for Safety Critical Applications</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181841</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  A CMOS harmonic signal LC oscillator driver for automotive applications
working in a harsh environment with high safety critical requirements is
described. The driver can be used with a wide range of external components
parameters (LC resonance network of a sensor). Quality factor of the external
LC network can vary two decades. Amplitude regulation of the driver is
digitally controlled and the DAC is constructed as exponential with
piece-wise-linear (PWL) approximation. Low current consumption for high quality
resonance networks is achieved. Realized oscillator is robust, used in safety
critical application and has low EMC emissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4832</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4832</id><created>2007-10-25</created><authors><author><keyname>Conti</keyname><forenames>Massimo</forenames></author></authors><title>SystemC Analysis of a New Dynamic Power Management Architecture</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181844</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper presents a new dynamic power management architecture of a System
on Chip. The Power State Machine describing the status of the core follows the
recommendations of the ACPI standard. The algorithm controls the power states
of each block on the basis of battery status, chip temperature and a user
defined task priority.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4833</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4833</id><created>2007-10-25</created><authors><author><keyname>Chappell</keyname><forenames>Steve</forenames></author><author><keyname>Macarthur</keyname><forenames>Alistair</forenames></author><author><keyname>Preston</keyname><forenames>Dan</forenames></author><author><keyname>Olmstead</keyname><forenames>Dave</forenames></author><author><keyname>Flint</keyname><forenames>Bob</forenames></author><author><keyname>Sullivan</keyname><forenames>Chris</forenames></author></authors><title>Exploiting Real-Time FPGA Based Adaptive Systems Technology for
  Real-Time Sensor Fusion in Next Generation Automotive Safety Systems</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181845</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  We present a system for the boresighting of sensors using inertial
measurement devices as the basis for developing a range of dynamic real-time
sensor fusion applications. The proof of concept utilizes a COTS FPGA platform
for sensor fusion and real-time correction of a misaligned video sensor. We
exploit a custom-designed 32-bit soft processor core and C-based design &amp;
synthesis for rapid, platform-neutral development. Kalman filter and sensor
fusion techniques established in advanced aviation systems are applied to
automotive vehicles with results exceeding typical industry requirements for
sensor alignment. Results of the static and the dynamic tests demonstrate that
using inexpensive accelerometers mounted on (or during assembly of) a sensor
and an Inertial Measurement Unit (IMU) fixed to a vehicle can be used to
compute the misalignment of the sensor to the IMU and thus vehicle. In some
cases the model predications and test results exceeded the requirements by an
order of magnitude with a 3-sigma or 99% confidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4834</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4834</id><created>2007-10-25</created><authors><author><keyname>Fanucci</keyname><forenames>L.</forenames></author><author><keyname>Giambastiani</keyname><forenames>A.</forenames></author><author><keyname>Iozzi</keyname><forenames>F.</forenames></author><author><keyname>Marino</keyname><forenames>C.</forenames></author><author><keyname>Rocchi</keyname><forenames>A.</forenames></author></authors><title>Platform Based Design for Automotive Sensor Conditioning</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181846</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  In this paper a general architecture suitable to interface several kinds of
sensors for automotive applications is presented. A platform based design
approach is pursued to improve system performance while minimizing
time-to-market.. The platform is composed by an analog front-end and a digital
section. The latter is based on a microcontroller core (8051 IP by Oregano)
plus a set of dedicated hardware dedicated to the complex signal processing
required for sensor conditioning. The microcontroller handles also the
communication with external devices (as a PC) for data output and fast
prototyping. A case study is presented concerning the conditioning of a Gyro
yaw rate sensor for automotive applications. Measured performance results
outperform current state-of-the-art commercial devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4835</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4835</id><created>2007-10-25</created><authors><author><keyname>Kirstein</keyname><forenames>K. -U.</forenames></author><author><keyname>Sedivy</keyname><forenames>J.</forenames></author><author><keyname>Salo</keyname><forenames>T.</forenames></author><author><keyname>Hagleitner</keyname><forenames>C.</forenames></author><author><keyname>Vancura</keyname><forenames>T.</forenames></author><author><keyname>Hierlemann</keyname><forenames>A.</forenames></author></authors><title>A CMOS-Based Tactile Sensor for Continuous Blood Pressure Monitoring</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181850</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  A monolithic integrated tactile sensor array is presented, which is used to
perform non-invasive blood pressure monitoring of a patient. The advantage of
this device compared to a hand cuff based approach is the capability of
recording continuous blood pressure data. The capacitive, membrane-based sensor
device is fabricated in an industrial CMOS-technology combined with post-CMOS
micromachining. The capacitance change is detected by a S?-modulator. The
modulator is operated at a sampling rate of 128kS/s and achieves a resolution
of 12bit with an external decimation filter and an OSR of 128.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4836</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4836</id><created>2007-10-25</created><authors><author><keyname>Milev</keyname><forenames>Momchil</forenames></author><author><keyname>Burt</keyname><forenames>Rod</forenames></author></authors><title>A Tool and Methodology for AC-Stability Analysis of Continuous-Time
  Closed-Loop Systems</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181849</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Presented are a methodology and a DFII-based tool for AC-stability analysis
of a wide variety of closed-loop continuous-time (operational amplifiers and
other linear circuits). The methodology used allows for easy identification and
diagnostics of ac-stability problems including not only main-loop effects but
also local-instability loops in current mirrors, bias circuits and emitter or
source followers without breaking the loop. The results of the analysis are
easy to interpret. Estimated phase margin is readily available. Instability
nodes and loops along with their respective oscillation frequencies are
immediately identified and mapped to the existing circuit nodes thus offering
significant advantages compared to traditional "black-box" methods of stability
analysis (Transient Overshoot, Bode and Phase margin plots etc.). The tool for
AC-Stability analysis is written in SKILL? and is fully integrated in DFII?
environment. Its "push-button" graphical user interface (GUI) is easy to use
and understand. The tool can be invoked directly from Composer? schematic and
does not require active Analog Artist? session. The tool is not dependent on
the use of a specific fabrication technology or Process Design Kit
customization. It requires OCEAN?, Spectre? and Waveform calculator
capabilities to run.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4838</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4838</id><created>2007-10-25</created><authors><author><keyname>Sandner</keyname><forenames>Christoph</forenames></author><author><keyname>Clara</keyname><forenames>Martin</forenames></author><author><keyname>Santner</keyname><forenames>Andreas</forenames></author><author><keyname>Hartig</keyname><forenames>Thomas</forenames></author><author><keyname>Kuttner</keyname><forenames>Franz</forenames></author></authors><title>A 6bit, 1.2GSps Low-Power Flash-ADC in 0.13$\mu$m Digital CMOS</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181853</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  A 6bit flash-ADC with 1.2GSps, wide analog bandwidth and low power, realized
in a standard digital 0.13 $\mu$m CMOS copper technology is presented.
Employing capacitive interpolation gives various advantages when designing for
low power: no need for a reference resistor ladder, implicit sample-and-hold
operation, no edge effects in the interpolation network (as compared to
resistive interpolation), and a very low input capacitance of only 400fF, which
leads to an easily drivable analog converter interface. Operating at 1.2GSps
the ADC achieves an effective resolution bandwidth (ERBW) of 700MHz, while
consuming 160mW of power. At 600MSps we achieve an ERBW of 600MHz with only
90mW power consumption, both from a 1.5V supply. This corresponds to
outstanding Figure-of-Merit numbers (FoM) of 2.2 and 1.5pJ/convstep,
respectively. The module area is 0.12mm^2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4839</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4839</id><created>2007-10-25</created><authors><author><keyname>Andersen</keyname><forenames>Terje N.</forenames></author><author><keyname>Briskemyr</keyname><forenames>Atle</forenames></author><author><keyname>Telsto</keyname><forenames>Frode</forenames></author><author><keyname>Bjornsen</keyname><forenames>Johnny</forenames></author><author><keyname>Bonnerud</keyname><forenames>Thomas E.</forenames></author><author><keyname>Hernes</keyname><forenames>Bjornar</forenames></author><author><keyname>Moldsvor</keyname><forenames>Oystein</forenames></author></authors><title>A 97mW 110MS/s 12b Pipeline ADC Implemented in 0.18$\mu$m Digital CMOS</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181852</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  A 12 bit Pipeline ADC fabricated in a 0.18 $\mu$m pure digital CMOS
technology is presented. Its nominal conversion rate is 110MS/s and the nominal
supply voltage is 1.8V. The effective number of bits is 10.4 when a 10MHz input
signal with 2V_{P-P} signal swing is applied. The occupied silicon area is
0.86mm^2 and the power consumption equals 97mW. A switched capacitor bias
current circuit scale the bias current automatically with the conversion rate,
which gives scaleable power consumption and full performance of the ADC from 20
to 140MS/s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4840</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4840</id><created>2007-10-25</created><authors><author><keyname>Bernardi</keyname><forenames>P.</forenames></author><author><keyname>Masera</keyname><forenames>G.</forenames></author><author><keyname>Quaglio</keyname><forenames>F.</forenames></author><author><keyname>Reorda</keyname><forenames>M. Sonza</forenames></author></authors><title>Testing Logic Cores using a BIST P1500 Compliant Approach: A Case of
  Study</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181854</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  In this paper we describe how we applied a BIST-based approach to the test of
a logic core to be included in System-on-a-chip (SoC) environments. The
approach advantages are the ability to protect the core IP, the simple test
interface (thanks also to the adoption of the P1500 standard), the possibility
to run the test at-speed, the reduced test time, and the good diagnostic
capabilities. The paper reports figures about the achieved fault coverage, the
required area overhead, and the performance slowdown, and compares the figures
with those for alternative approaches, such as those based on full scan and
sequential ATPG.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4842</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4842</id><created>2007-10-25</created><authors><author><keyname>Hillman</keyname><forenames>Dan</forenames></author></authors><title>Using Mobilize Power Management IP for Dynamic &amp; Static Power Reduction
  in SoC at 130 nm</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181856</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  At 130 nm and 90 nm, power consumption (both dynamic and static) has become a
barrier in the roadmap for SoC designs targeting battery powered, mobile
applications. This paper presents the results of dynamic and static power
reduction achieved implementing Tensilica's 32-bit Xtensa microprocessor core,
using Virtual Silicon's Power Management IP. Independent voltage islands are
created using Virtual Silicon's VIP PowerSaver standard cells by using voltage
level shifting cells and voltage isolation cells to implement power islands.
The VIP PowerSaver standard cells are characterized at 1.2V, 1.0V and 0.8V, to
accommodate voltage scaling. Power islands can also be turned off completely.
Designers can significantly lower both the dynamic power and the quiescent or
leakage power of their SoC designs, with very little impact on speed or area
using Virtual Silicon's VIP Gate Bias standard cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4843</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4843</id><created>2007-10-25</created><authors><author><keyname>Mello</keyname><forenames>Aline</forenames></author><author><keyname>Moller</keyname><forenames>Leandro</forenames></author><author><keyname>Calazans</keyname><forenames>Ney</forenames></author><author><keyname>Moraes</keyname><forenames>Fernando</forenames></author></authors><title>MultiNoC: A Multiprocessing System Enabled by a Network on Chip</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181855</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  The MultiNoC system implements a programmable on-chip multiprocessing
platform built on top of an efficient, low area overhead intra-chip
interconnection scheme. The employed interconnection structure is a Network on
Chip, or NoC. NoCs are emerging as a viable alternative to increasing demands
on interconnection architectures, due to the following characteristics: (i)
energy efficiency and reliability; (ii) scalability of bandwidth, when compared
to traditional bus architectures; (iii) reusability; (iv) distributed routing
decisions. An external host computer feeds MultiNoC with application
instructions and data. After this initialization procedure, MultiNoC executes
some algorithm. After finishing execution of the algorithm, output data can be
read back by the host. Sequential or parallel algorithms conveniently adapted
to the MultiNoC structure can be executed. The main motivation to propose this
design is to enable the investigation of current trends to increase the number
of embedded processors in SoCs, leading to the concept of "sea of processors"
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4844</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4844</id><created>2007-10-25</created><authors><author><keyname>Galanis</keyname><forenames>M. D.</forenames></author><author><keyname>Milidonis</keyname><forenames>A.</forenames></author><author><keyname>Theodoridis</keyname><forenames>G.</forenames></author><author><keyname>Soudris</keyname><forenames>D.</forenames></author><author><keyname>Goutis</keyname><forenames>C. E.</forenames></author></authors><title>A Partitioning Methodology for Accelerating Applications in Hybrid
  Reconfigurable Platforms</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181857</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  In this paper, we propose a methodology for partitioning and mapping
computational intensive applications in reconfigurable hardware blocks of
different granularity. A generic hybrid reconfigurable architecture is
considered so as the methodology can be applicable to a large number of
heterogeneous reconfigurable platforms. The methodology mainly consists of two
stages, the analysis and the mapping of the application onto fine and
coarse-grain hardware resources. A prototype framework consisting of analysis,
partitioning and mapping tools has been also developed. For the coarse-grain
reconfigurable hardware, we use our previous-developed high-performance
coarse-grain data-path. In this work, the methodology is validated using two
real-world applications, an OFDM transmitter and a JPEG encoder. In the case of
the OFDM transmitter, a maximum clock cycles decrease of 82% relative to the
ones in an all fine-grain mapping solution is achieved. The corresponding
performance improvement for the JPEG is 43%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4845</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4845</id><created>2007-10-25</created><authors><author><keyname>Rissa</keyname><forenames>Tero</forenames></author><author><keyname>Donlin</keyname><forenames>Adam</forenames></author><author><keyname>Luk</keyname><forenames>Wayne</forenames></author></authors><title>Evaluation of SystemC Modelling of Reconfigurable Embedded Systems</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181858</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper evaluates the use of pin and cycle accurate SystemC models for
embedded system design exploration and early software development. The target
system is MicroBlaze VanillaNet Platform running MicroBlaze uClinux operating
system. The paper compares Register Transfer Level (RTL) Hardware Description
Language (HDL) simulation speed to the simulation speed of several different
SystemC models. It is shown that simulation speed of pin and cycle accurate
models can go up to 150 kHz, compared to 100 Hz range of HDL simulation.
Furthermore, utilising techniques that temporarily compromise cycle accuracy,
effective simulation speed of up to 500 kHz can be obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4846</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4846</id><created>2007-10-25</created><authors><author><keyname>Borgatti</keyname><forenames>M.</forenames></author><author><keyname>Capello</keyname><forenames>A.</forenames></author><author><keyname>Rossi</keyname><forenames>U.</forenames></author><author><keyname>Lambert</keyname><forenames>J. -L.</forenames></author><author><keyname>Moussa</keyname><forenames>I.</forenames></author><author><keyname>Fummi</keyname><forenames>F.</forenames></author><author><keyname>Pravadelli</keyname><forenames>G.</forenames></author></authors><title>An Integrated Design and Verification Methodology for Reconfigurable
  Multimedia Systems</title><categories>cs.MM cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181860</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Recently a lot of multimedia applications are emerging on portable
appliances. They require both the flexibility of upgradeable devices
(traditionally software based) and a powerful computing engine (typically
hardware). In this context, programmable HW and dynamic reconfiguration allow
novel approaches to the migration of algorithms from SW to HW. Thus, in the
frame of the Symbad project, we propose an industrial design flow for
reconfigurable SoC's. The goal of Symbad consists of developing a system level
design platform for hardware and software SoC systems including formal and
semi-formal verification techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4848</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4848</id><created>2007-10-25</created><authors><author><keyname>Umezawa</keyname><forenames>Yasushi</forenames></author><author><keyname>Shimizu</keyname><forenames>Takeshi</forenames></author></authors><title>A Formal Verification Methodology for Checking Data Integrity</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181863</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  Formal verification techniques have been playing an important role in
pre-silicon validation processes. One of the most important points considered
in performing formal verification is to define good verification scopes; we
should define clearly what to be verified formally upon designs under tests. We
considered the following three practical requirements when we defined the scope
of formal verification. They are (a) hard to verify (b) small to handle, and
(c) easy to understand. Our novel approach is to break down generic properties
for system into stereotype properties in block level and to define requirements
for Verifiable RTL. Consequently, each designer instead of verification experts
can describe properties of the design easily, and formal model checking can be
applied systematically and thoroughly to all the leaf modules. During the
development of a component chip for server platforms, we focused on RAS
(Reliability, Availability, and Serviceability) features and described more
than 2000 properties in PSL. As a result of the formal verification, we found
several critical logic bugs in a short time with limited resources, and
successfully verified all of them. This paper presents a study of the
functional verification methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4850</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4850</id><created>2007-10-25</created><authors><author><keyname>Ullmann</keyname><forenames>Michael</forenames></author><author><keyname>Jin</keyname><forenames>Wansheng</forenames></author><author><keyname>Becker</keyname><forenames>Jurgen</forenames></author></authors><title>Hardware Support for QoS-based Function Allocation in Reconfigurable
  Systems</title><categories>cs.AR</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181859</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This contribution presents a new approach for allocating suitable
function-implementation variants depending on given quality-of-service
function-requirements for run-time reconfigurable multi-device systems. Our
approach adapts methodologies from the domain of knowledge-based systems which
can be used for doing run-time hardware/software resource usage optimizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4851</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4851</id><created>2007-10-25</created><authors><author><keyname>Falconeri</keyname><forenames>Giuseppe</forenames></author><author><keyname>Naifer</keyname><forenames>Walid</forenames></author><author><keyname>Romdhane</keyname><forenames>Nizar</forenames></author></authors><title>Common Reusable Verification Environment for BCA and RTL Models</title><categories>cs.LO</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181861</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper deals with a common verification methodology and environment for
SystemC BCA and RTL models. The aim is to save effort by avoiding the same work
done twice by different people and to reuse the same environment for the two
design views. Applying this methodology the verification task starts as soon as
the functional specification is signed off and it runs in parallel to the
models and design development. The verification environment is modeled with the
aid of dedicated verification languages and it is applied to both the models.
The test suite is exactly the same and thus it's possible to verify the
alignment between the two models. In fact the final step is to check the
cycle-by-cycle match of the interface behavior. A regression tool and a bus
analyzer have been developed to help the verification and the alignment
process. The former is used to automate the testbench generation and to run the
two test suites. The latter is used to verify the alignment between the two
models comparing the waveforms obtained in each run. The quality metrics used
to validate the flow are full functional coverage and full alignment at each IP
port.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4852</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4852</id><created>2007-10-25</created><authors><author><keyname>Macbeth</keyname><forenames>John S.</forenames></author><author><keyname>Heinz</keyname><forenames>Dietmar</forenames></author><author><keyname>Gray</keyname><forenames>Ken</forenames></author></authors><title>An Assembler Driven Verification Methodology (ADVM)</title><categories>cs.OH</categories><comments>Submitted on behalf of EDAA (http://www.edaa.com/)</comments><proxy>ccsd hal-00181862</proxy><journal-ref>Dans Design, Automation and Test in Europe | Designers'Forum -
  DATE'05, Munich : Allemagne (2005)</journal-ref><abstract>  This paper presents an overview of an assembler driven verification
methodology (ADVM) that was created and implemented for a chip card project at
Infineon Technologies AG. The primary advantage of this methodology is that it
enables rapid porting of directed tests to new targets and derivatives, with
only a minimum amount of code refactoring. As a consequence, considerable
verification development time and effort was saved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4965</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4965</id><created>2007-10-25</created><updated>2010-11-12</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>On compositions of numbers and graphs</title><categories>math.CO cs.DM</categories><comments>12 pages, 4 figures</comments><msc-class>05C20, 11C08, 17B56</msc-class><journal-ref>Bull. Soc. Sci. Lett. Lodz, 59, No1 , (2009),103-116</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The main purpose of this note is to pose a couple of problems which are
easily formulated thought some seem to be not yet solved. These problems are of
general interest for discrete mathematics including a new twig of a bough of
theory of graphs i.e. a given graph compositions. The problems result from and
are served in the entourage of series of exercises with hints based
predominantly on the second reference and other related recent papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4975</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4975</id><created>2007-10-25</created><updated>2009-08-07</updated><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author></authors><title>Node discovery problem for a social network</title><categories>cs.AI</categories><journal-ref>Connections vol.29, pp.62-76 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods to solve a node discovery problem for a social network are presented.
Covert nodes refer to the nodes which are not observable directly. They
transmit the influence and affect the resulting collaborative activities among
the persons in a social network, but do not appear in the surveillance logs
which record the participants of the collaborative activities. Discovering the
covert nodes is identifying the suspicious logs where the covert nodes would
appear if the covert nodes became overt. The performance of the methods is
demonstrated with a test dataset generated from computationally synthesized
networks and a real organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.4982</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.4982</id><created>2007-10-25</created><authors><author><keyname>Borgs</keyname><forenames>Christian</forenames></author><author><keyname>Chayes</keyname><forenames>Jennifer</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>First to Market is not Everything: an Analysis of Preferential
  Attachment with Fitness</title><categories>math.PR cs.SI</categories><abstract>  In this paper, we provide a rigorous analysis of preferential attachment with
fitness, a random graph model introduced by Bianconi and Barabasi. Depending on
the shape of the fitness distribution, we observe three distinct phases: a
first-mover-advantage phase, a fit-get-richer phase and an innovation-pays-off
phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.5338</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.5338</id><created>2007-10-29</created><authors><author><keyname>Itoh</keyname><forenames>Toshiya</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>Weighted Random Popular Matchings</title><categories>cs.DM cs.CC</categories><comments>13 pages, 2 figures</comments><acm-class>F.1.2; G.2.3</acm-class><journal-ref>Random Structures and Algorithms, 37(4), pp.477-494, 2010</journal-ref><doi>10.1002/rsa.20316</doi><abstract>  For a set A of n applicants and a set I of m items, we consider a problem of
computing a matching of applicants to items, i.e., a function M mapping A to I;
here we assume that each applicant $x \in A$ provides a preference list on
items in I. We say that an applicant $x \in A$ prefers an item p than an item q
if p is located at a higher position than q in its preference list, and we say
that x prefers a matching M over a matching M' if x prefers M(x) over M'(x).
For a given matching problem A, I, and preference lists, we say that M is more
popular than M' if the number of applicants preferring M over M' is larger than
that of applicants preferring M' over M, and M is called a popular matching if
there is no other matching that is more popular than M. Here we consider the
situation that A is partitioned into $A_{1},A_{2},...,A_{k}$, and that each
$A_{i}$ is assigned a weight $w_{i}&gt;0$ such that w_{1}&gt;w_{2}&gt;...&gt;w_{k}&gt;0$. For
such a matching problem, we say that M is more popular than M' if the total
weight of applicants preferring M over M' is larger than that of applicants
preferring M' over M, and we call M an k-weighted popular matching if there is
no other matching that is more popular than M. In this paper, we analyze the
2-weighted matching problem, and we show that (lower bound) if
$m/n^{4/3}=o(1)$, then a random instance of the 2-weighted matching problem
with $w_{1} \geq 2w_{2}$ has a 2-weighted popular matching with probability
o(1); and (upper bound) if $n^{4/3}/m = o(1)$, then a random instance of the
2-weighted matching problem with $w_{1} \geq 2w_{2}$ has a 2-weighted popular
matching with probability 1-o(1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.5455</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.5455</id><created>2007-10-29</created><authors><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Alvarez</keyname><forenames>Gonzalo</forenames></author><author><keyname>Li</keyname><forenames>Zhong</forenames></author><author><keyname>Halang</keyname><forenames>Wolfgang A.</forenames></author></authors><title>Analog Chaos-based Secure Communications and Cryptanalysis: A Brief
  Survey</title><categories>nlin.CD cs.CR</categories><comments>6 pages, 3 figures, ieeeconf.cls</comments><journal-ref>3rd International IEEE Scientific Conference on Physics and
  Control (PhysCon 2007), http://lib.physcon.ru/?item=1368</journal-ref><abstract>  A large number of analog chaos-based secure communication systems have been
proposed since the early 1990s exploiting the technique of chaos
synchronization. A brief survey of these chaos-based cryptosystems and of
related cryptanalytic results is given. Some recently proposed countermeasures
against known attacks are also introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.5465</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.5465</id><created>2007-10-29</created><authors><author><keyname>Arroyo</keyname><forenames>David</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Alvarez</keyname><forenames>Gonzalo</forenames></author><author><keyname>Halang</keyname><forenames>Wolfgang A.</forenames></author></authors><title>Cryptanalysis of an image encryption scheme based on a new total
  shuffling algorithm</title><categories>nlin.CD cs.CR cs.MM</categories><comments>8 pages, 2 figures, 1 table</comments><journal-ref>Chaos, Solitons &amp; Fractals, vol. 41, no. 5, pp. 2613-2616, 2009</journal-ref><doi>10.1016/j.chaos.2008.09.051</doi><abstract>  Chaotic systems have been broadly exploited through the last two decades to
build encryption methods. Recently, two new image encryption schemes have been
proposed, where the encryption process involves a permutation operation and an
XOR-like transformation of the shuffled pixels, which are controlled by three
chaotic systems. This paper discusses some defects of the schemes and how to
break them with a chosen-plaintext attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0710.5471</identifier>
 <datestamp>2010-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0710.5471</id><created>2007-10-29</created><authors><author><keyname>Arroyo</keyname><forenames>David</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Li</keyname><forenames>Shujun</forenames></author><author><keyname>Alvarez</keyname><forenames>Gonzalo</forenames></author></authors><title>Cryptanalysis of a computer cryptography scheme based on a filter bank</title><categories>nlin.CD cs.CR</categories><comments>6 pages, 1 figure</comments><journal-ref>Chaos, Solitons &amp; Fractals, vol. 41, no. 1, pp. 410-413, 2009</journal-ref><doi>10.1016/j.chaos.2008.01.020</doi><abstract>  This paper analyzes the security of a recently-proposed signal encryption
scheme based on a filter bank. A very critical weakness of this new signal
encryption procedure is exploited in order to successfully recover the
associated secret key.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.0834</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.0834</id><created>2007-11-06</created><updated>2008-12-19</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>An interface group for process components</title><categories>cs.LO</categories><comments>26 pages; section on non-associativity of component composition
  added, examples added</comments><report-no>PRG0707</report-no><acm-class>D.2.1; D.2.2; D.2.4; F.1.2; F.3.1</acm-class><journal-ref>Fundamenta Informaticae, 99(4):355--382, 2010</journal-ref><doi>10.3233/FI-2010-254</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We take a process component as a pair of an interface and a behaviour. We
study the composition of interacting process components in the setting of
process algebra. We formalize the interfaces of interacting process components
by means of an interface group. An interesting feature of the interface group
is that it allows for distinguishing between expectations and promises in
interfaces of process components. This distinction comes into play in case
components with both client and server behaviour are involved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.0838</identifier>
 <datestamp>2010-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.0838</id><created>2007-11-06</created><updated>2008-11-25</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>On the operating unit size of load/store architectures</title><categories>cs.AR</categories><comments>23 pages; minor errors corrected, explanations added, references
  replaced</comments><report-no>PRG0703</report-no><acm-class>C.0; F.1.1; F.1.3</acm-class><journal-ref>Mathematical Structures in Computer Science, 20(3):395--417, 2010</journal-ref><doi>10.1017/S0960129509990314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a strict version of the concept of a load/store instruction set
architecture in the setting of Maurer machines. We take the view that
transformations on the states of a Maurer machine are achieved by applying
threads as considered in thread algebra to the Maurer machine. We study how the
transformations on the states of the main memory of a strict load/store
instruction set architecture that can be achieved by applying threads depend on
the operating unit size, the cardinality of the instruction set, and the
maximal number of states of the threads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.0840</identifier>
 <datestamp>2010-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.0840</id><created>2007-11-06</created><updated>2008-11-18</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>A thread calculus with molecular dynamics</title><categories>cs.LO</categories><comments>47 pages; examples and results added, phrasing improved, references
  replaced</comments><acm-class>D.1.3; D.1.5; D.3.3; F.1.1; F.1.2; F.3.2</acm-class><journal-ref>Information and Computation, 208(7):817-844, 2010</journal-ref><doi>10.1016/j.ic.2010.01.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theory of threads, interleaving of threads, and interaction
between threads and services with features of molecular dynamics, a model of
computation that bears on computations in which dynamic data structures are
involved. Threads can interact with services of which the states consist of
structured data objects and computations take place by means of actions which
may change the structure of the data objects. The features introduced include
restriction of the scope of names used in threads to refer to data objects.
Because that feature makes it troublesome to provide a model based on
structural operational semantics and bisimulation, we construct a projective
limit model for the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.1189</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.1189</id><created>2007-11-07</created><updated>2011-09-22</updated><authors><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Clique Minors in Cartesian Products of Graphs</title><categories>math.CO cs.DM</categories><msc-class>05C83, 05C75</msc-class><journal-ref>New York J. Mathematics 17:627-682, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A "clique minor" in a graph G can be thought of as a set of connected
subgraphs in G that are pairwise disjoint and pairwise adjacent. The "Hadwiger
number" h(G) is the maximum cardinality of a clique minor in G. This paper
studies clique minors in the Cartesian product G*H.
  Our main result is a rough structural characterisation theorem for Cartesian
products with bounded Hadwiger number. It implies that if the product of two
sufficiently large graphs has bounded Hadwiger number then it is one of the
following graphs:
  - a planar grid with a vortex of bounded width in the outerface,
  - a cylindrical grid with a vortex of bounded width in each of the two `big'
faces, or
  - a toroidal grid.
  Motivation for studying the Hadwiger number of a graph includes Hadwiger's
Conjecture, which states that the chromatic number chi(G) &lt;= h(G). It is open
whether Hadwiger's Conjecture holds for every Cartesian product. We prove that
if |V(H)|-1 &gt;= chi(G) &gt;= chi(H) then Hadwiger's Conjecture holds for G*H. On
the other hand, we prove that Hadwiger's Conjecture holds for all Cartesian
products if and only if it holds for all G * K_2. We then show that h(G * K_2)
is tied to the treewidth of G.
  We also develop connections with pseudoachromatic colourings and connected
dominating sets that imply near-tight bounds on the Hadwiger number of grid
graphs (Cartesian products of paths) and Hamming graphs (Cartesian products of
cliques).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.1466</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.1466</id><created>2007-11-09</created><updated>2008-02-21</updated><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author><author><keyname>Ohsawa</keyname><forenames>Yukio</forenames></author></authors><title>Predicting relevant empty spots in social interaction</title><categories>cs.AI</categories><comments>11 pages, 5 figures, submitted to J. Systems Science and Complexity</comments><journal-ref>Journal of Systems Science and Complexity vol.21, pp.161-171
  (2008)</journal-ref><abstract>  An empty spot refers to an empty hard-to-fill space which can be found in the
records of the social interaction, and is the clue to the persons in the
underlying social network who do not appear in the records. This contribution
addresses a problem to predict relevant empty spots in social interaction.
Homogeneous and inhomogeneous networks are studied as a model underlying the
social interaction. A heuristic predictor function approach is presented as a
new method to address the problem. Simulation experiment is demonstrated over a
homogeneous network. A test data in the form of baskets is generated from the
simulated communication. Precision to predict the empty spots is calculated to
demonstrate the performance of the presented approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.1605</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.1605</id><created>2007-11-10</created><updated>2010-10-04</updated><authors><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author></authors><title>Asymptotic Capacity of Wireless Ad Hoc Networks with Realistic Links
  under a Honey Comb Topology</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors. 3 pages, 1 figure,
  Submitted to IEEE Communication Letters</comments><abstract>  We consider the effects of Rayleigh fading and lognormal shadowing in the
physical interference model for all the successful transmissions of traffic
across the network. New bounds are derived for the capacity of a given random
ad hoc wireless network that reflect packet drop or capture probability of the
transmission links. These bounds are based on a simplified network topology
termed as honey-comb topology under a given routing and scheduling scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.2157</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.2157</id><created>2007-11-14</created><updated>2011-07-13</updated><authors><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author></authors><title>On Approximating Multi-Criteria TSP</title><categories>cs.DS</categories><comments>Preliminary version at STACS 2009. This paper is a revised full
  version, where some proofs are simplified</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present approximation algorithms for almost all variants of the
multi-criteria traveling salesman problem (TSP).
  First, we devise randomized approximation algorithms for multi-criteria
maximum traveling salesman problems (Max-TSP). For multi-criteria Max-STSP,
where the edge weights have to be symmetric, we devise an algorithm with an
approximation ratio of 2/3 - eps. For multi-criteria Max-ATSP, where the edge
weights may be asymmetric, we present an algorithm with a ratio of 1/2 - eps.
Our algorithms work for any fixed number k of objectives. Furthermore, we
present a deterministic algorithm for bi-criteria Max-STSP that achieves an
approximation ratio of 7/27.
  Finally, we present a randomized approximation algorithm for the asymmetric
multi-criteria minimum TSP with triangle inequality Min-ATSP. This algorithm
achieves a ratio of log n + eps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.2562</identifier>
 <datestamp>2010-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.2562</id><created>2007-11-16</created><updated>2010-01-24</updated><authors><author><keyname>Ibrahim</keyname><forenames>Ashraf</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author><author><keyname>Rusek</keyname><forenames>Korben</forenames></author></authors><title>Algorithmic Arithmetic Fewnomial Theory I: One Variable</title><categories>math.NT cs.CC math.AG</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Withdrawn by the authors due to an error in the proof of the finite field
result (Thm. 1.5): The random primes used in the proof need NOT avoid the
exceptional primes from Lemma 2.7, thus leaving Thm. 1.5 unproved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.2618</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.2618</id><created>2007-11-16</created><updated>2011-09-20</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Arbab</keyname><forenames>Farhad</forenames></author><author><keyname>Ma</keyname><forenames>Huiye</forenames></author></authors><title>A System for Distributed Mechanisms: Design, Implementation and
  Applications</title><categories>cs.DC cs.GT</categories><comments>36 pages; revised and expanded version</comments><acm-class>C.2.4; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe here a structured system for distributed mechanism design
appropriate for both Intranet and Internet applications. In our approach the
players dynamically form a network in which they know neither their neighbours
nor the size of the network and interact to jointly take decisions. The only
assumption concerning the underlying communication layer is that for each pair
of processes there is a path of neighbours connecting them. This allows us to
deal with arbitrary network topologies.
  We also discuss the implementation of this system which consists of a
sequence of layers. The lower layers deal with the operations that implement
the basic primitives of distributed computing, namely low level communication
and distributed termination, while the upper layers use these primitives to
implement high level communication among players, including broadcasting and
multicasting, and distributed decision making.
  This yields a highly flexible distributed system whose specific applications
are realized as instances of its top layer. This design is implemented in Java.
  The system supports at various levels fault-tolerance and includes a
provision for distributed policing the purpose of which is to exclude
`dishonest' players. Also, it can be used for repeated creation of dynamically
formed networks of players interested in a joint decision making implemented by
means of a tax-based mechanism. We illustrate its flexibility by discussing a
number of implemented examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.2666</identifier>
 <datestamp>2013-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.2666</id><created>2007-11-16</created><authors><author><keyname>Harrison</keyname><forenames>Matthew T.</forenames></author></authors><title>The Generalized Asymptotic Equipartition Property: Necessary and
  Sufficient Conditions</title><categories>cs.IT math.IT</categories><comments>19 pages</comments><journal-ref>IEEE Transactions on Information Theory, (2008) 54: 3211-3216</journal-ref><doi>10.1109/TIT.2008.924668</doi><abstract>  Suppose a string $X_1^n=(X_1,X_2,...,X_n)$ generated by a memoryless source
$(X_n)_{n\geq 1}$ with distribution $P$ is to be compressed with distortion no
greater than $D\geq 0$, using a memoryless random codebook with distribution
$Q$. The compression performance is determined by the ``generalized asymptotic
equipartition property'' (AEP), which states that the probability of finding a
$D$-close match between $X_1^n$ and any given codeword $Y_1^n$, is
approximately $2^{-n R(P,Q,D)}$, where the rate function $R(P,Q,D)$ can be
expressed as an infimum of relative entropies. The main purpose here is to
remove various restrictive assumptions on the validity of this result that have
appeared in the recent literature. Necessary and sufficient conditions for the
generalized AEP are provided in the general setting of abstract alphabets and
unbounded distortion measures. All possible distortion levels $D\geq 0$ are
considered; the source $(X_n)_{n\geq 1}$ can be stationary and ergodic; and the
codebook distribution can have memory. Moreover, the behavior of the matching
probability is precisely characterized, even when the generalized AEP is not
valid. Natural characterizations of the rate function $R(P,Q,D)$ are
established under equally general conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.2745</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.2745</id><created>2007-11-19</created><updated>2009-08-03</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>On Capacity Scaling in Arbitrary Wireless Networks</title><categories>cs.IT math.IT</categories><comments>38 pages, 6 figures, to appear in IEEE Transactions on Information
  Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 55, pp. 3959-3982,
  September 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent work, Ozgur, Leveque, and Tse (2007) obtained a complete scaling
characterization of throughput scaling for random extended wireless networks
(i.e., $n$ nodes are placed uniformly at random in a square region of area
$n$). They showed that for small path-loss exponents $\alpha\in(2,3]$
cooperative communication is order optimal, and for large path-loss exponents
$\alpha &gt; 3$ multi-hop communication is order optimal. However, their results
(both the communication scheme and the proof technique) are strongly dependent
on the regularity induced with high probability by the random node placement.
  In this paper, we consider the problem of characterizing the throughput
scaling in extended wireless networks with arbitrary node placement. As a main
result, we propose a more general novel cooperative communication scheme that
works for arbitrarily placed nodes. For small path-loss exponents $\alpha \in
(2,3]$, we show that our scheme is order optimal for all node placements, and
achieves exactly the same throughput scaling as in Ozgur et al. This shows that
the regularity of the node placement does not affect the scaling of the
achievable rates for $\alpha\in (2,3]$. The situation is, however, markedly
different for large path-loss exponents $\alpha &gt;3$. We show that in this
regime the scaling of the achievable per-node rates depends crucially on the
regularity of the node placement. We then present a family of schemes that
smoothly "interpolate" between multi-hop and cooperative communication,
depending upon the level of regularity in the node placement. We establish
order optimality of these schemes under adversarial node placement for $\alpha
&gt; 3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.2801</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.2801</id><created>2007-11-18</created><updated>2007-12-02</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Inverse Sampling for Nonasymptotic Sequential Estimation of Bounded
  Variable Means</title><categories>math.ST cs.LG math.PR stat.TH</categories><comments>31 pages, 4 figures, added proofs</comments><msc-class>62L12; 62D05; 65C05</msc-class><abstract>  In this paper, we consider the nonasymptotic sequential estimation of means
of random variables bounded in between zero and one. We have rigorously
demonstrated that, in order to guarantee prescribed relative precision and
confidence level, it suffices to continue sampling until the sample sum is no
less than a certain bound and then take the average of samples as an estimate
for the mean of the bounded random variable. We have developed an explicit
formula and a bisection search method for the determination of such bound of
sample sum, without any knowledge of the bounded variable. Moreover, we have
derived bounds for the distribution of sample size. In the special case of
Bernoulli random variables, we have established analytical and numerical
methods to further reduce the bound of sample sum and thus improve the
efficiency of sampling. Furthermore, the fallacy of existing results are
detected and analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.3013</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.3013</id><created>2007-11-19</created><updated>2010-12-20</updated><authors><author><keyname>Streinu</keyname><forenames>Ileana</forenames></author><author><keyname>Theran</keyname><forenames>Louis</forenames></author></authors><title>Natural realizations of sparsity matroids</title><categories>math.CO cs.CG math.AG math.MG</categories><comments>Corrected some typos from the previous version; to appear in Ars
  Mathematica Contemporanea</comments><msc-class>05B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A hypergraph G with n vertices and m hyperedges with d endpoints each is
(k,l)-sparse if for all sub-hypergraphs G' on n' vertices and m' edges, m'\le
kn'-l. For integers k and l satisfying 0\le l\le dk-1, this is known to be a
linearly representable matroidal family.
  Motivated by problems in rigidity theory, we give a new linear representation
theorem for the (k,l)-sparse hypergraphs that is natural; i.e., the
representing matrix captures the vertex-edge incidence structure of the
underlying hypergraph G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.3591</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.3591</id><created>2007-11-22</created><updated>2008-03-03</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author></authors><title>An Estimation of Distribution Algorithm with Intelligent Local Search
  for Rule-based Nurse Rostering</title><categories>cs.NE cs.CE</categories><journal-ref>Journal of the Operational Research Society, 58 (12), pp
  1574-1585, 2007</journal-ref><doi>10.1057/palgrave.jors.2602308</doi><abstract>  This paper proposes a new memetic evolutionary algorithm to achieve explicit
learning in rule-based nurse rostering, which involves applying a set of
heuristic rules for each nurse's assignment. The main framework of the
algorithm is an estimation of distribution algorithm, in which an ant-miner
methodology improves the individual solutions produced in each generation.
Unlike our previous work (where learning is implicit), the learning in the
memetic estimation of distribution algorithm is explicit, i.e. we are able to
identify building blocks directly. The overall approach learns by building a
probabilistic model, i.e. an estimation of the probability distribution of
individual nurse-rule pairs that are used to construct schedules. The local
search processor (i.e. the ant-miner) reinforces nurse-rule pairs that receive
higher rewards. A challenging real world nurse rostering problem is used as the
test problem. Computational results show that the proposed approach outperforms
most existing approaches. It is suggested that the learning methodologies
suggested in this paper may be applied to other scheduling problems where
schedules are built systematically according to specific rules
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.4142</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.4142</id><created>2007-11-26</created><updated>2008-01-25</updated><authors><author><keyname>Santos-Neto</keyname><forenames>Elizeu</forenames></author><author><keyname>Ripeanu</keyname><forenames>Matei</forenames></author><author><keyname>Iamnitchi</keyname><forenames>Adriana</forenames></author></authors><title>Content Reuse and Interest Sharing in Tagging Communities</title><categories>cs.DL cs.IR</categories><comments>6 pages, 6 figures, AAAI Spring Symposium on Social Information
  Processing</comments><abstract>  Tagging communities represent a subclass of a broader class of user-generated
content-sharing online communities. In such communities users introduce and tag
content for later use. Although recent studies advocate and attempt to harness
social knowledge in this context by exploiting collaboration among users,
little research has been done to quantify the current level of user
collaboration in these communities. This paper introduces two metrics to
quantify the level of collaboration: content reuse and shared interest. Using
these two metrics, this paper shows that the current level of collaboration in
CiteULike and Connotea is consistently low, which significantly limits the
potential of harnessing the social knowledge in communities. This study also
discusses implications of these findings in the context of recommendation and
reputation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.4217</identifier>
 <datestamp>2010-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.4217</id><created>2007-11-27</created><updated>2009-08-04</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Instruction sequences with dynamically instantiated instructions</title><categories>cs.PL</categories><comments>25 pages; phrasing improved</comments><report-no>PRG0710</report-no><acm-class>D.3.1; D.3.3; F.1.1; F.3.2; F.3.3</acm-class><journal-ref>Fundamenta Informaticae, 96(1--2):27--48, 2009</journal-ref><doi>10.3233/FI-2009-165</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study sequential programs that are instruction sequences with dynamically
instantiated instructions. We define the meaning of such programs in two
different ways. In either case, we give a translation by which each program
with dynamically instantiated instructions is turned into a program without
them that exhibits on execution the same behaviour by interaction with some
service. The complexity of the translations differ considerably, whereas the
services concerned are equally simple. However, the service concerned in the
case of the simpler translation is far more powerful than the service concerned
in the other case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0711.4603</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0711.4603</id><created>2007-11-29</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author></authors><title>A Note on Quantum Hamming Bound</title><categories>quant-ph cs.IT math.IT</categories><abstract>  Proving the quantum Hamming bound for degenerate nonbinary stabilizer codes
has been an open problem for a decade. In this note, I prove this bound for
double error-correcting degenerate stabilizer codes. Also, I compute the
maximum length of single and double error-correcting MDS stabilizer codes over
finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0836</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0836</id><created>2007-12-05</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author><author><keyname>Collet</keyname><forenames>Pierre</forenames></author><author><keyname>Sapin</keyname><forenames>Emmanuel</forenames></author></authors><title>Evolving localizations in reaction-diffusion cellular automata</title><categories>cs.AI</categories><comments>Accepted for publication in Int. J. Modern Physics C</comments><journal-ref>International Journal of Modern Physics C (IJMPC) Volume: 19,
  Issue: 4 (April 2008) pp. 557-567</journal-ref><doi>10.1142/S0129183108012376</doi><abstract>  We consider hexagonal cellular automata with immediate cell neighbourhood and
three cell-states. Every cell calculates its next state depending on the
integral representation of states in its neighbourhood, i.e. how many
neighbours are in each one state. We employ evolutionary algorithms to breed
local transition functions that support mobile localizations (gliders), and
characterize sets of the functions selected in terms of quasi-chemical systems.
Analysis of the set of functions evolved allows to speculate that mobile
localizations are likely to emerge in the quasi-chemical systems with limited
diffusion of one reagent, a small number of molecules is required for
amplification of travelling localizations, and reactions leading to stationary
localizations involve relatively equal amount of quasi-chemical species.
Techniques developed can be applied in cascading signals in nature-inspired
spatially extended computing devices, and phenomenological studies and
classification of non-linear discrete systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0917</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0917</id><created>2007-12-06</created><authors><author><keyname>Bethke</keyname><forenames>Inge</forenames></author><author><keyname>Rodenburg</keyname><forenames>Piet</forenames></author></authors><title>Some properties of finite meadows</title><categories>math.RA cs.SC</categories><comments>8 pages, 1 table</comments><abstract>  The aim of this note is to describe the structure of finite meadows. We will
show that the class of finite meadows is the closure of the class of finite
fields under finite products. As a corollary, we obtain a unique representation
of minimal meadows in terms of prime fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.0975</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.0975</id><created>2007-12-06</created><authors><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Shor</keyname><forenames>Peter W.</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Random quantum codes from Gaussian ensembles and an uncertainty relation</title><categories>quant-ph cs.IT math.IT</categories><comments>9 pages, two-column style. This paper is a companion to
  quant-ph/0702005 and quant-ph/0702006</comments><journal-ref>Open Syst. Inf. Dyn. 15 (2008) 71-89</journal-ref><doi>10.1142/S1230161208000079</doi><abstract>  Using random Gaussian vectors and an information-uncertainty relation, we
give a proof that the coherent information is an achievable rate for
entanglement transmission through a noisy quantum channel. The codes are random
subspaces selected according to the Haar measure, but distorted as a function
of the sender's input density operator. Using large deviations techniques, we
show that classical data transmitted in either of two Fourier-conjugate bases
for the coding subspace can be decoded with low probability of error. A
recently discovered information-uncertainty relation then implies that the
quantum mutual information for entanglement encoded into the subspace and
transmitted through the channel will be high. The monogamy of quantum
correlations finally implies that the environment of the channel cannot be
significantly coupled to the entanglement, and concluding, which ensures the
existence of a decoding by the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1345</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1345</id><created>2007-12-09</created><updated>2008-10-15</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Sequential operators in computability logic</title><categories>cs.LO cs.AI math.LO</categories><comments>To appear in "Information and Computation"</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Information and Computation 206 (2008), pp. 1443-1475</journal-ref><doi>10.1016/j.ic.2008.10.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a
semantical platform and research program for redeveloping logic as a formal
theory of computability, as opposed to the formal theory of truth which it has
more traditionally been. Formulas in CL stand for (interactive) computational
problems, understood as games between a machine and its environment; logical
operators represent operations on such entities; and "truth" is understood as
existence of an effective solution, i.e., of an algorithmic winning strategy.
  The formalism of CL is open-ended, and may undergo series of extensions as
the study of the subject advances. The main groups of operators on which CL has
been focused so far are the parallel, choice, branching, and blind operators.
The present paper introduces a new important group of operators, called
sequential. The latter come in the form of sequential conjunction and
disjunction, sequential quantifiers, and sequential recurrences. As the name
may suggest, the algorithmic intuitions associated with this group are those of
sequential computations, as opposed to the intuitions of parallel computations
associated with the parallel group of operations: playing a sequential
combination of games means playing its components in a sequential fashion, one
after one.
  The main technical result of the present paper is a sound and complete
axiomatization of the propositional fragment of computability logic whose
vocabulary, together with negation, includes all three -- parallel, choice and
sequential -- sorts of conjunction and disjunction. An extension of this result
to the first-order level is also outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1402</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1402</id><created>2007-12-10</created><updated>2010-03-08</updated><authors><author><keyname>Bresler</keyname><forenames>Guy</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Sly</keyname><forenames>Allan</forenames></author></authors><title>Reconstruction of Markov Random Fields from Samples: Some Easy
  Observations and Algorithms</title><categories>cs.CC cs.LG</categories><comments>14 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov random fields are used to model high dimensional distributions in a
number of applied areas. Much recent interest has been devoted to the
reconstruction of the dependency structure from independent samples from the
Markov random fields. We analyze a simple algorithm for reconstructing the
underlying graph defining a Markov random field on $n$ nodes and maximum degree
$d$ given observations. We show that under mild non-degeneracy conditions it
reconstructs the generating graph with high probability using $\Theta(d
\epsilon^{-2}\delta^{-4} \log n)$ samples where $\epsilon,\delta$ depend on the
local interactions. For most local interaction $\eps,\delta$ are of order
$\exp(-O(d))$.
  Our results are optimal as a function of $n$ up to a multiplicative constant
depending on $d$ and the strength of the local interactions. Our results seem
to be the first results for general models that guarantee that {\em the}
generating model is reconstructed. Furthermore, we provide explicit $O(n^{d+2}
\epsilon^{-2}\delta^{-4} \log n)$ running time bound. In cases where the
measure on the graph has correlation decay, the running time is $O(n^2 \log n)$
for all fixed $d$. We also discuss the effect of observing noisy samples and
show that as long as the noise level is low, our algorithm is effective. On the
other hand, we construct an example where large noise implies
non-identifiability even for generic noise and interactions. Finally, we
briefly show that in some simple cases, models with hidden nodes can also be
recovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.1869</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.1869</id><created>2007-12-12</created><updated>2008-01-21</updated><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames><affiliation>Acadia Un. Wolfville N. S. Canada</affiliation></author><author><keyname>Labelle</keyname><forenames>Gilbert</forenames><affiliation>LaCIM UQAM Montreal Qc Canada</affiliation></author><author><keyname>Leroux</keyname><forenames>Pierre</forenames><affiliation>LaCIM UQAM Montreal Qc Canada</affiliation></author><author><keyname>Walsh</keyname><forenames>Timothy</forenames><affiliation>LaCIM UQAM Montreal Qc Canada</affiliation></author></authors><title>Two-connected graphs with prescribed three-connected components</title><categories>math.CO cs.DM</categories><comments>Work presented at the Ottawa-Carleton Discrete Mathematics Workshop,
  May 25-26, 2007 and at the Seminaire Lotharingien de Combinatoire, Bertinoro,
  Italy, September 24-26, 2007. 32 pages. 11 pdf figures. Version 2: Minor
  revisions, one Table added</comments><msc-class>05A15, 05C30, 05C75</msc-class><journal-ref>Adv. in Appl. Math. 43 (2009), no. 1, pp. 46-74</journal-ref><doi>10.1016/j.aam.2009.01.002</doi><abstract>  We adapt the classical 3-decomposition of any 2-connected graph to the case
of simple graphs (no loops or multiple edges). By analogy with the
block-cutpoint tree of a connected graph, we deduce from this decomposition a
bicolored tree tc(g) associated with any 2-connected graph g, whose white
vertices are the 3-components of g (3-connected components or polygons) and
whose black vertices are bonds linking together these 3-components, arising
from separating pairs of vertices of g. Two fundamental relationships on graphs
and networks follow from this construction. The first one is a dissymmetry
theorem which leads to the expression of the class B=B(F) of 2-connected
graphs, all of whose 3-connected components belong to a given class F of
3-connected graphs, in terms of various rootings of B. The second one is a
functional equation which characterizes the corresponding class R=R(F) of
two-pole networks all of whose 3-connected components are in F. All the
rootings of B are then expressed in terms of F and R. There follow
corresponding identities for all the associated series, in particular the edge
index series. Numerous enumerative consequences are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2223</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2223</id><created>2007-12-13</created><updated>2010-04-02</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author></authors><title>Entanglement-Assisted Quantum Convolutional Coding</title><categories>quant-ph cs.IT math.IT</categories><comments>Accepted for publication in Physical Review A</comments><report-no>CSI-07-12-01</report-no><journal-ref>Physical Review A 81, 042333 (2010)</journal-ref><doi>10.1103/PhysRevA.81.042333</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to protect a stream of quantum information from decoherence
induced by a noisy quantum communication channel. We exploit preshared
entanglement and a convolutional coding structure to develop a theory of
entanglement-assisted quantum convolutional coding. Our construction produces a
Calderbank-Shor-Steane (CSS) entanglement-assisted quantum convolutional code
from two arbitrary classical binary convolutional codes. The rate and
error-correcting properties of the classical convolutional codes directly
determine the corresponding properties of the resulting entanglement-assisted
quantum convolutional code. We explain how to encode our CSS
entanglement-assisted quantum convolutional codes starting from a stream of
information qubits, ancilla qubits, and shared entangled bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2585</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2585</id><created>2007-12-17</created><updated>2007-12-28</updated><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>Interval Edge Colourings of Complete Graphs and n-cubes</title><categories>cs.DM</categories><comments>4 pages</comments><journal-ref>Mathematical Problems of Computer Science 25, 2006, 5--8</journal-ref><abstract>  For complete graphs and n-cubes bounds are found for the possible number of
colours in an interval edge colourings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2595</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2595</id><created>2007-12-16</created><authors><author><keyname>Rosgen</keyname><forenames>Bill</forenames></author></authors><title>Distinguishing Short Quantum Computations</title><categories>quant-ph cs.CC</categories><comments>12 pages, 4 figures, to be published in the proceedings of STACS 2008</comments><doi>10.4230/LIPIcs.STACS.2008.1322</doi><abstract>  Distinguishing logarithmic depth quantum circuits on mixed states is shown to
be complete for QIP, the class of problems having quantum interactive proof
systems. Circuits in this model can represent arbitrary quantum processes, and
thus this result has implications for the verification of implementations of
quantum algorithms. The distinguishability problem is also complete for QIP on
constant depth circuits containing the unbounded fan-out gate. These results
are shown by reducing a QIP-complete problem to a logarithmic depth version of
itself using a parallelization technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2606</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2606</id><created>2007-12-16</created><updated>2010-10-19</updated><authors><author><keyname>Croll</keyname><forenames>Grenville J.</forenames></author></authors><title>Algorithmic Permutation of part of the Torah</title><categories>cs.CR</categories><comments>10 Pages. Presented at the Second Conference of the International
  Torah Codes Society, Jerusalem, Israel, 6th June 2000. Minor updates and
  added Appendix B in version 2, October 2010</comments><acm-class>E.3</acm-class><journal-ref>Proc. ANPA 27, Wesley College, Cambridge, UK, September 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A small part of the Torah is arranged into a two dimensional array. The
characters are then permuted using a simple recursive deterministic algorithm.
The various permutations are then passed through three stochastic filters and
one deterministic filter to identify the permutations which most closely
approximate readable Biblical Hebrew. Of the 15 Billion sequences available at
the second level of recursion, 800 pass the a priori thresholds set for each
filter. The resulting "Biblical Hebrew" text is available for inspection and
the generation of further material continues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.2629</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.2629</id><created>2007-12-16</created><updated>2008-01-04</updated><authors><author><keyname>Hamane</keyname><forenames>Ryoso</forenames></author><author><keyname>Itoh</keyname><forenames>Toshiya</forenames></author><author><keyname>Tomita</keyname><forenames>Kouhei</forenames></author></authors><title>Approximation Algorithms for the Highway Problem under the Coupon Model</title><categories>cs.DS</categories><comments>13 pages, 5 figures</comments><acm-class>F.2.2; G.1.2; G.2.1</acm-class><journal-ref>IEICE Trans. on Fundamentals, E92-A(8), pp.1779-1786, 2009</journal-ref><doi>10.1587/transfun.E92.A.1779</doi><abstract>  When a store sells items to customers, the store wishes to determine the
prices of the items to maximize its profit. Intuitively, if the store sells the
items with low (resp. high) prices, the customers buy more (resp. less) items,
which provides less profit to the store. So it would be hard for the store to
decide the prices of items. Assume that the store has a set V of n items and
there is a set E of m customers who wish to buy those items, and also assume
that each item i \in V has the production cost d_i and each customer e_j \in E
has the valuation v_j on the bundle e_j \subseteq V of items. When the store
sells an item i \in V at the price r_i, the profit for the item i is
p_i=r_i-d_i. The goal of the store is to decide the price of each item to
maximize its total profit. In most of the previous works, the item pricing
problem was considered under the assumption that p_i \geq 0 for each i \in V,
however, Balcan, et al. [In Proc. of WINE, LNCS 4858, 2007] introduced the
notion of loss-leader, and showed that the seller can get more total profit in
the case that p_i &lt; 0 is allowed than in the case that p_i &lt; 0 is not allowed.
In this paper, we consider the line and the cycle highway problem, and show
approximation algorithms for the line and/or cycle highway problem for which
the smallest valuation is s and the largest valuation is \ell or all valuations
are identical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3088</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3088</id><created>2007-12-19</created><updated>2012-09-07</updated><authors><author><keyname>Luo</keyname><forenames>Zhaohua</forenames></author></authors><title>Clones and Genoids in Lambda Calculus and First Order Logic</title><categories>cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A genoid is a category of two objects such that one is the product of itself
with the other. A genoid may be viewed as an abstract substitution algebra. It
is a remarkable fact that such a simple concept can be applied to present a
unified algebraic approach to lambda calculus and first order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3155</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3155</id><created>2007-12-19</created><updated>2007-12-28</updated><authors><author><keyname>Kamalian</keyname><forenames>Rafael R.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author></authors><title>On Interval Colorings of Complete k-partite Graphs K_{n}^{k}</title><categories>cs.DM</categories><comments>6 pages</comments><journal-ref>Mathematical Problems of Computer Science 26, 2006, 28--32</journal-ref><abstract>  Problems of existence, construction and estimation of parameters of interval
colorings of complete k-partite graphs K_{n}^{k} are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3829</identifier>
 <datestamp>2011-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3829</id><created>2007-12-21</created><updated>2010-01-03</updated><authors><author><keyname>Inui</keyname><forenames>Yoshifumi</forenames></author><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author></authors><title>Quantum Property Testing of Group Solvability</title><categories>quant-ph cs.DS</categories><comments>11 pages; supersedes arXiv:quant-ph/0610013</comments><journal-ref>Algorithmica 59(1): 35-47 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing efficiently whether a finite set with a binary operation over it,
given as an oracle, is a group is a well-known open problem in the field of
property testing. Recently, Friedl, Ivanyos and Santha have made a significant
step in the direction of solving this problem by showing that it it possible to
test efficiently whether the input is an Abelian group or is far, with respect
to some distance, from any Abelian group. In this paper, we make a step further
and construct an efficient quantum algorithm that tests whether the input is a
solvable group, or is far from any solvable group. More precisely, the number
of queries used by our algorithm is polylogarithmic in the size of the set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3870</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3870</id><created>2007-12-22</created><updated>2008-05-19</updated><authors><author><keyname>Hajek</keyname><forenames>Bruce</forenames></author></authors><title>Substitute Valuations: Generation and Structure</title><categories>cs.GT cs.PF</categories><comments>Revision includes more background and explanations</comments><acm-class>G.0</acm-class><doi>10.1016/j.peva.2008.07.001</doi><abstract>  Substitute valuations (in some contexts called gross substitute valuations)
are prominent in combinatorial auction theory. An algorithm is given in this
paper for generating a substitute valuation through Monte Carlo simulation. In
addition, the geometry of the set of all substitute valuations for a fixed
number of goods K is investigated. The set consists of a union of polyhedrons,
and the maximal polyhedrons are identified for K=4. It is shown that the
maximum dimension of the maximal polyhedrons increases with K nearly as fast as
two to the power K. Consequently, under broad conditions, if a combinatorial
algorithm can present an arbitrary substitute valuation given a list of input
numbers, the list must grow nearly as fast as two to the power K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3925</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3925</id><created>2007-12-23</created><authors><author><keyname>Heus</keyname><forenames>Pascal</forenames></author><author><keyname>Gomez</keyname><forenames>Richard</forenames></author></authors><title>QIS-XML: A metadata specification for Quantum Information Science</title><categories>cs.SE cs.DB quant-ph</categories><comments>26 pages, 22 figures</comments><abstract>  While Quantum Information Science (QIS) is still in its infancy, the ability
for quantum based hardware or computers to communicate and integrate with their
classical counterparts will be a major requirement towards their success.
Little attention however has been paid to this aspect of QIS. To manage and
exchange information between systems, today's classic Information Technology
(IT) commonly uses the eXtensible Markup Language (XML) and its related tools.
XML is composed of numerous specifications related to various fields of
expertise. No such global specification however has been defined for quantum
computers. QIS-XML is a proposed XML metadata specification for the description
of fundamental components of QIS (gates &amp; circuits) and a platform for the
development of a hardware independent low level pseudo-code for quantum
algorithms. This paper lays out the general characteristics of the QIS-XML
specification and outlines practical applications through prototype use cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.3973</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.3973</id><created>2007-12-24</created><authors><author><keyname>Collet</keyname><forenames>Pierre</forenames><affiliation>LIL</affiliation></author><author><keyname>Schoenauer</keyname><forenames>Marc</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>GUIDE: Unifying Evolutionary Engines through a Graphical User Interface</title><categories>cs.NE</categories><proxy>ccsd inria-00201074</proxy><journal-ref>Dans Evolution Artificielle 2936 (2003) 203-215</journal-ref><abstract>  Many kinds of Evolutionary Algorithms (EAs) have been described in the
literature since the last 30 years. However, though most of them share a common
structure, no existing software package allows the user to actually shift from
one model to another by simply changing a few parameters, e.g. in a single
window of a Graphical User Interface. This paper presents GUIDE, a Graphical
User Interface for DREAM Experiments that, among other user-friendly features,
unifies all kinds of EAs into a single panel, as far as evolution parameters
are concerned. Such a window can be used either to ask for one of the well
known ready-to-use algorithms, or to very easily explore new combinations that
have not yet been studied. Another advantage of grouping all necessary elements
to describe virtually all kinds of EAs is that it creates a fantastic pedagogic
tool to teach EAs to students and newcomers to the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4103</identifier>
 <datestamp>2010-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4103</id><created>2007-12-26</created><updated>2010-01-23</updated><authors><author><keyname>Kapinas</keyname><forenames>Vasilios M.</forenames></author><author><keyname>Mihos</keyname><forenames>Sotirios K.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>On the Monotonicity of the Generalized Marcum and Nuttall Q-Functions</title><categories>cs.IT math.IT</categories><comments>Published in IEEE Transactions on Information Theory, August 2009.
  Only slight formatting modifications</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 55, no. 8, pp. 3701-3710, Aug. 2009</journal-ref><doi>10.1109/TIT.2009.2023710</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monotonicity criteria are established for the generalized Marcum Q-function,
$\emph{Q}_{M}$, the standard Nuttall Q-function, $\emph{Q}_{M,N}$, and the
normalized Nuttall Q-function, $\mathcal{Q}_{M,N}$, with respect to their real
order indices M,N. Besides, closed-form expressions are derived for the
computation of the standard and normalized Nuttall Q-functions for the case
when M,N are odd multiples of 0.5 and $M\geq N$. By exploiting these results,
novel upper and lower bounds for $\emph{Q}_{M,N}$ and $\mathcal{Q}_{M,N}$ are
proposed. Furthermore, specific tight upper and lower bounds for
$\emph{Q}_{M}$, previously reported in the literature, are extended for real
values of M. The offered theoretical results can be efficiently applied in the
study of digital communications over fading channels, in the
information-theoretic analysis of multiple-input multiple-output systems and in
the description of stochastic processes in probability theory, among others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4159</identifier>
 <datestamp>2012-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4159</id><created>2007-12-26</created><updated>2012-11-27</updated><authors><author><keyname>Briscoe</keyname><forenames>G</forenames></author></authors><title>Creating a Digital Ecosystem: Service-Oriented Architectures with
  Distributed Evolutionary Computing</title><categories>cs.NE</categories><comments>This has been withdrawn by the author due to an error in using
  presentation notes in submission</comments><journal-ref>In JavaOne Conference, 2006, BOF-0759</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We start with a discussion of the relevant literature, including Nature
Inspired Computing as a framework in which to understand this work, and the
process of biomimicry to be used in mimicking the necessary biological
processes to create Digital Ecosystems. We then consider the relevant
theoretical ecology in creating the digital counterpart of a biological
ecosystem, including the topological structure of ecosystems, and evolutionary
processes within distributed environments. This leads to a discussion of the
relevant fields from computer science for the creation of Digital Ecosystems,
including evolutionary computing, Multi-Agent Systems, and Service-Oriented
Architectures. We then define Ecosystem-Oriented Architectures for the creation
of Digital Ecosystems, imbibed with the properties of self-organisation and
scalability from biological ecosystems, including a novel form of distributed
evolutionary computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4213</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4213</id><created>2007-12-27</created><authors><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Matsumoto</keyname><forenames>Keiji</forenames></author></authors><title>Exact Quantum Algorithms for the Leader Election Problem</title><categories>quant-ph cs.DC cs.DS</categories><comments>47 pages, preliminary version in Proceedings of STACS 2005</comments><journal-ref>ACM TOCT 4 (2012): Article 1; IEEE TPDS 23 (2012): 255 - 262</journal-ref><abstract>  This paper gives the first separation of quantum and classical pure (i.e.,
non-cryptographic) computing abilities with no restriction on the amount of
available computing resources, by considering the exact solvability of a
celebrated unsolvable problem in classical distributed computing, the ``leader
election problem'' on anonymous networks. The goal of the leader election
problem is to elect a unique leader from among distributed parties. The paper
considers this problem for anonymous networks, in which each party has the same
identifier. It is well-known that no classical algorithm can solve exactly
(i.e., in bounded time without error) the leader election problem in anonymous
networks, even if it is given the number of parties. This paper gives two
quantum algorithms that, given the number of parties, can exactly solve the
problem for any network topology in polynomial rounds and polynomial
communication/time complexity with respect to the number of parties, when the
parties are connected by quantum communication links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4273</identifier>
 <datestamp>2011-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4273</id><created>2007-12-27</created><updated>2011-12-02</updated><authors><author><keyname>Cappé</keyname><forenames>Olivier</forenames><affiliation>LTCI</affiliation></author><author><keyname>Moulines</keyname><forenames>Eric</forenames><affiliation>LTCI</affiliation></author></authors><title>Online EM Algorithm for Latent Data Models</title><categories>stat.CO cs.LG</categories><comments>Version that includes the corrigendum published in volume 73, part 5
  (2011), of the Journal of the Royal Statistical Society, Series B</comments><proxy>ccsd</proxy><journal-ref>Journal of the Royal Statistical Society Series B (Statistical
  Methodology) 71, 3 (2009) 593-613</journal-ref><doi>10.1111/j.1467-9868.2009.00698.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this contribution, we propose a generic online (also sometimes called
adaptive or recursive) version of the Expectation-Maximisation (EM) algorithm
applicable to latent variable models of independent observations. Compared to
the algorithm of Titterington (1984), this approach is more directly connected
to the usual EM algorithm and does not rely on integration with respect to the
complete data distribution. The resulting algorithm is usually simpler and is
shown to achieve convergence to the stationary points of the Kullback-Leibler
divergence between the marginal distribution of the observation and the model
distribution at the optimal rate, i.e., that of the maximum likelihood
estimator. In addition, the proposed approach is also suitable for conditional
(or regression) models, as illustrated in the case of the mixture of linear
regressions model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0712.4402</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0712.4402</id><created>2007-12-28</created><updated>2008-01-18</updated><authors><author><keyname>O'Flanagan</keyname><forenames>Ruadhan</forenames></author></authors><title>Judgment</title><categories>math.PR cs.AI math.LO</categories><comments>20 pages; minor changes; references added; submitted</comments><msc-class>60A05 (Primary) 03B42, 03B48 (Secondary)</msc-class><abstract>  The concept of a judgment as a logical action which introduces new
information into a deductive system is examined. This leads to a way of
mathematically representing implication which is distinct from the familiar
material implication, according to which "If A then B" is considered to be
equivalent to "B or not-A". This leads, in turn, to a resolution of the paradox
of the raven.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0249</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0249</id><created>2007-12-31</created><authors><author><keyname>Laubenbacher</keyname><forenames>Reinhard</forenames></author><author><keyname>Jarrah</keyname><forenames>Abdul S.</forenames></author><author><keyname>Mortveit</keyname><forenames>Henning</forenames></author><author><keyname>Ravi</keyname><forenames>S. S.</forenames></author></authors><title>A mathematical formalism for agent-based modeling</title><categories>cs.MA cs.DM math.CO</categories><comments>Prepared for the Encyclopedia of Complexity and System Science,
  Springer Verlag, 2008</comments><abstract>  Many complex systems can be modeled as multiagent systems in which the
constituent entities (agents) interact with each other. The global dynamics of
such a system is determined by the nature of the local interactions among the
agents. Since it is difficult to formally analyze complex multiagent systems,
they are often studied through computer simulations. While computer simulations
can be very useful, results obtained through simulations do not formally
validate the observed behavior. Thus, there is a need for a mathematical
framework which one can use to represent multiagent systems and formally
establish their properties. This work contains a brief exposition of some known
mathematical frameworks that can model multiagent systems. The focus is on one
such framework, namely that of finite dynamical systems. Both, deterministic
and stochastic versions of this framework are discussed. The paper contains a
sampling of the mathematical results from the literature to show how finite
dynamical systems can be used to carry out a rigorous study of the properties
of multiagent systems and it is shown how the framework can also serve as a
universal model for computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0253</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0253</id><created>2007-12-31</created><authors><author><keyname>Stephens</keyname><forenames>Greg J.</forenames></author><author><keyname>Bialek</keyname><forenames>William</forenames></author></authors><title>Toward a statistical mechanics of four letter words</title><categories>q-bio.NC cs.CL physics.data-an physics.soc-ph</categories><doi>10.1103/PhysRevE.81.066119</doi><abstract>  We consider words as a network of interacting letters, and approximate the
probability distribution of states taken on by this network. Despite the
intuition that the rules of English spelling are highly combinatorial (and
arbitrary), we find that maximum entropy models consistent with pairwise
correlations among letters provide a surprisingly good approximation to the
full statistics of four letter words, capturing ~92% of the multi-information
among letters and even "discovering" real words that were not represented in
the data from which the pairwise correlations were estimated. The maximum
entropy model defines an energy landscape on the space of possible words, and
local minima in this landscape account for nearly two-thirds of words used in
written English.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0258</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0258</id><created>2007-12-31</created><updated>2010-06-02</updated><authors><author><keyname>Benbernou</keyname><forenames>Nadia</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>On the Maximum Span of Fixed-Angle Chains</title><categories>cs.CG</categories><comments>28 pages, 21 figures. Preliminary version appeared in Proc. 18th
  Canad. Conf. Comput. Geom., pages 93-96, 2006. This paper has been withdrawn
  by the authors. Lemma 15 as stated is incorrect, and although we believe the
  main theorems following (Thms. 17 &amp; 18) are true, the proofs relying on
  Lem.15 are not valid</comments><report-no>Smith Computer Science 088</report-no><acm-class>F.2.2</acm-class><abstract>  Soss proved that it is NP-hard to find the maximum 2D span of a fixed-angle
polygonal chain: the largest distance achievable between the endpoints in a
planar embedding. These fixed-angle chains can serve as models of protein
backbones. The corresponding problem in 3D is open. We show that three special
cases of particular relevance to the protein model are solvable in polynomial
time. When all link lengths and all angles are equal, the maximum 3D span is
achieved in a flat configuration and can be computed in constant time. When all
angles are equal and the chain is simple (non-self-crossing), the maximum flat
span can be found in linear time. In 3D, when all angles are equal to 90 deg
(but the link lengths arbitrary), the maximum 3D span is in general nonplanar
but can be found in quadratic time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.0938</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.0938</id><created>2008-01-07</created><updated>2009-07-16</updated><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Cognitive Networks Achieve Throughput Scaling of a Homogeneous Network</title><categories>cs.IT math.IT</categories><comments>28 pages, 12 figures, submitted to IEEE Trans. on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 8, pp.
  5103-5115, Aug. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two distinct, but overlapping, networks that operate at the same
time, space, and frequency. The first network consists of $n$ randomly
distributed \emph{primary users}, which form either an ad hoc network, or an
infrastructure-supported ad hoc network with $l$ additional base stations. The
second network consists of $m$ randomly distributed, ad hoc secondary users or
cognitive users. The primary users have priority access to the spectrum and do
not need to change their communication protocol in the presence of secondary
users. The secondary users, however, need to adjust their protocol based on
knowledge about the locations of the primary nodes to bring little loss to the
primary network's throughput. By introducing preservation regions around
primary receivers and avoidance regions around primary base stations, we
propose two modified multihop routing protocols for the cognitive users. Base
on percolation theory, we show that when the secondary network is denser than
the primary network, both networks can simultaneously achieve the same
throughput scaling law as a stand-alone network. Furthermore, the primary
network throughput is subject to only a vanishingly fractional loss.
Specifically, for the ad hoc and the infrastructure-supported primary models,
the primary network achieves sum throughputs of order $n^{1/2}$ and
$\max\{n^{1/2},l\}$, respectively. For both primary network models, for any
$\delta&gt;0$, the secondary network can achieve sum throughput of order
$m^{1/2-\delta}$ with an arbitrarily small fraction of outage. Thus, almost all
secondary source-destination pairs can communicate at a rate of order
$m^{-1/2-\delta}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1253</identifier>
 <datestamp>2012-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1253</id><created>2008-01-08</created><updated>2009-07-26</updated><authors><author><keyname>Baillot</keyname><forenames>Patrick</forenames></author><author><keyname>Mazza</keyname><forenames>Damiano</forenames></author></authors><title>Linear Logic by Levels and Bounded Time Complexity</title><categories>cs.LO cs.CC</categories><comments>63 pages. To appear in Theoretical Computer Science. This version
  corrects minor fonts problems from v2</comments><journal-ref>Theoretical Computer Science 411 (2010) 470-503</journal-ref><doi>10.1016/j.tcs.2009.09.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new characterization of elementary and deterministic polynomial
time computation in linear logic through the proofs-as-programs correspondence.
Girard's seminal results, concerning elementary and light linear logic, achieve
this characterization by enforcing a stratification principle on proofs, using
the notion of depth in proof nets. Here, we propose a more general form of
stratification, based on inducing levels in proof nets by means of indexes,
which allows us to extend Girard's systems while keeping the same complexity
properties. In particular, it turns out that Girard's systems can be recovered
by forcing depth and level to coincide. A consequence of the higher flexibility
of levels with respect to depth is the absence of boxes for handling the
paragraph modality. We use this fact to propose a variant of our polytime
system in which the paragraph modality is only allowed on atoms, and which may
thus serve as a basis for developing lambda-calculus type assignment systems
with more efficient typing algorithms than existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1573</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1573</id><created>2008-01-10</created><updated>2010-12-13</updated><authors><author><keyname>Matzke</keyname><forenames>Christina</forenames></author><author><keyname>Challet</keyname><forenames>Damien</forenames></author></authors><title>Taking a shower in Youth Hostels: risks and delights of heterogeneity</title><categories>physics.soc-ph cs.GT</categories><comments>13 pages, 7 figures</comments><doi>10.1103/PhysRevE.84.016107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tuning one's shower in some hotels may turn into a challenging coordination
game with imperfect information. The temperature sensitivity increases with the
number of agents, making the problem possibly unlearnable. Because there is in
practice a finite number of possible tap positions, identical agents are
unlikely to reach even approximately their favorite water temperature. We show
that a population of agents with homogeneous strategies is evolutionary
unstable, which gives insights into the emergence of heterogeneity, the latter
being tempting but risky.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1655</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1655</id><created>2008-01-10</created><updated>2008-09-17</updated><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Justin</keyname><forenames>Jacques</forenames></author></authors><title>Episturmian words: a survey</title><categories>math.CO cs.DM</categories><comments>36 pages; major revision: improvements + new material + more
  references</comments><msc-class>68R15</msc-class><journal-ref>RAIRO - Theoretical Informatics and Applications 43 (2009) 402-433</journal-ref><doi>10.1051/ita/2009003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we survey the rich theory of infinite episturmian words which
generalize to any finite alphabet, in a rather resembling way, the well-known
family of Sturmian words on two letters. After recalling definitions and basic
properties, we consider episturmian morphisms that allow for a deeper study of
these words. Some properties of factors are described, including factor
complexity, palindromes, fractional powers, frequencies, and return words. We
also consider lexicographical properties of episturmian words, as well as their
connection to the balance property, and related notions such as finite
episturmian words, Arnoux-Rauzy sequences, and "episkew words" that generalize
the skew words of Morse and Hedlund.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1656</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1656</id><created>2008-01-10</created><updated>2008-04-11</updated><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Justin</keyname><forenames>Jacques</forenames></author><author><keyname>Widmer</keyname><forenames>Steve</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>Palindromic Richness</title><categories>math.CO cs.DM</categories><comments>26 pages; merged with work of Steve Widmer and Luca Q. Zamboni on
  weakly rich words; accepted by the European Journal of Combinatorics</comments><msc-class>68R15</msc-class><journal-ref>European Journal of Combinatorics 30 (2009) 510-531</journal-ref><doi>10.1016/j.ejc.2008.04.006</doi><abstract>  In this paper, we study combinatorial and structural properties of a new
class of finite and infinite words that are 'rich' in palindromes in the utmost
sense. A characteristic property of so-called "rich words" is that all complete
returns to any palindromic factor are themselves palindromes. These words
encompass the well-known episturmian words, originally introduced by the second
author together with X. Droubay and G. Pirillo in 2001. Other examples of rich
words have appeared in many different contexts. Here we present the first
unified approach to the study of this intriguing family of words.
  Amongst our main results, we give an explicit description of the periodic
rich infinite words and show that the recurrent balanced rich infinite words
coincide with the balanced episturmian words. We also consider two wider
classes of infinite words, namely "weakly rich words" and almost rich words
(both strictly contain all rich words, but neither one is contained in the
other). In particular, we classify all recurrent balanced weakly rich words. As
a consequence, we show that any such word on at least three letters is
necessarily episturmian; hence weakly rich words obey Fraenkel's conjecture.
Likewise, we prove that a certain class of almost rich words obeys Fraenkel's
conjecture by showing that the recurrent balanced ones are episturmian or
contain at least two distinct letters with the same frequency.
  Lastly, we study the action of morphisms on (almost) rich words with
particular interest in morphisms that preserve (almost) richness. Such
morphisms belong to the class of "P-morphisms" that was introduced by A. Hof,
O. Knill, and B. Simon in 1995.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.1658</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.1658</id><created>2008-01-10</created><updated>2010-08-21</updated><authors><author><keyname>Lipowski</keyname><forenames>Adam</forenames></author><author><keyname>Lipowska</keyname><forenames>Dorota</forenames></author></authors><title>Computational approach to the emergence and evolution of language -
  evolutionary naming game model</title><categories>physics.soc-ph cs.CL cs.MA</categories><comments>paper withdrawn, much revised version is under preparation</comments><abstract>  Computational modelling with multi-agent systems is becoming an important
technique of studying language evolution. We present a brief introduction into
this rapidly developing field, as well as our own contributions that include an
analysis of the evolutionary naming-game model. In this model communicating
agents, that try to establish a common vocabulary, are equipped with an
evolutionarily selected learning ability. Such a coupling of biological and
linguistic ingredients results in an abrupt transition: upon a small change of
the model control parameter a poorly communicating group of linguistically
unskilled agents transforms into almost perfectly communicating group with
large learning abilities. Genetic imprinting of the learning abilities proceeds
via Baldwin effect: initially unskilled communicating agents learn a language
and that creates a niche in which there is an evolutionary pressure for the
increase of learning ability. Under the assumption that communication intensity
increases continuously with finite speed, the transition is split into several
transition-like changes. It shows that the speed of cultural changes, that sets
an additional characteristic timescale, might be yet another factor affecting
the evolution of language. In our opinion, this model shows that linguistic and
biological processes have a strong influence on each other and this effect
certainly has contributed to an explosive development of our species.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2242</identifier>
 <datestamp>2010-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2242</id><created>2008-01-15</created><updated>2008-08-22</updated><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Information Spectrum Approach to Second-Order Coding Rate in Channel
  Coding</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory Volume 55, Issue 11, 4947
  - 4966 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Second-order coding rate of channel coding is discussed for general sequence
of channels. The optimum second-order transmission rate with a constant error
constraint $\epsilon$ is obtained by using the information spectrum method. We
apply this result to the discrete memoryless case, the discrete memoryless case
with a cost constraint, the additive Markovian case, and the Gaussian channel
case with an energy constraint. We also clarify that the Gallager bound does
not give the optimum evaluation in the second-order coding rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.2838</identifier>
 <datestamp>2010-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.2838</id><created>2008-01-18</created><updated>2010-11-23</updated><authors><author><keyname>Trahtman</keyname><forenames>A. N.</forenames></author></authors><title>An Algorithm for Road Coloring</title><categories>cs.DM</categories><comments>10 pages</comments><acm-class>G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A coloring of edges of a finite directed graph turns the graph into
finite-state automaton. The synchronizing word of a deterministic automaton is
a word in the alphabet of colors (considered as letters) of its edges that maps
the automaton to a single state. A coloring of edges of a directed graph of
uniform outdegree (constant outdegree of any vertex) is synchronizing if the
coloring turns the graph into a deterministic finite automaton possessing a
synchronizing word. The road coloring problem is the problem of synchronizing
coloring of a directed finite strongly connected graph of uniform outdegree if
the greatest common divisor of the lengths of all its cycles is one. The
problem posed in 1970 had evoked a noticeable interest among the specialists in
the theory of graphs, automata, codes, symbolic dynamics as well as among the
wide mathematical community. A polynomial time algorithm of $O(n^3)$ complexity
in the most worst case and quadratic in majority of studied cases for the road
coloring of the considered graph is presented below. The work is based on
recent positive solution of the road coloring problem. The algorithm was
implemented in the package TESTAS
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3048</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3048</id><created>2008-01-19</created><authors><author><keyname>Bagnoli</keyname><forenames>Franco</forenames></author><author><keyname>Guazzini</keyname><forenames>Andrea</forenames></author><author><keyname>Lio'</keyname><forenames>Pietro</forenames></author></authors><title>Human Heuristics for Autonomous Agents</title><categories>cs.MA cs.HC cs.NI</categories><comments>12 pages</comments><journal-ref>P. Li\'o et al. editors, BIOWIRE 2007, LNCS 5151, pages 340-351,
  Springer--Verlag Berlin Heidelberg 2008</journal-ref><doi>10.1007/978-3-540-92191-2_30</doi><abstract>  We investigate the problem of autonomous agents processing pieces of
information that may be corrupted (tainted). Agents have the option of
contacting a central database for a reliable check of the status of the
message, but this procedure is costly and therefore should be used with
parsimony. Agents have to evaluate the risk of being infected, and decide if
and when communicating partners are affordable. Trustability is implemented as
a personal (one-to-one) record of past contacts among agents, and as a
mean-field monitoring of the level of message corruption. Moreover, this
information is slowly forgotten in time, so that at the end everybody is
checked against the database. We explore the behavior of a homogeneous system
in the case of a fixed pool of spreaders of corrupted messages, and in the case
of spontaneous appearance of corrupted messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3117</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3117</id><created>2008-01-20</created><authors><author><keyname>Cao</keyname><forenames>Yongzhi</forenames></author></authors><title>A hierarchy of behavioral equivalences in the $\pi$-calculus with noisy
  channels</title><categories>cs.LO</categories><comments>30 pages, 2 figures</comments><journal-ref>Comput. J., vol. 53, no. 1, pp. 3-20, 2010</journal-ref><abstract>  The $\pi$-calculus is a process algebra where agents interact by sending
communication links to each other via noiseless communication channels. Taking
into account the reality of noisy channels, an extension of the $\pi$-calculus,
called the $\pi_N$-calculus, has been introduced recently. In this paper, we
present an early transitional semantics of the $\pi_N$-calculus, which is not a
directly translated version of the late semantics of $\pi_N$, and then extend
six kinds of behavioral equivalences consisting of reduction bisimilarity,
barbed bisimilarity, barbed equivalence, barbed congruence, bisimilarity, and
full bisimilarity into the $\pi_N$-calculus. Such behavioral equivalences are
cast in a hierarchy, which is helpful to verify behavioral equivalence of two
agents. In particular, we show that due to the noisy nature of channels, the
coincidence of bisimilarity and barbed equivalence, as well as the coincidence
of full bisimilarity and barbed congruence, in the $\pi$-calculus does not hold
in $\pi_N$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3209</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3209</id><created>2008-01-21</created><updated>2008-03-03</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Pyramidal Evolutionary Algorithm with Different Inter-Agent Partnering
  Strategies for Scheduling Problems</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO 2001), late-breaking papers volume, pp 1-8, San Francisco, USA</journal-ref><abstract>  This paper combines the idea of a hierarchical distributed genetic algorithm
with different inter-agent partnering strategies. Cascading clusters of
sub-populations are built from bottom up, with higher-level sub-populations
optimising larger parts of the problem. Hence higher-level sub-populations
search a larger search space with a lower resolution whilst lower-level
sub-populations search a smaller search space with a higher resolution. The
effects of different partner selection schemes amongst the agents on solution
quality are examined for two multiple-choice optimisation problems. It is shown
that partnering strategies that exploit problem-specific knowledge are superior
and can counter inappropriate (sub-) fitness measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3239</identifier>
 <datestamp>2014-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3239</id><created>2008-01-21</created><authors><author><keyname>Buk</keyname><forenames>Solomiya</forenames></author><author><keyname>Rovenchak</keyname><forenames>Andrij</forenames></author></authors><title>Online-concordance "Perekhresni stezhky" ("The Cross-Paths"), a novel by
  Ivan Franko</title><categories>cs.CL cs.DL</categories><comments>in Ukrainian</comments><journal-ref>Ivan Franko: Spirit, Science, Thought, Will (Proceedings of the
  International Scientific Congress dedicated to the 150th anniversary (Lviv,
  27 September -- 1 October 2006, Lviv University Press, Vol. 2, pp. 203-211,
  2010)</journal-ref><abstract>  In the article, theoretical principles and practical realization for the
compilation of the concordance to "Perekhresni stezhky" ("The Cross-Paths"), a
novel by Ivan Franko, are described. Two forms for the context presentation are
proposed. The electronic version of this lexicographic work is available
online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3539</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3539</id><created>2008-01-23</created><updated>2008-05-16</updated><authors><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>On the Effects of Idiotypic Interactions for Recommendation Communities
  in Artificial Immune Systems</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the 1st International Conference on Artificial
  Immune Systems (ICARIS 2002), pp 154-160, Canterbury, UK, 2001</journal-ref><abstract>  It has previously been shown that a recommender based on immune system
idiotypic principles can out perform one based on correlation alone. This paper
reports the results of work in progress, where we undertake some investigations
into the nature of this beneficial effect. The initial findings are that the
immune system recommender tends to produce different neighbourhoods, and that
the superior performance of this recommender is due partly to the different
neighbourhoods, and partly to the way that the idiotypic effect is used to
weight each neighbours recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3547</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3547</id><created>2008-01-23</created><updated>2008-03-03</updated><authors><author><keyname>Cazyer</keyname><forenames>Steve</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Recommender System based on the Immune Network</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the IEEE Congress on Evolutionary Computation (CEC
  2002), pp 807-813, Honolulu, USA, 2002</journal-ref><abstract>  The immune system is a complex biological system with a highly distributed,
adaptive and self-organising nature. This paper presents an artificial immune
system (AIS) that exploits some of these characteristics and is applied to the
task of film recommendation by collaborative filtering (CF). Natural evolution
and in particular the immune system have not been designed for classical
optimisation. However, for this problem, we are not interested in finding a
single optimum. Rather we intend to identify a sub-set of good matches on which
recommendations can be based. It is our hypothesis that an AIS built on two
central aspects of the biological immune system will be an ideal candidate to
achieve this: Antigen - antibody interaction for matching and antibody -
antibody interaction for diversity. Computational results are presented in
support of this conjecture and compared to those found by other CF techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3549</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3549</id><created>2008-01-23</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author></authors><title>The Danger Theory and Its Application to Artificial Immune Systems</title><categories>cs.NE cs.AI cs.CR</categories><journal-ref>Proceedings of the 1st International Conference on Artificial
  Immune Systems (ICARIS 2002), pp 141-148, Canterbury, Uk, 2002</journal-ref><abstract>  Over the last decade, a new idea challenging the classical self-non-self
viewpoint has become popular amongst immunologists. It is called the Danger
Theory. In this conceptual paper, we look at this theory from the perspective
of Artificial Immune System practitioners. An overview of the Danger Theory is
presented with particular emphasis on analogies in the Artificial Immune
Systems world. A number of potential application areas are then used to provide
a framing for a critical assessment of the concept, and its relevance for
Artificial Immune Systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3550</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3550</id><created>2008-01-23</created><updated>2008-03-03</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Partnering Strategies for Fitness Evaluation in a Pyramidal Evolutionary
  Algorithm</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the Genetic and Evolutionary Computation Conference
  (GECCO 2002), pp 263-270, New York, USA, 2002</journal-ref><abstract>  This paper combines the idea of a hierarchical distributed genetic algorithm
with different inter-agent partnering strategies. Cascading clusters of
sub-populations are built from bottom up, with higher-level sub-populations
optimising larger parts of the problem. Hence higher-level sub-populations
search a larger search space with a lower resolution whilst lower-level
sub-populations search a smaller search space with a higher resolution. The
effects of different partner selection schemes for (sub-)fitness evaluation
purposes are examined for two multiple-choice optimisation problems. It is
shown that random partnering strategies perform best by providing better
sampling and more diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3581</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3581</id><created>2008-01-23</created><authors><author><keyname>Dinitz</keyname><forenames>Yefim</forenames></author><author><keyname>Elkin</keyname><forenames>Michael</forenames></author><author><keyname>Solomon</keyname><forenames>Shay</forenames></author></authors><title>Shallow, Low, and Light Trees, and Tight Lower Bounds for Euclidean
  Spanners</title><categories>cs.CG cs.DS</categories><comments>41 pages, 11 figures</comments><acm-class>F.2.2; F.2.3; G.2.2</acm-class><abstract>  We show that for every $n$-point metric space $M$ there exists a spanning
tree $T$ with unweighted diameter $O(\log n)$ and weight $\omega(T) = O(\log n)
\cdot \omega(MST(M))$. Moreover, there is a designated point $rt$ such that for
every point $v$, $dist_T(rt,v) \le (1+\epsilon) \cdot dist_M(rt,v)$, for an
arbitrarily small constant $\epsilon &gt; 0$. We extend this result, and provide a
tradeoff between unweighted diameter and weight, and prove that this tradeoff
is \emph{tight up to constant factors} in the entire range of parameters. These
results enable us to settle a long-standing open question in Computational
Geometry. In STOC'95 Arya et al. devised a construction of Euclidean Spanners
with unweighted diameter $O(\log n)$ and weight $O(\log n) \cdot
\omega(MST(M))$. Ten years later in SODA'05 Agarwal et al. showed that this
result is tight up to a factor of $O(\log \log n)$. We close this gap and show
that the result of Arya et al. is tight up to constant factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3697</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3697</id><created>2008-01-24</created><updated>2013-12-15</updated><authors><author><keyname>Bell</keyname><forenames>George I.</forenames></author></authors><title>The mathematics of Septoku</title><categories>math.CO cs.DM math.GM</categories><comments>11 pages, 9 figures; many minor changes</comments><msc-class>00A08, 97A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Septoku is a Sudoku variant invented by Bruce Oberg, played on a hexagonal
grid of 37 cells. We show that up to rotations, reflections, and symbol
permutations, there are only six valid Septoku boards. In order to have a
unique solution, we show that the minimum number of given values is six. We
generalize the puzzle to other board shapes, and devise a puzzle on a
star-shaped board with 73 cells with six givens which has a unique solution. We
show how this puzzle relates to the unsolved Hadwiger-Nelson problem in
combinatorial geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3703</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3703</id><created>2008-01-24</created><updated>2009-04-14</updated><authors><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author><author><keyname>Pinto</keyname><forenames>Raquel</forenames></author></authors><title>On minimality of convolutional ring encoders</title><categories>cs.IT math.IT</categories><comments>13 pages in v1, submitted; 8 pages in revision v2</comments><journal-ref>IEEE Trans. Information Theory, Vol. 55, No. 11, pp. 4890-4897,
  November 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional codes are considered with code sequences modelled as
semi-infinite Laurent series. It is wellknown that a convolutional code C over
a finite group G has a minimal trellis representation that can be derived from
code sequences. It is also wellknown that, for the case that G is a finite
field, any polynomial encoder of C can be algebraically manipulated to yield a
minimal polynomial encoder whose controller canonical realization is a minimal
trellis. In this paper we seek to extend this result to the finite ring case G
= Z_{p^r} by introducing a socalled "p-encoder". We show how to manipulate a
polynomial encoding of a noncatastrophic convolutional code over Z_{p^r} to
produce a particular type of p-encoder ("minimal p-encoder") whose controller
canonical realization is a minimal trellis with nonlinear features. The minimum
number of trellis states is then expressed as p^gamma, where gamma is the sum
of the row degrees of the minimal p-encoder. In particular, we show that any
convolutional code over Z_{p^r} admits a delay-free p-encoder which implies the
novel result that delay-freeness is not a property of the code but of the
encoder, just as in the field case. We conjecture that a similar result holds
with respect to catastrophicity, i.e., any catastrophic convolutional code over
Z_{p^r} admits a noncatastrophic p-encoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3837</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3837</id><created>2008-01-24</created><updated>2011-05-24</updated><authors><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>Universal Fingerprinting: Capacity and Random-Coding Exponents</title><categories>cs.IT math.IT</categories><comments>69 pages, revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies fingerprinting (traitor tracing) games in which the number
of colluders and the collusion channel are unknown. The fingerprints are
embedded into host sequences representing signals to be protected and provide
the receiver with the capability to trace back pirated copies to the colluders.
The colluders and the fingerprint embedder are subject to signal fidelity
constraints. Our problem setup unifies the signal-distortion and Boneh-Shaw
formulations of fingerprinting. The fundamental tradeoffs between fingerprint
codelength, number of users, number of colluders, fidelity constraints, and
decoding reliability are then determined. Several bounds on fingerprinting
capacity have been presented in recent literature. This paper derives exact
capacity formulas and presents a new randomized fingerprinting scheme with the
following properties: (1) the encoder and receiver assume a nominal coalition
size but do not need to know the actual coalition size and the collusion
channel; (2) a tunable parameter $\Delta$ trades off false-positive and
false-negative error exponents; (3) the receiver provides a reliability metric
for its decision; and (4) the scheme is capacity-achieving when the
false-positive exponent $\Delta$ tends to zero and the nominal coalition size
coincides with the actual coalition size.
  A fundamental component of the new scheme is the use of a "time-sharing"
randomized sequence. The decoder is a maximum penalized mutual information
decoder, where the significance of each candidate coalition is assessed
relative to a threshold, and the penalty is proportional to the coalition size.
A much simpler {\em threshold decoder} that satisfies properties (1)---(3)
above but not (4) is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3878</identifier>
 <datestamp>2013-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3878</id><created>2008-01-25</created><updated>2009-03-19</updated><authors><author><keyname>Muramatsu</keyname><forenames>Jun</forenames></author><author><keyname>Miyake</keyname><forenames>Shigeki</forenames></author></authors><title>Hash Property and Coding Theorems for Sparse Matrices and
  Maximum-Likelihood Coding</title><categories>cs.IT math.IT</categories><comments>This manuscript has been submitted to IEEE Transactions on
  Information Theory and a part of this manuscript has been submitted to IEEE
  International Symposium on Information Theory (ISIT2008,ISIT2009). 55 pages
  v2: major changes</comments><journal-ref>IEEE Transactions on Information Theory, vol 56, no. 5,
  pp.2143-2167, May 2010; Corrections: IEEE Transactions on Information Theory,
  vol. 56, no.9, p. 4762, Sep. 2010. Corrections: vol.56, no.9, p.4762, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove the achievability of several coding
problems by using sparse matrices (the maximum column weight grows
logarithmically in the block length) and maximal-likelihood (ML) coding. These
problems are the Slepian-Wolf problem, the Gel'fand-Pinsker problem, the
Wyner-Ziv problem, and the One-helps-one problem (source coding with partial
side information at the decoder). To this end, the notion of a hash property
for an ensemble of functions is introduced and it is proved that an ensemble of
$q$-ary sparse matrices satisfies the hash property. Based on this property, it
is proved that the rate of codes using sparse matrices and maximal-likelihood
(ML) coding can achieve the optimal rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3971</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3971</id><created>2008-01-25</created><updated>2008-05-16</updated><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Bayesian Optimisation Algorithm for the Nurse Scheduling Problem</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the IEEE Congress on Evolutionary Computation (CEC
  2003), pp 2149-2156, Canberra, Australia, 2003</journal-ref><abstract>  A Bayesian optimization algorithm for the nurse scheduling problem is
presented, which involves choosing a suitable scheduling rule from a set for
each nurses assignment. Unlike our previous work that used Gas to implement
implicit learning, the learning in the proposed algorithm is explicit, ie.
Eventually, we will be able to identify and mix building blocks directly. The
Bayesian optimization algorithm is applied to implement such explicit learning
by building a Bayesian network of the joint distribution of solutions. The
conditional probability of each variable in the network is computed according
to an initial set of promising solutions. Subsequently, each new instance for
each variable is generated, ie in our case, a new rule string has been
obtained. Another set of rule strings will be generated in this way, some of
which will replace previous strings based on fitness selection. If stopping
conditions are not met, the conditional probabilities for all nodes in the
Bayesian network are updated again using the current set of promising rule
strings. Computational results from 52 real data instances demonstrate the
success of this approach. It is also suggested that the learning mechanism in
the proposed approach might be suitable for other scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.3985</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.3985</id><created>2008-01-25</created><updated>2011-01-08</updated><authors><author><keyname>Kwasniewski</keyname><forenames>A. Krzysztof</forenames></author><author><keyname>Dziemianczuk</keyname><forenames>M.</forenames></author></authors><title>Cobweb posets - Recent Results</title><categories>math.CO cs.DM</categories><comments>27 pages, 15 figures</comments><msc-class>06A07, 05C70, 05C75, 11B39,</msc-class><journal-ref>Adv. Stud. Contemp. Math. volume 16 (2), 2008 (April) pp. 197-218</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cobweb posets uniquely represented by directed acyclic graphs are such a
generalization of the Fibonacci tree that allows joint combinatorial
interpretation for all of them under admissibility condition. This
interpretation was derived in the source papers ([6,7] and references therein
to the first author).[7,6,8] include natural enquires to be reported on here.
The purpose of this presentation is to report on the progress in solving
computational problems which are quite easily formulated for the new class of
directed acyclic graphs interpreted as Hasse diagrams. The problems posed there
and not yet all solved completely are of crucial importance for the vast class
of new partially ordered sets with joint combinatorial interpretation. These so
called cobweb posets - are relatives of Fibonacci tree and are labeled by
specific number sequences - natural numbers sequence and Fibonacci sequence
included. The cobweb posets might be identified with a chain of di-bicliques
i.e. by definition - a chain of complete bipartite one direction digraphs [6].
Any chain of relations is therefore obtainable from the cobweb poset chain of
complete relations via deleting arcs in di-bicliques of the complete relations
chain. In particular we response to one of those problems [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4119</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4119</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Strategic Alert Throttling for Intrusion Detection Systems</title><categories>cs.NE cs.CR</categories><journal-ref>4th WSEAS International Conference on Information Security (WSEAS
  2005), Tenerife, Spain, 2005</journal-ref><abstract>  Network intrusion detection systems are themselves becoming targets of
attackers. Alert flood attacks may be used to conceal malicious activity by
hiding it among a deluge of false alerts sent by the attacker. Although these
types of attacks are very hard to stop completely, our aim is to present
techniques that improve alert throughput and capacity to such an extent that
the resources required to successfully mount the attack become prohibitive. The
key idea presented is to combine a token bucket filter with a realtime
correlation algorithm. The proposed algorithm throttles alert output from the
IDS when an attack is detected. The attack graph used in the correlation
algorithm is used to make sure that alerts crucial to forming strategies are
not discarded by throttling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4190</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4190</id><created>2008-01-28</created><updated>2009-07-27</updated><authors><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Phylogenies without Branch Bounds: Contracting the Short, Pruning the
  Deep</title><categories>q-bio.PE cs.CE cs.DS math.PR math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new phylogenetic reconstruction algorithm which, unlike most
previous rigorous inference techniques, does not rely on assumptions regarding
the branch lengths or the depth of the tree. The algorithm returns a forest
which is guaranteed to contain all edges that are: 1) sufficiently long and 2)
sufficiently close to the leaves. How much of the true tree is recovered
depends on the sequence length provided. The algorithm is distance-based and
runs in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4287</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4287</id><created>2008-01-28</created><updated>2008-03-03</updated><authors><author><keyname>Chen</keyname><forenames>Qi</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Movie Recommendation Systems Using An Artificial Immune System</title><categories>cs.NE cs.AI</categories><journal-ref>6th International Conference in Adaptive Computing in Design and
  Manufacture (ACDM 2004), Bristol, UK, 2004</journal-ref><abstract>  We apply the Artificial Immune System (AIS) technology to the Collaborative
Filtering (CF) technology when we build the movie recommendation system. Two
different affinity measure algorithms of AIS, Kendall tau and Weighted Kappa,
are used to calculate the correlation coefficients for this movie
recommendation system. From the testing we think that Weighted Kappa is more
suitable than Kendall tau for movie problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4312</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4312</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author><author><keyname>Din</keyname><forenames>Aniza</forenames></author></authors><title>Investigating Artificial Immune Systems For Job Shop Rescheduling In
  Changing Environments</title><categories>cs.NE cs.CE</categories><journal-ref>6th International Conference in Adaptive Computing in Design and
  Manufacture (ACDM 2004), Bristol, UK, 2004</journal-ref><abstract>  Artificial immune system can be used to generate schedules in changing
environments and it has been proven to be more robust than schedules developed
using a genetic algorithm. Good schedules can be produced especially when the
number of the antigens is increased. However, an increase in the range of the
antigens had somehow affected the fitness of the immune system. In this
research, we are trying to improve the result of the system by rescheduling the
same problem using the same method while at the same time maintaining the
robustness of the schedules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4314</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4314</id><created>2008-01-28</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Artificial Immune Systems (AIS) - A New Paradigm for Heuristic Decision
  Making</title><categories>cs.NE cs.AI</categories><journal-ref>Invited Keynote Talk, Annual Operational Research Conference 46,
  York, UK, 2004</journal-ref><abstract>  Over the last few years, more and more heuristic decision making techniques
have been inspired by nature, e.g. evolutionary algorithms, ant colony
optimisation and simulated annealing. More recently, a novel computational
intelligence technique inspired by immunology has emerged, called Artificial
Immune Systems (AIS). This immune system inspired technique has already been
useful in solving some computational problems. In this keynote, we will very
briefly describe the immune system metaphors that are relevant to AIS. We will
then give some illustrative real-world problems suitable for AIS use and show a
step-by-step algorithm walkthrough. A comparison of AIS to other well-known
algorithms and areas for future work will round this keynote off. It should be
noted that as AIS is still a young and evolving field, there is not yet a fixed
algorithm template and hence actual implementations might differ somewhat from
the examples given here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0801.4817</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0801.4817</id><created>2008-01-30</created><updated>2014-11-01</updated><authors><author><keyname>Su</keyname><forenames>Shenghui</forenames></author><author><keyname>Lv</keyname><forenames>Shuwang</forenames></author></authors><title>The REESSE2+ Public-key Encryption Scheme</title><categories>cs.CR cs.CC</categories><comments>11 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives the definitions of an anomalous super-increasing sequence
and an anomalous subset sum separately, proves the two properties of an
anomalous super-increasing sequence, and proposes the REESSE2+ public-key
encryption scheme which includes the three algorithms for key generation,
encryption and decryption. The paper discusses the necessity and sufficiency of
the lever function for preventing the Shamir extremum attack, analyzes the
security of REESSE2+ against extracting a private key from a public key through
the exhaustive search, recovering a plaintext from a ciphertext plus a knapsack
of high density through the L3 lattice basis reduction method, and
heuristically obtaining a plaintext through the meet-in-the-middle attack or
the adaptive-chosen-ciphertext attack. The authors evaluate the time complexity
of REESSE2+ encryption and decryption algorithms, compare REESSE2+ with ECC and
NTRU, and find that the encryption speed of REESSE2+ is ten thousand times
faster than ECC and NTRU bearing the equivalent security, and the decryption
speed of REESSE2+ is roughly equivalent to ECC and NTRU respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0314</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0314</id><created>2008-02-03</created><updated>2010-09-01</updated><authors><author><keyname>Michael</keyname><forenames>Morris</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author><author><keyname>Ukkonen</keyname><forenames>Esko</forenames></author></authors><title>On the complexity of finding gapped motifs</title><categories>cs.CC cs.DM</categories><comments>Published in Journal of Discrete Algorithms</comments><doi>10.1016/j.jda.2009.12.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the corresponding author because the newest
version is now published in Journal of Discrete Algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0351</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0351</id><created>2008-02-04</created><updated>2012-01-22</updated><authors><author><keyname>Srinivasa</keyname><forenames>Sunil</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Path Loss Exponent Estimation in a Large Field of Interferers</title><categories>cs.IT math.IT</categories><comments>Work underway</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless channels, the path loss exponent (PLE) has a strong impact on the
quality of links, and hence, it needs to be accurately estimated for the
efficient design and operation of wireless networks. In this paper, we address
the problem of PLE estimation in large wireless networks, which is relevant to
several important issues in networked communications such as localization,
energy-efficient routing, and channel access. We consider a large ad hoc
network where nodes are distributed as a homogeneous Poisson point process on
the plane and the channels are subject to Nakagami-m fading. We propose and
discuss three distributed algorithms for estimating the PLE under these
settings which explicitly take into account the interference in the network. In
addition, we provide simulation results to demonstrate the performance of the
algorithms and quantify the estimation errors. We also describe how to estimate
the PLE accurately even in networks with spatially varying PLEs and more
general node distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0534</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0534</id><created>2008-02-04</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Capacity of Wireless Networks within o(log(SNR)) - the Impact of Relays,
  Feedback, Cooperation and Full-Duplex Operation</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 55, No. 5, May 2009,
  Pages: 2334-2344</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work has characterized the sum capacity of
time-varying/frequency-selective wireless interference networks and $X$
networks within $o(\log({SNR}))$, i.e., with an accuracy approaching 100% at
high SNR (signal to noise power ratio). In this paper, we seek similar capacity
characterizations for wireless networks with relays, feedback, full duplex
operation, and transmitter/receiver cooperation through noisy channels. First,
we consider a network with $S$ source nodes, $R$ relay nodes and $D$
destination nodes with random time-varying/frequency-selective channel
coefficients and global channel knowledge at all nodes. We allow full-duplex
operation at all nodes, as well as causal noise-free feedback of all received
signals to all source and relay nodes. The sum capacity of this network is
characterized as $\frac{SD}{S+D-1}\log({SNR})+o(\log({SNR}))$. The implication
of the result is that the capacity benefits of relays, causal feedback,
transmitter/receiver cooperation through physical channels and full duplex
operation become a negligible fraction of the network capacity at high SNR.
Some exceptions to this result are also pointed out in the paper. Second, we
consider a network with $K$ full duplex nodes with an independent message from
every node to every other node in the network. We find that the sum capacity of
this network is bounded below by $\frac{K(K-1)}{2K-2}+o(\log({SNR}))$ and
bounded above by $\frac{K(K-1)}{2K-3}+o(\log({SNR}))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0738</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0738</id><created>2008-02-05</created><updated>2009-10-08</updated><authors><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Win</keyname><forenames>Moe Z.</forenames></author><author><keyname>Shin</keyname><forenames>Hyundong</forenames></author></authors><title>MIMO Networks: the Effects of Interference</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Info. Theory</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 56, no. 1, pp. 336-349, Jan. 2010</journal-ref><doi>10.1109/TIT.2009.2034810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input/multiple-output (MIMO) systems promise enormous capacity
increase and are being considered as one of the key technologies for future
wireless networks. However, the decrease in capacity due to the presence of
interferers in MIMO networks is not well understood. In this paper, we develop
an analytical framework to characterize the capacity of MIMO communication
systems in the presence of multiple MIMO co-channel interferers and noise. We
consider the situation in which transmitters have no information about the
channel and all links undergo Rayleigh fading. We first generalize the known
determinant representation of hypergeometric functions with matrix arguments to
the case when the argument matrices have eigenvalues of arbitrary multiplicity.
This enables the derivation of the distribution of the eigenvalues of Gaussian
quadratic forms and Wishart matrices with arbitrary correlation, with
application to both single user and multiuser MIMO systems. In particular, we
derive the ergodic mutual information for MIMO systems in the presence of
multiple MIMO interferers. Our analysis is valid for any number of interferers,
each with arbitrary number of antennas having possibly unequal power levels.
This framework, therefore, accommodates the study of distributed MIMO systems
and accounts for different positions of the MIMO interferers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.0823</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.0823</id><created>2008-02-06</created><authors><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author></authors><title>Doubly-Generalized LDPC Codes: Stability Bound over the BEC</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Inform. Theory</comments><journal-ref>IEEE Trans. Inform. Theory, vol. 55, no. 3, pp. 1027-1046, March
  2009</journal-ref><doi>10.1109/TIT.2008.2011446</doi><abstract>  The iterative decoding threshold of low-density parity-check (LDPC) codes
over the binary erasure channel (BEC) fulfills an upper bound depending only on
the variable and check nodes with minimum distance 2. This bound is a
consequence of the stability condition, and is here referred to as stability
bound. In this paper, a stability bound over the BEC is developed for
doubly-generalized LDPC codes, where the variable and the check nodes can be
generic linear block codes, assuming maximum a posteriori erasure correction at
each node. It is proved that in this generalized context as well the bound
depends only on the variable and check component codes with minimum distance 2.
A condition is also developed, namely the derivative matching condition, under
which the bound is achieved with equality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1312</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1312</id><created>2008-02-10</created><updated>2008-06-25</updated><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author></authors><title>Untangling polygons and graphs</title><categories>cs.CG cs.DM</categories><comments>11 pages, 3 figures</comments><journal-ref>Discrete and Computational Geometry 43(2): 402-411 (2010)</journal-ref><doi>10.1007/s00454-009-9150-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Untangling is a process in which some vertices of a planar graph are moved to
obtain a straight-line plane drawing. The aim is to move as few vertices as
possible. We present an algorithm that untangles the cycle graph C_n while
keeping at least \Omega(n^{2/3}) vertices fixed. For any graph G, we also
present an upper bound on the number of fixed vertices in the worst case. The
bound is a function of the number of vertices, maximum degree and diameter of
G. One of its consequences is the upper bound O((n log n)^{2/3}) for all
3-vertex-connected planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1332</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1332</id><created>2008-02-10</created><updated>2008-04-11</updated><authors><author><keyname>Bucci</keyname><forenames>Michelangelo</forenames></author><author><keyname>De Luca</keyname><forenames>Alessandro</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>A connection between palindromic and factor complexity using return
  words</title><categories>math.CO cs.DM</categories><comments>17 pages; minor adjustment to the main theorem and other minor
  changes (particularly in Sections 3 and 4); accepted by "Advances in Applied
  Mathematics"</comments><msc-class>68R15</msc-class><journal-ref>Advances In Applied Mathematics 42 (2009) 60--74</journal-ref><doi>10.1016/j.aam.2008.03.005</doi><abstract>  In this paper we prove that for any infinite word W whose set of factors is
closed under reversal, the following conditions are equivalent:
  (I) all complete returns to palindromes are palindromes;
  (II) P(n) + P(n+1) = C(n+1) - C(n) + 2 for all n, where P (resp. C) denotes
the palindromic complexity (resp. factor complexity) function of W, which
counts the number of distinct palindromic factors (resp. factors) of each
length in W.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1361</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1361</id><created>2008-02-10</created><updated>2010-04-20</updated><authors><author><keyname>Karavelas</keyname><forenames>Menelaos I.</forenames></author></authors><title>Guarding curvilinear art galleries with edge or mobile guards via
  2-dominance of triangulation graphs</title><categories>cs.CG</categories><comments>45 pages, 33 figures, short version has appeared in [M. I. Karavelas.
  Guarding curvilinear art galleries with edge or mobile guards. 2008 ACM
  Symposium on Solid and Physical Modeling (SPM08), 339-345, 2008.]; v2: new
  lower bound for the edge 2-dominance problem which now matches the upper
  bound</comments><acm-class>F.2.2; I.3.5</acm-class><journal-ref>Comput. Geom. Theory Appl. 44(1):20-51, 2011</journal-ref><doi>10.1016/j.comgeo.2010.07.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of monitoring an art gallery modeled as a polygon,
the edges of which are arcs of curves, with edge or mobile guards. Our focus is
on piecewise-convex polygons, i.e., polygons that are locally convex, except
possibly at the vertices, and their edges are convex arcs. We transform the
problem of monitoring a piecewise-convex polygon to the problem of 2-dominating
a properly defined triangulation graph with edges or diagonals, where
2-dominance requires that every triangle in the triangulation graph has at
least two of its vertices in its 2-dominating set. We show that
$\lfloor\frac{n+1}{3}\rfloor$ diagonal guards or $\lfloor\frac{2n+1}{5}\rfloor$
edge guards are always sufficient and sometimes necessary, in order to
2-dominate a triangulation graph. Furthermore, we show how to compute: a
diagonal 2-dominating set of size $\lfloor\frac{n+1}{3}\rfloor$ in linear time,
an edge 2-dominating set of size $\lfloor\frac{2n+1}{5}\rfloor$ in $O(n^2)$
time, and an edge 2-dominating set of size $\lfloor\frac{3n}{7}\rfloor$ in O(n)
time. Based on the above-mentioned results, we prove that, for piecewise-convex
polygons, we can compute: a mobile guard set of size
$\lfloor\frac{n+1}{3}\rfloor$ in $O(n\log{}n)$ time, an edge guard set of size
$\lfloor\frac{2n+1}{5}\rfloor$ in $O(n^2)$ time, and an edge guard set of size
$\lfloor\frac{3n}{7}\rfloor$ in $O(n\log{}n)$ time. Finally, we show that
$\lfloor\frac{n}{3}\rfloor$ mobile or $\lceil\frac{n}{3}\rceil$ edge guards are
sometimes necessary. When restricting our attention to monotone
piecewise-convex polygons, the bounds mentioned above drop:
$\lceil\frac{n+1}{4}\rceil$ edge or mobile guards are always sufficient and
sometimes necessary; such an edge or mobile guard set, of size at most
$\lceil\frac{n+1}{4}\rceil$, can be computed in O(n) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1382</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1382</id><created>2008-02-11</created><authors><author><keyname>Kwasniewski</keyname><forenames>A. K.</forenames></author></authors><title>New type Stirling like numbers - an email style letter</title><categories>math.CO cs.DM</categories><comments>3 pages</comments><msc-class>05C20, 11C08, 17B56</msc-class><journal-ref>Bulletin of the ICA Vol. 49 (2007), pp. 99-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of the Fibonacci cobweb poset from [1] has been naturally extended
to any admissible sequence $F$ in [2] where it was also recognized that the
celebrated prefab notion of Bender and Goldman [3] - (see also [4,5]) - admits
such an extension so as to encompass the new type combinatorial objects from
[2] as leading examples. Recently the present author had introduced also [6]
two natural partial orders in there: one $\leq$ in grading-natural subsets of
cobweb`s prefabs sets [2] and in the second proposal one endows the set sums of
the so called "prefabiants" with such another partial order that one arrives at
Bell-like numbers including Fibonacci triad sequences introduced by the present
author in [7]. Here we quote the basic observations concerning the new type
Stirling like numbers as they appear in [6]. For more on notation, Stirling
like numbers of the first kind and for proofs - see [6].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.1578</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.1578</id><created>2008-02-12</created><updated>2009-07-28</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Thread extraction for polyadic instruction sequences</title><categories>cs.PL</categories><comments>21 pages; error corrected; presentation improved</comments><report-no>PRG0803</report-no><acm-class>D.3.1; D.3.3; F.1.1; F.3.2; F.3.3</acm-class><journal-ref>Scientific Annals of Computer Science, 21(2):283--310, 2011.
  http://www.infoiasi.ro/bin/download/Annals/XXI2/XXI2_4.pdf</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the phenomenon that instruction sequences are split
into fragments which somehow produce a joint behaviour. In order to bring this
phenomenon better into the picture, we formalize a simple mechanism by which
several instruction sequence fragments can produce a joint behaviour. We also
show that, even in the case of this simple mechanism, it is a non-trivial
matter to explain by means of a translation into a single instruction sequence
what takes place on execution of a collection of instruction sequence
fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2001</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2001</id><created>2008-02-14</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dowsland</keyname><forenames>Kathryn</forenames></author></authors><title>Exploiting problem structure in a genetic algorithm approach to a nurse
  rostering problem</title><categories>cs.NE cs.CE</categories><journal-ref>Journal of Scheduling, 3(3), pp 139-153, 2000</journal-ref><doi>10.1002/(SICI)1099-1425(200005/06)3:3&lt;139::AID-JOS41&gt;3.0.CO;2-2</doi><abstract>  There is considerable interest in the use of genetic algorithms to solve
problems arising in the areas of scheduling and timetabling. However, the
classical genetic algorithm paradigm is not well equipped to handle the
conflict between objectives and constraints that typically occurs in such
problems. In order to overcome this, successful implementations frequently make
use of problem specific knowledge. This paper is concerned with the development
of a GA for a nurse rostering problem at a major UK hospital. The structure of
the constraints is used as the basis for a co-evolutionary strategy using
co-operating sub-populations. Problem specific knowledge is also used to define
a system of incentives and disincentives, and a complementary mutation
operator. Empirical results based on 52 weeks of live data show how these
features are able to improve an unsuccessful canonical GA to the point where it
is able to provide a practical solution to the problem
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2108</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2108</id><created>2008-02-14</created><updated>2009-08-18</updated><authors><author><keyname>VanderZee</keyname><forenames>Evan</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Guoy</keyname><forenames>Damrong</forenames></author><author><keyname>Ramos</keyname><forenames>Edgar</forenames></author></authors><title>Well-Centered Triangulation</title><categories>cs.CG cs.NA</categories><comments>Content has been added to experimental results section. Significant
  edits in introduction and in summary of current and previous results. Minor
  edits elsewhere</comments><report-no>UIUCDCS-R-2008-2936</report-no><acm-class>I.3.5</acm-class><journal-ref>SIAM J. Sci. Comput. 31, 6 (2010) 4497-4523</journal-ref><doi>10.1137/090748214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Meshes composed of well-centered simplices have nice orthogonal dual meshes
(the dual Voronoi diagram). This is useful for certain numerical algorithms
that prefer such primal-dual mesh pairs. We prove that well-centered meshes
also have optimality properties and relationships to Delaunay and minmax angle
triangulations. We present an iterative algorithm that seeks to transform a
given triangulation in two or three dimensions into a well-centered one by
minimizing a cost function and moving the interior vertices while keeping the
mesh connectivity and boundary vertices fixed. The cost function is a direct
result of a new characterization of well-centeredness in arbitrary dimensions
that we present. Ours is the first optimization-based heuristic for
well-centeredness, and the first one that applies in both two and three
dimensions. We show the results of applying our algorithm to small and large
two-dimensional meshes, some with a complex boundary, and obtain a
well-centered tetrahedralization of the cube. We also show numerical evidence
that our algorithm preserves gradation and that it improves the maximum and
minimum angles of acute triangulations created by the best known previous
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2125</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2125</id><created>2008-02-14</created><authors><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Multiple Access Outerbounds and the Inseparability of Parallel
  Interference Channels</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 55, No. 9, Sep.
  2009,Pages: 3983-3990</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that the capacity of parallel (multi-carrier) Gaussian
point-to-point, multiple access and broadcast channels can be achieved by
separate encoding for each subchannel (carrier) subject to a power allocation
across carriers. In this paper we show that such a separation does not apply to
parallel Gaussian interference channels in general. A counter-example is
provided in the form of a 3 user interference channel where separate encoding
can only achieve a sum capacity of $\log({SNR})+o(\log({SNR}))$ per carrier
while the actual capacity, achieved only by joint-encoding across carriers, is
$3/2\log({SNR}))+o(\log({SNR}))$ per carrier. As a byproduct of our analysis,
we propose a class of multiple-access-outerbounds on the capacity of the 3 user
interference channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2134</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2134</id><created>2008-02-14</created><updated>2011-10-09</updated><authors><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author></authors><title>Minimizing the Maximum Interference is Hard</title><categories>cs.NI cs.CG</categories><comments>4 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following interference model for wireless sensor and ad hoc
networks: the receiver interference of a node is the number of transmission
ranges it lies in. We model transmission ranges as disks. For this case we show
that choosing transmission radii which minimize the maximum interference while
maintaining a connected symmetric communication graph is NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2385</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2385</id><created>2008-02-17</created><updated>2010-01-19</updated><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author></authors><title>Essential variables and positions in terms</title><categories>math.GM cs.IT math.IT</categories><comments>17 pages, 2 figures</comments><msc-class>08B05; 03C05; 08A02</msc-class><journal-ref>J. Algebra Universalis, Vol. 61, No 3-4, (2009), pp. 381-397</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The paper deals with $\Sigma-$composition of terms, which allows us to extend
the derivation rules in formal deduction of identities.
  The concept of essential variables and essential positions of terms with
respect to a set of identities is a key step in the simplification of the
process of formal deduction. $\Sigma-$composition of terms is defined as
replacement between $\Sigma$-equal terms. This composition induces $\Sigma
R-$deductively closed sets of identities. In analogy to balanced identities we
introduce and investigate $\Sigma-$balanced identities for a given set of
identities $\Sigma$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2432</identifier>
 <datestamp>2010-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2432</id><created>2008-02-18</created><updated>2010-01-27</updated><authors><author><keyname>Durand</keyname><forenames>Bruno</forenames><affiliation>LIF</affiliation></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames><affiliation>LIP</affiliation></author><author><keyname>Shen</keyname><forenames>Alexander</forenames><affiliation>LIF</affiliation></author></authors><title>Fixed Point and Aperiodic Tilings</title><categories>cs.CC cs.DM</categories><comments>v5: technical revision (positions of figures are shifted)</comments><proxy>ccsd hal-00256364</proxy><journal-ref>12th International Conference on Developments in Language Theory,
  Kyoto : Japan (2008)</journal-ref><doi>10.1007/978-3-540-85780-8_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An aperiodic tile set was first constructed by R.Berger while proving the
undecidability of the domino problem. It turned out that aperiodic tile sets
appear in many topics ranging from logic (the Entscheidungsproblem) to physics
(quasicrystals) We present a new construction of an aperiodic tile set that is
based on Kleene's fixed-point construction instead of geometric arguments. This
construction is similar to J. von Neumann self-reproducing automata; similar
ideas were also used by P. Gacs in the context of error-correcting
computations. The flexibility of this construction allows us to construct a
"robust" aperiodic tile set that does not have periodic (or close to periodic)
tilings even if we allow some (sparse enough) tiling errors. This property was
not known for any of the existing aperiodic tile sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2451</identifier>
 <datestamp>2010-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2451</id><created>2008-02-18</created><updated>2010-06-10</updated><authors><author><keyname>Bocherer</keyname><forenames>Georg</forenames></author><author><keyname>Junior</keyname><forenames>Valdemar Cardoso da Rocha</forenames></author><author><keyname>Pimentel</keyname><forenames>Cecilio</forenames></author></authors><title>Capacity of General Discrete Noiseless Channels</title><categories>cs.IT math.IT</categories><comments>4 pages. Essentially the paper that appeared in Proc. ISCTA '07,
  2007. From v1 to v2, one error was corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the capacity of the discrete noiseless channel introduced
by Shannon. A sufficient condition is given for the capacity to be
well-defined. For a general discrete noiseless channel allowing non-integer
valued symbol weights, it is shown that the capacity--if well-defined--can be
determined from the radius of convergence of its generating function, from the
smallest positive pole of its generating function, or from the rightmost real
singularity of its complex generating function. A generalisation is given for
Pringsheim's Theorem and for the Exponential Growth Formula to generating
functions of combinatorial structures with non-integer valued symbol weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2655</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2655</id><created>2008-02-19</created><updated>2010-06-09</updated><authors><author><keyname>Bubeck</keyname><forenames>Sébastien</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Munos</keyname><forenames>Rémi</forenames><affiliation>INRIA Futurs</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>DMA, GREGH</affiliation></author></authors><title>Pure Exploration for Multi-Armed Bandit Problems</title><categories>math.ST cs.LG stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the framework of stochastic multi-armed bandit problems and study
the possibilities and limitations of forecasters that perform an on-line
exploration of the arms. These forecasters are assessed in terms of their
simple regret, a regret notion that captures the fact that exploration is only
constrained by the number of available rounds (not necessarily known in
advance), in contrast to the case when the cumulative regret is considered and
when exploitation needs to be performed at the same time. We believe that this
performance criterion is suited to situations when the cost of pulling an arm
is expressed in terms of resources rather than rewards. We discuss the links
between the simple and the cumulative regret. One of the main results in the
case of a finite number of arms is a general lower bound on the simple regret
of a forecaster in terms of its cumulative regret: the smaller the latter, the
larger the former. Keeping this result in mind, we then exhibit upper bounds on
the simple regret of some forecasters. The paper ends with a study devoted to
continuous-armed bandit problems; we show that the simple regret can be
minimized with respect to a family of probability distributions if and only if
the cumulative regret can be minimized for it. Based on this equivalence, we
are able to prove that the separable metric spaces are exactly the metric
spaces on which these regrets can be minimized with respect to the family of
all probability distributions with continuous mean-payoff functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.2736</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.2736</id><created>2008-02-20</created><updated>2010-09-01</updated><authors><author><keyname>Guillemot</keyname><forenames>Sylvain</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author><author><keyname>Berry</keyname><forenames>Vincent</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>On the approximability of the Maximum Agreement SubTree and Maximum
  Compatible Tree problems</title><categories>cs.CC cs.DM</categories><comments>Published in Discrete Applied Mathematics</comments><doi>10.1016/j.dam.2008.06.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the corresponding author because the newest
version is now published in Discrete Applied Mathematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3300</identifier>
 <datestamp>2014-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3300</id><created>2008-02-22</created><authors><author><keyname>La Mura</keyname><forenames>Pierfrancesco</forenames></author></authors><title>Projective Expected Utility</title><categories>quant-ph cs.GT</categories><comments>7 pages, to appear in the Proceedings of Quantum Interaction 2008</comments><journal-ref>J. of Math. Psychology, 53:5 (2009)</journal-ref><doi>10.1016/j.jmp.2009.02.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by several classic decision-theoretic paradoxes, and by analogies
with the paradoxes which in physics motivated the development of quantum
mechanics, we introduce a projective generalization of expected utility along
the lines of the quantum-mechanical generalization of probability theory. The
resulting decision theory accommodates the dominant paradoxes, while retaining
significant simplicity and tractability. In particular, every finite game
within this larger class of preferences still has an equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3414</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3414</id><created>2008-02-22</created><updated>2011-12-30</updated><authors><author><keyname>Abel</keyname><forenames>Zachary</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>Universal Reconfiguration of (Hyper-)cubic Robots</title><categories>cs.CG cs.MA cs.RO</categories><comments>5 pages, 2 figures</comments><acm-class>I.2.11; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a simple reconfigurable robot model which has not been previously
examined: cubic robots comprised of three-dimensional cubic modules which can
slide across each other and rotate about each others' edges. We demonstrate
that the cubic robot model is universal, i.e., that an n-module cubic robot can
reconfigure itself into any specified n-module configuration. Additionally, we
provide an algorithm that efficiently plans and executes cubic robot motion.
Our results directly extend to a d-dimensional model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3492</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3492</id><created>2008-02-24</created><updated>2010-03-25</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>The RDF Virtual Machine</title><categories>cs.PL</categories><comments>keywords: Resource Description Framework, Virtual Machines,
  Distributed Computing, Semantic Web</comments><report-no>LA-UR-08-03925</report-no><acm-class>F.1.2; I.2.4; E.1</acm-class><journal-ref>Knowledge-Based Systems, 24(6), 890-903, August 2011</journal-ref><doi>10.1016/j.knosys.2011.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Resource Description Framework (RDF) is a semantic network data model
that is used to create machine-understandable descriptions of the world and is
the basis of the Semantic Web. This article discusses the application of RDF to
the representation of computer software and virtual computing machines. The
Semantic Web is posited as not only a web of data, but also as a web of
programs and processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3513</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3513</id><created>2008-02-24</created><authors><author><keyname>Dereniowski</keyname><forenames>Dariusz</forenames></author></authors><title>The Complexity of Node Blocking for Dags</title><categories>cs.GT cs.DM</categories><comments>7 pages, 3 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Journal of Combinatorial Theory, Series A 118 (2011) 248-256</journal-ref><doi>10.1016/j.jcta.2010.03.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following modification of annihilation game called node
blocking. Given a directed graph, each vertex can be occupied by at most one
token. There are two types of tokens, each player can move his type of tokens.
The players alternate their moves and the current player $i$ selects one token
of type $i$ and moves the token along a directed edge to an unoccupied vertex.
If a player cannot make a move then he loses. We consider the problem of
determining the complexity of the game: given an arbitrary configuration of
tokens in a directed acyclic graph, does the current player has a winning
strategy? We prove that the problem is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3528</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3528</id><created>2008-02-24</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Starck</keyname><forenames>Jean-Luc</forenames></author></authors><title>Wavelet and Curvelet Moments for Image Classification: Application to
  Aggregate Mixture Grading</title><categories>cs.CV</categories><comments>Submitted to Pattern Recognition Letters</comments><journal-ref>Pattern Recognition Letters, 29, 1557-1564, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show the potential for classifying images of mixtures of aggregate, based
themselves on varying, albeit well-defined, sizes and shapes, in order to
provide a far more effective approach compared to the classification of
individual sizes and shapes. While a dominant (additive, stationary) Gaussian
noise component in image data will ensure that wavelet coefficients are of
Gaussian distribution, long tailed distributions (symptomatic, for example, of
extreme values) may well hold in practice for wavelet coefficients. Energy (2nd
order moment) has often been used for image characterization for image
content-based retrieval, and higher order moments may be important also, not
least for capturing long tailed distributional behavior. In this work, we
assess 2nd, 3rd and 4th order moments of multiresolution transform -- wavelet
and curvelet transform -- coefficients as features. As analysis methodology,
taking account of image types, multiresolution transforms, and moments of
coefficients in the scales or bands, we use correspondence analysis as well as
k-nearest neighbors supervised classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3554</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3554</id><created>2008-02-24</created><updated>2009-02-20</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Data Traffic Dynamics and Saturation on a Single Link</title><categories>cs.NI cs.PF</categories><comments>10 pages, 5 figures</comments><journal-ref>International Journal of Computer, Information, and Systems
  Science, and Engineering, vol 3, no. 1, 11-16 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dynamics of User Datagram Protocol (UDP) traffic over Ethernet between
two computers are analyzed using nonlinear dynamics which shows that there are
two clear regimes in the data flow: free flow and saturated. The two most
important variables affecting this are the packet size and packet flow rate.
However, this transition is due to a transcritical bifurcation rather than
phase transition in models such as in vehicle traffic or theorized large-scale
computer network congestion. It is hoped this model will help lay the
groundwork for further research on the dynamics of networks, especially
computer networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3563</identifier>
 <datestamp>2013-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3563</id><created>2008-02-25</created><updated>2008-08-06</updated><authors><author><keyname>Khan</keyname><forenames>Usman A.</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose' M. F.</forenames></author></authors><title>Distributed Sensor Localization in Random Environments using Minimal
  Number of Anchor Nodes</title><categories>cs.IT math.IT</categories><comments>30 pages, submitted to IEEE Transactions on Signal Processing</comments><journal-ref>U. A. Khan, S. Kar, and J. M. F. Moura, "Distributed sensor
  localization in random environments using minimal number of anchor nodes,"
  IEEE Transactions on Signal Processing, vol. 57, no. 5, pp. 2000-2016, May
  2009</journal-ref><doi>10.1109/TSP.2009.2014812</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper develops DILOC, a \emph{distributive}, \emph{iterative} algorithm
that locates M sensors in $\mathbb{R}^m, m\geq 1$, with respect to a minimal
number of m+1 anchors with known locations. The sensors exchange data with
their neighbors only; no centralized data processing or communication occurs,
nor is there centralized knowledge about the sensors' locations. DILOC uses the
barycentric coordinates of a sensor with respect to its neighbors that are
computed using the Cayley-Menger determinants. These are the determinants of
matrices of inter-sensor distances. We show convergence of DILOC by associating
with it an absorbing Markov chain whose absorbing states are the anchors. We
introduce a stochastic approximation version extending DILOC to random
environments when the knowledge about the intercommunications among sensors and
the inter-sensor distances are noisy, and the communication links among
neighbors fail at random times. We show a.s. convergence of the modified DILOC
and characterize the error between the final estimates and the true values of
the sensors' locations. Numerical studies illustrate DILOC under a variety of
deterministic and random operating conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3820</identifier>
 <datestamp>2014-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3820</id><created>2008-02-26</created><updated>2012-07-18</updated><authors><author><keyname>Skopenkov</keyname><forenames>A.</forenames></author></authors><title>On the Kuratowski graph planarity criterion</title><categories>math.GT cs.DM math.CO</categories><comments>English version: 4 pages and 4 figures, Russian version: 10 pages and
  13 figures. Exposition improved</comments><msc-class>57M15, 05C10</msc-class><journal-ref>Mat. Prosveschenie, 9 (2005), 116-128, and 11 (2007), 159--160</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is purely expositional. The statement of the Kuratowski graph
planarity criterion is simple and well-known. However, its classical proof is
not easy. In this paper we present the Makarychev proof (with further
simplifications by Prasolov, Telishev, Zaslavski and the author) which is
possibly the simplest. In the Rusian version before the proof we present all
the necessary definitions, and afterwards we state some close results on graphs
and more general spaces. The paper is accessible for students familiar with the
notion of a graph, and could be an interesting easy reading for mature
mathematicians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3875</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3875</id><created>2008-02-26</created><authors><author><keyname>Adamatzky</keyname><forenames>Andy</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>Are complex systems hard to evolve?</title><categories>cs.NE</categories><journal-ref>Volume 14, Issue 6, pages 15-20, July/August 2009</journal-ref><doi>10.1002/cplx.20269</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary complexity is here measured by the number of trials/evaluations
needed for evolving a logical gate in a non-linear medium. Behavioural
complexity of the gates evolved is characterised in terms of cellular automata
behaviour. We speculate that hierarchies of behavioural and evolutionary
complexities are isomorphic up to some degree, subject to substrate specificity
of evolution and the spectrum of evolution parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3885</identifier>
 <datestamp>2010-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3885</id><created>2008-02-26</created><authors><author><keyname>de Luca</keyname><forenames>Aldo</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>Rich, Sturmian, and trapezoidal words</title><categories>math.CO cs.DM</categories><comments>7 pages</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 407 (2008) 569--573</journal-ref><doi>10.1016/j.tcs.2008.06.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore various interconnections between rich words,
Sturmian words, and trapezoidal words. Rich words, first introduced in
arXiv:0801.1656 by the second and third authors together with J. Justin and S.
Widmer, constitute a new class of finite and infinite words characterized by
having the maximal number of palindromic factors. Every finite Sturmian word is
rich, but not conversely. Trapezoidal words were first introduced by the first
author in studying the behavior of the subword complexity of finite Sturmian
words. Unfortunately this property does not characterize finite Sturmian words.
In this note we show that the only trapezoidal palindromes are Sturmian. More
generally we show that Sturmian palindromes can be characterized either in
terms of their subword complexity (the trapezoidal property) or in terms of
their palindromic complexity. We also obtain a similar characterization of rich
palindromes in terms of a relation between palindromic complexity and subword
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.3888</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.3888</id><created>2008-02-26</created><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Levé</keyname><forenames>Florence</forenames></author><author><keyname>Richomme</keyname><forenames>Gwénaël</forenames></author></authors><title>Directive words of episturmian words: equivalences and normalization</title><categories>cs.DM math.CO</categories><comments>15 pages</comments><journal-ref>RAIRO - Theoretical Informatics and Applications 43 (2009) 299-319</journal-ref><doi>10.1051/ita:2008029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Episturmian morphisms constitute a powerful tool to study episturmian words.
Indeed, any episturmian word can be infinitely decomposed over the set of pure
episturmian morphisms. Thus, an episturmian word can be defined by one of its
morphic decompositions or, equivalently, by a certain directive word. Here we
characterize pairs of words directing a common episturmian word. We also
propose a way to uniquely define any episturmian word through a normalization
of its directive words. As a consequence of these results, we characterize
episturmian words having a unique directive word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4002</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4002</id><created>2008-02-27</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author></authors><title>Sensing Danger: Innate Immunology for Intrusion Detection</title><categories>cs.NE cs.CR</categories><journal-ref>Information Security Technical Report, 12(4), pp 218-227, 2007</journal-ref><doi>10.1016/j.istr.2007.10.003</doi><abstract>  The immune system provides an ideal metaphor for anomaly detection in general
and computer security in particular. Based on this idea, artificial immune
systems have been used for a number of years for intrusion detection,
unfortunately so far with little success. However, these previous systems were
largely based on immunological theory from the 1970s and 1980s and over the
last decade our understanding of immunological processes has vastly improved.
In this paper we present two new immune inspired algorithms based on the latest
immunological discoveries, such as the behaviour of Dendritic Cells. The
resultant algorithms are applied to real world intrusion problems and show
encouraging results. Overall, we believe there is a bright future for these
next generation artificial immune algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4215</identifier>
 <datestamp>2012-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4215</id><created>2008-02-28</created><authors><author><keyname>Ausloos</keyname><forenames>M.</forenames></author></authors><title>Equilibrium (Zipf) and Dynamic (Grasseberg-Procaccia) method based
  analyses of human texts. A comparison of natural (english) and artificial
  (esperanto) languages</title><categories>physics.soc-ph cs.CL physics.data-an</categories><comments>22 pages, 87 references, 5 tables, 8 figures</comments><journal-ref>Physica A 387 (25) 6411-6420 (2008)</journal-ref><doi>10.1016/j.physa.2008.07.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A comparison of two english texts from Lewis Carroll, one (Alice in
wonderland), also translated into esperanto, the other (Through a looking
glass) are discussed in order to observe whether natural and artificial
languages significantly differ from each other. One dimensional time series
like signals are constructed using only word frequencies (FTS) or word lengths
(LTS). The data is studied through (i) a Zipf method for sorting out
correlations in the FTS and (ii) a Grassberger-Procaccia (GP) technique based
method for finding correlations in LTS. Features are compared : different power
laws are observed with characteristic exponents for the ranking properties, and
the {\it phase space attractor dimensionality}. The Zipf exponent can take
values much less than unity ($ca.$ 0.50 or 0.30) depending on how a sentence is
defined. This non-universality is conjectured to be a measure of the author
$style$. Moreover the attractor dimension $r$ is a simple function of the so
called phase space dimension $n$, i.e., $r = n^{\lambda}$, with $\lambda =
0.79$. Such an exponent should also conjecture to be a measure of the author
$creativity$. However, even though there are quantitative differences between
the original english text and its esperanto translation, the qualitative
differences are very minutes, indicating in this case a translation relatively
well respecting, along our analysis lines, the content of the author writing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4237</identifier>
 <datestamp>2010-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4237</id><created>2008-02-28</created><updated>2010-04-09</updated><authors><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author></authors><title>Safety alternating automata on data words</title><categories>cs.LO</categories><comments>23 pages</comments><acm-class>F.4.1; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data word is a sequence of pairs of a letter from a finite alphabet and an
element from an infinite set, where the latter can only be compared for
equality. Safety one-way alternating automata with one register on infinite
data words are considered, their nonemptiness is shown EXPSPACE-complete, and
their inclusion decidable but not primitive recursive. The same complexity
bounds are obtained for satisfiability and refinement, respectively, for the
safety fragment of linear temporal logic with freeze quantification. Dropping
the safety restriction, adding past temporal operators, or adding one more
register, each causes undecidability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4307</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4307</id><created>2008-02-28</created><updated>2014-03-18</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>A O(n^8) X O(n^7) Linear Programming Model of the Quadratic Assignment
  Problem</title><categories>cs.DM cs.CC</categories><comments>Theorem 21 and Corollary 22 are in error; The modeling needs
  9-dimensional variables instead of the 8-dimensional variables defined in
  notations 6.9</comments><acm-class>G.1.6; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn because Theorem 21 and Corollary 22 are in
error; The modeling idea is OK, but it needs 9-dimensional variables instead of
the 8-dimensional variables defined in notations 6.9.
  Examples of the correct model (with 9-index variables) are: (1) Diaby, M.,
"Linear Programming Formulation of the Set Partitioning Problem," International
Journal of Operational Research 8:4 (August 2010) pp. 399-427; (2) Diaby, M.,
"Linear Programming Formulation of the Vertex Coloring Problem," International
Journal of Mathematics in Operational Research 2:3 (May 2010) pp. 259-289; (3)
Diaby, M., "The Traveling Salesman Problem: A Linear Programming Formulation,"
WSEAS Transactions on Mathematics, 6:6 (June 2007) pp. 745-754.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0802.4330</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0802.4330</id><created>2008-02-29</created><updated>2011-05-09</updated><authors><author><keyname>Farrell</keyname><forenames>Brendan</forenames></author><author><keyname>Strohmer</keyname><forenames>Thomas</forenames></author></authors><title>Eigenvalue Estimates and Mutual Information for the Linear Time-Varying
  Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory This version is
  a substantial revision of the earlier version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider linear time-varying channels with additive white Gaussian noise.
For a large class of such channels we derive rigorous estimates of the
eigenvalues of the correlation matrix of the effective channel in terms of the
sampled time-varying transfer function and, thus, provide a theoretical
justification for a relationship that has been frequently observed in the
literature. We then use this eigenvalue estimate to derive an estimate of the
mutual information of the channel. Our approach is constructive and is based on
a careful balance of the trade-off between approximate operator
diagonalization, signal dimension loss, and accuracy of eigenvalue estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0048</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0048</id><created>2008-03-01</created><updated>2011-05-12</updated><authors><author><keyname>Dong</keyname><forenames>Xin</forenames></author><author><keyname>Cooperman</keyname><forenames>Gene</forenames></author></authors><title>A Bit-Compatible Shared Memory Parallelization for ILU(k)
  Preconditioning and a Bit-Compatible Generalization to Distributed Memory</title><categories>cs.DC</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ILU(k) is a commonly used preconditioner for iterative linear solvers for
sparse, non-symmetric systems. It is often preferred for the sake of its
stability. We present TPILU(k), the first efficiently parallelized ILU(k)
preconditioner that maintains this important stability property. Even better,
TPILU(k) preconditioning produces an answer that is bit-compatible with the
sequential ILU(k) preconditioning. In terms of performance, the TPILU(k)
preconditioning is shown to run faster whenever more cores are made available
to it --- while continuing to be as stable as sequential ILU(k). This is in
contrast to some competing methods that may become unstable if the degree of
thread parallelism is raised too far. Where Block Jacobi ILU(k) fails in an
application, it can be replaced by TPILU(k) in order to maintain good
performance, while also achieving full stability. As a further optimization,
TPILU(k) offers an optional level-based incomplete inverse method as a fast
approximation for the original ILU(k) preconditioned matrix. Although this
enhancement is not bit-compatible with classical ILU(k), it is bit-compatible
with the output from the single-threaded version of the same algorithm. In
experiments on a 16-core computer, the enhanced TPILU(k)-based iterative linear
solver performed up to 9 times faster. As we approach an era of many-core
computing, the ability to efficiently take advantage of many cores will become
ever more important. TPILU(k) also demonstrates good performance on cluster or
Grid. For example, the new algorithm achieves 50 times speedup with 80 nodes
for general sparse matrices of dimension 160,000 that are diagonally dominant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0134</identifier>
 <datestamp>2010-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0134</id><created>2008-03-02</created><updated>2010-02-25</updated><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Petrosyan</keyname><forenames>Samvel S.</forenames></author><author><keyname>Vardanyan</keyname><forenames>Gagik N.</forenames></author></authors><title>On disjoint matchings in cubic graphs</title><categories>cs.DM</categories><comments>41 pages, 8 figures, minor chages</comments><journal-ref>Discrete Mathematics, 310/10-11 (2010), pp. 1588-1613</journal-ref><doi>10.1016/j.disc.2010.02.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For $i=2,3$ and a cubic graph $G$ let $\nu_{i}(G)$ denote the maximum number
of edges that can be covered by $i$ matchings. We show that $\nu_{2}(G)\geq
{4/5}| V(G)| $ and $\nu_{3}(G)\geq {7/6}| V(G)| $. Moreover, it turns out that
$\nu_{2}(G)\leq \frac{|V(G)|+2\nu_{3}(G)}{4}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0146</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0146</id><created>2008-03-02</created><authors><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author></authors><title>Polynomial time algorithms for bi-criteria, multi-objective and ratio
  problems in clustering and imaging. Part I: Normalized cut and ratio regions</title><categories>cs.CV cs.DM</categories><comments>15 pages, 4 figures</comments><journal-ref>IEEE Transactions on Pattern Analysis and Machine Intelligence,
  May 2010 32:5 889-898</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partitioning and grouping of similar objects plays a fundamental role in
image segmentation and in clustering problems. In such problems a typical goal
is to group together similar objects, or pixels in the case of image
processing. At the same time another goal is to have each group distinctly
dissimilar from the rest and possibly to have the group size fairly large.
These goals are often combined as a ratio optimization problem. One example of
such problem is the normalized cut problem, another is the ratio regions
problem. We devise here the first polynomial time algorithms solving these
problems optimally. The algorithms are efficient and combinatorial. This
contrasts with the heuristic approaches used in the image segmentation
literature that formulate those problems as nonlinear optimization problems,
which are then relaxed and solved with spectral techniques in real numbers.
These approaches not only fail to deliver an optimal solution, but they are
also computationally expensive. The algorithms presented here use as a
subroutine a minimum $s,t-cut procedure on a related graph which is of
polynomial size. The output consists of the optimal solution to the respective
ratio problem, as well as a sequence of nested solution with respect to any
relative weighting of the objectives of the numerator and denominator.
  An extension of the results here to bi-criteria and multi-criteria objective
functions is presented in part II.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0378</identifier>
 <datestamp>2011-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0378</id><created>2008-03-04</created><updated>2008-07-16</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Thread algebra for poly-threading</title><categories>cs.LO</categories><comments>24 pages, sections 9, 10, and 11 are added</comments><report-no>PRG0810</report-no><acm-class>D.4.1; F.1.1; F.1.2; F.3.2</acm-class><journal-ref>Formal Aspects of Computing, 23(4):567--583, 2011</journal-ref><doi>10.1007/s00165-011-0178-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Threads as considered in basic thread algebra are primarily looked upon as
behaviours exhibited by sequential programs on execution. It is a fact of life
that sequential programs are often fragmented. Consequently, fragmented program
behaviours are frequently found. In this paper, we consider this phenomenon. We
extend basic thread algebra with the barest mechanism for sequencing of threads
that are taken for fragments. This mechanism, called poly-threading, supports
both autonomous and non-autonomous thread selection in sequencing. We relate
the resulting theory to the algebraic theory of processes known as ACP and use
it to describe analytic execution architectures suited for fragmented programs.
We also consider the case where the steps of fragmented program behaviours are
interleaved in the ways of non-distributed and distributed multi-threading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0473</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0473</id><created>2008-03-04</created><updated>2010-11-15</updated><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Duffield</keyname><forenames>Nick</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Lund</keyname><forenames>Carsten</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Stream sampling for variance-optimal estimation of subset sums</title><categories>cs.DS</categories><comments>31 pages. An extended abstract appeared in the proceedings of the
  20th ACM-SIAM Symposium on Discrete Algorithms (SODA 2009)</comments><acm-class>C.2.3; E.1; F.2; G.3; H.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  From a high volume stream of weighted items, we want to maintain a generic
sample of a certain limited size $k$ that we can later use to estimate the
total weight of arbitrary subsets. This is the classic context of on-line
reservoir sampling, thinking of the generic sample as a reservoir. We present
an efficient reservoir sampling scheme, $\varoptk$, that dominates all previous
schemes in terms of estimation quality.
  $\varoptk$ provides {\em variance optimal unbiased estimation of subset
sums}. More precisely, if we have seen $n$ items of the stream, then for {\em
any} subset size $m$, our scheme based on $k$ samples minimizes the average
variance over all subsets of size $m$. In fact, the optimality is against any
off-line scheme with $k$ samples tailored for the concrete set of items seen.
In addition to optimal average variance, our scheme provides tighter worst-case
bounds on the variance of {\em particular} subsets than previously possible. It
is efficient, handling each new item of the stream in $O(\log k)$ time.
Finally, it is particularly well suited for combination of samples from
different streams in a distributed setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0726</identifier>
 <datestamp>2013-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0726</id><created>2008-03-05</created><updated>2013-05-30</updated><authors><author><keyname>Béal</keyname><forenames>Marie-Pierre</forenames></author><author><keyname>Perrin</keyname><forenames>Dominique</forenames></author></authors><title>A quadratic algorithm for road coloring</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Road Coloring Theorem states that every aperiodic directed graph with
constant out-degree has a synchronized coloring. This theorem had been
conjectured during many years as the Road Coloring Problem before being settled
by A. Trahtman. Trahtman's proof leads to an algorithm that finds a
synchronized labeling with a cubic worst-case time complexity. We show a
variant of his construction with a worst-case complexity which is quadratic in
time and linear in space. We also extend the Road Coloring Theorem to the
periodic case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0858</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0858</id><created>2008-03-06</created><updated>2010-11-23</updated><authors><author><keyname>Kang</keyname><forenames>Mihyun</forenames></author><author><keyname>Pikhurko</keyname><forenames>Oleg</forenames></author><author><keyname>Ravsky</keyname><forenames>Alexander</forenames></author><author><keyname>Schacht</keyname><forenames>Mathias</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>Untangling planar graphs from a specified vertex position - Hard cases</title><categories>cs.DM cs.CG</categories><comments>18 pages, 4 figures. Lemma 3.3 is corrected, several amendments are
  made throughout the paper</comments><journal-ref>Discrete Applied Mathematics 159:8 (2011) 789-799</journal-ref><doi>10.1016/j.dam.2011.01.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a planar graph $G$, we consider drawings of $G$ in the plane where
edges are represented by straight line segments (which possibly intersect).
Such a drawing is specified by an injective embedding $\pi$ of the vertex set
of $G$ into the plane. We prove that a wheel graph $W_n$ admits a drawing $\pi$
such that, if one wants to eliminate edge crossings by shifting vertices to new
positions in the plane, then at most $(2+o(1))\sqrt n$ of all $n$ vertices can
stay fixed. Moreover, such a drawing $\pi$ exists even if it is presupposed
that the vertices occupy any prescribed set of points in the plane. Similar
questions are discussed for other families of planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.0924</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.0924</id><created>2008-03-06</created><updated>2010-02-18</updated><authors><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Lee</keyname><forenames>Homin K.</forenames></author><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author><author><keyname>Raskhodnikova</keyname><forenames>Sofya</forenames></author><author><keyname>Smith</keyname><forenames>Adam</forenames></author></authors><title>What Can We Learn Privately?</title><categories>cs.LG cs.CC cs.CR cs.DB</categories><comments>35 pages, 2 figures</comments><journal-ref>SIAM Journal of Computing 40(3) (2011) 793-826</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning problems form an important category of computational tasks that
generalizes many of the computations researchers apply to large real-life data
sets. We ask: what concept classes can be learned privately, namely, by an
algorithm whose output does not depend too heavily on any one input or specific
training example? More precisely, we investigate learning algorithms that
satisfy differential privacy, a notion that provides strong confidentiality
guarantees in contexts where aggregate information is released about a database
containing sensitive information about individuals. We demonstrate that,
ignoring computational constraints, it is possible to privately agnostically
learn any concept class using a sample size approximately logarithmic in the
cardinality of the concept class. Therefore, almost anything learnable is
learnable privately: specifically, if a concept class is learnable by a
(non-private) algorithm with polynomial sample complexity and output size, then
it can be learned privately using a polynomial number of samples. We also
present a computationally efficient private PAC learner for the class of parity
functions. Local (or randomized response) algorithms are a practical class of
private algorithms that have received extensive investigation. We provide a
precise characterization of local private learning algorithms. We show that a
concept class is learnable by a local algorithm if and only if it is learnable
in the statistical query (SQ) model. Finally, we present a separation between
the power of interactive and noninteractive local learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1207</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1207</id><created>2008-03-07</created><updated>2010-09-28</updated><authors><author><keyname>Dinh</keyname><forenames>Hang</forenames></author></authors><title>Serious Flaws in Korf et al.'s Analysis on Time Complexity of A*</title><categories>cs.AI</categories><comments>This paper has been withdrawn</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1393</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1393</id><created>2008-03-10</created><authors><author><keyname>Kwaśniewski</keyname><forenames>A. Krzysztof</forenames></author><author><keyname>Krot-Sieniawska</keyname><forenames>Ewa</forenames></author></authors><title>On inversion formulas and Fibonomial coefficients</title><categories>math.CO cs.DM math.GM</categories><comments>4 pages, presented at the Gian-Carlo Rota Polish Seminar,
  http://ii.uwb.edu.pl/akk/sem/sem_rota.htm, submitted to FECS'08: The 2008
  International Conference on Frontiers in Education: WORLDCOMP'08</comments><msc-class>05A19, 11B39, 15A09</msc-class><journal-ref>Proc. Jangjeon Math. Soc. volume 11 (1), 2008 (June),65-68</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A research problem for undergraduates and graduates is being posed as a cap
for the prior antecedent regular discrete mathematics exercises. [Here cap is
not necessarily CAP=Competitive Access Provider, though nevertheless ...] The
object of the cap problem of final interest i.e. array of fibonomial
coefficients and the issue of its combinatorial meaning is to be found in
A.K.Kwa\'sniewski's source papers. The cap problem number seven - still opened
for students has been placed on Mathemagics page of the first author
[http://ii.uwb.edu.pl/akk/dydaktyka/dyskr/dyskretna.htm]. The indicatory
references are to point at a part of the vast domain of the foundations of
computer science in ArXiv affiliation noted as CO.cs.DM. The presentation has
been verified in a tutor system of communication with a couple of intelligent
students. The result is top secret.Temporarily. [Contact: Wikipedia; Theory of
cognitive development].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1568</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1568</id><created>2008-03-11</created><authors><author><keyname>Chen</keyname><forenames>Qi</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Dempster-Shafer for Anomaly Detection</title><categories>cs.NE cs.AI cs.CR</categories><journal-ref>Proceedings of the International Conference on Data Mining (DMIN
  2006), pp 232-238, Las Vegas, USA 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we implement an anomaly detection system using the
Dempster-Shafer method. Using two standard benchmark problems we show that by
combining multiple signals it is possible to achieve better results than by
using a single signal. We further show that by applying this approach to a
real-world email dataset the algorithm works for email worm detection.
Dempster-Shafer can be a promising method for anomaly detection problems with
multiple features (data sources), and two or more classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1576</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1576</id><created>2008-03-11</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Adewunmi</keyname><forenames>Adrian</forenames></author></authors><title>Simulation Optimization of the Crossdock Door Assignment Problem</title><categories>cs.NE cs.CE</categories><journal-ref>UK Operational Research Society Simulation Workshop 2006 (SW
  2006), Leamington Spa, UK 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this report is to present the Crossdock Door Assignment
Problem, which involves assigning destinations to outbound dock doors of
Crossdock centres such that travel distance by material handling equipment is
minimized. We propose a two fold solution; simulation and optimization of the
simulation model simulation optimization. The novel aspect of our solution
approach is that we intend to use simulation to derive a more realistic
objective function and use Memetic algorithms to find an optimal solution. The
main advantage of using Memetic algorithms is that it combines a local search
with Genetic Algorithms. The Crossdock Door Assignment Problem is a new domain
application to Memetic Algorithms and it is yet unknown how it will perform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1596</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1596</id><created>2008-03-11</created><authors><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Christopher</forenames></author><author><keyname>Robinson</keyname><forenames>Mark</forenames></author><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Sprigg</keyname><forenames>Christine</forenames></author></authors><title>Using Intelligent Agents to understand organisational behaviour</title><categories>cs.NE cs.MA</categories><journal-ref>Proceedings of the British Psychology Society Annual Conference,
  Occupational Psychology Division (BPS 2007), Bristol, UK 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces two ongoing research projects which seek to apply
computer modelling techniques in order to simulate human behaviour within
organisations. Previous research in other disciplines has suggested that
complex social behaviours are governed by relatively simple rules which, when
identified, can be used to accurately model such processes using computer
technology. The broad objective of our research is to develop a similar
capability within organisational psychology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1604</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1604</id><created>2008-03-11</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Christopher</forenames></author></authors><title>Using Intelligent Agents to Understand Management Practices and Retail
  Productivity</title><categories>cs.NE cs.CE cs.MA</categories><journal-ref>Proceedings of the Winter Simulation Conference (WSC 2007), pp
  2212-2220, Washington, USA 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent agents offer a new and exciting way of understanding the world of
work. In this paper we apply agent-based modeling and simulation to investigate
a set of problems in a retail context. Specifically, we are working to
understand the relationship between human resource management practices and
retail productivity. Despite the fact we are working within a relatively novel
and complex domain, it is clear that intelligent agents could offer potential
for fostering sustainable organizational capabilities in the future. The
project is still at an early stage. So far we have conducted a case study in a
UK department store to collect data and capture impressions about operations
and actors within departments. Furthermore, based on our case study we have
built and tested our first version of a retail branch simulator which we will
present in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1621</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1621</id><created>2008-03-11</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Christopher</forenames></author></authors><title>An Agent-Based Simulation of In-Store Customer Experiences</title><categories>cs.NE cs.CE cs.MA</categories><journal-ref>Operational Research Society 4th Simulation Workshop (SW08), in
  print, pp, Worcestershire, UK 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agent-based modelling and simulation offers a new and exciting way of
understanding the world of work. In this paper we describe the development of
an agent-based simulation model, designed to help to understand the
relationship between human resource management practices and retail
productivity. We report on the current development of our simulation model
which includes new features concerning the evolution of customers over time. To
test some of these features we have conducted a series of experiments dealing
with customer pool sizes, standard and noise reduction modes, and the spread of
the word of mouth. Our multi-disciplinary research team draws upon expertise
from work psychologists and computer scientists. Despite the fact we are
working within a relatively novel and complex domain, it is clear that
intelligent agents offer potential for fostering sustainable organisational
capabilities in the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1626</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1626</id><created>2008-03-11</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan</forenames></author></authors><title>Genetic-Algorithm Seeding Of Idiotypic Networks For Mobile-Robot
  Navigation</title><categories>cs.NE cs.RO</categories><journal-ref>Proceedings of the International Conference on Informatics in
  Control, Automation and Robotics (ICINCO 2008), in print, pp, Funchal,
  Portugal, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robot-control designers have begun to exploit the properties of the human
immune system in order to produce dynamic systems that can adapt to complex,
varying, real-world tasks. Jernes idiotypic-network theory has proved the most
popular artificial-immune-system (AIS) method for incorporation into
behaviour-based robotics, since idiotypic selection produces highly adaptive
responses. However, previous efforts have mostly focused on evolving the
network connections and have often worked with a single, pre-engineered set of
behaviours, limiting variability. This paper describes a method for encoding
behaviours as a variable set of attributes, and shows that when the encoding is
used with a genetic algorithm (GA), multiple sets of diverse behaviours can
develop naturally and rapidly, providing much greater scope for flexible
behaviour-selection. The algorithm is tested extensively with a simulated
e-puck robot that navigates around a maze by tracking colour. Results show that
highly successful behaviour sets can be generated within about 25 minutes, and
that much greater diversity can be obtained when multiple autonomous
populations are used, rather than a single one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1728</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1728</id><created>2008-03-12</created><authors><author><keyname>Abdullah</keyname><forenames>Salwani</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author><author><keyname>Din</keyname><forenames>Aniza</forenames></author><author><keyname>Qu</keyname><forenames>Rong</forenames></author></authors><title>Investigating a Hybrid Metaheuristic For Job Shop Rescheduling</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the 3rd Australian Conference on Artificial Life
  (ACAL07), Lecture Notes in Computer Science 4828, pp 357-368, Gold Coast,
  Australia 2007</journal-ref><doi>10.1007/978-3-540-76931-6_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous research has shown that artificial immune systems can be used to
produce robust schedules in a manufacturing environment. The main goal is to
develop building blocks (antibodies) of partial schedules that can be used to
construct backup solutions (antigens) when disturbances occur during
production. The building blocks are created based upon underpinning ideas from
artificial immune systems and evolved using a genetic algorithm (Phase I). Each
partial schedule (antibody) is assigned a fitness value and the best partial
schedules are selected to be converted into complete schedules (antigens). We
further investigate whether simulated annealing and the great deluge algorithm
can improve the results when hybridised with our artificial immune system
(Phase II). We use ten fixed solutions as our target and measure how well we
cover these specific scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1985</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1985</id><created>2008-03-13</created><authors><author><keyname>Adewunmi</keyname><forenames>Adrian</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Byrne</keyname><forenames>Mike</forenames></author></authors><title>An Investigation of the Sequential Sampling Method for Crossdocking
  Simulation Output Variance Reduction</title><categories>cs.NE cs.CE</categories><journal-ref>Operational Research Society 4th Simulation Workshop (SW08) in
  print, pp, Worcestershire, UK 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the reduction of variance associated with a
simulation output performance measure, using the Sequential Sampling method
while applying minimum simulation replications, for a class of JIT (Just in
Time) warehousing system called crossdocking. We initially used the Sequential
Sampling method to attain a desired 95% confidence interval half width of
plus/minus 0.5 for our chosen performance measure (Total usage cost, given the
mean maximum level of 157,000 pounds and a mean minimum level of 149,000
pounds). From our results, we achieved a 95% confidence interval half width of
plus/minus 2.8 for our chosen performance measure (Total usage cost, with an
average mean value of 115,000 pounds). However, the Sequential Sampling method
requires a huge number of simulation replications to reduce variance for our
simulation output value to the target level. Arena (version 11) simulation
software was used to conduct this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1993</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1993</id><created>2008-03-13</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author></authors><title>Improved Squeaky Wheel Optimisation for Driver Scheduling</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the 9th International Conference on Parallel
  Problem Solving from Nature (PPSN IX), Lecture Notes in Computer Science
  4193, pp 182-191, Reykjavik, Iceland, 2006</journal-ref><doi>10.1007/11844297_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a technique called Improved Squeaky Wheel Optimisation
for driver scheduling problems. It improves the original Squeaky Wheel
Optimisations effectiveness and execution speed by incorporating two additional
steps of Selection and Mutation which implement evolution within a single
solution. In the ISWO, a cycle of
Analysis-Selection-Mutation-Prioritization-Construction continues until
stopping conditions are reached. The Analysis step first computes the fitness
of a current solution to identify troublesome components. The Selection step
then discards these troublesome components probabilistically by using the
fitness measure, and the Mutation step follows to further discard a small
number of components at random. After the above steps, an input solution
becomes partial and thus the resulting partial solution needs to be repaired.
The repair is carried out by using the Prioritization step to first produce
priorities that determine an order by which the following Construction step
then schedules the remaining components. Therefore, the optimisation in the
ISWO is achieved by solution disruption, iterative improvement and an iterative
constructive repair process performed. Encouraging experimental results are
reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1994</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1994</id><created>2008-03-13</created><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>The Application of Bayesian Optimization and Classifier Systems in Nurse
  Scheduling</title><categories>cs.NE cs.CE</categories><journal-ref>Proceedings of the 8th International Conference on Parallel
  Problem Solving from Nature (PPSN VIII), Lecture Notes in Computer Science
  3242, pp 581-590, Birmingham, UK 2004</journal-ref><doi>10.1007/b100601</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two ideas taken from Bayesian optimization and classifier systems are
presented for personnel scheduling based on choosing a suitable scheduling rule
from a set for each persons assignment. Unlike our previous work of using
genetic algorithms whose learning is implicit, the learning in both approaches
is explicit, i.e. we are able to identify building blocks directly. To achieve
this target, the Bayesian optimization algorithm builds a Bayesian network of
the joint probability distribution of the rules used to construct solutions,
while the adapted classifier system assigns each rule a strength value that is
constantly updated according to its usefulness in the current situation.
Computational results from 52 real data instances of nurse scheduling
demonstrate the success of both approaches. It is also suggested that the
learning mechanism in the proposed approaches might be suitable for other
scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.1997</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.1997</id><created>2008-03-13</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Bentley</keyname><forenames>Peter</forenames></author><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author><author><keyname>Jungwon</keyname><forenames>Kim</forenames></author><author><keyname>McLeod</keyname><forenames>Julie</forenames></author></authors><title>Danger Theory: The Link between AIS and IDS?</title><categories>cs.NE cs.AI cs.CR</categories><journal-ref>Proceedings of the 2nd International Conference on Artificial
  Immune Systems (ICARIS 2003), Lecture Notes in Computer Science 2787, pp
  147-155, doi: 10.1007/b12020, Edinburgh, UK 2003</journal-ref><doi>10.1007/b12020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present ideas about creating a next generation Intrusion Detection System
based on the latest immunological theories. The central challenge with computer
security is determining the difference between normal and potentially harmful
activity. For half a century, developers have protected their systems by coding
rules that identify and block specific events. However, the nature of current
and future threats in conjunction with ever larger IT systems urgently requires
the development of automated and adaptive defensive tools. A promising solution
is emerging in the form of Artificial Immune Systems. The Human Immune System
can detect and defend against harmful and previously unseen invaders, so can we
not build a similar Intrusion Detection System for our computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2123</identifier>
 <datestamp>2012-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2123</id><created>2008-03-14</created><updated>2008-09-09</updated><authors><author><keyname>Fontein</keyname><forenames>Felix</forenames><affiliation>University of Zurich</affiliation></author></authors><title>Groups from Cyclic Infrastructures and Pohlig-Hellman in Certain
  Infrastructures</title><categories>cs.CR</categories><comments>14 pages</comments><journal-ref>Advances in Mathematics of Communications, 2 (3), 2008</journal-ref><doi>10.3934/amc.2008.2.293</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In discrete logarithm based cryptography, a method by Pohlig and Hellman
allows solving the discrete logarithm problem efficiently if the group order is
known and has no large prime factors. The consequence is that such groups are
avoided. In the past, there have been proposals for cryptography based on
cyclic infrastructures. We will show that the Pohlig-Hellman method can be
adapted to certain cyclic infrastructures, which similarly implies that certain
infrastructures should not be used for cryptography. This generalizes a result
by M\"uller, Vanstone and Zuccherato for infrastructures obtained from
hyperelliptic function fields.
  We recall the Pohlig-Hellman method, define the concept of a cyclic
infrastructure and briefly describe how to obtain such infrastructures from
certain function fields of unit rank one. Then, we describe how to obtain
cyclic groups from discrete cyclic infrastructures and how to apply the
Pohlig-Hellman method to compute absolute distances, which is in general a
computationally hard problem for cyclic infrastructures. Moreover, we give an
algorithm which allows to test whether an infrastructure satisfies certain
requirements needed for applying the Pohlig-Hellman method, and discuss whether
the Pohlig-Hellman method is applicable in infrastructures obtained from number
fields. Finally, we discuss how this influences cryptography based on cyclic
infrastructures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2262</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2262</id><created>2008-03-14</created><updated>2010-03-30</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Constant-Rank Codes and Their Connection to Constant-Dimension Codes</title><categories>cs.IT math.IT</categories><comments>10 pages, 3 figures, accepted to appear in IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant-dimension codes have recently received attention due to their
significance to error control in noncoherent random linear network coding. What
the maximal cardinality of any constant-dimension code with finite dimension
and minimum distance is and how to construct the optimal constant-dimension
code (or codes) that achieves the maximal cardinality both remain open research
problems. In this paper, we introduce a new approach to solving these two
problems. We first establish a connection between constant-rank codes and
constant-dimension codes. Via this connection, we show that optimal
constant-dimension codes correspond to optimal constant-rank codes over
matrices with sufficiently many rows. As such, the two aforementioned problems
are equivalent to determining the maximum cardinality of constant-rank codes
and to constructing optimal constant-rank codes, respectively. To this end, we
then derive bounds on the maximum cardinality of a constant-rank code with a
given minimum rank distance, propose explicit constructions of optimal or
asymptotically optimal constant-rank codes, and establish asymptotic bounds on
the maximum rate of a constant-rank code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2316</identifier>
 <datestamp>2011-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2316</id><created>2008-03-15</created><authors><author><keyname>Shende</keyname><forenames>Vivek V.</forenames></author><author><keyname>Markov</keyname><forenames>Igor L.</forenames></author></authors><title>On the CNOT-cost of TOFFOLI gates</title><categories>quant-ph cs.ET</categories><comments>28 pages</comments><journal-ref>Quant.Inf.Comp. 9(5-6):461-486 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The three-input TOFFOLI gate is the workhorse of circuit synthesis for
classical logic operations on quantum data, e.g., reversible arithmetic
circuits. In physical implementations, however, TOFFOLI gates are decomposed
into six CNOT gates and several one-qubit gates. Though this decomposition has
been known for at least 10 years, we provide here the first demonstration of
its CNOT-optimality.
  We study three-qubit circuits which contain less than six CNOT gates and
implement a block-diagonal operator, then show that they implicitly describe
the cosine-sine decomposition of a related operator. Leveraging the canonicity
of such decompositions to limit one-qubit gates appearing in respective
circuits, we prove that the n-qubit analogue of the TOFFOLI requires at least
2n CNOT gates. Additionally, our results offer a complete classification of
three-qubit diagonal operators by their CNOT-cost, which holds even if ancilla
qubits are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2392</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2392</id><created>2008-03-17</created><updated>2008-04-17</updated><authors><author><keyname>Needell</keyname><forenames>D.</forenames></author><author><keyname>Tropp</keyname><forenames>J. A.</forenames></author></authors><title>CoSaMP: Iterative signal recovery from incomplete and inaccurate samples</title><categories>math.NA cs.IT math.IT</categories><comments>30 pages. Revised. Presented at Information Theory and Applications,
  31 January 2008, San Diego</comments><msc-class>41A46, 68Q25, 68W20, 90C27</msc-class><journal-ref>Appl. Comput. Harmon. Anal., Vol. 26, pp. 301-321, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sampling offers a new paradigm for acquiring signals that are
compressible with respect to an orthonormal basis. The major algorithmic
challenge in compressive sampling is to approximate a compressible signal from
noisy samples. This paper describes a new iterative recovery algorithm called
CoSaMP that delivers the same guarantees as the best optimization-based
approaches. Moreover, this algorithm offers rigorous bounds on computational
cost and storage. It is likely to be extremely efficient for practical problems
because it requires only matrix-vector multiplies with the sampling matrix. For
many cases of interest, the running time is just O(N*log^2(N)), where N is the
length of the signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2443</identifier>
 <datestamp>2012-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2443</id><created>2008-03-17</created><authors><author><keyname>Claussen</keyname><forenames>Jens Christian</forenames></author></authors><title>Discrete stochastic processes, replicator and Fokker-Planck equations of
  coevolutionary dynamics in finite and infinite populations</title><categories>q-bio.PE cond-mat.stat-mech cs.SI math.PR math.ST physics.bio-ph physics.soc-ph stat.TH</categories><comments>Banach Center publications, in press</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite-size fluctuations in coevolutionary dynamics arise in models of
biological as well as of social and economic systems. This brief tutorial
review surveys a systematic approach starting from a stochastic process
discrete both in time and state. The limit $N\to \infty$ of an infinite
population can be considered explicitly, generally leading to a replicator-type
equation in zero order, and to a Fokker-Planck-type equation in first order in
$1/\sqrt{N}$. Consequences and relations to some previous approaches are
outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2957</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2957</id><created>2008-03-20</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dowsland</keyname><forenames>Kathryn</forenames></author></authors><title>Enhanced Direct and Indirect Genetic Algorithm Approaches for a Mall
  Layout and Tenant Selection Problem</title><categories>cs.NE cs.CE</categories><journal-ref>Journal of Heuristics, 8(5), pp 503-514, 2002</journal-ref><doi>10.1023/A:1016536623961,</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During our earlier research, it was recognised that in order to be successful
with an indirect genetic algorithm approach using a decoder, the decoder has to
strike a balance between being an optimiser in its own right and finding
feasible solutions. Previously this balance was achieved manually. Here we
extend this by presenting an automated approach where the genetic algorithm
itself, simultaneously to solving the problem, sets weights to balance the
components out. Subsequently we were able to solve a complex and non-linear
scheduling problem better than with a standard direct genetic algorithm
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2965</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2965</id><created>2008-03-20</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>An Indirect Genetic Algorithm for Set Covering Problems</title><categories>cs.NE cs.AI</categories><journal-ref>Journal of the Operational Research Society, 53(10), pp 1118-1126
  2002</journal-ref><doi>10.1057/palgrave.jors.2601317</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new type of genetic algorithm for the set covering
problem. It differs from previous evolutionary approaches first because it is
an indirect algorithm, i.e. the actual solutions are found by an external
decoder function. The genetic algorithm itself provides this decoder with
permutations of the solution variables and other parameters. Second, it will be
shown that results can be further improved by adding another indirect
optimisation layer. The decoder will not directly seek out low cost solutions
but instead aims for good exploitable solutions. These are then post optimised
by another hill-climbing algorithm. Although seemingly more complicated, we
will show that this three-stage approach has advantages in terms of solution
quality, speed and adaptability to new types of problems over more direct
approaches. Extensive computational results are presented and compared to the
latest evolutionary and other heuristic approaches to the same data instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2966</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2966</id><created>2008-03-20</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Bull</keyname><forenames>Larry</forenames></author></authors><title>On the Application of Hierarchical Coevolutionary Genetic Algorithms:
  Recombination and Evaluation Partners</title><categories>cs.NE cs.AI</categories><journal-ref>Journal of Applied System Studies, 4(2), pp 2-17, 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the use of a hierarchical coevolutionary genetic
algorithm under different partnering strategies. Cascading clusters of
sub-populations are built from the bottom up, with higher-level sub-populations
optimising larger parts of the problem. Hence higher-level sub-populations
potentially search a larger search space with a lower resolution whilst
lower-level sub-populations search a smaller search space with a higher
resolution. The effects of different partner selection schemes amongst the
sub-populations on solution quality are examined for two constrained
optimisation problems. We examine a number of recombination partnering
strategies in the construction of higher-level individuals and a number of
related schemes for evaluating sub-solutions. It is shown that partnering
strategies that exploit problem-specific knowledge are superior and can counter
inappropriate (sub)fitness measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2967</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2967</id><created>2008-03-20</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>White</keyname><forenames>Paul</forenames></author></authors><title>Building Better Nurse Scheduling Algorithms</title><categories>cs.NE cs.CE</categories><journal-ref>Annals of Operations Research, 128, pp 159-177, 2004</journal-ref><doi>10.1023/B:ANOR.0000019103.31340.a6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this research is twofold: Firstly, to model and solve a complex
nurse scheduling problem with an integer programming formulation and
evolutionary algorithms. Secondly, to detail a novel statistical method of
comparing and hence building better scheduling algorithms by identifying
successful algorithm modifications. The comparison method captures the results
of algorithms in a single figure that can then be compared using traditional
statistical techniques. Thus, the proposed method of comparing algorithms is an
objective procedure designed to assist in the process of improving an
algorithm. This is achieved even when some results are non-numeric or missing
due to infeasibility. The final algorithm outperforms all previous evolutionary
algorithms, which relied on human expertise for modification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2969</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2969</id><created>2008-03-20</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dowsland</keyname><forenames>Kathryn</forenames></author></authors><title>An Indirect Genetic Algorithm for a Nurse Scheduling Problem</title><categories>cs.NE cs.CE</categories><journal-ref>Computers &amp; Operations Research, 31(5), pp 761-778, 2004</journal-ref><doi>10.1016/S0305-0548(03)00034-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a Genetic Algorithms approach to a manpower-scheduling
problem arising at a major UK hospital. Although Genetic Algorithms have been
successfully used for similar problems in the past, they always had to overcome
the limitations of the classical Genetic Algorithms paradigm in handling the
conflict between objectives and constraints. The approach taken here is to use
an indirect coding based on permutations of the nurses, and a heuristic decoder
that builds schedules from these permutations. Computational experiments based
on 52 weeks of live data are used to evaluate three different decoders with
varying levels of intelligence, and four well-known crossover operators.
Results are further enhanced by introducing a hybrid crossover operator and by
making use of simple bounds to reduce the size of the solution space. The
results reveal that the proposed algorithm is able to find high quality
solutions and is both faster and more flexible than a recently published Tabu
Search approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2970</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2970</id><created>2008-03-20</created><updated>2008-05-16</updated><authors><author><keyname>Cayzer</keyname><forenames>Steve</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A Recommender System based on Idiotypic Artificial Immune Networks</title><categories>cs.NE cs.AI</categories><journal-ref>Journal of Mathematical Modelling and Algorithms, 4(2), pp
  181-198, 2005</journal-ref><doi>10.1007/s10852-004-5336-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The immune system is a complex biological system with a highly distributed,
adaptive and self-organising nature. This paper presents an Artificial Immune
System (AIS) that exploits some of these characteristics and is applied to the
task of film recommendation by Collaborative Filtering (CF). Natural evolution
and in particular the immune system have not been designed for classical
optimisation. However, for this problem, we are not interested in finding a
single optimum. Rather we intend to identify a sub-set of good matches on which
recommendations can be based. It is our hypothesis that an AIS built on two
central aspects of the biological immune system will be an ideal candidate to
achieve this: Antigen-antibody interaction for matching and idiotypic
antibody-antibody interaction for diversity. Computational results are
presented in support of this conjecture and compared to those found by other CF
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2973</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2973</id><created>2008-03-20</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author><author><keyname>Hesketh-Roberts</keyname><forenames>Thomas</forenames></author></authors><title>Rule Generalisation in Intrusion Detection Systems using Snort</title><categories>cs.NE cs.CR</categories><journal-ref>International Journal of Electronic Security and Digital
  Forensics, 1 (1), pp 101-116, 2007</journal-ref><doi>10.1504/IJESDF.2007.013596,</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intrusion Detection Systems (ids)provide an important layer of security for
computer systems and networks, and are becoming more and more necessary as
reliance on Internet services increases and systems with sensitive data are
more commonly open to Internet access. An ids responsibility is to detect
suspicious or unacceptable system and network activity and to alert a systems
administrator to this activity. The majority of ids use a set of signatures
that define what suspicious traffic is, and Snort is one popular and actively
developing open-source ids that uses such a set of signatures known as Snort
rules. Our aim is to identify a way in which Snort could be developed further
by generalising rules to identify novel attacks. In particular, we attempted to
relax and vary the conditions and parameters of current Snort rules, using a
similar approach to classic rule learning operators such as generalisation and
specialisation. We demonstrate the effectiveness of our approach through
experiments with standard datasets and show that we are able to detect
previously undeleted variants of various attacks. We conclude by discussing the
general effectiveness and appropriateness of generalisation in Snort based ids
rule processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2975</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2975</id><created>2008-03-20</created><updated>2008-05-16</updated><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author></authors><title>An Estimation of Distribution Algorithm for Nurse Scheduling</title><categories>cs.NE cs.CE</categories><journal-ref>Annals of Operations Research, 155 (1), pp 289-309, 2007</journal-ref><doi>10.1007/s10479-007-0214-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schedules can be built in a similar way to a human scheduler by using a set
of rules that involve domain knowledge. This paper presents an Estimation of
Distribution Algorithm (eda) for the nurse scheduling problem, which involves
choosing a suitable scheduling rule from a set for the assignment of each
nurse. Unlike previous work that used Genetic Algorithms (ga) to implement
implicit learning, the learning in the proposed algorithm is explicit, i.e. we
identify and mix building blocks directly. The eda is applied to implement such
explicit learning by building a Bayesian network of the joint distribution of
solutions. The conditional probability of each variable in the network is
computed according to an initial set of promising solutions. Subsequently, each
new instance for each variable is generated by using the corresponding
conditional probabilities, until all variables have been generated, i.e. in our
case, a new rule string has been obtained. Another set of rule strings will be
generated in this way, some of which will replace previous strings based on
fitness selection. If stopping conditions are not met, the conditional
probabilities for all nodes in the Bayesian network are updated again using the
current set of promising rule strings. Computational results from 52 real data
instances demonstrate the success of this approach. It is also suggested that
the learning mechanism in the proposed approach might be suitable for other
scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2981</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2981</id><created>2008-03-20</created><authors><author><keyname>Whitbrook</keyname><forenames>Amanda</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Garibaldi</keyname><forenames>Jonathan</forenames></author></authors><title>Idiotypic Immune Networks in Mobile Robot Control</title><categories>cs.NE cs.AI cs.RO</categories><journal-ref>IEEE Transactions on Systems, Man and Cybernetics, Part B, 37(6),
  1581- 1598, 2007</journal-ref><doi>10.1109/TSMCB.2007.907334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Jerne's idiotypic network theory postulates that the immune response involves
inter-antibody stimulation and suppression as well as matching to antigens. The
theory has proved the most popular Artificial Immune System (ais) model for
incorporation into behavior-based robotics but guidelines for implementing
idiotypic selection are scarce. Furthermore, the direct effects of employing
the technique have not been demonstrated in the form of a comparison with
non-idiotypic systems. This paper aims to address these issues. A method for
integrating an idiotypic ais network with a Reinforcement Learning based
control system (rl) is described and the mechanisms underlying antibody
stimulation and suppression are explained in detail. Some hypotheses that
account for the network advantage are put forward and tested using three
systems with increasing idiotypic complexity. The basic rl, a simplified hybrid
ais-rl that implements idiotypic selection independently of derived
concentration levels and a full hybrid ais-rl scheme are examined. The test bed
takes the form of a simulated Pioneer robot that is required to navigate
through maze worlds detecting and tracking door markers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.2995</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.2995</id><created>2008-03-20</created><updated>2008-03-22</updated><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Battisti</keyname><forenames>Giuliana</forenames></author><author><keyname>Celia</keyname><forenames>Helen</forenames></author><author><keyname>Clegg</keyname><forenames>Christopher</forenames></author><author><keyname>Fu</keyname><forenames>Xiaolan</forenames></author><author><keyname>De Hoyos</keyname><forenames>Raphael</forenames></author><author><keyname>Iona</keyname><forenames>Alfonsiana</forenames></author><author><keyname>Petrescu</keyname><forenames>Alina</forenames></author><author><keyname>Adriano</keyname><forenames>Peixoto</forenames></author></authors><title>The Role of Management Practices in Closing the Productivity Gap</title><categories>cs.OH</categories><journal-ref>AIM Working Paper Series Number 065, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is no doubt that management practices are linked to the productivity
and performance of a company. However, research findings are mixed. This paper
provides a multi-disciplinary review of the current evidence of such a
relationship and offers suggestions for further exploration. We provide an
extensive review of the literature in terms of research findings from studies
that have been trying to measure and understand the impact that individual
management practices and clusters of management practices have on productivity
at different levels of analysis. We focus our review on Operations Management
(om) and Human Resource Management (hrm) practices as well as joint
applications of these practices. In conclusion, we can say that taken as a
whole, the research findings are equivocal. Some studies have found a positive
relationship between the adoption of management practices and productivity,
some negative and some no association whatsoever. We believe that the lack of
universal consensus on the effect of the adoption of complementary management
practices might be driven either by measurement issues or by the level of
analysis. Consequently, there is a need for further research. In particular,
for a multi-level approach from the lowest possible level of aggregation up to
the firm-level of analysis in order to assess the impact of management
practices upon the productivity of firms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3363</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3363</id><created>2008-03-24</created><updated>2009-06-26</updated><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author></authors><title>Node discovery in a networked organization</title><categories>cs.AI</categories><journal-ref>Proceedings of the IEEE International Conference on Systems, Man
  and Cybernetics, San Antonio, October 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, I present a method to solve a node discovery problem in a
networked organization. Covert nodes refer to the nodes which are not
observable directly. They affect social interactions, but do not appear in the
surveillance logs which record the participants of the social interactions.
Discovering the covert nodes is defined as identifying the suspicious logs
where the covert nodes would appear if the covert nodes became overt. A
mathematical model is developed for the maximal likelihood estimation of the
network behind the social interactions and for the identification of the
suspicious logs. Precision, recall, and F measure characteristics are
demonstrated with the dataset generated from a real organization and the
computationally synthesized datasets. The performance is close to the
theoretical limit for any covert nodes in the networks of any topologies and
sizes if the ratio of the number of observation to the number of possible
communication patterns is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3459</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3459</id><created>2008-03-24</created><authors><author><keyname>Marquezino</keyname><forenames>F. L.</forenames></author><author><keyname>Portugal</keyname><forenames>R.</forenames></author></authors><title>The QWalk Simulator of Quantum Walks</title><categories>quant-ph cs.MS</categories><comments>21 pages, 11 figures. Accepted in Computer Physics Communications.
  Simulator can be downloaded from http://qubit.lncc.br/qwalk</comments><journal-ref>Computer Physics Communications, Volume 179, Issue 5, Pages
  359-369. (2008)</journal-ref><doi>10.1016/j.cpc.2008.02.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several research groups are giving special attention to quantum walks
recently, because this research area have been used with success in the
development of new efficient quantum algorithms. A general simulator of quantum
walks is very important for the development of this area, since it allows the
researchers to focus on the mathematical and physical aspects of the research
instead of deviating the efforts to the implementation of specific numerical
simulations. In this paper we present QWalk, a quantum walk simulator for one-
and two-dimensional lattices. Finite two-dimensional lattices with generic
topologies can be used. Decoherence can be simulated by performing measurements
or by breaking links of the lattice. We use examples to explain the usage of
the software and to show some recent results of the literature that are easily
reproduced by the simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3490</identifier>
 <datestamp>2010-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3490</id><created>2008-03-24</created><updated>2008-11-11</updated><authors><author><keyname>Xu</keyname><forenames>Huan</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author></authors><title>Robustness and Regularization of Support Vector Machines</title><categories>cs.LG cs.AI</categories><journal-ref>Journal of Machine Learning Research, vol 10, 1485-1510, year 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider regularized support vector machines (SVMs) and show that they are
precisely equivalent to a new robust optimization formulation. We show that
this equivalence of robust optimization and regularization has implications for
both algorithms, and analysis. In terms of algorithms, the equivalence suggests
more general SVM-like algorithms for classification that explicitly build in
protection to noise, and at the same time control overfitting. On the analysis
front, the equivalence of robustness and regularization, provides a robust
optimization interpretation for the success of regularized SVMs. We use the
this new robustness interpretation of SVMs to give a new proof of consistency
of (kernelized) SVMs, thus establishing robustness as the reason regularized
SVMs generalize well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3773</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3773</id><created>2008-03-26</created><updated>2008-04-30</updated><authors><author><keyname>Wyrembelski</keyname><forenames>Rafael F.</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias J.</forenames></author><author><keyname>Bjelakovic</keyname><forenames>Igor</forenames></author><author><keyname>Schnurr</keyname><forenames>Clemens</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>Capacity of Gaussian MIMO Bidirectional Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>Proc. IEEE International Symposium on Information Theory (ISIT 2008),
  Toronto, Canada, July 2008</comments><doi>10.1109/ISIT.2008.4595053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the broadcast phase of a three-node network, where a relay node
establishes a bidirectional communication between two nodes using a spectrally
efficient two-phase decode-and-forward protocol. In the first phase the two
nodes transmit their messages to the relay node. Then the relay node decodes
the messages and broadcasts a re-encoded composition of them in the second
phase. We consider Gaussian MIMO channels and determine the capacity region for
the second phase which we call the Gaussian MIMO bidirectional broadcast
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3816</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3816</id><created>2008-03-26</created><authors><author><keyname>Gomadam</keyname><forenames>Krishna</forenames></author><author><keyname>Cadambe</keyname><forenames>Viveck R.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Approaching the Capacity of Wireless Networks through Distributed
  Interference Alignment</title><categories>cs.IT math.IT</categories><comments>10 pages 2 columns</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 57, No. 6, June,
  2011, Pages: 3309-3322</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent results establish the optimality of interference alignment to approach
the Shannon capacity of interference networks at high SNR. However, the extent
to which interference can be aligned over a finite number of signalling
dimensions remains unknown. Another important concern for interference
alignment schemes is the requirement of global channel knowledge. In this work
we provide examples of iterative algorithms that utilize the reciprocity of
wireless networks to achieve interference alignment with only local channel
knowledge at each node. These algorithms also provide numerical insights into
the feasibility of interference alignment that are not yet available in theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3900</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3900</id><created>2008-03-27</created><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Burke</keyname><forenames>Edmund</forenames></author></authors><title>A Component Based Heuristic Search method with Adaptive Perturbations
  for Hospital Personnel Scheduling</title><categories>cs.NE cs.CE</categories><journal-ref>Technical Report NOTTCS-TR-2007-4, University of Nottingham, UK,,
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nurse rostering is a complex scheduling problem that affects hospital
personnel on a daily basis all over the world. This paper presents a new
component-based approach with adaptive perturbations, for a nurse scheduling
problem arising at a major UK hospital. The main idea behind this technique is
to decompose a schedule into its components (i.e. the allocated shift pattern
of each nurse), and then mimic a natural evolutionary process on these
components to iteratively deliver better schedules. The worthiness of all
components in the schedule has to be continuously demonstrated in order for
them to remain there. This demonstration employs a dynamic evaluation function
which evaluates how well each component contributes towards the final
objective. Two perturbation steps are then applied: the first perturbation
eliminates a number of components that are deemed not worthy to stay in the
current schedule; the second perturbation may also throw out, with a low level
of probability, some worthy components. The eliminated components are
replenished with new ones using a set of constructive heuristics using local
optimality criteria. Computational results using 52 data instances demonstrate
the applicability of the proposed approach in solving real-world problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3905</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3905</id><created>2008-03-27</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Introduction to Multi-Agent Simulation</title><categories>cs.NE cs.MA</categories><journal-ref>Encyclopaedia of Decision Making and Decision Support
  Technologies, 554-564, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When designing systems that are complex, dynamic and stochastic in nature,
simulation is generally recognised as one of the best design support
technologies, and a valuable aid in the strategic and tactical decision making
process. A simulation model consists of a set of rules that define how a system
changes over time, given its current state. Unlike analytical models, a
simulation model is not solved but is run and the changes of system states can
be observed at any point in time. This provides an insight into system dynamics
rather than just predicting the output of a system based on specific inputs.
Simulation is not a decision making tool but a decision support tool, allowing
better informed decisions to be made. Due to the complexity of the real world,
a simulation model can only be an approximation of the target system. The
essence of the art of simulation modelling is abstraction and simplification.
Only those characteristics that are important for the study and analysis of the
target system should be included in the simulation model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3912</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3912</id><created>2008-03-27</created><authors><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Dasgupta</keyname><forenames>Dipankar</forenames></author></authors><title>Artificial Immune Systems Tutorial</title><categories>cs.NE cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The biological immune system is a robust, complex, adaptive system that
defends the body from foreign pathogens. It is able to categorize all cells (or
molecules) within the body as self-cells or non-self cells. It does this with
the help of a distributed task force that has the intelligence to take action
from a local and also a global perspective using its network of chemical
messengers for communication. There are two major branches of the immune
system. The innate immune system is an unchanging mechanism that detects and
destroys certain invading organisms, whilst the adaptive immune system responds
to previously unknown foreign cells and builds a response to them that can
remain in the body over a long period of time. This remarkable information
processing biological system has caught the attention of computer science in
recent years. A novel computational intelligence technique, inspired by
immunology, has emerged, called Artificial Immune Systems. Several concepts
from the immune have been extracted and applied for solution to real world
science and engineering problems. In this tutorial, we briefly describe the
immune system metaphors that are relevant to existing Artificial Immune Systems
methods. We will then show illustrative real-world problems suitable for
Artificial Immune Systems and give a step-by-step algorithm walkthrough for one
such problem. A comparison of the Artificial Immune Systems to other well-known
algorithms, areas for future work, tips &amp; tricks and a list of resources will
round this tutorial off. It should be noted that as Artificial Immune Systems
is still a young and evolving field, there is not yet a fixed algorithm
template and hence actual implementations might differ somewhat from time to
time and from those examples given here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.3969</identifier>
 <datestamp>2013-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.3969</id><created>2008-03-27</created><updated>2013-05-22</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Bethke</keyname><forenames>Inge</forenames></author><author><keyname>Ponse</keyname><forenames>Alban</forenames></author></authors><title>Cancellation Meadows: a Generic Basis Theorem and Some Applications</title><categories>math.RA cs.LO</categories><comments>24 pages, 6 tables; Inge Bethke is added as an extra author; new
  title (previous title: A Generic Basis Theorem for Cancellation Meadows)</comments><msc-class>AC, RA</msc-class><journal-ref>The Computer Journal 56(1): 3-14, 2013</journal-ref><doi>10.1093/comjnl/bxs028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let Q_0 denote the rational numbers expanded to a "meadow", that is, after
taking its zero-totalized form (0^{-1}=0) as the preferred interpretation. In
this paper we consider "cancellation meadows", i.e., meadows without proper
zero divisors, such as $Q_0$ and prove a generic completeness result. We apply
this result to cancellation meadows expanded with differentiation operators,
the sign function, and with floor, ceiling and a signed variant of the square
root, respectively. We give an equational axiomatization of these operators and
thus obtain a finite basis for various expanded cancellation meadows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.4074</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.4074</id><created>2008-03-28</created><updated>2009-02-02</updated><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author><author><keyname>Ohsawa</keyname><forenames>Yukio</forenames></author></authors><title>Reflective visualization and verbalization of unconscious preference</title><categories>cs.AI</categories><comments>This will be submitted to KES Journal</comments><journal-ref>International Journal of Advanced Intelligence Paradigms Vol.2,
  pp.125-139 (2010)</journal-ref><doi>10.1504/IJAIP.2010.030531</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method is presented, that can help a person become aware of his or her
unconscious preferences, and convey them to others in the form of verbal
explanation. The method combines the concepts of reflection, visualization, and
verbalization. The method was tested in an experiment where the unconscious
preferences of the subjects for various artworks were investigated. In the
experiment, two lessons were learned. The first is that it helps the subjects
become aware of their unconscious preferences to verbalize weak preferences as
compared with strong preferences through discussion over preference diagrams.
The second is that it is effective to introduce an adjustable factor into
visualization to adapt to the differences in the subjects and to foster their
mutual understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.4197</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.4197</id><created>2008-03-31</created><updated>2008-09-13</updated><authors><author><keyname>Privman</keyname><forenames>V.</forenames></author><author><keyname>Strack</keyname><forenames>G.</forenames></author><author><keyname>Solenov</keyname><forenames>D.</forenames></author><author><keyname>Pita</keyname><forenames>M.</forenames></author><author><keyname>Katz</keyname><forenames>E.</forenames></author></authors><title>Optimization of Enzymatic Biochemical Logic for Noise Reduction and
  Scalability: How Many Biocomputing Gates Can Be Interconnected in a Circuit?</title><categories>q-bio.MN cond-mat.other cond-mat.soft cs.CC q-bio.BM q-bio.OT q-bio.QM quant-ph</categories><journal-ref>J. Phys. Chem. B 112, 11777-11784 (2008)</journal-ref><doi>10.1021/jp802673q</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report an experimental evaluation of the "input-output surface" for a
biochemical AND gate. The obtained data are modeled within the rate-equation
approach, with the aim to map out the gate function and cast it in the language
of logic variables appropriate for analysis of Boolean logic for scalability.
In order to minimize "analog" noise, we consider a theoretical approach for
determining an optimal set for the process parameters to minimize "analog"
noise amplification for gate concatenation. We establish that under optimized
conditions, presently studied biochemical gates can be concatenated for up to
order 10 processing steps. Beyond that, new paradigms for avoiding noise
build-up will have to be developed. We offer a general discussion of the ideas
and possible future challenges for both experimental and theoretical research
for advancing scalable biochemical computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.4354</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.4354</id><created>2008-03-30</created><updated>2014-03-18</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>A O(n^8) X O(n^7) Linear Programming Model of the Traveling Salesman
  Problem</title><categories>cs.DM</categories><comments>Theorem 25 and Corollary 26 are incorrect. The modeling needs
  9-dimensional variables instead of the 8-dimensional variables defined in
  notations 10.2</comments><acm-class>G.1.6; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn because Theorem 25 and Corollary 26 are
incorrect. The modeling idea is OK but it needs 9-dimensional variables instead
of the 8-dimensional variables defined in notations 10.2.
  Examples of the correct model (with 9-index variables) are: (1) Diaby, M.,
"Linear Programming Formulation of the Set Partitioning Problem," International
Journal of Operational Research 8:4 (August 2010) pp. 399-427; (2) Diaby, M.,
"Linear Programming Formulation of the Vertex Coloring Problem," International
Journal of Mathematics in Operational Research 2:3 (May 2010) pp. 259-289; (3)
Diaby, M., "The Traveling Salesman Problem: A Linear Programming Formulation,"
WSEAS Transactions on Mathematics, 6:6 (June 2007) pp. 745-754.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0803.4479</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0803.4479</id><created>2008-03-31</created><updated>2008-04-23</updated><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Saidi</keyname><forenames>Olivier</forenames></author></authors><title>Unconditionally secure computers, algorithms and hardware, such as
  memories, processors, keyboards, flash and hard drives</title><categories>physics.gen-ph cs.CR</categories><comments>4 pages</comments><journal-ref>Fluctuation and Noise Letters 8 (2008) L95-L98</journal-ref><doi>10.1142/S0219477508004362</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the case of the need of extraordinary security,
Kirchhoff-loop-Johnson-(like)-noise ciphers can easily be integrated on
existing types of digital chips in order to provide secure data communication
between hardware processors, memory chips, hard disks and other units within a
computer or other data processor system. The secure key exchange can take place
at the very first run and the system can renew the key later at random times
with an authenticated fashion to prohibit man-in-the-middle attack. The key can
be stored in flash memories within the communicating chip units at hidden
random addresses among other random bits that are continuously generated by the
secure line but are never actually used. Thus, even if the system is
disassembled, and the eavesdropper can have direct access to the communication
lines between the units, or even if she is trying to use a man-in-the-middle
attack, no information can be extracted. The only way to break the code is to
learn the chip structure, to understand the machine code program and to read
out the information during running by accessing the proper internal ports of
the working chips. However such an attack needs extraordinary resources and
even that can be prohibited by a password lockout. The unconditional security
of commercial algorithms against piracy can be provided in a similar way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0041</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0041</id><created>2008-03-31</created><authors><author><keyname>Stojnic</keyname><forenames>Mihailo</forenames></author><author><keyname>Parvaresh</keyname><forenames>Farzad</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>On the reconstruction of block-sparse signals with an optimal number of
  measurements</title><categories>cs.IT cs.NA math.IT</categories><doi>10.1016/j.jmr.2011.02.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let A be an M by N matrix (M &lt; N) which is an instance of a real random
Gaussian ensemble. In compressed sensing we are interested in finding the
sparsest solution to the system of equations A x = y for a given y. In general,
whenever the sparsity of x is smaller than half the dimension of y then with
overwhelming probability over A the sparsest solution is unique and can be
found by an exhaustive search over x with an exponential time complexity for
any y. The recent work of Cand\'es, Donoho, and Tao shows that minimization of
the L_1 norm of x subject to A x = y results in the sparsest solution provided
the sparsity of x, say K, is smaller than a certain threshold for a given
number of measurements. Specifically, if the dimension of y approaches the
dimension of x, the sparsity of x should be K &lt; 0.239 N. Here, we consider the
case where x is d-block sparse, i.e., x consists of n = N / d blocks where each
block is either a zero vector or a nonzero vector. Instead of L_1-norm
relaxation, we consider the following relaxation min x \| X_1 \|_2 + \| X_2
\|_2 + ... + \| X_n \|_2, subject to A x = y where X_i = (x_{(i-1)d+1},
x_{(i-1)d+2}, ..., x_{i d}) for i = 1,2, ..., N. Our main result is that as n
-&gt; \infty, the minimization finds the sparsest solution to Ax = y, with
overwhelming probability in A, for any x whose block sparsity is k/n &lt; 1/2 -
O(\epsilon), provided M/N &gt; 1 - 1/d, and d = \Omega(\log(1/\epsilon)/\epsilon).
The relaxation can be solved in polynomial time using semi-definite
programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0318</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0318</id><created>2008-04-02</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author><author><keyname>Schreckenberg</keyname><forenames>Michael</forenames></author></authors><title>Moore and more and symmetry</title><categories>cs.MA physics.comp-ph</categories><comments>Proceedings contribution in N. Waldau et al. (editors) "Pedestrian
  and Evacuation Dynamics 2005" (2006) pages 297-308. Springer-Verlag Berlin
  Heidelberg. ISBN: 978-3-540-47062-5</comments><doi>10.1007/978-3-540-47064-9_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In any spatially discrete model of pedestrian motion which uses a regular
lattice as basis, there is the question of how the symmetry between the
different directions of motion can be restored as far as possible but with
limited computational effort. This question is equivalent to the question ''How
important is the orientation of the axis of discretization for the result of
the simulation?'' An optimization in terms of symmetry can be combined with the
implementation of higher and heterogeniously distributed walking speeds by
representing different walking speeds via different amounts of cells an agent
may move during one round. Therefore all different possible neighborhoods for
speeds up to v = 10 (cells per round) will be examined for the amount of
deviation from radial symmetry. Simple criteria will be stated which will allow
find an optimal neighborhood for each speed. It will be shown that following
these criteria even the best mixture of steps in Moore and von Neumann
neighborhoods is unable to reproduce the optimal neighborhood for a speed as
low as 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0409</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0409</id><created>2008-04-02</created><updated>2010-01-03</updated><authors><author><keyname>Otmani</keyname><forenames>Ayoub</forenames></author><author><keyname>Tillich</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Dallot</keyname><forenames>Leonard</forenames></author></authors><title>Cryptanalysis of Two McEliece Cryptosystems Based on Quasi-Cyclic Codes</title><categories>cs.CR cs.DM</categories><comments>Major corrections. This version supersedes previuos ones</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We cryptanalyse here two variants of the McEliece cryptosystem based on
quasi-cyclic codes. Both aim at reducing the key size by restricting the public
and secret generator matrices to be in quasi-cyclic form. The first variant
considers subcodes of a primitive BCH code. We prove that this variant is not
secure by finding and solving a linear system satisfied by the entries of the
secret permutation matrix.
  The other variant uses quasi-cyclic low density parity-check codes. This
scheme was devised to be immune against general attacks working for McEliece
type cryptosystems based on low density parity-check codes by choosing in the
McEliece scheme more general one-to-one mappings than permutation matrices. We
suggest here a structural attack exploiting the quasi-cyclic structure of the
code and a certain weakness in the choice of the linear transformations that
hide the generator matrix of the code. Our analysis shows that with high
probability a parity-check matrix of a punctured version of the secret code can
be recovered in cubic time complexity in its length. The complete
reconstruction of the secret parity-check matrix of the quasi-cyclic low
density parity-check codes requires the search of codewords of low weight which
can be done with about $2^{37}$ operations for the specific parameters
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0510</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0510</id><created>2008-04-03</created><updated>2012-04-03</updated><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Ryabko</keyname><forenames>Boris</forenames><affiliation>SIBSUTI, ICT SBRAS</affiliation></author></authors><title>Nonparametric Statistical Inference for Ergodic Processes</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Conference version in: D. Ryabko, B. Ryabko, On hypotheses testing
  for ergodic processes, in Proceedgings of Information Theory Workshop, 2008,
  Porto, Portugal, pp. 281-283</comments><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Information Theory 56, 3 (2010) 1430-1435</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a method for statistical analysis of time series is proposed,
which is used to obtain solutions to some classical problems of mathematical
statistics under the only assumption that the process generating the data is
stationary ergodic. Namely, three problems are considered: goodness-of-fit (or
identity) testing, process classification, and the change point problem. For
each of the problems a test is constructed that is asymptotically accurate for
the case when the data is generated by stationary ergodic processes. The tests
are based on empirical estimates of distributional distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0524</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0524</id><created>2008-04-03</created><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Bayesian Optimisation Algorithm for Nurse Scheduling</title><categories>cs.NE cs.CE</categories><journal-ref>Scalable Optimization via Probabilistic Modeling: From Algorithms
  to Applications (Studies in Computational Intelligence), edited by M Pelikan,
  K Sastry and E Cantu Paz, Chapter 17, pp 315-332, Springer, 2006</journal-ref><doi>10.1007/978-3-540-34954-9_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our research has shown that schedules can be built mimicking a human
scheduler by using a set of rules that involve domain knowledge. This chapter
presents a Bayesian Optimization Algorithm (BOA) for the nurse scheduling
problem that chooses such suitable scheduling rules from a set for each nurses
assignment. Based on the idea of using probabilistic models, the BOA builds a
Bayesian network for the set of promising solutions and samples these networks
to generate new candidate solutions. Computational results from 52 real data
instances demonstrate the success of this approach. It is also suggested that
the learning mechanism in the proposed algorithm may be suitable for other
scheduling problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0573</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0573</id><created>2008-04-03</created><authors><author><keyname>Morrison</keyname><forenames>Tom</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>An Artificial Immune System as a Recommender System for Web Sites</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the 1st International Conference on Artificial
  Immune Systems (ICARIS 2002), pp 161-169, Canterbury, UK, 2002</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Immune Systems have been used successfully to build recommender
systems for film databases. In this research, an attempt is made to extend this
idea to web site recommendation. A collection of more than 1000 individuals web
profiles (alternatively called preferences / favourites / bookmarks file) will
be used. URLs will be classified using the DMOZ (Directory Mozilla) database of
the Open Directory Project as our ontology. This will then be used as the data
for the Artificial Immune Systems rather than the actual addresses. The first
attempt will involve using a simple classification code number coupled with the
number of pages within that classification code. However, this implementation
does not make use of the hierarchical tree-like structure of DMOZ.
Consideration will then be given to the construction of a similarity measure
for web profiles that makes use of this hierarchical information to build a
better-informed Artificial Immune System.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0580</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0580</id><created>2008-04-03</created><authors><author><keyname>Li</keyname><forenames>Jingpeng</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Explicit Learning: an Effort towards Human Scheduling Algorithms</title><categories>cs.NE cs.AI</categories><journal-ref>Proceedings of the 1st Multidisciplinary International Conference
  on Scheduling: Theory and Applications (MISTA 2003), pp 240-241, Nottingham,
  UK 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scheduling problems are generally NP-hard combinatorial problems, and a lot
of research has been done to solve these problems heuristically. However, most
of the previous approaches are problem-specific and research into the
development of a general scheduling algorithm is still in its infancy.
  Mimicking the natural evolutionary process of the survival of the fittest,
Genetic Algorithms (GAs) have attracted much attention in solving difficult
scheduling problems in recent years. Some obstacles exist when using GAs: there
is no canonical mechanism to deal with constraints, which are commonly met in
most real-world scheduling problems, and small changes to a solution are
difficult. To overcome both difficulties, indirect approaches have been
presented (in [1] and [2]) for nurse scheduling and driver scheduling, where
GAs are used by mapping the solution space, and separate decoding routines then
build solutions to the original problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0629</identifier>
 <datestamp>2012-07-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0629</id><created>2008-04-03</created><updated>2012-03-06</updated><authors><author><keyname>Kalka</keyname><forenames>Arkadius</forenames></author><author><keyname>Teicher</keyname><forenames>Mina</forenames></author><author><keyname>Tsaban</keyname><forenames>Boaz</forenames></author></authors><title>Short expressions of permutations as products and cryptanalysis of the
  Algebraic Eraser</title><categories>math.GR cs.CR math.CO math.PR</categories><comments>Final version, accepted to Advances in Applied Mathematics. Title
  slightly changed</comments><journal-ref>Advances in Applied Mathematics 49 (2012) 57-76</journal-ref><doi>10.1016/j.aam.2012.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  On March 2004, Anshel, Anshel, Goldfeld, and Lemieux introduced the
\emph{Algebraic Eraser} scheme for key agreement over an insecure channel,
using a novel hybrid of infinite and finite noncommutative groups. They also
introduced the \emph{Colored Burau Key Agreement Protocol (CBKAP)}, a concrete
realization of this scheme.
  We present general, efficient heuristic algorithms, which extract the shared
key out of the public information provided by CBKAP. These algorithms are,
according to heuristic reasoning and according to massive experiments,
successful for all sizes of the security parameters, assuming that the keys are
chosen with standard distributions.
  Our methods come from probabilistic group theory (permutation group actions
and expander graphs). In particular, we provide a simple algorithm for finding
short expressions of permutations in $S_n$, as products of given random
permutations. Heuristically, our algorithm gives expressions of length
$O(n^2\log n)$, in time and space $O(n^3)$. Moreover, this is provable from
\emph{the Minimal Cycle Conjecture}, a simply stated hypothesis concerning the
uniform distribution on $S_n$. Experiments show that the constants in these
estimations are small. This is the first practical algorithm for this problem
for $n\ge 256$.
  Remark: \emph{Algebraic Eraser} is a trademark of SecureRF. The variant of
CBKAP actually implemented by SecureRF uses proprietary distributions, and thus
our results do not imply its vulnerability. See also arXiv:abs/12020598
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0686</identifier>
 <datestamp>2011-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0686</id><created>2008-04-04</created><authors><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Discrimination of two channels by adaptive methods and its application
  to quantum system</title><categories>quant-ph cs.IT math.IT math.ST stat.TH</categories><journal-ref>IEEE Transactions on Information Theory, Volume 55, Issue 8, 3807
  - 3820 (2009)</journal-ref><doi>10.1109/TIT.2009.2023726</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The optimal exponential error rate for adaptive discrimination of two
channels is discussed. In this problem, adaptive choice of input signal is
allowed. This problem is discussed in various settings. It is proved that
adaptive choice does not improve the exponential error rate in these settings.
These results are applied to quantum state discrimination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0722</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0722</id><created>2008-04-04</created><updated>2009-03-13</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author></authors><title>A Memetic Algorithm for the Generalized Traveling Salesman Problem</title><categories>cs.DS</categories><comments>15 pages, to appear in Natural Computing, Springer, available online:
  http://www.springerlink.com/content/5v4568l492272865/?p=e1779dd02e4d4cbfa49d0d27b19b929f&amp;pi=13</comments><journal-ref>Natural Computing 9(1) (2010) 47-60</journal-ref><doi>10.1007/s11047-009-9111-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized traveling salesman problem (GTSP) is an extension of the
well-known traveling salesman problem. In GTSP, we are given a partition of
cities into groups and we are required to find a minimum length tour that
includes exactly one city from each group. The recent studies on this subject
consider different variations of a memetic algorithm approach to the GTSP. The
aim of this paper is to present a new memetic algorithm for GTSP with a
powerful local search procedure. The experiments show that the proposed
algorithm clearly outperforms all of the known heuristics with respect to both
solution quality and running time. While the other memetic algorithms were
designed only for the symmetric GTSP, our algorithm can solve both symmetric
and asymmetric instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0735</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0735</id><created>2008-04-04</created><updated>2009-04-14</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author></authors><title>Generalized Traveling Salesman Problem Reduction Algorithms</title><categories>cs.DS</categories><comments>To appear in Algorithmic Operations Research</comments><journal-ref>Algorithmic Operations Research 4 (2009) 144-154</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generalized traveling salesman problem (GTSP) is an extension of the
well-known traveling salesman problem. In GTSP, we are given a partition of
cities into groups and we are required to find a minimum length tour that
includes exactly one city from each group. The aim of this paper is to present
a problem reduction algorithm that deletes redundant vertices and edges,
preserving the optimal solution. The algorithm's running time is O(N^3) in the
worst case, but it is significantly faster in practice. The algorithm has
reduced the problem size by 15-20% on average in our experiments and this has
decreased the solution time by 10-60% for each of the considered solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.0813</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.0813</id><created>2008-04-04</created><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Berry</keyname><forenames>Randall A.</forenames></author></authors><title>Spatial Interference Cancelation for Mobile Ad Hoc Networks: Perfect CSI</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages; submitted to IEEE Globecom 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference between nodes directly limits the capacity of mobile ad hoc
networks. This paper focuses on spatial interference cancelation with perfect
channel state information (CSI), and analyzes the corresponding network
capacity. Specifically, by using multiple antennas, zero-forcing beamforming is
applied at each receiver for canceling the strongest interferers. Given spatial
interference cancelation, the network transmission capacity is analyzed in this
paper, which is defined as the maximum transmitting node density under
constraints on outage and the signal-to-interference-noise ratio. Assuming the
Poisson distribution for the locations of network nodes and spatially i.i.d.
Rayleigh fading channels, mathematical tools from stochastic geometry are
applied for deriving scaling laws for transmission capacity. Specifically, for
small target outage probability, transmission capacity is proved to increase
following a power law, where the exponent is the inverse of the size of antenna
array or larger depending on the pass loss exponent. As shown by simulations,
spatial interference cancelation increases transmission capacity by an order of
magnitude or more even if only one extra antenna is added to each node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1021</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1021</id><created>2008-04-07</created><authors><author><keyname>Villard</keyname><forenames>Gilles</forenames><affiliation>LIP</affiliation></author></authors><title>Differentiation of Kaltofen's division-free determinant algorithm</title><categories>cs.SC cs.MS</categories><proxy>ccsd ensl-00270753</proxy><journal-ref>Journal of Symbolic Computation 7, 46 (2011) 773-790</journal-ref><doi>10.1016/j.jsc.2010.08.012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kaltofen has proposed a new approach in [Kaltofen 1992] for computing matrix
determinants. The algorithm is based on a baby steps/giant steps construction
of Krylov subspaces, and computes the determinant as the constant term of a
characteristic polynomial. For matrices over an abstract field and by the
results of Baur and Strassen 1983, the determinant algorithm, actually a
straight-line program, leads to an algorithm with the same complexity for
computing the adjoint of a matrix [Kaltofen 1992]. However, the latter is
obtained by the reverse mode of automatic differentiation and somehow is not
``explicit''. We study this adjoint algorithm, show how it can be implemented
(without resorting to an automatic transformation), and demonstrate its use on
polynomial matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1183</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1183</id><created>2008-04-08</created><authors><author><keyname>Muramatsu</keyname><forenames>Jun</forenames></author><author><keyname>Miyake</keyname><forenames>Shigeki</forenames></author></authors><title>Hash Property and Fixed-rate Universal Coding Theorems</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, Mar. 2008. 15
  pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 6, pp.
  2688-2698, June 2010. Corrections: IEEE Transactions on Information Theory,
  vol. 58, no. 5, pp. 3305-3307, May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove the achievability of fixed-rate universal
coding problems by using our previously introduced notion of hash property.
These problems are the fixed-rate lossless universal source coding problem and
the fixed-rate universal channel coding problem. Since an ensemble of sparse
matrices satisfies the hash property requirement, it is proved that we can
construct universal codes by using sparse matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1244</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1244</id><created>2008-04-08</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>Geometric Data Analysis, From Correspondence Analysis to Structured Data
  Analysis (book review)</title><categories>cs.AI</categories><comments>5 pages, 8 citations. Accepted in Journal of Classification</comments><acm-class>I.5; G.3; H.3; I.7; J.4</acm-class><journal-ref>Journal of Classification 25, 137-141, 2008</journal-ref><doi>10.1007/s00357-008-9007-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Review of: Brigitte Le Roux and Henry Rouanet, Geometric Data Analysis, From
Correspondence Analysis to Structured Data Analysis, Kluwer, Dordrecht, 2004,
xi+475 pp.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1266</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1266</id><created>2008-04-08</created><authors><author><keyname>Kim</keyname><forenames>Jungwon</forenames></author><author><keyname>Bentley</keyname><forenames>Peter J.</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author><author><keyname>Greensmith</keyname><forenames>Julie</forenames></author><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Twycross</keyname><forenames>Jamie</forenames></author></authors><title>Immune System Approaches to Intrusion Detection - A Review</title><categories>cs.NE cs.CR</categories><journal-ref>Natural Computing, 6(4), pp 413-466, 2007</journal-ref><doi>10.1007/s11047-006-9026-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of artificial immune systems in intrusion detection is an appealing
concept for two reasons. Firstly, the human immune system provides the human
body with a high level of protection from invading pathogens, in a robust,
self-organised and distributed manner. Secondly, current techniques used in
computer security are not able to cope with the dynamic and increasingly
complex nature of computer systems and their security. It is hoped that
biologically inspired approaches in this area, including the use of
immune-based systems will be able to meet this challenge. Here we review the
algorithms used, the development of the systems and the outcome of their
implementation. We provide an introduction and analysis of the key developments
within this field, in addition to making suggestions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1281</identifier>
 <datestamp>2010-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1281</id><created>2008-04-08</created><updated>2008-05-16</updated><authors><author><keyname>Tedesco</keyname><forenames>Gianni</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Data Reduction in Intrusion Alert Correlation</title><categories>cs.CR cs.NE</categories><journal-ref>WSEAS Transactions on Computers, 5(1), pp 186-193, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network intrusion detection sensors are usually built around low level models
of network traffic. This means that their output is of a similarly low level
and as a consequence, is difficult to analyze. Intrusion alert correlation is
the task of automating some of this analysis by grouping related alerts
together. Attack graphs provide an intuitive model for such analysis.
Unfortunately alert flooding attacks can still cause a loss of service on
sensors, and when performing attack graph correlation, there can be a large
number of extraneous alerts included in the output graph. This obscures the
fine structure of genuine attacks and makes them more difficult for human
operators to discern. This paper explores modified correlation algorithms which
attempt to minimize the impact of this attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1667</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1667</id><created>2008-04-10</created><updated>2010-05-03</updated><authors><author><keyname>Urban</keyname><forenames>Christian</forenames></author><author><keyname>Cheney</keyname><forenames>James</forenames></author><author><keyname>Berghofer</keyname><forenames>Stefan</forenames></author></authors><title>Mechanizing the Metatheory of LF</title><categories>cs.LO</categories><comments>Accepted to ACM Transactions on Computational Logic. Preprint.</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LF is a dependent type theory in which many other formal systems can be
conveniently embedded. However, correct use of LF relies on nontrivial
metatheoretic developments such as proofs of correctness of decision procedures
for LF's judgments. Although detailed informal proofs of these properties have
been published, they have not been formally verified in a theorem prover. We
have formalized these properties within Isabelle/HOL using the Nominal Datatype
Package, closely following a recent article by Harper and Pfenning. In the
process, we identified and resolved a gap in one of the proofs and a small
number of minor lacunae in others. We also formally derive a version of the
type checking algorithm from which Isabelle/HOL can generate executable code.
Besides its intrinsic interest, our formalization provides a foundation for
studying the adequacy of LF encodings, the correctness of Twelf-style
metatheoretic reasoning, and the metatheory of extensions to LF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1729</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1729</id><created>2008-04-10</created><updated>2008-09-03</updated><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Dogguy</keyname><forenames>Mehdi</forenames><affiliation>PPS</affiliation></author></authors><title>On affine usages in signal-based communication</title><categories>cs.LO</categories><proxy>ccsd hal-00272023</proxy><journal-ref>Programming Languages and Systems, 6th Asian Symposium, APLAS
  2008, France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a type system for a synchronous pi-calculus formalising the
notion of affine usage in signal-based communication. In particular, we
identify a limited number of usages that preserve affinity and that can be
composed. As a main application of the resulting system, we show that typable
programs are deterministic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1777</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1777</id><created>2008-04-10</created><updated>2009-03-20</updated><authors><author><keyname>Dereniowski</keyname><forenames>Dariusz</forenames></author></authors><title>Phutball is PSPACE-hard</title><categories>cs.GT cs.DM</categories><comments>13 pages, 7 figures</comments><acm-class>F.2.2</acm-class><journal-ref>Theoretical Computer Science 411 (2010) 3971-3978</journal-ref><doi>10.1016/j.tcs.2010.08.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the $n\times n$ game of Phutball. It is shown that, given an
arbitrary position of stones on the board, it is a PSPACE-hard problem to
determine whether the specified player can win the game, regardless of the
opponent's choices made during the game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.1839</identifier>
 <datestamp>2010-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.1839</id><created>2008-04-11</created><authors><author><keyname>Fletcher</keyname><forenames>Alyson K.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K.</forenames></author></authors><title>Necessary and Sufficient Conditions on Sparsity Pattern Recovery</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. on Information Theory, vol. 55, no. 12, pp. 5758-5772,
  December 2009</journal-ref><doi>10.1109/TIT.2009.2032726</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of detecting the sparsity pattern of a k-sparse vector in R^n
from m random noisy measurements is of interest in many areas such as system
identification, denoising, pattern recognition, and compressed sensing. This
paper addresses the scaling of the number of measurements m, with signal
dimension n and sparsity-level nonzeros k, for asymptotically-reliable
detection. We show a necessary condition for perfect recovery at any given SNR
for all algorithms, regardless of complexity, is m = Omega(k log(n-k))
measurements. Conversely, it is shown that this scaling of Omega(k log(n-k))
measurements is sufficient for a remarkably simple ``maximum correlation''
estimator. Hence this scaling is optimal and does not require more
sophisticated techniques such as lasso or matching pursuit. The constants for
both the necessary and sufficient conditions are precisely defined in terms of
the minimum-to-average ratio of the nonzero components and the SNR. The
necessary condition improves upon previous results for maximum likelihood
estimation. For lasso, it also provides a necessary condition at any SNR and
for low SNR improves upon previous work. The sufficient condition provides the
first asymptotically-reliable detection guarantee at finite SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.2036</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.2036</id><created>2008-04-12</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Towards Physarum robots: computing and manipulating on water surface</title><categories>cs.RO cs.AI</categories><comments>Submitted to Int J Intelligent and Robotic Systems, February 2008</comments><journal-ref>Journal of Bionic Engineering Volume 5, Issue 4, December 2008,
  Pages 348-357</journal-ref><doi>10.1016/S1672-6529(08)60180-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plasmodium of Physarym polycephalum is an ideal biological substrate for
implementing concurrent and parallel computation, including combinatorial
geometry and optimization on graphs. We report results of scoping experiments
on Physarum computing in conditions of minimal friction, on the water surface.
We show that plasmodium of Physarum is capable for computing a basic spanning
trees and manipulating of light-weight objects. We speculate that our results
pave the pathways towards design and implementation of amorphous biological
robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.2138</identifier>
 <datestamp>2012-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.2138</id><created>2008-04-14</created><authors><author><keyname>Lember</keyname><forenames>J.</forenames></author><author><keyname>Koloydenko</keyname><forenames>A.</forenames></author></authors><title>A constructive proof of the existence of Viterbi processes</title><categories>math.ST cs.IT math.IT math.PR stat.CO stat.ML stat.TH</categories><comments>Submitted to the IEEE Transactions on Information Theory, focuses on
  the proofs of the results presented in arXiv:0709.2317, and arXiv:0803.2394</comments><journal-ref>IEEE Transactions on Information Theory, volume 56, issue 4, 2010,
  pages 2017 - 2033</journal-ref><doi>10.1109/TIT.2010.2040897</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the early days of digital communication, hidden Markov models (HMMs)
have now been also routinely used in speech recognition, processing of natural
languages, images, and in bioinformatics. In an HMM $(X_i,Y_i)_{i\ge 1}$,
observations $X_1,X_2,...$ are assumed to be conditionally independent given an
``explanatory'' Markov process $Y_1,Y_2,...$, which itself is not observed;
moreover, the conditional distribution of $X_i$ depends solely on $Y_i$.
Central to the theory and applications of HMM is the Viterbi algorithm to find
{\em a maximum a posteriori} (MAP) estimate $q_{1:n}=(q_1,q_2,...,q_n)$ of
$Y_{1:n}$ given observed data $x_{1:n}$. Maximum {\em a posteriori} paths are
also known as Viterbi paths or alignments. Recently, attempts have been made to
study the behavior of Viterbi alignments when $n\to \infty$. Thus, it has been
shown that in some special cases a well-defined limiting Viterbi alignment
exists. While innovative, these attempts have relied on rather strong
assumptions and involved proofs which are existential. This work proves the
existence of infinite Viterbi alignments in a more constructive manner and for
a very general class of HMMs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.2337</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.2337</id><created>2008-04-15</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Schost</keyname><forenames>Éric</forenames></author></authors><title>Power Series Composition and Change of Basis</title><categories>cs.SC</categories><proxy>ccsd inria-00273385</proxy><doi>10.1145/1390768.1390806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient algorithms are known for many operations on truncated power series
(multiplication, powering, exponential, ...). Composition is a more complex
task. We isolate a large class of power series for which composition can be
performed efficiently. We deduce fast algorithms for converting polynomials
between various bases, including Euler, Bernoulli, Fibonacci, and the
orthogonal Laguerre, Hermite, Jacobi, Krawtchouk, Meixner and
Meixner-Pollaczek.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.2373</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.2373</id><created>2008-04-15</created><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Schost</keyname><forenames>Éric</forenames></author></authors><title>Fast Conversion Algorithms for Orthogonal Polynomials</title><categories>cs.SC</categories><proxy>ccsd inria-00273508</proxy><doi>10.1016/j.laa.2009.08.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss efficient conversion algorithms for orthogonal polynomials. We
describe a known conversion algorithm from an arbitrary orthogonal basis to the
monomial basis, and deduce a new algorithm of the same complexity for the
converse operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.2469</identifier>
 <datestamp>2015-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.2469</id><created>2008-04-15</created><updated>2009-02-10</updated><authors><author><keyname>Schönhuth</keyname><forenames>Alexander</forenames></author></authors><title>On analytic properties of entropy rate</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, to appear</comments><journal-ref>IEEE Transactions on Information Theory, 55(5), 2119-2127, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entropy rate is a real valued functional on the space of discrete random
sources which lacks a closed formula even for subclasses of sources which have
intuitive parameterizations. A good way to overcome this problem is to examine
its analytic properties relative to some reasonable topology. A canonical
choice of a topology is that of the norm of total variation as it immediately
arises with the idea of a discrete random source as a probability measure on
sequence space. It is shown that entropy rate is Lipschitzian relative to this
topology, which, by well known facts, is close to differentiability. An
application of this theorem leads to a simple and elementary proof of the
existence of entropy rate of random sources with finite evolution dimension.
This class of sources encompasses arbitrary hidden Markov sources and quantum
random walks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.2576</identifier>
 <datestamp>2010-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.2576</id><created>2008-04-16</created><updated>2009-10-01</updated><authors><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author></authors><title>Interlace Polynomials: Enumeration, Unimodality, and Connections to
  Codes</title><categories>math.CO cs.IT math.IT</categories><comments>19 pages, 17 figures</comments><journal-ref>Discrete Appl. Math. 158(6), pp. 636-648, 2010.</journal-ref><doi>10.1016/j.dam.2009.11.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interlace polynomial q was introduced by Arratia, Bollobas, and Sorkin.
It encodes many properties of the orbit of a graph under edge local
complementation (ELC). The interlace polynomial Q, introduced by Aigner and van
der Holst, similarly contains information about the orbit of a graph under
local complementation (LC). We have previously classified LC and ELC orbits,
and now give an enumeration of the corresponding interlace polynomials of all
graphs of order up to 12. An enumeration of all circle graphs of order up to 12
is also given. We show that there exist graphs of all orders greater than 9
with interlace polynomials q whose coefficient sequences are non-unimodal,
thereby disproving a conjecture by Arratia et al. We have verified that for
graphs of order up to 12, all polynomials Q have unimodal coefficients. It has
been shown that LC and ELC orbits of graphs correspond to equivalence classes
of certain error-correcting codes and quantum states. We show that the
properties of these codes and quantum states are related to properties of the
associated interlace polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3064</identifier>
 <datestamp>2013-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3064</id><created>2008-04-18</created><updated>2008-06-04</updated><authors><author><keyname>Kostakos</keyname><forenames>Vassilis</forenames></author><author><keyname>Kostakos</keyname><forenames>Panos A.</forenames></author></authors><title>Intelligence gathering by capturing the social processes within prisons</title><categories>cs.CY</categories><comments>21 pages, 7 Figures, 1 table</comments><journal-ref>International Journal of Pervasive Computing and Communications,
  6(4):423-431, 2010</journal-ref><doi>10.1108/17427371011097622</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a prototype system that can be used to capture longitudinal
socialising processes by recording people's encounters in space. We argue that
such a system can usefully be deployed in prisons and other detention
facilities in order help intelligence analysts assess the behaviour or
terrorist and organised crime groups, and their potential relationships. Here
we present the results of a longitudinal study, carried out with civilians,
which demonstrates the capabilities of our system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3215</identifier>
 <datestamp>2013-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3215</id><created>2008-04-20</created><authors><author><keyname>der Heiden</keyname><forenames>Matthias an</forenames></author><author><keyname>Sortais</keyname><forenames>Michel</forenames></author><author><keyname>Scheutzow</keyname><forenames>Michael</forenames></author><author><keyname>Reisslein</keyname><forenames>Martin</forenames></author><author><keyname>Maier</keyname><forenames>Martin</forenames></author></authors><title>Multicast Capacity of Optical WDM Packet Ring for Hotspot Traffic</title><categories>cs.IT math.IT</categories><doi>10.1016/j.osn.2011.05.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Packet-switching WDM ring networks with a hotspot transporting unicast,
multicast, and broadcast traffic are important components of high-speed
metropolitan area networks. For an arbitrary multicast fanout traffic model
with uniform, hotspot destination, and hotspot source packet traffic, we
analyze the maximum achievable long-run average packet throughput, which we
refer to as \textit{multicast capacity}, of bi-directional shortest-path routed
WDM rings. We identify three segments that can experience the maximum
utilization, and thus, limit the multicast capacity. We characterize the
segment utilization probabilities through bounds and approximations, which we
verify through simulations. We discover that shortest-path routing can lead to
utilization probabilities above one half for moderate to large portions of
hotspot source multi- and broadcast traffic, and consequently multicast
capacities of less than two simultaneous packet transmissions. We outline a
one-copy routing strategy that guarantees a multicast capacity of at least two
simultaneous packet transmissions for arbitrary hotspot source traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3241</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3241</id><created>2008-04-21</created><updated>2013-11-23</updated><authors><author><keyname>Vergara</keyname><forenames>Sossio</forenames></author></authors><title>A Synthesizer Based on Frequency-Phase Analysis and Square Waves</title><categories>cs.SD cs.DM</categories><comments>9 pages. Digital Signal Processing Journal 22 (2012)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces an effective generalization of the polar flavor of
the Fourier Theorem based on a new method of analysis. Under the premises of
the new theory an ample class of functions become viable as bases, with the
further advantage of using the same basis for analysis and reconstruction. In
fact other tools, like the wavelets, admit specially built nonorthogonal bases
but require different bases for analysis and reconstruction (biorthogonal and
dual bases) and vectorial coordinates; this renders those systems unintuitive
and computing intensive. As an example of the advantages of the new
generalization of the Fourier Theorem, this paper introduces a novel method for
the synthesis that is based on frequency-phase series of square waves (the
equivalent of the polar Fourier Theorem but for nonorthogonal bases). The
resulting synthesizer is very efficient needing only few components, frugal in
terms of computing needs, and viable for many applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3351</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3351</id><created>2008-04-21</created><updated>2011-01-18</updated><authors><author><keyname>Di Giusto</keyname><forenames>Cinzia</forenames></author><author><keyname>Gabbrielli</keyname><forenames>Maurizio</forenames></author><author><keyname>Meo</keyname><forenames>Maria Chiara</forenames></author></authors><title>On the Expressive Power of Multiple Heads in CHR</title><categories>cs.LO cs.DC</categories><comments>v.6 Minor changes, new formulation of definitions, changed some
  details in the proofs</comments><acm-class>D.3.2; D.3.3; F.1.1; F.1.2; F.3.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Constraint Handling Rules (CHR) is a committed-choice declarative language
which has been originally designed for writing constraint solvers and which is
nowadays a general purpose language. CHR programs consist of multi-headed
guarded rules which allow to rewrite constraints into simpler ones until a
solved form is reached. Many empirical evidences suggest that multiple heads
augment the expressive power of the language, however no formal result in this
direction has been proved, so far.
  In the first part of this paper we analyze the Turing completeness of CHR
with respect to the underneath constraint theory. We prove that if the
constraint theory is powerful enough then restricting to single head rules does
not affect the Turing completeness of the language. On the other hand,
differently from the case of the multi-headed language, the single head CHR
language is not Turing powerful when the underlying signature (for the
constraint theory) does not contain function symbols.
  In the second part we prove that, no matter which constraint theory is
considered, under some reasonable assumptions it is not possible to encode the
CHR language (with multi-headed rules) into a single headed language while
preserving the semantics of the programs. We also show that, under some
stronger assumptions, considering an increasing number of atoms in the head of
a rule augments the expressive power of the language.
  These results provide a formal proof for the claim that multiple heads
augment the expressive power of the CHR language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3434</identifier>
 <datestamp>2013-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3434</id><created>2008-04-21</created><updated>2013-12-25</updated><authors><author><keyname>Selinger</keyname><forenames>Peter</forenames></author></authors><title>Lecture notes on the lambda calculus</title><categories>cs.LO</categories><comments>120 pages. Added in v2: section on polymorphism</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a set of lecture notes that developed out of courses on the lambda
calculus that I taught at the University of Ottawa in 2001 and at Dalhousie
University in 2007 and 2013. Topics covered in these notes include the untyped
lambda calculus, the Church-Rosser theorem, combinatory algebras, the
simply-typed lambda calculus, the Curry-Howard isomorphism, weak and strong
normalization, polymorphism, type inference, denotational semantics, complete
partial orders, and the language PCF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3439</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3439</id><created>2008-04-21</created><updated>2010-04-28</updated><authors><author><keyname>Aeron</keyname><forenames>Shuchin</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author><author><keyname>Zhao</keyname><forenames>Manqi</forenames></author></authors><title>Information theoretic bounds for Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>30 pages, 2 figures, submitted to IEEE Trans. on IT</comments><report-no>INSPEC accession number 11523421</report-no><journal-ref>IEEE Transactions on Information Theory, 56, Issue:10, Oct. 2010,
  5111-5130</journal-ref><doi>10.1109/TIT.2010.2059891</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we derive information theoretic performance bounds to sensing
and reconstruction of sparse phenomena from noisy projections. We consider two
settings: output noise models where the noise enters after the projection and
input noise models where the noise enters before the projection. We consider
two types of distortion for reconstruction: support errors and mean-squared
errors. Our goal is to relate the number of measurements, $m$, and $\snr$, to
signal sparsity, $k$, distortion level, $d$, and signal dimension, $n$. We
consider support errors in a worst-case setting. We employ different variations
of Fano's inequality to derive necessary conditions on the number of
measurements and $\snr$ required for exact reconstruction. To derive sufficient
conditions we develop new insights on max-likelihood analysis based on a novel
superposition property. In particular this property implies that small support
errors are the dominant error events. Consequently, our ML analysis does not
suffer the conservatism of the union bound and leads to a tighter analysis of
max-likelihood. These results provide order-wise tight bounds. For output noise
models we show that asymptotically an $\snr$ of $\Theta(\log(n))$ together with
$\Theta(k \log(n/k))$ measurements is necessary and sufficient for exact
support recovery. Furthermore, if a small fraction of support errors can be
tolerated, a constant $\snr$ turns out to be sufficient in the linear sparsity
regime. In contrast for input noise models we show that support recovery fails
if the number of measurements scales as $o(n\log(n)/SNR)$ implying poor
compression performance for such cases. We also consider Bayesian set-up and
characterize tradeoffs between mean-squared distortion and the number of
measurements using rate-distortion theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3459</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3459</id><created>2008-04-22</created><updated>2010-06-01</updated><authors><author><keyname>Delahaye</keyname><forenames>Jean-Paul</forenames></author><author><keyname>Zenil</keyname><forenames>Hector</forenames></author></authors><title>Towards a stable definition of Kolmogorov-Chaitin complexity</title><categories>cs.IT cs.CC math.IT</categories><comments>15 pages, 4 figures, 2 tables. V2 minor typo corrections. Paper web
  page on Experimental Algorithmic Information Theory:
  http://http://www.mathrix.org/experimentalAIT/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although information content is invariant up to an additive constant, the
range of possible additive constants applicable to programming languages is so
large that in practice it plays a major role in the actual evaluation of K(s),
the Kolmogorov-Chaitin complexity of a string s. Some attempts have been made
to arrive at a framework stable enough for a concrete definition of K,
independent of any constant under a programming language, by appealing to the
"naturalness" of the language in question. The aim of this paper is to present
an approach to overcome the problem by looking at a set of models of
computation converging in output probability distribution such that that
"naturalness" can be inferred, thereby providing a framework for a stable
definition of K under the set of convergent models of computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.3868</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.3868</id><created>2008-04-24</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author><author><keyname>Bönisch</keyname><forenames>Cornelia</forenames></author><author><keyname>Vortisch</keyname><forenames>Peter</forenames></author></authors><title>Comparison of Various Methods for the Calculation of the Distance
  Potential Field</title><categories>physics.comp-ph cs.MA physics.soc-ph</categories><comments>Extended version of proceedings contriution to be published in
  "Pedestrian and Evacuation Dynamics 2008", Springer; conference held in
  February 2008 at Wuppertal University</comments><journal-ref>Pedestrian and Evacuation Dynamics 2008 (2010), Part 2, 335-346</journal-ref><doi>10.1007/978-3-642-04504-2_29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The distance from a given position toward one or more destinations, exits,
and way points is a more or less important input variable in most models of
pedestrian dynamics. Except for the special case when there are no obstacles in
a concave scenario -- i.e. each position is visible from any other -- the
calculation of these distances is a non-trivial task. This isn't that big a
problem, as long as the model only demands the distances to be stored in a
Static Floor Field also called Potential Field, which never changes throughout
the whole simulation. In this case a pre-calculation once before the simulation
starts is sufficient. But if one wants to allow changes of the geometry during
a simulation run -- imagine doors or the blocking of a corridor due to some
hazard -- in the Distance Potential Field, calculation time matters strongly.
This contribution gives an overview over existing and new exact and approximate
methods to calculate a potential field, analytical investigations for their
exactness, and tests of their computation speed. The advantages and drawbacks
of the methods are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4150</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4150</id><created>2008-04-25</created><updated>2012-11-23</updated><authors><author><keyname>Tiwary</keyname><forenames>Hans Raj</forenames></author></authors><title>On Computing the Shadows and Slices of Polytopes</title><categories>cs.CC cs.CG</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of computing the projection of an arbitrary
$d$-polytope along $k$ orthogonal vectors for various input and output forms.
We show that if $d$ and $k$ are part of the input (i.e. not a constant) and we
are interested in output-sensitive algorithms, then in most forms the problem
is equivalent to enumerating vertices of polytopes, except in two where it is
NP-hard. In two other forms the problem is trivial. We also review the
complexity of computing projections when the projection directions are in some
sense non-degenerate. For full-dimensional polytopes containing origin in the
interior, projection is an operation dual to intersecting the polytope with a
suitable linear subspace and so the results in this paper can be dualized by
interchanging vertices with facets and projection with intersection. To compare
the complexity of projection and vertex enumeration, we define new complexity
classes based on the complexity of Vertex Enumeration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4204</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4204</id><created>2008-04-26</created><updated>2012-01-22</updated><authors><author><keyname>Srinivasa</keyname><forenames>Sunil</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Distance Distributions in Finite Uniformly Random Networks: Theory and
  Applications</title><categories>cs.IT math.IT</categories><comments>Published in IEEE Transactions on Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless networks, the knowledge of nodal distances is essential for
several areas such as system configuration, performance analysis and protocol
design. In order to evaluate distance distributions in random networks, the
underlying nodal arrangement is almost universally taken to be an infinite
Poisson point process. While this assumption is valid in some cases, there are
also certain impracticalities to this model. For example, practical networks
are non-stationary, and the number of nodes in disjoint areas are not
independent. This paper considers a more realistic network model where a finite
number of nodes are uniformly randomly distributed in a general d-dimensional
ball of radius R and characterizes the distribution of Euclidean distances in
the system. The key result is that the probability density function of the
distance from the center of the network to its nth nearest neighbor follows a
generalized beta distribution. This finding is applied to study network
characteristics such as energy consumption, interference, outage and
connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4316</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4316</id><created>2008-04-27</created><authors><author><keyname>Sarvepalli</keyname><forenames>Pradeep Kiran</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author><author><keyname>Klappenecker</keyname><forenames>Andreas</forenames></author></authors><title>Asymmetric Quantum LDPC Codes</title><categories>quant-ph cs.IT math.IT</categories><comments>5 pages, 1 figure, 1 table, to appear in the Proceedings of the 2008
  IEEE International Symposium on Information Theory</comments><journal-ref>Proceedings 2008 IEEE International Symposium on Information
  Theory (ISIT 2008), Toronto, Canada, pp. 305-309, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, quantum error-correcting codes were proposed that capitalize on the
fact that many physical error models lead to a significant asymmetry between
the probabilities for bit flip and phase flip errors. An example for a channel
which exhibits such asymmetry is the combined amplitude damping and dephasing
channel, where the probabilities of bit flips and phase flips can be related to
relaxation and dephasing time, respectively. We give systematic constructions
of asymmetric quantum stabilizer codes that exploit this asymmetry. Our
approach is based on a CSS construction that combines BCH and finite geometry
LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4336</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4336</id><created>2008-04-28</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author><author><keyname>Kaufman</keyname><forenames>Maike</forenames></author><author><keyname>Schreckenberg</keyname><forenames>Michael</forenames></author></authors><title>Counterflow Extension for the F.A.S.T.-Model</title><categories>cs.MA physics.comp-ph</categories><comments>Contribution to Crowds and Cellular Automata Workshop 2008. Accepted
  for publication in "Cellular Automata -- 8th International Conference on
  Cellular Automata for Research and Industry, ACRI 2008, Yokohama, Japan,
  September 23-26, Springer 2008, Proceedings"</comments><journal-ref>Cellular Automata Lecture Notes in Computer Science, 2008, Volume
  5191/2008, 555-558</journal-ref><doi>10.1007/978-3-540-79992-4_75</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The F.A.S.T. (Floor field and Agent based Simulation Tool) model is a
microscopic model of pedestrian dynamics, which is discrete in space and time.
It was developed in a number of more or less consecutive steps from a simple CA
model. This contribution is a summary of a study on an extension of the
F.A.S.T-model for counterflow situations. The extensions will be explained and
it will be shown that the extended F.A.S.T.-model is capable of handling
various counterflow situations and to reproduce the well known lane formation
effect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4347</identifier>
 <datestamp>2013-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4347</id><created>2008-04-28</created><updated>2013-11-23</updated><authors><author><keyname>Vergara</keyname><forenames>Sossio</forenames></author></authors><title>Nonorthogonal Bases and Phase Decomposition: Properties and Applications</title><categories>cs.NA cs.SD math.FA</categories><comments>11 pages</comments><journal-ref>Published in : Digital Signal Processing (2014), pp. 223-230</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper [1] it was discussed the viability of functional analysis
using as a basis a couple of generic functions, and hence vectorial
decomposition. Here we complete the paradigm exploiting one of the analysis
methodologies developed there, but applied to phase coordinates, so needing
only one function as a basis. It will be shown that, thanks to the novel
iterative analysis, any function satisfying a rather loose requisite is
ontologically a basis. This in turn generalizes the polar version of the
Fourier theorem to an ample class of nonorthogonal bases. The main advantage of
this generalization is that it inherits some of the properties of the original
Fourier theorem. As a result the new transform has a wide range of applications
and some remarkable consequences. The new tool will be compared with wavelets
and frames. Examples of analysis and reconstruction of functions using the
developed algorithms and generic bases will be given. Some of the properties,
and applications that can promptly benefit from the theory, will be discussed.
The implementation of a matched filter for noise suppression will be used as an
example of the potential of the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4383</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4383</id><created>2008-04-28</created><updated>2008-07-04</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author></authors><title>Practical Automated Partial Verification of Multi-Paradigm Real-Time
  Models</title><categories>cs.LO</categories><comments>33 pages; fixed a few typos and added data to Table 2</comments><journal-ref>Proceedings of the 10th International Conference on Formal
  Engineering Methods (ICFEM'08). Lecture Notes in Computer Science,
  5256:298--317, Springer-Verlag, October 2008</journal-ref><doi>10.1007/978-3-540-88194-0_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a fully automated verification technique that permits
to analyze real-time systems described using a continuous notion of time and a
mixture of operational (i.e., automata-based) and descriptive (i.e.,
logic-based) formalisms. The technique relies on the reduction, under
reasonable assumptions, of the continuous-time verification problem to its
discrete-time counterpart. This reconciles in a viable and effective way the
dense/discrete and operational/descriptive dichotomies that are often
encountered in practice when it comes to specifying and analyzing complex
critical systems. The article investigates the applicability of the technique
through a significant example centered on a communication protocol. More
precisely, concurrent runs of the protocol are formalized by parallel instances
of a Timed Automaton, while the synchronization rules between these instances
are specified through Metric Temporal Logic formulas, thus creating a
multi-paradigm model. Verification tests run on this model using a bounded
validity checker implementing the technique show consistent results and
interesting performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4415</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4415</id><created>2008-04-28</created><updated>2008-07-27</updated><authors><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>Eppstein's bound on intersecting triangles revisited</title><categories>cs.CG</categories><comments>Minor revision following referee's suggestions. To appear in Journal
  of Combinatorial Theory, Series A. 5 pages, 1 figure</comments><journal-ref>Journal of Combinatorial Theory, Series A, 116:494-497, 2009</journal-ref><doi>10.1016/j.jcta.2008.07.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let S be a set of n points in the plane, and let T be a set of m triangles
with vertices in S. Then there exists a point in the plane contained in
Omega(m^3 / (n^6 log^2 n)) triangles of T. Eppstein (1993) gave a proof of this
claim, but there is a problem with his proof. Here we provide a correct proof
by slightly modifying Eppstein's argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4464</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4464</id><created>2008-04-28</created><updated>2008-09-17</updated><authors><author><keyname>Bukh</keyname><forenames>Boris</forenames></author><author><keyname>Matoušek</keyname><forenames>Jiří</forenames></author><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author></authors><title>Stabbing simplices by points and flats</title><categories>math.CO cs.CG</categories><comments>18 pages, 5 figures</comments><msc-class>52C10, 52C35, 52A35, 54C99</msc-class><journal-ref>Discrete and Computational Geometry, 43:321--338, 2010</journal-ref><doi>10.1007/s00454-008-9124-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following result was proved by Barany in 1982: For every d &gt;= 1 there
exists c_d &gt; 0 such that for every n-point set S in R^d there is a point p in
R^d contained in at least c_d n^{d+1} - O(n^d) of the simplices spanned by S.
  We investigate the largest possible value of c_d. It was known that c_d &lt;=
1/(2^d(d+1)!) (this estimate actually holds for every point set S). We
construct sets showing that c_d &lt;= (d+1)^{-(d+1)}, and we conjecture this
estimate to be tight. The best known lower bound, due to Wagner, is c_d &gt;=
gamma_d := (d^2+1)/((d+1)!(d+1)^{d+1}); in his method, p can be chosen as any
centerpoint of S. We construct n-point sets with a centerpoint that is
contained in no more than gamma_d n^{d+1}+O(n^d) simplices spanned by S, thus
showing that the approach using an arbitrary centerpoint cannot be further
improved.
  We also prove that for every n-point set S in R^d there exists a (d-2)-flat
that stabs at least c_{d,d-2} n^3 - O(n^2) of the triangles spanned by S, with
c_{d,d-2}&gt;=(1/24)(1- 1/(2d-1)^2). To this end, we establish an equipartition
result of independent interest (generalizing planar results of Buck and Buck
and of Ceder): Every mass distribution in R^d can be divided into 4d-2 equal
parts by 2d-1 hyperplanes intersecting in a common (d-2)-flat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4489</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4489</id><created>2008-04-28</created><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Generalized Degrees of Freedom of the Symmetric Gaussian $K$ User
  Interference Channel</title><categories>cs.IT math.IT</categories><comments>12 pages</comments><journal-ref>IEEE Transactions on Information Theory, July 2010, Vol. 56,
  Issue: 7, Pages: 3297-3303</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We characterize the generalized degrees of freedom of the $K$ user symmetric
Gaussian interference channel where all desired links have the same
signal-to-noise ratio (SNR) and all undesired links carrying interference have
the same interference-to-noise ratio, ${INR}={SNR}^\alpha$. We find that the
number of generalized degrees of freedom per user, $d(\alpha)$, does not depend
on the number of users, so that the characterization is identical to the 2 user
interference channel with the exception of a singularity at $\alpha=1$ where
$d(1)=\frac{1}{K}$. The achievable schemes use multilevel coding with a nested
lattice structure that opens the possibility that the sum of interfering
signals can be decoded at a receiver even though the messages carried by the
interfering signals are not decodable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4523</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4523</id><created>2008-04-28</created><updated>2008-10-08</updated><authors><author><keyname>Masanes</keyname><forenames>Lluis</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>A non-distillability criterion for secret correlations</title><categories>quant-ph cs.CR</categories><comments>5 pages</comments><journal-ref>Quantum Information and Computation, Vol.10, No.1&amp;2, pp0152 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within entanglement theory there are criteria which certify that some quantum
states cannot be distilled into pure entanglement. An example is the positive
partial transposition criterion. Here we present, for the first time, the
analogous thing for secret correlations. We introduce a computable criterion
which certifies that a probability distribution between two honest parties and
an eavesdropper cannot be (asymptotically) distilled into a secret key. The
existence of non-distillable correlations with positive secrecy cost, also
known as bound information, is an open question. This criterion may be the key
for finding bound information. However, if it turns out that this criterion
does not detect bound information, then, a very interesting consequence
follows: any distribution with positive secrecy cost can increase the secrecy
content of another distribution. In other words, all correlations with positive
secrecy cost constitute a useful resource.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4565</identifier>
 <datestamp>2013-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4565</id><created>2008-04-29</created><updated>2013-06-05</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Data linkage algebra, data linkage dynamics, and priority rewriting</title><categories>cs.LO</categories><comments>48 pages, typos corrected, phrasing improved, definition of services
  replaced; presentation improved; presentation improved and appendix added</comments><report-no>PRG0806</report-no><acm-class>D.3.3; D.4.2; F.1.1; F.3.2; F.3.3</acm-class><journal-ref>Fundamenta Informaticae, 128(4):367--412, 2013</journal-ref><doi>10.3233/FI-2013-950</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an algebra of data linkages. Data linkages are intended for
modelling the states of computations in which dynamic data structures are
involved. We present a simple model of computation in which states of
computations are modelled as data linkages and state changes take place by
means of certain actions. We describe the state changes and replies that result
from performing those actions by means of a term rewriting system with rule
priorities. The model in question is an upgrade of molecular dynamics. The
upgrading is mainly concerned with the features to deal with values and the
features to reclaim garbage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4815</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4815</id><created>2008-04-30</created><authors><author><keyname>Floréen</keyname><forenames>Patrik</forenames></author><author><keyname>Hassinen</keyname><forenames>Marja</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>Tight local approximation results for max-min linear programs</title><categories>cs.DC</categories><comments>16 pages</comments><doi>10.1007/978-3-540-92862-1_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a bipartite max-min LP, we are given a bipartite graph $\myG = (V \cup I
\cup K, E)$, where each agent $v \in V$ is adjacent to exactly one constraint
$i \in I$ and exactly one objective $k \in K$. Each agent $v$ controls a
variable $x_v$. For each $i \in I$ we have a nonnegative linear constraint on
the variables of adjacent agents. For each $k \in K$ we have a nonnegative
linear objective function of the variables of adjacent agents. The task is to
maximise the minimum of the objective functions. We study local algorithms
where each agent $v$ must choose $x_v$ based on input within its
constant-radius neighbourhood in $\myG$. We show that for every $\epsilon&gt;0$
there exists a local algorithm achieving the approximation ratio ${\Delta_I (1
- 1/\Delta_K)} + \epsilon$. We also show that this result is the best possible
-- no local algorithm can achieve the approximation ratio ${\Delta_I (1 -
1/\Delta_K)}$. Here $\Delta_I$ is the maximum degree of a vertex $i \in I$, and
$\Delta_K$ is the maximum degree of a vertex $k \in K$. As a methodological
contribution, we introduce the technique of graph unfolding for the design of
local approximation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0804.4859</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0804.4859</id><created>2008-04-30</created><updated>2011-07-07</updated><authors><author><keyname>Degorre</keyname><forenames>Julien</forenames></author><author><keyname>Kaplan</keyname><forenames>Marc</forenames></author><author><keyname>Laplante</keyname><forenames>Sophie</forenames></author><author><keyname>Roland</keyname><forenames>Jérémie</forenames></author></authors><title>The communication complexity of non-signaling distributions</title><categories>quant-ph cs.CC</categories><comments>23 pages. V2: major modifications, extensions and additions compared
  to V1. V3 (21 pages): proofs have been updated and simplified, particularly
  Theorem 10 and Theorem 22. V4 (23 pages): Section 3.1 has been rewritten (in
  particular Lemma 10 and its proof), and various minor modifications have been
  made. V5 (24 pages): various modifications in the presentation</comments><journal-ref>In MFCS'09, LNCS, vol 5734, 270-281 (2009). Quantum Information &amp;
  Computation, 11(7&amp;8):649-676 (2011)</journal-ref><doi>10.1007/978-3-642-03816-7_24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a model of communication complexity that encompasses many
well-studied problems, including classical and quantum communication
complexity, the complexity of simulating distributions arising from bipartite
measurements of shared quantum states, and XOR games. In this model, Alice gets
an input x, Bob gets an input y, and their goal is to each produce an output
a,b distributed according to some pre-specified joint distribution p(a,b|x,y).
  We introduce a new technique based on affine combinations of lower-complexity
distributions. Specifically, we introduce two complexity measures, one which
gives lower bounds on classical communication, and one for quantum
communication. These measures can be expressed as convex optimization problems.
We show that the dual formulations have a striking interpretation, since they
coincide with maximum violations of Bell and Tsirelson inequalities. The dual
expressions are closely related to the winning probability of XOR games. These
lower bounds subsume many known communication complexity lower bound methods,
most notably the recent lower bounds of Linial and Shraibman for the special
case of Boolean functions.
  We show that the gap between the quantum and classical lower bounds is at
most linear in the size of the support of the distribution, and does not depend
on the size of the inputs. This translates into a bound on the gap between
maximal Bell and Tsirelson inequality violations, which was previously known
only for the case of distributions with Boolean outcomes and uniform marginals.
  Finally, we give an exponential upper bound on quantum and classical
communication complexity in the simultaneous messages model, for any
non-signaling distribution. One consequence is a simple proof that any quantum
distribution can be approximated with a constant number of bits of
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0053</identifier>
 <datestamp>2011-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0053</id><created>2008-05-01</created><authors><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Particle Filtering for Large Dimensional State Spaces with Multimodal
  Observation Likelihoods</title><categories>cs.IT math.IT math.ST stat.ME stat.TH</categories><comments>To appear in IEEE Trans. Signal Processing</comments><journal-ref>IEEE Trans. Sig. Proc., vol. 56(10-1), pp. 4583-4597, Oct. 2008</journal-ref><doi>10.1109/TSP.2008.925969</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study efficient importance sampling techniques for particle filtering (PF)
when either (a) the observation likelihood (OL) is frequently multimodal or
heavy-tailed, or (b) the state space dimension is large or both. When the OL is
multimodal, but the state transition pdf (STP) is narrow enough, the optimal
importance density is usually unimodal. Under this assumption, many techniques
have been proposed. But when the STP is broad, this assumption does not hold.
We study how existing techniques can be generalized to situations where the
optimal importance density is multimodal, but is unimodal conditioned on a part
of the state vector. Sufficient conditions to test for the unimodality of this
conditional posterior are derived. The number of particles, N, to accurately
track using a PF increases with state space dimension, thus making any regular
PF impractical for large dimensional tracking problems. We propose a solution
that partially addresses this problem. An important class of large dimensional
problems with multimodal OL is tracking spatially varying physical quantities
such as temperature or pressure in a large area using a network of sensors
which may be nonlinear and/or may have non-negligible failure probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0162</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0162</id><created>2008-05-01</created><updated>2008-06-02</updated><authors><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>Shu</keyname><forenames>Chang</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author><author><keyname>Brunton</keyname><forenames>Alan</forenames></author></authors><title>Morphing of Triangular Meshes in Shape Space</title><categories>cs.CG cs.GR</categories><comments>Improved experimental results</comments><journal-ref>International Journal of Shape Modeling, 16(1-2):195-212, 2010</journal-ref><doi>10.1142/S0218654310001341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to morph between two isometric poses of the same
non-rigid object given as triangular meshes. We model the morphs as linear
interpolations in a suitable shape space $\mathcal{S}$. For triangulated 3D
polygons, we prove that interpolating linearly in this shape space corresponds
to the most isometric morph in $\mathbb{R}^3$. We then extend this shape space
to arbitrary triangulations in 3D using a heuristic approach and show the
practical use of the approach using experiments. Furthermore, we discuss a
modified shape space that is useful for isometric skeleton morphing. All of the
newly presented approaches solve the morphing problem without the need to solve
a minimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0241</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0241</id><created>2008-05-02</created><authors><author><keyname>Mitchell</keyname><forenames>David G. M.</forenames></author><author><keyname>Pusane</keyname><forenames>Ali E.</forenames></author><author><keyname>Zigangirov</keyname><forenames>Kamil Sh.</forenames></author><author><keyname>Costello,</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Asymptotically Good LDPC Convolutional Codes Based on Protographs</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Symposium on Information
  Theory, Toronto, ON, Canada, July 6 - 11, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LDPC convolutional codes have been shown to be capable of achieving the same
capacity-approaching performance as LDPC block codes with iterative
message-passing decoding. In this paper, asymptotic methods are used to
calculate a lower bound on the free distance for several ensembles of
asymptotically good protograph-based LDPC convolutional codes. Further, we show
that the free distance to constraint length ratio of the LDPC convolutional
codes exceeds the minimum distance to block length ratio of corresponding LDPC
block codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0330</identifier>
 <datestamp>2010-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0330</id><created>2008-05-02</created><updated>2010-06-14</updated><authors><author><keyname>Jurdzinski</keyname><forenames>Marcin</forenames></author><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author></authors><title>Alternating Automata on Data Trees and XPath Satisfiability</title><categories>cs.LO cs.DB cs.FL</categories><comments>23 pages</comments><acm-class>F.4.1; F.1.1; H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data tree is an unranked ordered tree whose every node is labelled by a
letter from a finite alphabet and an element ("datum") from an infinite set,
where the latter can only be compared for equality. The article considers
alternating automata on data trees that can move downward and rightward, and
have one register for storing data. The main results are that nonemptiness over
finite data trees is decidable but not primitive recursive, and that
nonemptiness of safety automata is decidable but not elementary. The proofs use
nondeterministic tree automata with faulty counters. Allowing upward moves,
leftward moves, or two registers, each causes undecidability. As corollaries,
decidability is obtained for two data-sensitive fragments of the XPath query
language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0459</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0459</id><created>2008-05-05</created><authors><author><keyname>Owladeghaffari</keyname><forenames>Hamed</forenames></author></authors><title>Phase transition in SONFIS&amp;SORST</title><categories>cs.AI</categories><comments>submitted to :The Sixth International Conference on Rough Sets and
  Current Trends in Computing; Akron, Ohio, USA,2008</comments><acm-class>F.4.1</acm-class><doi>10.1007/978-3-540-88425-5_35</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we introduce general frame of MAny Connected Intelligent
Particles Systems (MACIPS). Connections and interconnections between particles
get a complex behavior of such merely simple system (system in
system).Contribution of natural computing, under information granulation
theory, are the main topics of this spacious skeleton. Upon this clue, we
organize two algorithms involved a few prominent intelligent computing and
approximate reasoning methods: self organizing feature map (SOM), Neuro- Fuzzy
Inference System and Rough Set Theory (RST). Over this, we show how our
algorithms can be taken as a linkage of government-society interaction, where
government catches various fashions of behavior: solid (absolute) or flexible.
So, transition of such society, by changing of connectivity parameters (noise)
from order to disorder is inferred. Add to this, one may find an indirect
mapping among financial systems and eventual market fluctuations with MACIPS.
Keywords: phase transition, SONFIS, SORST, many connected intelligent particles
system, society-government interaction
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0501</identifier>
 <datestamp>2010-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0501</id><created>2008-05-05</created><authors><author><keyname>Senger</keyname><forenames>Christian</forenames></author><author><keyname>Sidorenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor</forenames></author></authors><title>Decoding Generalized Concatenated Codes Using Interleaved Reed-Solomon
  Codes</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Symposium on Information
  Theory, Toronto, ON, Canada, July 6 - 11, 2008. 5 pages, 2 figures</comments><doi>10.1109/ISIT.2008.4595300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalized Concatenated codes are a code construction consisting of a number
of outer codes whose code symbols are protected by an inner code. As outer
codes, we assume the most frequently used Reed-Solomon codes; as inner code, we
assume some linear block code which can be decoded up to half its minimum
distance. Decoding up to half the minimum distance of Generalized Concatenated
codes is classically achieved by the Blokh-Zyablov-Dumer algorithm, which
iteratively decodes by first using the inner decoder to get an estimate of the
outer code words and then using an outer error/erasure decoder with a varying
number of erasures determined by a set of pre-calculated thresholds. In this
paper, a modified version of the Blokh-Zyablov-Dumer algorithm is proposed,
which exploits the fact that a number of outer Reed-Solomon codes with average
minimum distance d can be grouped into one single Interleaved Reed-Solomon code
which can be decoded beyond d/2. This allows to skip a number of decoding
iterations on the one hand and to reduce the complexity of each decoding
iteration significantly - while maintaining the decoding performance - on the
other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0612</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0612</id><created>2008-05-05</created><authors><author><keyname>Gagarin</keyname><forenames>Andrei</forenames></author><author><keyname>Poghosyan</keyname><forenames>Anush</forenames></author><author><keyname>Zverovich</keyname><forenames>Vadim E.</forenames></author></authors><title>Upper bounds for alpha-domination parameters</title><categories>math.CO cs.DM</categories><comments>7 pages; Presented at the 4th East Coast Combinatorial Conference,
  Antigonish (Nova Scotia, Canada), May 1-2, 2008</comments><msc-class>05C69 (Primary), 68R10, 68W20, 90B15 (Secondary)</msc-class><journal-ref>Graphs Combin. 25 (2009), no. 4, pp. 513-520</journal-ref><doi>10.1007/s00373-009-0864-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a new upper bound for the alpha-domination number.
This result generalises the well-known Caro-Roditty bound for the domination
number of a graph. The same probabilistic construction is used to generalise
another well-known upper bound for the classical domination in graphs. We also
prove similar upper bounds for the alpha-rate domination number, which combines
the concepts of alpha-domination and k-tuple domination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0642</identifier>
 <datestamp>2010-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0642</id><created>2008-05-06</created><authors><author><keyname>Owladeghaffari</keyname><forenames>Hamed</forenames></author></authors><title>Order to Disorder Transitions in Hybrid Intelligent Systems: a Hatch to
  the Interactions of Nations -Governments</title><categories>cs.AI cs.IT math.IT</categories><comments>submitted to:The 2008 IEEE International Conference on Granular
  Computing (GrC 2008)</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, under general frame of MAny Connected Intelligent Particles
Systems (MACIPS), we reproduce two new simple subsets of such intelligent
complex network, namely hybrid intelligent systems, involved a few prominent
intelligent computing and approximate reasoning methods: self organizing
feature map (SOM), Neuro-Fuzzy Inference System and Rough Set Theory (RST).
Over this, we show how our algorithms can be construed as a linkage of
government-society interaction, where government catches various fashions of
behavior: solid (absolute) or flexible. So, transition of such society, by
changing of connectivity parameters (noise) from order to disorder is inferred.
Add to this, one may find an indirect mapping among financial systems and
eventual market fluctuations with MACIPS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0697</identifier>
 <datestamp>2012-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0697</id><created>2008-05-06</created><authors><author><keyname>Perez</keyname><forenames>Meir</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Stochastic Optimization Approaches for Solving Sudoku</title><categories>cs.NE</categories><comments>13 pages</comments><doi>10.1016/j.eswa.2012.04.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the Sudoku problem is solved using stochastic search techniques
and these are: Cultural Genetic Algorithm (CGA), Repulsive Particle Swarm
Optimization (RPSO), Quantum Simulated Annealing (QSA) and the Hybrid method
that combines Genetic Algorithm with Simulated Annealing (HGASA). The results
obtained show that the CGA, QSA and HGASA are able to solve the Sudoku puzzle
with CGA finding a solution in 28 seconds, while QSA finding a solution in 65
seconds and HGASA in 1.447 seconds. This is mainly because HGASA combines the
parallel searching of GA with the flexibility of SA. The RPSO was found to be
unable to solve the puzzle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.0730</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.0730</id><created>2008-05-06</created><updated>2008-09-17</updated><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Levé</keyname><forenames>Florence</forenames></author><author><keyname>Richomme</keyname><forenames>Gwénaël</forenames></author></authors><title>Quasiperiodic and Lyndon episturmian words</title><categories>math.CO cs.DM</categories><comments>33 pages; minor changes</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 409 (2008) 578-600</journal-ref><doi>10.1016/j.tcs.2008.09.056</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently the second two authors characterized quasiperiodic Sturmian words,
proving that a Sturmian word is non-quasiperiodic if and only if it is an
infinite Lyndon word. Here we extend this study to episturmian words (a natural
generalization of Sturmian words) by describing all the quasiperiods of an
episturmian word, which yields a characterization of quasiperiodic episturmian
words in terms of their "directive words". Even further, we establish a
complete characterization of all episturmian words that are Lyndon words. Our
main results show that, unlike the Sturmian case, there is a much wider class
of episturmian words that are non-quasiperiodic, besides those that are
infinite Lyndon words. Our key tools are morphisms and directive words, in
particular "normalized" directive words, which we introduced in an earlier
paper. Also of importance is the use of "return words" to characterize
quasiperiodic episturmian words, since such a method could be useful in other
contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1071</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1071</id><created>2008-05-07</created><updated>2010-05-31</updated><authors><author><keyname>Svitkina</keyname><forenames>Zoya</forenames></author><author><keyname>Fleischer</keyname><forenames>Lisa</forenames></author></authors><title>Submodular approximation: sampling-based algorithms and lower bounds</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce several generalizations of classical computer science problems
obtained by replacing simpler objective functions with general submodular
functions. The new problems include submodular load balancing, which
generalizes load balancing or minimum-makespan scheduling, submodular sparsest
cut and submodular balanced cut, which generalize their respective graph cut
problems, as well as submodular function minimization with a cardinality lower
bound. We establish upper and lower bounds for the approximability of these
problems with a polynomial number of queries to a function-value oracle. The
approximation guarantees for most of our algorithms are of the order of
sqrt(n/ln n). We show that this is the inherent difficulty of the problems by
proving matching lower bounds. We also give an improved lower bound for the
problem of approximately learning a monotone submodular function. In addition,
we present an algorithm for approximately learning submodular functions with
special structure, whose guarantee is close to the lower bound. Although quite
restrictive, the class of functions with this structure includes the ones that
are used for lower bounds both by us and in previous work. This demonstrates
that if there are significantly stronger lower bounds for this problem, they
rely on more general submodular functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1257</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1257</id><created>2008-05-08</created><updated>2012-03-24</updated><authors><author><keyname>Kari</keyname><forenames>Chadi</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author><author><keyname>Shashidhar</keyname><forenames>Narasimha</forenames></author></authors><title>Randomized Work-Competitive Scheduling for Cooperative Computing on
  $k$-partite Task Graphs</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental problem in distributed computing is the task of cooperatively
executing a given set of $t$ tasks by $p$ processors where the communication
medium is dynamic and subject to failures. The dynamics of the communication
medium lead to groups of processors being disconnected and possibly reconnected
during the entire course of the computation furthermore tasks can have
dependencies among them. In this paper, we present a randomized algorithm whose
competitive ratio is dependent on the dynamics of the communication medium and
also on the nature of the dependencies among the tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1266</identifier>
 <datestamp>2010-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1266</id><created>2008-05-08</created><updated>2010-09-10</updated><authors><author><keyname>Papadopoulos</keyname><forenames>Fragkiskos</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Vahdat</keyname><forenames>Amin</forenames></author></authors><title>Greedy Forwarding in Dynamic Scale-Free Networks Embedded in Hyperbolic
  Metric Spaces</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.NI physics.soc-ph</categories><journal-ref>INFOCOM 2010, p.2973-2981</journal-ref><doi>10.1109/INFCOM.2010.5462131</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that complex (scale-free) network topologies naturally emerge from
hyperbolic metric spaces. Hyperbolic geometry facilitates maximally efficient
greedy forwarding in these networks. Greedy forwarding is topology-oblivious.
Nevertheless, greedy packets find their destinations with 100% probability
following almost optimal shortest paths. This remarkable efficiency sustains
even in highly dynamic networks. Our findings suggest that forwarding
information through complex networks, such as the Internet, is possible without
the overhead of existing routing protocols, and may also find practical
applications in overlay networks for tasks such as application-level routing,
information sharing, and data distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1292</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1292</id><created>2008-05-09</created><authors><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Physically-Relativized Church-Turing Hypotheses</title><categories>physics.comp-ph cs.CC</categories><comments>interdisciplinary paper: philosophy of physics, computational
  physics, computational complexity and computability</comments><journal-ref>pp.1431-1447 in Applied Mathematics and Computation vol.215:4
  (2009)</journal-ref><doi>10.1016/j.amc.2009.04.062</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We turn `the' Church-Turing Hypothesis from an ambiguous source of
sensational speculations into a (collection of) sound and well-defined
scientific problem(s):
  Examining recent controversies, and causes for misunderstanding, concerning
the state of the Church-Turing Hypothesis (CTH), suggests to study the CTH
relative to an arbitrary but specific physical theory--rather than vaguely
referring to ``nature'' in general. To this end we combine (and compare)
physical structuralism with (models of computation in) complexity theory. The
benefit of this formal framework is illustrated by reporting on some previous,
and giving one new, example result(s) of computability and complexity in
computational physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1386</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1386</id><created>2008-05-09</created><updated>2011-01-03</updated><authors><author><keyname>Kieffer</keyname><forenames>Steven</forenames></author><author><keyname>Avigad</keyname><forenames>Jeremy</forenames></author><author><keyname>Friedman</keyname><forenames>Harvey</forenames></author></authors><title>A language for mathematical knowledge management</title><categories>cs.LO</categories><acm-class>F.4.1; I.2.4</acm-class><journal-ref>Studies in Logic, Grammar and Rhetoric, 18:51-66, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that the language of Zermelo Fraenkel set theory with definitions
and partial functions provides the most promising bedrock semantics for
communicating and sharing mathematical knowledge. We then describe a syntactic
sugaring of that language that provides a way of writing remarkably readable
assertions without straying far from the set-theoretic semantics. We illustrate
with some examples of formalized textbook definitions from elementary set
theory and point-set topology. We also present statistics concerning the
complexity of these definitions, under various complexity measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1696</identifier>
 <datestamp>2010-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1696</id><created>2008-05-12</created><updated>2010-10-15</updated><authors><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Alfonseca</keyname><forenames>Manuel</forenames></author><author><keyname>Ortega</keyname><forenames>Alfonso</forenames></author></authors><title>Grammatical Evolution with Restarts for Fast Fractal Generation</title><categories>cs.NE cs.SC</categories><comments>26 pages, 13 figures, Extended version of the paper presented at
  ANNIE'04</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous work, the authors proposed a Grammatical Evolution algorithm to
automatically generate Lindenmayer Systems which represent fractal curves with
a pre-determined fractal dimension. This paper gives strong statistical
evidence that the probability distributions of the execution time of that
algorithm exhibits a heavy tail with an hyperbolic probability decay for long
executions, which explains the erratic performance of different executions of
the algorithm. Three different restart strategies have been incorporated in the
algorithm to mitigate the problems associated to heavy tail distributions: the
first assumes full knowledge of the execution time probability distribution,
the second and third assume no knowledge. These strategies exploit the fact
that the probability of finding a solution in short executions is
non-negligible and yield a severe reduction, both in the expected execution
time (up to one order of magnitude) and in its variance, which is reduced from
an infinite to a finite value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1715</identifier>
 <datestamp>2012-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1715</id><created>2008-05-12</created><updated>2012-05-03</updated><authors><author><keyname>Shour</keyname><forenames>Robert</forenames></author></authors><title>Isotropy, entropy, and energy scaling</title><categories>cs.IT math.IT nlin.AO</categories><comments>v2 scaling focus; v3 isotropy focus; v4: revises a nat log thm; v5-8:
  isotropy and degrees of freedom focus with corrected proofreading; v9-10:
  rewrite of v5-8</comments><acm-class>H.1.1; J.2; J.3; J.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two principles explain emergence. First, in the Receipt's reference frame,
Deg(S) = 4/3 Deg(R), where Supply S is an isotropic radiative energy source,
Receipt R receives S's energy, and Deg is a system's degrees of freedom based
on its mean path length. S's 1/3 more degrees of freedom relative to R enables
R's growth and increasing complexity. Second, rho(R) = Deg(R) times rho(r),
where rho(R) represents the collective rate of R and rho(r) represents the rate
of an individual in R: as Deg(R) increases due to the first principle, the
multiplier effect of networking in R increases. A universe like ours with
isotropic energy distribution, in which both principles are operative, is
therefore predisposed to exhibit emergence, and, for reasons shown, a
ubiquitous role for the natural logarithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1740</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1740</id><created>2008-05-12</created><authors><author><keyname>Ayalew</keyname><forenames>Yirsaw</forenames></author><author><keyname>Clermont</keyname><forenames>Markus</forenames></author><author><keyname>Mittermeir</keyname><forenames>Roland T.</forenames></author></authors><title>Detecting Errors in Spreadsheets</title><categories>cs.SE</categories><comments>12 Pages, 5 Figures; ISBN: 1 86166 158 4</comments><acm-class>D.1.7, D.2.1, D.2.11, D.3.2, D.3.3, H.4.1, K.6.4, K.8.1</acm-class><journal-ref>Proc. European Spreadsheet Risks Int. Grp. (EuSpRIG) 2000 51-63</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents two complementary strategies for identifying errors in
spreadsheet programs. The strategies presented are grounded on the assumption
that spreadsheets are software, albeit of a different nature than conventional
procedural software. Correspondingly, strategies for identifying errors have to
take into account the inherent properties of spreadsheets as much as they have
to recognize that the conceptual models of 'spreadsheet programmers' differ
from the conceptual models of conventional programmers. Nevertheless, nobody
can and will write a spreadsheet, without having such a conceptual model in
mind, be it of numeric nature or be it of geometrical nature focused on some
layout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.1827</identifier>
 <datestamp>2014-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.1827</id><created>2008-05-13</created><authors><author><keyname>Bossy</keyname><forenames>Mireille</forenames><affiliation>INRIA Sophia Antipolis / INRIA Lorraine / IECN</affiliation></author><author><keyname>Baude</keyname><forenames>Françoise</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Doan</keyname><forenames>Viet Dung</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Gaikwad</keyname><forenames>Abhijeet</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Stokes-Rees</keyname><forenames>Ian</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Parallel Pricing Algorithms for Multi--Dimensional Bermudan/American
  Options using Monte Carlo methods</title><categories>cs.DC cs.CE</categories><proxy>ccsd inria-00278514</proxy><report-no>RR-6530</report-no><journal-ref>N&amp;deg; RR-6530 (2008)</journal-ref><doi>10.1016/j.matcom.2010.08.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present two parallel Monte Carlo based algorithms for
pricing multi--dimensional Bermudan/American options. First approach relies on
computation of the optimal exercise boundary while the second relies on
classification of continuation and exercise values. We also evaluate the
performance of both the algorithms in a desktop grid environment. We show the
effectiveness of the proposed approaches in a heterogeneous computing
environment, and identify scalability constraints due to the algorithmic
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.2438</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.2438</id><created>2008-05-16</created><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>Certified Exact Transcendental Real Number Computation in Coq</title><categories>cs.LO cs.MS cs.NA</categories><comments>This paper is to be part of the proceedings of the 21st International
  Conference on Theorem Proving in Higher Order Logics (TPHOLs 2008)</comments><journal-ref>Ait Mohamed, C. Munoz, and S. Tahar (Eds.): TPHOLs 2008, LNCS
  5170, pp. 246-261, 2008</journal-ref><doi>10.1007/978-3-540-71067-7_21</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Reasoning about real number expressions in a proof assistant is challenging.
Several problems in theorem proving can be solved by using exact real number
computation. I have implemented a library for reasoning and computing with
complete metric spaces in the Coq proof assistant and used this library to
build a constructive real number implementation including elementary real
number functions and proofs of correctness. Using this library, I have created
a tactic that automatically proves strict inequalities over closed elementary
real number expressions by computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.2630</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.2630</id><created>2008-05-17</created><updated>2013-06-18</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author></authors><title>Sequential Design of Experiments via Linear Programming</title><categories>cs.DS</categories><comments>The results and presentation in this paper are subsumed by the
  article "Approximation algorithms for Bayesian multi-armed bandit problems"
  http://arxiv.org/abs/1306.3525</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The celebrated multi-armed bandit problem in decision theory models the basic
trade-off between exploration, or learning about the state of a system, and
exploitation, or utilizing the system. In this paper we study the variant of
the multi-armed bandit problem where the exploration phase involves costly
experiments and occurs before the exploitation phase; and where each play of an
arm during the exploration phase updates a prior belief about the arm. The
problem of finding an inexpensive exploration strategy to optimize a certain
exploitation objective is NP-Hard even when a single play reveals all
information about an arm, and all exploration steps cost the same.
  We provide the first polynomial time constant-factor approximation algorithm
for this class of problems. We show that this framework also generalizes
several problems of interest studied in the context of data acquisition in
sensor networks. Our analyses also extends to switching and setup costs, and to
concave utility objectives.
  Our solution approach is via a novel linear program rounding technique based
on stochastic packing. In addition to yielding exploration policies whose
performance is within a small constant factor of the adaptive optimal policy, a
nice feature of this approach is that the resulting policies explore the arms
sequentially without revisiting any arm. Sequentiality is a well-studied
concept in decision theory, and is very desirable in domains where multiple
explorations can be conducted in parallel, for instance, in the sensor network
context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.2705</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.2705</id><created>2008-05-17</created><authors><author><keyname>Lucarini</keyname><forenames>Valerio</forenames></author></authors><title>Three-dimensional Random Voronoi Tessellations: From Cubic Crystal
  Lattices to Poisson Point Processes</title><categories>cond-mat.stat-mech cond-mat.dis-nn cond-mat.other cs.CG math-ph math.MP nlin.PS physics.data-an</categories><comments>18 pages, 7 figures</comments><journal-ref>J. Stat. Phys., 134, 185-206 (2009)</journal-ref><doi>10.1007/s10955-008-9668-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perturb the SC, BCC, and FCC crystal structures with a spatial Gaussian
noise whose adimensional strength is controlled by the parameter a, and analyze
the topological and metrical properties of the resulting Voronoi Tessellations
(VT). The topological properties of the VT of the SC and FCC crystals are
unstable with respect to the introduction of noise, because the corresponding
polyhedra are geometrically degenerate, whereas the tessellation of the BCC
crystal is topologically stable even against noise of small but finite
intensity. For weak noise, the mean area of the perturbed BCC and FCC crystals
VT increases quadratically with a. In the case of perturbed SCC crystals, there
is an optimal amount of noise that minimizes the mean area of the cells.
Already for a moderate noise (a&gt;0.5), the properties of the three perturbed VT
are indistinguishable, and for intense noise (a&gt;2), results converge to the
Poisson-VT limit. Notably, 2-parameter gamma distributions are an excellent
model for the empirical of of all considered properties. The VT of the
perturbed BCC and FCC structures are local maxima for the isoperimetric
quotient, which measures the degre of sphericity of the cells, among space
filling VT. In the BCC case, this suggests a weaker form of the recentluy
disproved Kelvin conjecture. Due to the fluctuations of the shape of the cells,
anomalous scalings with exponents &gt;3/2 is observed between the area and the
volumes of the cells, and, except for the FCC case, also for a-&gt;0. In the
Poisson-VT limit, the exponent is about 1.67. As the number of faces is
positively correlated with the sphericity of the cells, the anomalous scaling
is heavily reduced when we perform powerlaw fits separately on cells with a
specific number of faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.2797</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.2797</id><created>2008-05-19</created><updated>2012-03-10</updated><authors><author><keyname>Pinter</keyname><forenames>M.</forenames></author></authors><title>Young's axiomatization of the Shapley value - a new proof</title><categories>cs.GT</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Young (1985)'s characterization of the Shapley value, and give a
new proof of this axiomatization. Moreover, as applications of the new proof,
we show that Young (1985)'s axiomatization of the Shapley value works on
various well-known subclasses of TU games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.2855</identifier>
 <datestamp>2013-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.2855</id><created>2008-05-19</created><updated>2008-07-03</updated><authors><author><keyname>Summers</keyname><forenames>Ed</forenames></author><author><keyname>Isaac</keyname><forenames>Antoine</forenames></author><author><keyname>Redding</keyname><forenames>Clay</forenames></author><author><keyname>Krech</keyname><forenames>Dan</forenames></author></authors><title>LCSH, SKOS and Linked Data</title><categories>cs.DL cs.IR</categories><comments>Submission for the Dublin Core 2008 conference in Berlin</comments><acm-class>H.3.7</acm-class><journal-ref>Web Semantics: Science, Services and Agents on the World Wide Web,
  Volume 20, May 2013, Pages 35-49, ISSN 1570-8268</journal-ref><doi>10.1016/j.websem.2013.05.001</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A technique for converting Library of Congress Subject Headings MARCXML to
Simple Knowledge Organization System (SKOS) RDF is described. Strengths of the
SKOS vocabulary are highlighted, as well as possible points for extension, and
the integration of other semantic web vocabularies such as Dublin Core. An
application for making the vocabulary available as linked-data on the Web is
also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.3521</identifier>
 <datestamp>2011-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.3521</id><created>2008-05-22</created><updated>2009-11-16</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Towards applied theories based on computability logic</title><categories>cs.LO cs.AI math.LO math.NT</categories><comments>To appear in 2010 in the Journal of Symbolic Logic</comments><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Journal of Symbolic Logic 75 (2010), pp. 565-601</journal-ref><doi>10.2178/jsl/1268917495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a
recently launched program for redeveloping logic as a formal theory of
computability, as opposed to the formal theory of truth that logic has more
traditionally been. Formulas in it represent computational problems, "truth"
means existence of an algorithmic solution, and proofs encode such solutions.
Within the line of research devoted to finding axiomatizations for ever more
expressive fragments of CL, the present paper introduces a new deductive system
CL12 and proves its soundness and completeness with respect to the semantics of
CL. Conservatively extending classical predicate calculus and offering
considerable additional expressive and deductive power, CL12 presents a
reasonable, computationally meaningful, constructive alternative to classical
logic as a basis for applied theories. To obtain a model example of such
theories, this paper rebuilds the traditional, classical-logic-based Peano
arithmetic into a computability-logic-based counterpart. Among the purposes of
the present contribution is to provide a starting point for what, as the author
wishes to hope, might become a new line of research with a potential of
interesting findings -- an exploration of the presumably quite unusual
metatheory of CL-based arithmetic and other CL-based applied systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.3528</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.3528</id><created>2008-05-22</created><updated>2011-09-08</updated><authors><author><keyname>Silberstein</keyname><forenames>Natalia</forenames></author></authors><title>Coding Theory and Projective Spaces</title><categories>cs.IT math.IT</categories><comments>This is a PhD thesis performed at the Technion by Natalia Silberstein
  and supervised by Prof. Tuvi Etzion</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The projective space of order $n$ over a finite field $\F_q$ is a set of all
subspaces of the vector space $\F_q^{n}$. In this work, we consider
error-correcting codes in the projective space, focusing mainly on constant
dimension codes. We start with the different representations of subspaces in
the projective space. These representations involve matrices in reduced row
echelon form, associated binary vectors, and Ferrers diagrams. Based on these
representations, we provide a new formula for the computation of the distance
between any two subspaces in the projective space. We examine lifted maximum
rank distance (MRD) codes, which are nearly optimal constant dimension codes.
We prove that a lifted MRD code can be represented in such a way that it forms
a block design known as a transversal design. The incidence matrix of the
transversal design derived from a lifted MRD code can be viewed as a
parity-check matrix of a linear code in the Hamming space. We find the
properties of these codes which can be viewed also as LDPC codes. We present
new bounds and constructions for constant dimension codes. First, we present a
multilevel construction for constant dimension codes, which can be viewed as a
generalization of a lifted MRD codes construction. This construction is based
on a new type of rank-metric codes, called Ferrers diagram rank-metric codes.
Then we derive upper bounds on the size of constant dimension codes which
contain the lifted MRD code, and provide a construction for two families of
codes, that attain these upper bounds. We generalize the well-known concept of
a punctured code for a code in the projective space to obtain large codes which
are not constant dimension. We present efficient enumerative encoding and
decoding techniques for the Grassmannian. Finally we describe a search method
for constant dimension lexicodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.3799</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.3799</id><created>2008-05-24</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Ganz</keyname><forenames>Adam</forenames></author><author><keyname>McKie</keyname><forenames>Stewart</forenames></author></authors><title>The Structure of Narrative: the Case of Film Scripts</title><categories>cs.AI</categories><comments>28 pages, 7 figures, 21 references</comments><acm-class>I.5.4; I.2.7; H.3.1</acm-class><journal-ref>Pattern Recognition, 42 (2), 302-312, 2009</journal-ref><doi>10.1016/j.patcog.2008.05.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the style and structure of story narrative using the case of film
scripts. The practical importance of this is noted, especially the need to have
support tools for television movie writing. We use the Casablanca film script,
and scripts from six episodes of CSI (Crime Scene Investigation). For analysis
of style and structure, we quantify various central perspectives discussed in
McKee's book, "Story: Substance, Structure, Style, and the Principles of
Screenwriting". Film scripts offer a useful point of departure for exploration
of the analysis of more general narratives. Our methodology, using
Correspondence Analysis, and hierarchical clustering, is innovative in a range
of areas that we discuss. In particular this work is groundbreaking in taking
the qualitative analysis of McKee and grounding this analysis in a quantitative
and algorithmic framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.3964</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.3964</id><created>2008-05-26</created><updated>2011-05-15</updated><authors><author><keyname>Lopes</keyname><forenames>Fabricio Martins</forenames></author><author><keyname>Martins-Jr</keyname><forenames>David Correa</forenames></author><author><keyname>Cesar-Jr</keyname><forenames>Roberto M.</forenames></author></authors><title>DimReduction - Interactive Graphic Environment for Dimensionality
  Reduction</title><categories>cs.CV</categories><comments>13 pages, 4 figures, site http://code.google.com/p/dimreduction/</comments><acm-class>I.5.2</acm-class><journal-ref>BMC Bioinformatics 2008, 9:451</journal-ref><doi>10.1186/1471-2105-9-451</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Feature selection is a pattern recognition approach to choose important
variables according to some criteria to distinguish or explain certain
phenomena. There are many genomic and proteomic applications which rely on
feature selection to answer questions such as: selecting signature genes which
are informative about some biological state, e.g. normal tissues and several
types of cancer; or defining a network of prediction or inference among
elements such as genes, proteins, external stimuli and other elements of
interest. In these applications, a recurrent problem is the lack of samples to
perform an adequate estimate of the joint probabilities between element states.
A myriad of feature selection algorithms and criterion functions are proposed,
although it is difficult to point the best solution in general. The intent of
this work is to provide an open-source multiplataform graphical environment to
apply, test and compare many feature selection approaches suitable to be used
in bioinformatics problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.4007</identifier>
 <datestamp>2012-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.4007</id><created>2008-05-26</created><updated>2012-01-05</updated><authors><author><keyname>Pinter</keyname><forenames>Miklos</forenames></author></authors><title>Every hierarchy of beliefs is a type</title><categories>cs.GT</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When modeling game situations of incomplete information one usually considers
the players' hierarchies of beliefs, a source of all sorts of complications.
Hars\'anyi (1967-68)'s idea henceforth referred to as the "Hars\'anyi program"
is that hierarchies of beliefs can be replaced by "types". The types constitute
the "type space". In the purely measurable framework Heifetz and Samet (1998)
formalize the concept of type spaces and prove the existence and the uniqueness
of a universal type space. Meier (2001) shows that the purely measurable
universal type space is complete, i.e., it is a consistent object. With the aim
of adding the finishing touch to these results, we will prove in this paper
that in the purely measurable framework every hierarchy of beliefs can be
represented by a unique element of the complete universal type space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.4059</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.4059</id><created>2008-05-27</created><updated>2011-04-28</updated><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author></authors><title>Menger's Paths with Minimum Mergings</title><categories>cs.IT math.CO math.IT</categories><comments>28 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an acyclic directed graph with multiple sources and multiple sinks, we
prove that one can choose the Merger's paths between the sources and the sinks
such that the number of mergings between these paths is upper bounded by a
constant depending only on the min-cuts between the sources and the sinks,
regardless of the size and topology of the graph. We also give bounds on the
minimum number of mergings between these paths, and discuss how it depends on
the min-cuts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.4112</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.4112</id><created>2008-05-27</created><authors><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author></authors><title>On the entropy and log-concavity of compound Poisson measures</title><categories>cs.IT math.IT math.PR</categories><report-no>Superceded by arXiv:0912.0581</report-no><msc-class>62B10, 94A17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated, in part, by the desire to develop an information-theoretic
foundation for compound Poisson approximation limit theorems (analogous to the
corresponding developments for the central limit theorem and for simple Poisson
approximation), this work examines sufficient conditions under which the
compound Poisson distribution has maximal entropy within a natural class of
probability measures on the nonnegative integers. We show that the natural
analog of the Poisson maximum entropy property remains valid if the measures
under consideration are log-concave, but that it fails in general. A parallel
maximum entropy result is established for the family of compound binomial
measures. The proofs are largely based on ideas related to the semigroup
approach introduced in recent work by Johnson for the Poisson family.
Sufficient conditions are given for compound distributions to be log-concave,
and specific examples are presented illustrating all the above results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0805.4560</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0805.4560</id><created>2008-05-29</created><authors><author><keyname>Owladeghaffari</keyname><forenames>H.</forenames></author></authors><title>Rock mechanics modeling based on soft granulation theory</title><categories>cs.AI</categories><doi>10.1016/j.ijrmms.2008.09.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes application of information granulation theory, on the
design of rock engineering flowcharts. Firstly, an overall flowchart, based on
information granulation theory has been highlighted. Information granulation
theory, in crisp (non-fuzzy) or fuzzy format, can take into account engineering
experiences (especially in fuzzy shape-incomplete information or superfluous),
or engineering judgments, in each step of designing procedure, while the
suitable instruments modeling are employed. In this manner and to extension of
soft modeling instruments, using three combinations of Self Organizing Map
(SOM), Neuro-Fuzzy Inference System (NFIS), and Rough Set Theory (RST) crisp
and fuzzy granules, from monitored data sets are obtained. The main underlined
core of our algorithms are balancing of crisp(rough or non-fuzzy) granules and
sub fuzzy granules, within non fuzzy information (initial granulation) upon the
open-close iterations. Using different criteria on balancing best granules
(information pockets), are obtained. Validations of our proposed methods, on
the data set of in-situ permeability in rock masses in Shivashan dam, Iran have
been highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0253</identifier>
 <datestamp>2011-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0253</id><created>2008-06-02</created><updated>2011-11-11</updated><authors><author><keyname>Ravsky</keyname><forenames>Alexander</forenames></author><author><keyname>Verbitsky</keyname><forenames>Oleg</forenames></author></authors><title>On collinear sets in straight line drawings</title><categories>cs.CG cs.DM</categories><comments>Several small amendments; 21 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider straight line drawings of a planar graph $G$ with possible edge
crossings. The \emph{untangling problem} is to eliminate all edge crossings by
moving as few vertices as possible to new positions. Let $fix(G)$ denote the
maximum number of vertices that can be left fixed in the worst case. In the
\emph{allocation problem}, we are given a planar graph $G$ on $n$ vertices
together with an $n$-point set $X$ in the plane and have to draw $G$ without
edge crossings so that as many vertices as possible are located in $X$. Let
$fit(G)$ denote the maximum number of points fitting this purpose in the worst
case. As $fix(G)\le fit(G)$, we are interested in upper bounds for the latter
and lower bounds for the former parameter.
  For each $\epsilon&gt;0$, we construct an infinite sequence of graphs with
$fit(G)=O(n^{\sigma+\epsilon})$, where $\sigma&lt;0.99$ is a known graph-theoretic
constant, namely the shortness exponent for the class of cubic polyhedral
graphs. To the best of our knowledge, this is the first example of graphs with
$fit(G)=o(n)$. On the other hand, we prove that $fix(G)\ge\sqrt{n/30}$ for all
$G$ with tree-width at most 2. This extends the lower bound obtained by Goaoc
et al. [Discrete and Computational Geometry 42:542-569 (2009)] for outerplanar
graphs.
  Our upper bound for $fit(G)$ is based on the fact that the constructed graphs
can have only few collinear vertices in any crossing-free drawing. To prove the
lower bound for $fix(G)$, we show that graphs of tree-width 2 admit drawings
that have large sets of collinear vertices with some additional special
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0478</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0478</id><created>2008-06-03</created><authors><author><keyname>Terui</keyname><forenames>Akira</forenames></author></authors><title>Subresultants in Recursive Polynomial Remainder Sequence</title><categories>math.AC cs.SC</categories><comments>13 pages. Presented at CASC 2003 (Passau, Germany, September 20-26,
  2003)</comments><msc-class>13P99; 68W30</msc-class><journal-ref>Proceedings of The 6th International Workshop on Computer Algebra
  in Scientific Computing: CASC 2003, Institute for Informatics, Technische
  Universitat Munchen, Garching, Germanay, 2003, 363-375</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce concepts of "recursive polynomial remainder sequence (PRS)" and
"recursive subresultant," and investigate their properties. In calculating PRS,
if there exists the GCD (greatest common divisor) of initial polynomials, we
calculate "recursively" with new PRS for the GCD and its derivative, until a
constant is derived. We call such a PRS a recursive PRS. We define recursive
subresultants to be determinants representing the coefficients in recursive PRS
by coefficients of initial polynomials. Finally, we discuss usage of recursive
subresultants in approximate algebraic computation, which motivates the present
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0488</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0488</id><created>2008-06-03</created><authors><author><keyname>Terui</keyname><forenames>Akira</forenames></author></authors><title>Recursive Polynomial Remainder Sequence and the Nested Subresultants</title><categories>math.AC cs.SC</categories><comments>12 pages. Presented at CASC 2005 (Kalamata, Greece, Septermber 12-16,
  2005)</comments><msc-class>13P99; 68W30</msc-class><journal-ref>Computer Algebra in Scientific Computing (Proc. CASC 2005),
  Lecture Notes in Computer Science 3718, Springer, 2005, 445-456</journal-ref><doi>10.1007/11555964_38</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give two new expressions of subresultants, nested subresultant and reduced
nested subresultant, for the recursive polynomial remainder sequence (PRS)
which has been introduced by the author. The reduced nested subresultant
reduces the size of the subresultant matrix drastically compared with the
recursive subresultant proposed by the authors before, hence it is much more
useful for investigation of the recursive PRS. Finally, we discuss usage of the
reduced nested subresultant in approximate algebraic computation, which
motivates the present work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0495</identifier>
 <datestamp>2010-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0495</id><created>2008-06-03</created><authors><author><keyname>Terui</keyname><forenames>Akira</forenames></author></authors><title>Recursive Polynomial Remainder Sequence and its Subresultants</title><categories>math.AC cs.SC</categories><comments>30 pages. Preliminary versions of this paper have been presented at
  CASC 2003 (arXiv:0806.0478 [math.AC]) and CASC 2005 (arXiv:0806.0488
  [math.AC])</comments><msc-class>13P99; 68W30</msc-class><journal-ref>Journal of Algebra, Vol. 320, No. 2, pp. 633-659, 2008</journal-ref><doi>10.1016/j.jalgebra.2007.12.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce concepts of "recursive polynomial remainder sequence (PRS)" and
"recursive subresultant," along with investigation of their properties. A
recursive PRS is defined as, if there exists the GCD (greatest common divisor)
of initial polynomials, a sequence of PRSs calculated "recursively" for the GCD
and its derivative until a constant is derived, and recursive subresultants are
defined by determinants representing the coefficients in recursive PRS as
functions of coefficients of initial polynomials. We give three different
constructions of subresultant matrices for recursive subresultants; while the
first one is built-up just with previously defined matrices thus the size of
the matrix increases fast as the recursion deepens, the last one reduces the
size of the matrix drastically by the Gaussian elimination on the second one
which has a "nested" expression, i.e. a Sylvester matrix whose elements are
themselves determinants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0557</identifier>
 <datestamp>2011-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0557</id><created>2008-06-03</created><updated>2011-07-11</updated><authors><author><keyname>Li</keyname><forenames>Qin</forenames></author><author><keyname>Li</keyname><forenames>Chengqing</forenames></author><author><keyname>Wu</keyname><forenames>Chunhui</forenames></author><author><keyname>Long</keyname><forenames>Dongyang</forenames></author><author><keyname>Wang</keyname><forenames>Changji</forenames></author></authors><title>An efficient and provably secure arbitrated quantum signature scheme</title><categories>quant-ph cs.CR</categories><comments>some contents changed, 12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an efficient arbitrated quantum signature scheme is proposed
by combining quantum cryptographic techniques and some ideas in classical
cryptography. In the presented scheme, the signatory and the receiver can share
a long-term secret key with the arbitrator by utilizing the key together with a
random number. While in previous quantum signature schemes, the key shared
between the signatory and the arbitrator or between the receiver and the
arbitrator could be used only once, and thus each time when a signatory needs
to sign, the signatory and the receiver have to obtain a new key shared with
the arbitrator through a quantum key distribution protocol. Detailed
theoretical analysis shows that the proposed scheme is efficient and provably
secure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0562</identifier>
 <datestamp>2011-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0562</id><created>2008-06-03</created><updated>2010-05-31</updated><authors><author><keyname>Bontemps</keyname><forenames>Dominique</forenames><affiliation>LM-Orsay</affiliation></author></authors><title>Universal Coding on Infinite Alphabets: Exponentially Decreasing
  Envelopes</title><categories>cs.IT math.IT</categories><proxy>ccsd</proxy><journal-ref>IEEE Transactions on Information Theory 57, 3 (2011) 1466 - 1478</journal-ref><doi>10.1109/TIT.2010.2103831</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of universal lossless coding on a countable
infinite alphabet. It focuses on some classes of sources defined by an envelope
condition on the marginal distribution, namely exponentially decreasing
envelope classes with exponent $\alpha$. The minimax redundancy of
exponentially decreasing envelope classes is proved to be equivalent to
$\frac{1}{4 \alpha \log e} \log^2 n$. Then a coding strategy is proposed, with
a Bayes redundancy equivalent to the maximin redundancy. At last, an adaptive
algorithm is provided, whose redundancy is equivalent to the minimax redundancy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0840</identifier>
 <datestamp>2012-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0840</id><created>2008-06-04</created><updated>2012-12-17</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>A Dynamic Programming Framework for Combinatorial Optimization Problems
  on Graphs with Bounded Pathwidth</title><categories>cs.DS cs.DM</categories><comments>Some of the ideas presented in this paper were later used by the
  author for preparing algorithmic tasks for several contests where the author
  was a member of the scientific committee (e.g. ACM ICPC Southeastern regional
  contest 2009 and Balkan olympiad in informatics 2011). Such tasks (including
  the task statement and solutions) can be found in the attached zip archive;
  THETA 16 / AQTR, Cluj-Napoca : Romania (2008)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an algorithmic framework for solving a class of
combinatorial optimization problems on graphs with bounded pathwidth. The
problems are NP-hard in general, but solvable in linear time on this type of
graphs. The problems are relevant for assessing network reliability and
improving the network's performance and fault tolerance. The main technique
considered in this paper is dynamic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0874</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0874</id><created>2008-06-04</created><updated>2008-08-08</updated><authors><author><keyname>Kostakos</keyname><forenames>Vassilis</forenames></author></authors><title>Towards sustainable transport: wireless detection of passenger trips on
  public transport buses</title><categories>cs.CY</categories><comments>13 pages, 4 figures, 1 table</comments><journal-ref>Personal and Ubiquitous Computing, 17(8):1807-1816, 2013</journal-ref><doi>10.1007/s00779-013-0652-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important problem in creating efficient public transport is obtaining data
about the set of trips that passengers make, usually referred to as an
Origin/Destination (OD) matrix. Obtaining this data is problematic and
expensive in general, especially in the case of buses because on-board
ticketing systems do not record where and when passengers get off a bus. In
this paper we describe a novel and inexpensive system that uses off-the-shelf
Bluetooth hardware to accurately record passenger journeys. Here we show how
our system can be used to derive passenger OD matrices, and additionally we
show how our data can be used to further improve public transport services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0920</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0920</id><created>2008-06-05</created><updated>2010-09-16</updated><authors><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author><author><keyname>Buchin</keyname><forenames>Maike</forenames></author><author><keyname>Byrka</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Nöllenburg</keyname><forenames>Martin</forenames></author><author><keyname>Okamoto</keyname><forenames>Yoshio</forenames></author><author><keyname>Silveira</keyname><forenames>Rodrigo I.</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>Drawing (Complete) Binary Tanglegrams: Hardness, Approximation,
  Fixed-Parameter Tractability</title><categories>cs.CG cs.CC</categories><comments>Journal version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A \emph{binary tanglegram} is a drawing of a pair of rooted binary trees
whose leaf sets are in one-to-one correspondence; matching leaves are connected
by inter-tree edges. For applications, for example, in phylogenetics, it is
essential that both trees are drawn without edge crossings and that the
inter-tree edges have as few crossings as possible. It is known that finding a
tanglegram with the minimum number of crossings is NP-hard and that the problem
is fixed-parameter tractable with respect to that number.
  We prove that under the Unique Games Conjecture there is no constant-factor
approximation for binary trees. We show that the problem is NP-hard even if
both trees are complete binary trees. For this case we give an $O(n^3)$-time
2-approximation and a new, simple fixed-parameter algorithm. We show that the
maximization version of the dual problem for binary trees can be reduced to a
version of MaxCut for which the algorithm of Goemans and Williamson yields a
0.878-approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0936</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0936</id><created>2008-06-05</created><updated>2008-09-18</updated><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author></authors><title>On convergence-sensitive bisimulation and the embedding of CCS in timed
  CCS</title><categories>cs.LO</categories><proxy>ccsd hal-00285337</proxy><journal-ref>Proceedings of the 15th Workshop on Expressiveness in Concurrency
  (EXPRESS 2008), Canada (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a notion of convergence-sensitive bisimulation that is built just
over the notions of (internal) reduction and of (static) context. In the
framework of timed CCS, we characterise this notion of `contextual'
bisimulation via the usual labelled transition system. We also remark that it
provides a suitable semantic framework for a fully abstract embedding of
untimed processes into timed ones. Finally, we show that the notion can be
refined to include sensitivity to divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.0983</identifier>
 <datestamp>2012-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.0983</id><created>2008-06-05</created><updated>2012-10-12</updated><authors><author><keyname>Boyar</keyname><forenames>Joan</forenames></author><author><keyname>Irani</keyname><forenames>Sandy</forenames></author><author><keyname>Larsen</keyname><forenames>Kim S.</forenames></author></authors><title>A Comparison of Performance Measures for Online Algorithms</title><categories>cs.DS</categories><acm-class>F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a systematic study of several proposed measures for
online algorithms in the context of a specific problem, namely, the two server
problem on three colinear points. Even though the problem is simple, it
encapsulates a core challenge in online algorithms which is to balance
greediness and adaptability. We examine Competitive Analysis, the Max/Max
Ratio, the Random Order Ratio, Bijective Analysis and Relative Worst Order
Analysis, and determine how these measures compare the Greedy Algorithm, Double
Coverage, and Lazy Double Coverage, commonly studied algorithms in the context
of server problems. We find that by the Max/Max Ratio and Bijective Analysis,
Greedy is the best of the three algorithms. Under the other measures, Double
Coverage and Lazy Double Coverage are better, though Relative Worst Order
Analysis indicates that Greedy is sometimes better. Only Bijective Analysis and
Relative Worst Order Analysis indicate that Lazy Double Coverage is better than
Double Coverage. Our results also provide the first proof of optimality of an
algorithm under Relative Worst Order Analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1148</identifier>
 <datestamp>2010-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1148</id><created>2008-06-06</created><updated>2010-09-06</updated><authors><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author><author><keyname>Zumstein</keyname><forenames>Philipp</forenames></author></authors><title>Unsatisfiable CNF Formulas need many Conflicts</title><categories>cs.DM</categories><comments>new version; added an upper bound on the number of conflicts</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pair of clauses in a CNF formula constitutes a conflict if there is a
variable that occurs positively in one clause and negatively in the other. A
CNF formula without any conflicts is satisfiable. The Lovasz Local Lemma
implies that a k-CNF formula is satisfiable if each clause conflicts with at
most 2^k/e-1 clauses. It does not, however, give any good bound on how many
conflicts an unsatisfiable formula has globally. We show here that every
unsatisfiable k-CNF formula requires 2.69^k conflicts and there exist
unsatisfiable k-CNF formulas with 3.51^k conflicts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1215</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1215</id><created>2008-06-06</created><updated>2010-05-28</updated><authors><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author></authors><title>Performance of LDPC Codes Under Faulty Iterative Decoding</title><categories>cs.IT math.IT</categories><comments>Revised in May 2010 in response to reviewer comments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Departing from traditional communication theory where decoding algorithms are
assumed to perform without error, a system where noise perturbs both
computational devices and communication channels is considered here. This paper
studies limits in processing noisy signals with noisy circuits by investigating
the effect of noise on standard iterative decoders for low-density parity-check
codes. Concentration of decoding performance around its average is shown to
hold when noise is introduced into message-passing and local computation.
Density evolution equations for simple faulty iterative decoders are derived.
In one model, computing nonlinear estimation thresholds shows that performance
degrades smoothly as decoder noise increases, but arbitrarily small probability
of error is not achievable. Probability of error may be driven to zero in
another system model; the decoding threshold again decreases smoothly with
decoder noise. As an application of the methods developed, an achievability
result for reliable memory systems constructed from unreliable components is
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1231</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1231</id><created>2008-06-06</created><updated>2010-02-11</updated><authors><author><keyname>Assis</keyname><forenames>F. M.</forenames></author><author><keyname>Mateus</keyname><forenames>P.</forenames></author><author><keyname>Omar</keyname><forenames>Y.</forenames></author></authors><title>Improving Classical Authentication with Quantum Communication</title><categories>cs.IT cs.CR math.IT</categories><comments>New improved version, with several clarifications in the text and new
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a quantum-enhanced protocol to authenticate classical messages,
with improved security with respect to the classical scheme introduced by
Brassard in 1983. In that protocol, the shared key is the seed of a
pseudo-random generator (PRG) and a hash function is used to create the
authentication tag of a public message. We show that a quantum encoding of
secret bits offers more security than the classical XOR function introduced by
Brassard. Furthermore, we establish the relationship between the bias of a PRG
and the amount of information about the key that the attacker can retrieve from
a block of authenticated messages. Finally, we prove that quantum resources can
improve both the secrecy of the key generated by the PRG and the secrecy of the
tag obtained with a hidden hash function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1413</identifier>
 <datestamp>2013-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1413</id><created>2008-06-09</created><updated>2013-03-12</updated><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM, IMJ, LIP</affiliation></author></authors><title>Topological Complexity of Context-Free omega-Languages: A Survey</title><categories>cs.LO cs.CC math.LO</categories><proxy>ccsd</proxy><report-no>LIP Research Report RR 2008-17</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey recent results on the topological complexity of context-free
omega-languages which form the second level of the Chomsky hierarchy of
languages of infinite words. In particular, we consider the Borel hierarchy and
the Wadge hierarchy of non-deterministic or deterministic context-free
omega-languages. We study also decision problems, the links with the notions of
ambiguity and of degrees of ambiguity, and the special case of omega-powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.1438</identifier>
 <datestamp>2013-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.1438</id><created>2008-06-09</created><updated>2013-01-04</updated><authors><author><keyname>Bekkai</keyname><forenames>Siham</forenames></author><author><keyname>Kouider</keyname><forenames>Mekkia</forenames></author></authors><title>On Mean Distance and Girth</title><categories>cs.DM</categories><comments>this paper has been withdrawn because it has been published</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We bound the mean distance in a connected graph which is not a tree in
function of its order $n$ and its girth $g$. On one hand, we show that mean
distance is at most $\frac{n+1}{3}-\frac{g(g^2-4)}{12n(n-1)}$ if $g$ is even
and at most $\frac{n+1}{3}-\frac{g(g^2-1)}{12n(n-1)}$ if $g$ is odd. On the
other hand, we prove that mean distance is at least $\frac{ng}{4(n-1)}$ unless
$G$ is an odd cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2006</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2006</id><created>2008-06-12</created><updated>2012-01-06</updated><authors><author><keyname>Martin</keyname><forenames>Arnaud</forenames><affiliation>E3I2</affiliation></author></authors><title>Fusion de classifieurs pour la classification d'images sonar</title><categories>cs.CV cs.AI</categories><proxy>ccsd</proxy><journal-ref>Revue Nationale des Technologies de l'Information E, 5 (2005)
  259-268</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present some high level information fusion approaches for
numeric and symbolic data. We study the interest of such method particularly
for classifier fusion. A comparative study is made in a context of sea bed
characterization from sonar images. The classi- fication of kind of sediment is
a difficult problem because of the data complexity. We compare high level
information fusion and give the obtained performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2096</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2096</id><created>2008-06-12</created><authors><author><keyname>Kempner</keyname><forenames>Yulia</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>Geometry of antimatroidal point sets</title><categories>math.CO cs.DM</categories><comments>14 pages, 3 figures</comments><msc-class>52B40 (Primary); 05B50 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of "antimatroid with repetition" was conceived by Bjorner, Lovasz
and Shor in 1991 as a multiset extension of the notion of antimatroid. When the
underlying set consists of only two elements, such two-dimensional antimatroids
correspond to point sets in the plane. In this research we concentrate on
geometrical properties of antimatroidal point sets in the plane and prove that
these sets are exactly parallelogram polyominoes. Our results imply that
two-dimensional antimatroids have convex dimension 2. The second part of the
research is devoted to geometrical properties of three-dimensional antimatroids
closed under intersection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2287</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2287</id><created>2008-06-13</created><updated>2013-06-21</updated><authors><author><keyname>Furer</keyname><forenames>Martin</forenames></author><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author></authors><title>Approximately Counting Embeddings into Random Graphs</title><categories>cs.DS cs.DM</categories><comments>Earlier version appeared in Random 2008. Fixed an typo in Definition
  3.1</comments><doi>10.1017/S0963548314000339</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let H be a graph, and let C_H(G) be the number of (subgraph isomorphic)
copies of H contained in a graph G. We investigate the fundamental problem of
estimating C_H(G). Previous results cover only a few specific instances of this
general problem, for example, the case when H has degree at most one
(monomer-dimer problem). In this paper, we present the first general subcase of
the subgraph isomorphism counting problem which is almost always efficiently
approximable. The results rely on a new graph decomposition technique.
Informally, the decomposition is a labeling of the vertices such that every
edge is between vertices with different labels and for every vertex all
neighbors with a higher label have identical labels. The labeling implicitly
generates a sequence of bipartite graphs which permits us to break the problem
of counting embeddings of large subgraphs into that of counting embeddings of
small subgraphs. Using this method, we present a simple randomized algorithm
for the counting problem. For all decomposable graphs H and all graphs G, the
algorithm is an unbiased estimator. Furthermore, for all graphs H having a
decomposition where each of the bipartite graphs generated is small and almost
all graphs G, the algorithm is a fully polynomial randomized approximation
scheme.
  We show that the graph classes of H for which we obtain a fully polynomial
randomized approximation scheme for almost all G includes graphs of degree at
most two, bounded-degree forests, bounded-length grid graphs, subdivision of
bounded-degree graphs, and major subclasses of outerplanar graphs,
series-parallel graphs and planar graphs, whereas unbounded-length grid graphs
are excluded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2923</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2923</id><created>2008-06-18</created><updated>2012-03-19</updated><authors><author><keyname>Luttenberger</keyname><forenames>Michael</forenames></author></authors><title>Strategy Iteration using Non-Deterministic Strategies for Solving Parity
  Games</title><categories>cs.GT cs.LO</categories><acm-class>D.2.4; F.3.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article extends the idea of solving parity games by strategy iteration
to non-deterministic strategies: In a non-deterministic strategy a player
restricts himself to some non-empty subset of possible actions at a given node,
instead of limiting himself to exactly one action. We show that a
strategy-improvement algorithm by by Bjoerklund, Sandberg, and Vorobyov can
easily be adapted to the more general setting of non-deterministic strategies.
Further, we show that applying the heuristic of "all profitable switches" leads
to choosing a "locally optimal" successor strategy in the setting of
non-deterministic strategies, thereby obtaining an easy proof of an algorithm
by Schewe. In contrast to the algorithm by Bjoerklund et al., we present our
algorithm directly for parity games which allows us to compare it to the
algorithm by Jurdzinski and Voege: We show that the valuations used in both
algorithm coincide on parity game arenas in which one player can "surrender".
Thus, our algorithm can also be seen as a generalization of the one by
Jurdzinski and Voege to non-deterministic strategies. Finally, using
non-deterministic strategies allows us to show that the number of improvement
steps is bound from above by O(1.724^n). For strategy-improvement algorithms,
this bound was previously only known to be attainable by using randomization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.2947</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.2947</id><created>2008-06-18</created><updated>2009-07-10</updated><authors><author><keyname>Kamouna</keyname><forenames>Rafee Ebrahim</forenames></author></authors><title>The Kleene-Rosser Paradox, The Liar's Paradox &amp; A Fuzzy Logic
  Programming Paradox Imply SAT is (NOT) NP-complete</title><categories>cs.LO</categories><comments>Submitted to the ACM Transactions on Computation Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After examining the {\bf P} versus {\bf NP} problem against the Kleene-Rosser
paradox of the $\lambda$-calculus [94], it was found that it represents a
counter-example to NP-completeness. We prove that it contradicts the proof of
Cook's theorem. A logical formalization of the liar's paradox leads to the same
result. This formalization of the liar's paradox into a computable form is a
2-valued instance of a fuzzy logic programming paradox discovered in the system
of [90]. Three proofs that show that {\bf SAT} is (NOT) NP-complete are
presented. The counter-example classes to NP-completeness are also
counter-examples to Fagin's theorem [36] and the Immermann-Vardi theorem
[89,110], the fundamental results of descriptive complexity. All these results
show that {\bf ZF$\not$C} is inconsistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3023</identifier>
 <datestamp>2010-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3023</id><created>2008-06-18</created><updated>2010-07-13</updated><authors><author><keyname>Lin</keyname><forenames>C.</forenames></author><author><keyname>Veeravalli</keyname><forenames>V. V.</forenames></author><author><keyname>Meyn</keyname><forenames>S.</forenames></author></authors><title>A Random Search Framework for Convergence Analysis of Distributed
  Beamforming with Feedback</title><categories>cs.DC cs.IT math.IT</categories><comments>8 pages, 3 figures, presented partially at ITA '08 and PSU School of
  Info. Theory '08</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of this work is on the analysis of transmit beamforming schemes
with a low-rate feedback link in wireless sensor/relay networks, where nodes in
the network need to implement beamforming in a distributed manner.
Specifically, the problem of distributed phase alignment is considered, where
neither the transmitters nor the receiver has perfect channel state
information, but there is a low-rate feedback link from the receiver to the
transmitters. In this setting, a framework is proposed for systematically
analyzing the performance of distributed beamforming schemes. To illustrate the
advantage of this framework, a simple adaptive distributed beamforming scheme
that was recently proposed by Mudambai et al. is studied. Two important
properties for the received signal magnitude function are derived. Using these
properties and the systematic framework, it is shown that the adaptive
distributed beamforming scheme converges both in probability and in mean.
Furthermore, it is established that the time required for the adaptive scheme
to converge in mean scales linearly with respect to the number of sensor/relay
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3209</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3209</id><created>2008-06-19</created><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>A Computer Verified Theory of Compact Sets</title><categories>cs.LO</categories><comments>This paper is to be part of the proceedings of the Symbolic
  Computation in Software Science Austrian-Japanese Workshop (SCSS 2008)</comments><report-no>RISC-Linz Report Series 08-08</report-no><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Compact sets in constructive mathematics capture our intuition of what
computable subsets of the plane (or any other complete metric space) ought to
be. A good representation of compact sets provides an efficient means of
creating and displaying images with a computer. In this paper, I build upon
existing work about complete metric spaces to define compact sets as the
completion of the space of finite sets under the Hausdorff metric. This
definition allowed me to quickly develop a computer verified theory of compact
sets. I applied this theory to compute provably correct plots of uniformly
continuous functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3471</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3471</id><created>2008-06-20</created><updated>2010-06-15</updated><authors><author><keyname>Canepa</keyname><forenames>Davide</forenames></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria Gradinariu</forenames></author></authors><title>Stabilizing Tiny Interaction Protocols</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the self-stabilizing implementation of a class of
token based algorithms. In the current work we only consider interactions
between weak nodes. They are uniform, they do not have unique identifiers, are
static and their interactions are restricted to a subset of nodes called
neighbours. While interacting, a pair of neighbouring nodes may create mobile
agents (that materialize in the current work the token abstraction) that
perform traversals of the network and accelerate the system stabilization. In
this work we only explore the power of oblivious stateless agents.
  Our work shows that the agent paradigm is an elegant distributed tool for
achieving self-stabilization in Tiny Interaction Protocols (TIP). Nevertheless,
in order to reach the full power of classical self-stabilizing algorithms more
complex classes of agents have to be considered (e.g. agents with memory,
identifiers or communication skills). Interestingly, our work proposes for the
first time a model that unifies the recent studies in mobile robots(agents)
that evolve in a discrete space and the already established population
protocols paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3474</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3474</id><created>2008-06-20</created><updated>2009-09-29</updated><authors><author><keyname>Ensslin</keyname><forenames>Torsten A.</forenames></author><author><keyname>Frommert</keyname><forenames>Mona</forenames></author><author><keyname>Kitaura</keyname><forenames>Francisco S.</forenames></author></authors><title>Information field theory for cosmological perturbation reconstruction
  and non-linear signal analysis</title><categories>astro-ph cs.IT hep-th math.IT physics.data-an stat.CO</categories><comments>38 pages, 6 figures, LaTeX; version accepted by PRD</comments><report-no>J-MPA2270e</report-no><doi>10.1103/PhysRevD.80.105005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop information field theory (IFT) as a means of Bayesian inference on
spatially distributed signals, the information fields. A didactical approach is
attempted. Starting from general considerations on the nature of measurements,
signals, noise, and their relation to a physical reality, we derive the
information Hamiltonian, the source field, propagator, and interaction terms.
Free IFT reproduces the well known Wiener-filter theory. Interacting IFT can be
diagrammatically expanded, for which we provide the Feynman rules in position-,
Fourier-, and spherical harmonics space, and the Boltzmann-Shannon information
measure. The theory should be applicable in many fields. However, here, two
cosmological signal recovery problems are discussed in their IFT-formulation.
1) Reconstruction of the cosmic large-scale structure matter distribution from
discrete galaxy counts in incomplete galaxy surveys within a simple model of
galaxy formation. We show that a Gaussian signal, which should resemble the
initial density perturbations of the Universe, observed with a strongly
non-linear, incomplete and Poissonian-noise affected response, as the processes
of structure and galaxy formation and observations provide, can be
reconstructed thanks to the virtue of a response-renormalization flow equation.
2) We design a filter to detect local non-linearities in the cosmic microwave
background, which are predicted from some Early-Universe inflationary
scenarios, and expected due to measurement imperfections. This filter is the
optimal Bayes' estimator up to linear order in the non-linearity parameter and
can be used even to construct sky maps of non-linearities in the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3480</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3480</id><created>2008-06-20</created><updated>2009-12-13</updated><authors><author><keyname>German</keyname><forenames>Oleg</forenames></author><author><keyname>Lakshtanov</keyname><forenames>Evgeny</forenames></author></authors><title>"Minesweeper" and spectrum of discrete Laplacians</title><categories>cs.DM</categories><comments>We add consideration of tables based on the triangle tiling of the
  plane. Its paper version encounters situations typical for the computer
  "Minesweeper" game</comments><journal-ref>Applicable Analysis, Vol. 89, No. 12, December 2010, 1907-1916</journal-ref><doi>10.1080/00036811.2010.505189</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to a problem inspired by the "Minesweeper" computer
game. It is shown that certain configurations of open cells guarantee the
existence and the uniqueness of solution. Mathematically the problem is reduced
to some spectral properties of discrete differential operators. It is shown how
the uniqueness can be used to create a new game which preserves the spirit of
"Minesweeper" but does not require a computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3787</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3787</id><created>2008-06-23</created><updated>2010-10-18</updated><authors><author><keyname>Pedersen</keyname><forenames>Ted</forenames><affiliation>University of Minnesota, Duluth</affiliation></author></authors><title>Computational Approaches to Measuring the Similarity of Short Contexts :
  A Review of Applications and Methods</title><categories>cs.CL</categories><comments>23 pages</comments><journal-ref>University of Minnesota Supercomputing Institute Research Report
  UMSI 2010/118, October 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Measuring the similarity of short written contexts is a fundamental problem
in Natural Language Processing. This article provides a unifying framework by
which short context problems can be categorized both by their intended
application and proposed solution. The goal is to show that various problems
and methodologies that appear quite different on the surface are in fact very
closely related. The axes by which these categorizations are made include the
format of the contexts (headed versus headless), the way in which the contexts
are to be measured (first-order versus second-order similarity), and the
information used to represent the features in the contexts (micro versus macro
views). The unifying thread that binds together many short context applications
and methods is the fact that similarity decisions must be made between contexts
that share few (if any) words in common.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.3827</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.3827</id><created>2008-06-24</created><updated>2012-12-20</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Optimal Scheduling of File Transfers with Divisible Sizes on Multiple
  Disjoint Paths</title><categories>cs.DS cs.NI</categories><comments>The algorithmic techniques presented in this paper (particularly the
  block partitioning framework) were used as part of the official solutions for
  several tasks proposed by the author in the 2012 Romanian National Olympiad
  in Informatics (the statements and solutions for these tasks can be found in
  the attached zip archive)</comments><proxy>ccsd</proxy><journal-ref>Proceedings of the IEEE Romania International Conference
  "Communications", 2008. (ISBN: 978-606-521-008-0), Bucharest : Romania (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I investigate several offline and online data transfer
scheduling problems and propose efficient algorithms and techniques for
addressing them. In the offline case, I present a novel, heuristic, algorithm
for scheduling files with divisible sizes on multiple disjoint paths, in order
to maximize the total profit (the problem is equivalent to the multiple
knapsack problem with divisible item sizes). I then consider a cost
optimization problem for transferring a sequence of identical files, subject to
time constraints imposed by the data transfer providers. For the online case I
propose an algorithmic framework based on the block partitioning method, which
can speed up the process of resource allocation and reservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4034</identifier>
 <datestamp>2012-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4034</id><created>2008-06-25</created><updated>2010-05-07</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Data linkage dynamics with shedding</title><categories>cs.LO</categories><comments>22 pages; introduction improved. arXiv admin note: substantial text
  overlap with arXiv:0804.4565</comments><report-no>PRG0809</report-no><acm-class>D.3.3; D.4.2; F.1.1; F.3.3</acm-class><journal-ref>Fundamenta Informaticae, 103(1--4):31--52, 2010</journal-ref><doi>10.3233/FI-2010-317</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study shedding in the setting of data linkage dynamics, a simple model of
computation that bears on the use of dynamic data structures in programming.
Shedding is complementary to garbage collection. With shedding, each time a
link to a data object is updated by a program, it is determined whether or not
the link will possibly be used once again by the program, and if not the link
is automatically removed. Thus, everything is made garbage as soon as it can be
viewed as garbage. By that, the effectiveness of garbage collection becomes
maximal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4168</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4168</id><created>2008-06-25</created><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Established Clustering Procedures for Network Analysis</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In light of the burgeoning interest in network analysis in the new millenium,
we bring to the attention of contemporary network theorists, a two-stage
double-standarization and hierarchical clustering (single-linkage-like)
procedure devised in 1974. In its many applications over the next
decade--primarily to the migration flows between geographic subdivisions within
nations--the presence was often revealed of ``hubs''. These are, typically,
``cosmopolitan/non-provincial'' areas--such as the French capital, Paris--which
send and receive people relatively broadly across their respective nations.
Additionally, this two-stage procedure--which ``might very well be the most
successful application of cluster analysis'' (R. C. Dubes)--has detected many
(physically or socially) isolated groups (regions) of areas, such as those
forming the southern islands, Shikoku and Kyushu, of Japan, the Italian islands
of Sardinia and Sicily, and the New England region of the United States.
Further, we discuss a (complementary) approach developed in 1976, involving the
application of the max-flow/min-cut theorem to raw/non-standardized flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4511</identifier>
 <datestamp>2013-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4511</id><created>2008-06-27</created><updated>2013-10-23</updated><authors><author><keyname>Wishnevsky</keyname><forenames>Konstantin P.</forenames></author></authors><title>The model of quantum evolution</title><categories>cs.AI</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to extremely unscientific
errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4631</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4631</id><created>2008-06-27</created><updated>2010-11-04</updated><authors><author><keyname>Salikhmetov</keyname><forenames>Anton</forenames></author></authors><title>The Heap Lambda Machine</title><categories>cs.LO</categories><comments>14 pages, 4 figures, source code appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new machine architecture for evaluating lambda
expressions using the normal-order reduction, which guarantees that every
lambda expression will be evaluated if the expression has its normal form and
the system has enough memory. The architecture considered here operates using
heap memory only. Lambda expressions are represented as graphs, and all
algorithms used in the processing unit of this machine are non-recursive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4746</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4746</id><created>2008-06-29</created><updated>2010-09-26</updated><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Concept-Oriented Programming</title><categories>cs.PL</categories><comments>46 pages, 8 figures, 11 listings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object-oriented programming (OOP) is aimed at describing the structure and
behaviour of objects by hiding the mechanism of their representation and access
in primitive references. In this article we describe an approach, called
concept-oriented programming (COP), which focuses on modelling references
assuming that they also possess application-specific structure and behaviour
accounting for a great deal or even most of the overall program complexity.
References in COP are completely legalized and get the same status as objects
while the functions are distributed among both objects and references. In order
to support this design we introduce a new programming construct, called
concept, which generalizes conventional classes and concept inclusion relation
generalizing class inheritance. The main advantage of COP is that it allows
programmers to describe two sides of any program: explicitly used functions of
objects and intermediate functionality of references having cross-cutting
nature and executed implicitly behind the scenes during object access.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4790</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4790</id><created>2008-06-29</created><updated>2010-02-03</updated><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Chung</keyname><forenames>Kai-Min</forenames></author><author><keyname>Liu</keyname><forenames>Zhenming</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>AMS Without 4-Wise Independence on Product Domains</title><categories>cs.DS</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In their seminal work, Alon, Matias, and Szegedy introduced several sketching
techniques, including showing that 4-wise independence is sufficient to obtain
good approximations of the second frequency moment. In this work, we show that
their sketching technique can be extended to product domains $[n]^k$ by using
the product of 4-wise independent functions on $[n]$. Our work extends that of
Indyk and McGregor, who showed the result for $k = 2$. Their primary motivation
was the problem of identifying correlations in data streams. In their model, a
stream of pairs $(i,j) \in [n]^2$ arrive, giving a joint distribution $(X,Y)$,
and they find approximation algorithms for how close the joint distribution is
to the product of the marginal distributions under various metrics, which
naturally corresponds to how close $X$ and $Y$ are to being independent. By
using our technique, we obtain a new result for the problem of approximating
the $\ell_2$ distance between the joint distribution and the product of the
marginal distributions for $k$-ary vectors, instead of just pairs, in a single
pass. Our analysis gives a randomized algorithm that is a $(1 \pm \epsilon)$
approximation (with probability $1-\delta$) that requires space logarithmic in
$n$ and $m$ and proportional to $3^k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0806.4874</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0806.4874</id><created>2008-06-30</created><authors><author><keyname>Ong</keyname><forenames>Lawrence</forenames></author><author><keyname>Motani</keyname><forenames>Mehul</forenames></author></authors><title>Myopic Coding in Multiterminal Networks</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, Vol. 54, No. 7, pp.
  3295-3314, Jul. 2008</journal-ref><doi>10.1109/TIT.2008.924675</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the interplay between cooperation and achievable
rates in multi-terminal networks. Cooperation refers to the process of nodes
working together to relay data toward the destination. There is an inherent
tradeoff between achievable information transmission rates and the level of
cooperation, which is determined by how many nodes are involved and how the
nodes encode/decode the data. We illustrate this trade-off by studying
information-theoretic decode-forward based coding strategies for data
transmission in multi-terminal networks. Decode-forward strategies are usually
discussed in the context of omniscient coding, in which all nodes in the
network fully cooperate with each other, both in encoding and decoding. In this
paper, we investigate myopic coding, in which each node cooperates with only a
few neighboring nodes. We show that achievable rates of myopic decode-forward
can be as large as that of omniscient decode-forward in the low SNR regime. We
also show that when each node has only a few cooperating neighbors, adding one
node into the cooperation increases the transmission rate significantly.
Furthermore, we show that myopic decode-forward can achieve non-zero rates as
the network size grows without bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0038</identifier>
 <datestamp>2010-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0038</id><created>2008-06-30</created><updated>2010-03-04</updated><authors><author><keyname>Zhang</keyname><forenames>Changyong</forenames></author></authors><title>A Novel Mathematical Model for the Unique Shortest Path Routing Problem</title><categories>math.OC cs.DS</categories><comments>31 pages, 4 figures</comments><msc-class>90B10; 90B18</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link weights are the principal parameters of shortest path routing protocols,
the most commonly used protocols for IP networks. The problem of optimally
setting link weights for unique shortest path routing is addressed. Due to the
complexity of the constraints involved, there exist challenges to formulate the
problem properly, so that a solution algorithm may be developed which could
prove to be more efficient than those already in existence. In this paper, a
novel complete formulation with a polynomial number of constraints is first
introduced and then mathematically proved to be correct. It is further
illustrated that the formulation has advantages over a prior one in terms of
both constraint structure and model size for a proposed decomposition method to
solve the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0093</identifier>
 <datestamp>2010-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0093</id><created>2008-07-01</created><authors><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames></author><author><keyname>Borgwardt</keyname><forenames>Karsten M.</forenames></author><author><keyname>Kondor</keyname><forenames>Imre Risi</forenames></author><author><keyname>Schraudolph</keyname><forenames>Nicol N.</forenames></author></authors><title>Graph Kernels</title><categories>cs.LG</categories><comments>http://jmlr.csail.mit.edu/papers/v11/vishwanathan10a.html</comments><journal-ref>Journal of Machine Learning Research 11 (Apr): 1201-1242, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a unified framework to study graph kernels, special cases of which
include the random walk graph kernel \citep{GaeFlaWro03,BorOngSchVisetal05},
marginalized graph kernel \citep{KasTsuIno03,KasTsuIno04,MahUedAkuPeretal04},
and geometric kernel on graphs \citep{Gaertner02}. Through extensions of linear
algebra to Reproducing Kernel Hilbert Spaces (RKHS) and reduction to a
Sylvester equation, we construct an algorithm that improves the time complexity
of kernel computation from $O(n^6)$ to $O(n^3)$. When the graphs are sparse,
conjugate gradient solvers or fixed-point iterations bring our algorithm into
the sub-cubic domain. Experiments on graphs from bioinformatics and other
application domains show that it is often more than a thousand times faster
than previous approaches. We then explore connections between diffusion kernels
\citep{KonLaf02}, regularization on graphs \citep{SmoKon03}, and graph kernels,
and use these connections to propose new graph kernels. Finally, we show that
rational kernels \citep{CorHafMoh02,CorHafMoh03,CorHafMoh04} when specialized
to graphs reduce to the random walk graph kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0199</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0199</id><created>2008-07-01</created><updated>2011-04-11</updated><authors><author><keyname>Unger</keyname><forenames>Thomas</forenames></author><author><keyname>Markin</keyname><forenames>Nadya</forenames></author></authors><title>Quadratic Forms and Space-Time Block Codes from Generalized Quaternion
  and Biquaternion Algebras</title><categories>cs.IT math.IT</categories><comments>8 pages, final version</comments><journal-ref>IEEE Trans. Inform. Theory 57 (2011), no. 9, 6148-6156</journal-ref><doi>10.1109/TIT.2011.2161909</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of space-time block codes (STBCs), the theory of generalized
quaternion and biquaternion algebras (i.e., tensor products of two quaternion
algebras) over arbitrary base fields is presented, as well as quadratic form
theoretic criteria to check if such algebras are division algebras. For base
fields relevant to STBCs, these criteria are exploited, via Springer's theorem,
to construct several explicit infinite families of (bi-)quaternion division
algebras. These are used to obtain new $2\x 2$ and $4\x 4$ STBCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0484</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0484</id><created>2008-07-03</created><updated>2009-12-09</updated><authors><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author></authors><title>Improved bounds and new techniques for Davenport-Schinzel sequences and
  their generalizations</title><categories>cs.DM cs.CG</categories><comments>To appear in Journal of the ACM. 48 pages, 3 figures</comments><journal-ref>Journal of the ACM, 57, article 17, 44 pages, 2010</journal-ref><doi>10.1145/1706591.1706597</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let lambda_s(n) denote the maximum length of a Davenport-Schinzel sequence of
order s on n symbols. For s=3 it is known that lambda_3(n) = Theta(n alpha(n))
(Hart and Sharir, 1986). For general s&gt;=4 there are almost-tight upper and
lower bounds, both of the form n * 2^poly(alpha(n)) (Agarwal, Sharir, and Shor,
1989). Our first result is an improvement of the upper-bound technique of
Agarwal et al. We obtain improved upper bounds for s&gt;=6, which are tight for
even s up to lower-order terms in the exponent. More importantly, we also
present a new technique for deriving upper bounds for lambda_s(n). With this
new technique we: (1) re-derive the upper bound of lambda_3(n) &lt;= 2n alpha(n) +
O(n sqrt alpha(n)) (first shown by Klazar, 1999); (2) re-derive our own new
upper bounds for general s; and (3) obtain improved upper bounds for the
generalized Davenport-Schinzel sequences considered by Adamec, Klazar, and
Valtr (1992). Regarding lower bounds, we show that lambda_3(n) &gt;= 2n alpha(n) -
O(n), and therefore, the coefficient 2 is tight. We also present a simpler
version of the construction of Agarwal, Sharir, and Shor that achieves the
known lower bounds for even s&gt;=4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0908</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0908</id><created>2008-07-06</created><updated>2008-09-02</updated><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author></authors><title>The Correspondence Analysis Platform for Uncovering Deep Structure in
  Data and Information</title><categories>cs.AI</categories><comments>Sixth Annual Boole Lecture in Informatics, Boole Centre for Research
  in Informatics, Cork, Ireland, 29 April 2008. 28 pp., 17 figures. To appear,
  Computer Journal. This version: 3 typos corrected</comments><acm-class>I.5.4; H.3.1; I.2.7</acm-class><journal-ref>Computer Journal, 53 (3), 304-315, 2010</journal-ref><doi>10.1093/comjnl/bxn045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two aspects of information semantics: (i) the collection of all
relationships, (ii) tracking and spotting anomaly and change. The first is
implemented by endowing all relevant information spaces with a Euclidean metric
in a common projected space. The second is modelled by an induced ultrametric.
A very general way to achieve a Euclidean embedding of different information
spaces based on cross-tabulation counts (and from other input data formats) is
provided by Correspondence Analysis. From there, the induced ultrametric that
we are particularly interested in takes a sequential - e.g. temporal - ordering
of the data into account. We employ such a perspective to look at narrative,
"the flow of thought and the flow of language" (Chafe). In application to
policy decision making, we show how we can focus analysis in a small number of
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.0942</identifier>
 <datestamp>2012-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.0942</id><created>2008-07-07</created><updated>2012-06-12</updated><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Eswaran</keyname><forenames>Krishnan</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>Secrecy via Sources and Channels</title><categories>cs.IT math.IT</categories><comments>42 pages, 7 figures, to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alice and Bob want to share a secret key and to communicate an independent
message, both of which they desire to be kept secret from an eavesdropper Eve.
We study this problem of secret communication and secret key generation when
two resources are available -- correlated sources at Alice, Bob, and Eve, and a
noisy broadcast channel from Alice to Bob and Eve which is independent of the
sources. We are interested in characterizing the fundamental trade-off between
the rates of the secret message and secret key. We present an achievable
solution and prove its optimality for the parallel channels and sources case
when each sub-channel and source component satisfies a degradation order
(either in favor of the legitimate receiver or the eavesdropper). This includes
the case of jointly Gaussian sources and an additive Gaussian channel, for
which the secrecy region is evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1016</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1016</id><created>2008-07-07</created><authors><author><keyname>Arthan</keyname><forenames>Rob</forenames></author><author><keyname>Martin</keyname><forenames>Ursula</forenames></author><author><keyname>Mathiesen</keyname><forenames>Erik A.</forenames></author><author><keyname>Oliva</keyname><forenames>Paulo</forenames></author></authors><title>A General Framework for Sound and Complete Floyd-Hoare Logics</title><categories>cs.LO cs.OH</categories><comments>27 pages</comments><acm-class>F.3.1</acm-class><journal-ref>ACM Transactions on Computational Logic, 11(1), 2009</journal-ref><doi>10.1145/1614431.1614438</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an abstraction of Hoare logic to traced symmetric
monoidal categories, a very general framework for the theory of systems. Our
abstraction is based on a traced monoidal functor from an arbitrary traced
monoidal category into the category of pre-orders and monotone relations. We
give several examples of how our theory generalises usual Hoare logics (partial
correctness of while programs, partial correctness of pointer programs), and
provide some case studies on how it can be used to develop new Hoare logics
(run-time analysis of while programs and stream circuits).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1158</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1158</id><created>2008-07-07</created><updated>2010-06-19</updated><authors><author><keyname>Subramanian</keyname><forenames>Abhay T.</forenames></author><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author></authors><title>Path Gain Algebraic Formulation for the Scalar Linear Network Coding
  Problem</title><categories>cs.IT math.IT</categories><comments>12 pages, 6 figures. Accepted for publication in IEEE Transactions on
  Information Theory (May 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the algebraic view, the solution to a network coding problem is seen as a
variety specified by a system of polynomial equations typically derived by
using edge-to-edge gains as variables. The output from each sink is equated to
its demand to obtain polynomial equations. In this work, we propose a method to
derive the polynomial equations using source-to-sink path gains as the
variables. In the path gain formulation, we show that linear and quadratic
equations suffice; therefore, network coding becomes equivalent to a system of
polynomial equations of maximum degree 2. We present algorithms for generating
the equations in the path gains and for converting path gain solutions to
edge-to-edge gain solutions. Because of the low degree, simplification is
readily possible for the system of equations obtained using path gains. Using
small-sized network coding problems, we show that the path gain approach
results in simpler equations and determines solvability of the problem in
certain cases. On a larger network (with 87 nodes and 161 edges), we show how
the path gain approach continues to provide deterministic solutions to some
network coding problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1253</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1253</id><created>2008-07-08</created><updated>2008-11-17</updated><authors><author><keyname>Brody</keyname><forenames>Dorje C.</forenames></author><author><keyname>Davis</keyname><forenames>Mark H. A.</forenames></author><author><keyname>Friedman</keyname><forenames>Robyn L.</forenames></author><author><keyname>Hughston</keyname><forenames>Lane P.</forenames></author></authors><title>Informed Traders</title><categories>q-fin.TR cs.IT math.IT math.PR</categories><comments>20 pages, 5 figures. Version to appear in the Proceedings of the
  Royal Society A</comments><journal-ref>Proceedings of the Royal Society London A465, 1103-1122 (2009)</journal-ref><doi>10.1098/rspa.2008.0465</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An asymmetric information model is introduced for the situation in which
there is a small agent who is more susceptible to the flow of information in
the market than the general market participant, and who tries to implement
strategies based on the additional information. In this model market
participants have access to a stream of noisy information concerning the future
return of an asset, whereas the informed trader has access to a further
information source which is obscured by an additional noise that may be
correlated with the market noise. The informed trader uses the extraneous
information source to seek statistical arbitrage opportunities, while at the
same time accommodating the additional risk. The amount of information
available to the general market participant concerning the asset return is
measured by the mutual information of the asset price and the associated cash
flow. The worth of the additional information source is then measured in terms
of the difference of mutual information between the general market participant
and the informed trader. This difference is shown to be nonnegative when the
signal-to-noise ratio of the information flow is known in advance. Explicit
trading strategies leading to statistical arbitrage opportunities, taking
advantage of the additional information, are constructed, illustrating how
excess information can be translated into profit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1494</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1494</id><created>2008-07-09</created><authors><author><keyname>Gagliolo</keyname><forenames>Matteo</forenames></author><author><keyname>Schmidhuber</keyname><forenames>Juergen</forenames></author></authors><title>Algorithm Selection as a Bandit Problem with Unbounded Losses</title><categories>cs.AI cs.GT cs.LG</categories><comments>15 pages, 2 figures</comments><report-no>IDSIA-07-08</report-no><acm-class>F.2.2; G.3; I.1.2; I.2.6; I.2.8</acm-class><doi>10.1007/978-3-642-13800-3_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithm selection is typically based on models of algorithm performance,
learned during a separate offline training sequence, which can be prohibitively
expensive. In recent work, we adopted an online approach, in which a
performance model is iteratively updated and used to guide selection on a
sequence of problem instances. The resulting exploration-exploitation trade-off
was represented as a bandit problem with expert advice, using an existing
solver for this game, but this required the setting of an arbitrary bound on
algorithm runtimes, thus invalidating the optimal regret of the solver. In this
paper, we propose a simpler framework for representing algorithm selection as a
bandit problem, with partial information, and an unknown bound on losses. We
adapt an existing solver to this game, proving a bound on its expected regret,
which holds also for the resulting algorithm selection technique. We present
preliminary experiments with a set of SAT solvers on a mixed SAT-UNSAT
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1513</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1513</id><created>2008-07-09</created><authors><author><keyname>Tapson</keyname><forenames>J.</forenames></author><author><keyname>Jin</keyname><forenames>C.</forenames></author><author><keyname>van Schaik</keyname><forenames>A.</forenames></author><author><keyname>Etienne-Cummings</keyname><forenames>R.</forenames></author></authors><title>A First-Order Non-Homogeneous Markov Model for the Response of Spiking
  Neurons Stimulated by Small Phase-Continuous Signals</title><categories>q-bio.NC cs.NE</categories><comments>Accepted for publication in Neural Computation</comments><journal-ref>Neural Computation Volume 21 Issue 6 Pages 1554-1588 Year 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a first-order non-homogeneous Markov model for the
interspike-interval density of a continuously stimulated spiking neuron. The
model allows the conditional interspike-interval density and the stationary
interspike-interval density to be expressed as products of two separate
functions, one of which describes only the neuron characteristics, and the
other of which describes only the signal characteristics. This allows the use
of this model to predict the response when the underlying neuron model is not
known or well determined. The approximation shows particularly clearly that
signal autocorrelations and cross-correlations arise as natural features of the
interspike-interval density, and are particularly clear for small signals and
moderate noise. We show that this model simplifies the design of spiking neuron
cross-correlation systems, and describe a four-neuron mutual inhibition network
that generates a cross-correlation output for two input signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1550</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1550</id><created>2008-07-10</created><updated>2008-07-23</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Discernment of Hubs and Clusters in Socioeconomic Networks</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>17 pages, small mathematical expression for the probability 0.973469
  now correctly written (mid. p. 9)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interest in the analysis of networks has grown rapidly in the new millennium.
Consequently, we promote renewed attention to a certain methodological approach
introduced in 1974. Over the succeeding decade, this
two-stage--double-standardization and hierarchical clustering
(single-linkage-like)--procedure was applied to a wide variety of weighted,
directed networks of a socioeconomic nature, frequently revealing the presence
of ``hubs''. These were, typically--in the numerous instances studied of
migration flows between geographic subdivisions within
nations--``cosmopolitan/non-provincial'' areas, a prototypical example being
the French capital, Paris. Such locations emit and absorb people broadly across
their respective nations. Additionally, the two-stage procedure--which ``might
very well be the most successful application of cluster analysis'' (R. C.
Dubes, 1985)--detected many (physically or socially) isolated, functional
groups (regions) of areas, such as the southern islands, Shikoku and Kyushu, of
Japan, the Italian islands of Sardinia and Sicily, and the New England region
of the United States. Further, we discuss a (complementary) approach developed
in 1976, in which the max-flow/min-cut theorem was applied to
raw/non-standardized (interindustry, as well as migration) flows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1773</identifier>
 <datestamp>2012-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1773</id><created>2008-07-11</created><updated>2010-09-24</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Heath,</keyname><forenames>Robert W.</forenames><suffix>Jr.</suffix></author><author><keyname>Berry</keyname><forenames>Randall A.</forenames></author></authors><title>Spatial Interference Cancellation for Multi-Antenna Mobile Ad Hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>28 pages; submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference between nodes is a critical impairment in mobile ad hoc networks
(MANETs). This paper studies the role of multiple antennas in mitigating such
interference. Specifically, a network is studied in which receivers apply
zero-forcing beamforming to cancel the strongest interferers. Assuming a
network with Poisson distributed transmitters and independent Rayleigh fading
channels, the transmission capacity is derived, which gives the maximum number
of successful transmissions per unit area. Mathematical tools from stochastic
geometry are applied to obtain the asymptotic transmission capacity scaling and
characterize the impact of inaccurate channel state information (CSI). It is
shown that, if each node cancels L interferers, the transmission capacity
decreases as the outage probability to the power of 1/(L+1) as the outage
probability vanishes. For fixed outage probability, as L grows, the
transmission capacity increases as L to the power of (1-2/alpha) where alpha is
the path-loss exponent. Moreover, CSI inaccuracy is shown to have no effect on
the transmission capacity scaling as the outage probability vanishes, provided
that the CSI training sequence has an appropriate length, which we derived.
Numerical results suggest that canceling merely one interferer by each node
increases the transmission capacity by an order of magnitude or more, even when
the CSI is imperfect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.1949</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.1949</id><created>2008-07-11</created><updated>2010-09-07</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Virtual Transmission Method, A New Distributed Algorithm to Solve Sparse
  Linear System</title><categories>math.NA cs.DC</categories><comments>v1: short paper to describe VTM, published by NCM'08; v2: add an
  example of level-two splitting; v3: full paper; v4: rename EVS to GNBT; add
  lines coupling technique; v5: reuse EVS, get rid of GNBT; more info, see
  http://weifei00.googlepages.com</comments><msc-class>65F10, 65F50, 68M14</msc-class><acm-class>G.1.0; B.7.2</acm-class><doi>10.1109/NCM.2008.160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new parallel algorithm which could work naturally
on the parallel computer with arbitrary number of processors. This algorithm is
named Virtual Transmission Method (VTM). Its physical backgroud is the lossless
transmission line and microwave network. The basic idea of VTM is to insert
lossless transmission lines into the sparse linear system to achieve
distributed computing.
  VTM is proved to be convergent to solve SPD linear system. Preconditioning
method and performance model are presented. Numerical experiments show that VTM
is efficient, accurate and stable.
  Accompanied with VTM, we bring in a new technique to partition the symmetric
linear system, which is named Generalized Node &amp; Branch Tearing (GNBT). It is
based on Kirchhoff's Current Law from circuit theory. We proved that GNBT is
feasible to partition any SPD linear system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2158</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2158</id><created>2008-07-14</created><updated>2009-05-19</updated><authors><author><keyname>Masanes</keyname><forenames>Lluis</forenames></author></authors><title>Universally-composable privacy amplification from causality constraints</title><categories>quant-ph cs.CR cs.IT math.IT</categories><comments>4 pages</comments><journal-ref>Phys. Rev. Lett. 102, 140501 (2009)</journal-ref><doi>10.1103/PhysRevLett.102.140501</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider schemes for secret key distribution which use as a resource
correlations that violate Bell inequalities. We provide the first security
proof for such schemes, according to the strongest notion of security, the so
called universally-composable security. Our security proof does not rely on the
validity of quantum mechanics, it solely relies on the impossibility of
arbitrarily-fast signaling between separate physical systems. This allows for
secret communication in situations where the participants distrust their
quantum devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2303</identifier>
 <datestamp>2010-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2303</id><created>2008-07-15</created><authors><author><keyname>Bucci</keyname><forenames>Michelangelo</forenames></author><author><keyname>De Luca</keyname><forenames>Alessandro</forenames></author><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames></author></authors><title>A new characteristic property of rich words</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>68R15</msc-class><journal-ref>Theoretical Computer Science 410 (2009) 2860-2863</journal-ref><doi>10.1016/j.tcs.2008.11.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Originally introduced and studied by the third and fourth authors together
with J. Justin and S. Widmer in arXiv:0801.1656, rich words constitute a new
class of finite and infinite words characterized by containing the maximal
number of distinct palindromes. Several characterizations of rich words have
already been established. A particularly nice characteristic property is that
all 'complete returns' to palindromes are palindromes. In this note, we prove
that rich words are also characterized by the property that each factor is
uniquely determined by its longest palindromic prefix and its longest
palindromic suffix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2358</identifier>
 <datestamp>2010-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2358</id><created>2008-07-15</created><updated>2010-09-27</updated><authors><author><keyname>Fekete</keyname><forenames>Sandor P.</forenames></author><author><keyname>Schmidt</keyname><forenames>Christiane</forenames></author></authors><title>Polygon Exploration with Time-Discrete Vision</title><categories>cs.CG cs.RO</categories><comments>28 pages, 17 figures, 2 photographs, 3 tables, Latex. Updated some
  details (title, figures and text) for final journal revision, including
  explicit assumption of full edge visibility</comments><acm-class>F.2.2; I.2.9</acm-class><journal-ref>Computational Geometry: Theory and Applications, 43 (2010),
  148-168</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of autonomous robots with two- and three-dimensional scanning
capabilities, classical visibility-based exploration methods from computational
geometry have gained in practical importance. However, real-life laser scanning
of useful accuracy does not allow the robot to scan continuously while in
motion; instead, it has to stop each time it surveys its environment. This
requirement was studied by Fekete, Klein and Nuechter for the subproblem of
looking around a corner, but until now has not been considered in an online
setting for whole polygonal regions.
  We give the first algorithmic results for this important algorithmic problem
that combines stationary art gallery-type aspects with watchman-type issues in
an online scenario: We demonstrate that even for orthoconvex polygons, a
competitive strategy can be achieved only for limited aspect ratio A (the ratio
of the maximum and minimum edge length of the polygon), i.e., for a given lower
bound on the size of an edge; we give a matching upper bound by providing an
O(log A)-competitive strategy for simple rectilinear polygons, using the
assumption that each edge of the polygon has to be fully visible from some scan
point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2677</identifier>
 <datestamp>2010-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2677</id><created>2008-07-16</created><updated>2010-02-06</updated><authors><author><keyname>Unnikrishnan</keyname><forenames>Jayakrishnan</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal</forenames></author></authors><title>Algorithms for Dynamic Spectrum Access with Learning for Cognitive Radio</title><categories>cs.NI cs.LG</categories><comments>Published in IEEE Transactions on Signal Processing, February 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of dynamic spectrum sensing and access in cognitive
radio systems as a partially observed Markov decision process (POMDP). A group
of cognitive users cooperatively tries to exploit vacancies in primary
(licensed) channels whose occupancies follow a Markovian evolution. We first
consider the scenario where the cognitive users have perfect knowledge of the
distribution of the signals they receive from the primary users. For this
problem, we obtain a greedy channel selection and access policy that maximizes
the instantaneous reward, while satisfying a constraint on the probability of
interfering with licensed transmissions. We also derive an analytical universal
upper bound on the performance of the optimal policy. Through simulation, we
show that our scheme achieves good performance relative to the upper bound and
improved performance relative to an existing scheme.
  We then consider the more practical scenario where the exact distribution of
the signal from the primary is unknown. We assume a parametric model for the
distribution and develop an algorithm that can learn the true distribution,
still guaranteeing the constraint on the interference probability. We show that
this algorithm outperforms the naive design that assumes a worst case value for
the parameter. We also provide a proof for the convergence of the learning
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.2859</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.2859</id><created>2008-07-17</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>The Transport Capacity of a Wireless Network is a Subadditive Euclidean
  Functional</title><categories>cs.IT math.IT</categories><doi>10.1239/jap/1285335416</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The transport capacity of a dense ad hoc network with n nodes scales like
\sqrt(n). We show that the transport capacity divided by \sqrt(n) approaches a
non-random limit with probability one when the nodes are i.i.d. distributed on
the unit square. We prove that the transport capacity under the protocol model
is a subadditive Euclidean functional and use the machinery of subadditive
functions in the spirit of Steele to show the existence of the limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3026</identifier>
 <datestamp>2010-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3026</id><created>2008-07-18</created><updated>2008-11-08</updated><authors><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Finding paths of length k in O*(2^k) time</title><categories>cs.DS cs.DM</categories><comments>7 pages. Revised version to appear in Information Processing Letters</comments><journal-ref>Information Processing Letters, 109(6):315--318, February 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a randomized algorithm that determines if a given graph has a simple
path of length at least k in O(2^k poly(n,k)) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3096</identifier>
 <datestamp>2011-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3096</id><created>2008-07-19</created><updated>2011-02-22</updated><authors><author><keyname>Guatteri</keyname><forenames>Giuseppina</forenames></author></authors><title>Stochastic Maximum Principle for a PDEs with noise and control on the
  boundary</title><categories>math.PR cs.SY math.OC</categories><comments>15pgs</comments><msc-class>60H15, 90C46, 93E03, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove necessary conditions for optimality of a stochastic
control problem for a class of stochastic partial differential equations that
is controlled through the boundary. This kind of problems can be interpreted as
a stochastic control problem for an evolution system in an Hilbert space. The
regularity of the solution of the adjoint equation, that is a backward
stochastic equation in infinite dimension, plays a crucial role in the
formulation of the maximum principle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3374</identifier>
 <datestamp>2011-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3374</id><created>2008-07-21</created><updated>2010-09-05</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>The Dynamics of Internet Traffic: Self-Similarity, Self-Organization,
  and Complex Phenomena</title><categories>nlin.AO cs.NI nlin.CD</categories><comments>63 pages, 7 figures, 7 tables, submitted to Advances in Complex
  Systems</comments><journal-ref>Advances in Complex Systems, 14, 6 p. 905-949 (2011)</journal-ref><doi>10.1142/S0219525911003451</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Internet is the most complex system ever created in human history.
Therefore, its dynamics and traffic unsurprisingly take on a rich variety of
complex dynamics, self-organization, and other phenomena that have been
researched for years. This paper is a review of the complex dynamics of
Internet traffic. Departing from normal treatises, we will take a view from
both the network engineering and physics perspectives showing the strengths and
weaknesses as well as insights of both. In addition, many less covered
phenomena such as traffic oscillations, large-scale effects of worm traffic,
and comparisons of the Internet and biological models will be covered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3648</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3648</id><created>2008-07-23</created><updated>2010-02-18</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Ponse</keyname><forenames>A.</forenames></author></authors><title>Proposition Algebra with Projective Limits</title><categories>cs.LO</categories><comments>43 pages, 3 tables</comments><acm-class>F.3.2</acm-class><journal-ref>ACM Transactions on Computational Logic, 12 (3), Article 21, 2011</journal-ref><doi>10.1145/1929954.1929958</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential propositional logic deviates from ordinary propositional logic by
taking into account that during the sequential evaluation of a propositional
statement,atomic propositions may yield different Boolean values at repeated
occurrences. We introduce `free valuations' to capture this dynamics of a
propositional statement's environment. The resulting logic is phrased as an
equationally specified algebra rather than in the form of proof rules, and is
named `proposition algebra'. It is strictly more general than Boolean algebra
to the extent that the classical connectives fail to be expressively complete
in the sequential case. The four axioms for free valuation congruence are then
combined with other axioms in order define a few more valuation congruences
that gradually identify more propositional statements, up to static valuation
congruence (which is the setting of conventional propositional logic).
  Proposition algebra is developed in a fashion similar to the process algebra
ACP and the program algebra PGA, via an algebraic specification which has a
meaningful initial algebra for which a range of coarser congruences are
considered important as well. In addition infinite objects (that is
propositional statements, processes and programs respectively) are dealt with
by means of an inverse limit construction which allows the transfer of
knowledge concerning finite objects to facts about infinite ones while reducing
all facts about infinite objects to an infinity of facts about finite ones in
return.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.3803</identifier>
 <datestamp>2013-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.3803</id><created>2008-07-24</created><updated>2013-04-11</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Brun</keyname><forenames>Todd A.</forenames></author></authors><title>Quantum Convolutional Coding with Shared Entanglement: General Structure</title><categories>quant-ph cs.IT math.IT</categories><comments>23 pages, replaced with final published version</comments><report-no>CSI-08-07-02</report-no><journal-ref>Quantum Information Processing, Volume 9, Number 5, pages 509-540,
  September 2010</journal-ref><doi>10.1007/s11128-010-0179-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general theory of entanglement-assisted quantum convolutional
coding. The codes have a convolutional or memory structure, they assume that
the sender and receiver share noiseless entanglement prior to quantum
communication, and they are not restricted to possess the
Calderbank-Shor-Steane structure as in previous work. We provide two
significant advances for quantum convolutional coding theory. We first show how
to "expand" a given set of quantum convolutional generators. This expansion
step acts as a preprocessor for a polynomial symplectic Gram-Schmidt
orthogonalization procedure that simplifies the commutation relations of the
expanded generators to be the same as those of entangled Bell states (ebits)
and ancilla qubits. The above two steps produce a set of generators with
equivalent error-correcting properties to those of the original generators. We
then demonstrate how to perform online encoding and decoding for a stream of
information qubits, halves of ebits, and ancilla qubits. The upshot of our
theory is that the quantum code designer can engineer quantum convolutional
codes with desirable error-correcting properties without having to worry about
the commutation relations of these generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4132</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4132</id><created>2008-07-25</created><updated>2010-10-11</updated><authors><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Mandrioli</keyname><forenames>Dino</forenames></author><author><keyname>Morzenti</keyname><forenames>Angelo</forenames></author><author><keyname>Rossi</keyname><forenames>Matteo</forenames></author></authors><title>Modeling Time in Computing: A Taxonomy and a Comparative Survey</title><categories>cs.GL</categories><comments>More typos fixed</comments><journal-ref>ACM Computing Surveys, 42(2):1--59, February 2010</journal-ref><doi>10.1145/1667062.1667063</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing relevance of areas such as real-time and embedded systems,
pervasive computing, hybrid systems control, and biological and social systems
modeling is bringing a growing attention to the temporal aspects of computing,
not only in the computer science domain, but also in more traditional fields of
engineering.
  This article surveys various approaches to the formal modeling and analysis
of the temporal features of computer-based systems, with a level of detail that
is suitable also for non-specialists. In doing so, it provides a unifying
framework, rather than just a comprehensive list of formalisms.
  The paper first lays out some key dimensions along which the various
formalisms can be evaluated and compared. Then, a significant sample of
formalisms for time modeling in computing are presented and discussed according
to these dimensions. The adopted perspective is, to some extent, historical,
going from "traditional" models and formalisms to more modern ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4494</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4494</id><created>2008-07-28</created><updated>2011-05-25</updated><authors><author><keyname>McEwen</keyname><forenames>J. D.</forenames></author></authors><title>Fast, exact (but unstable) spin spherical harmonic transforms</title><categories>astro-ph cs.IT math.IT</categories><comments>15 pages, 5 figures, replaced to match version accepted by ARJP</comments><journal-ref>All Res.J.Phys.1:4-18,2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications data are measured or defined on a spherical manifold;
spherical harmonic transforms are then required to access the frequency content
of the data. We derive algorithms to perform forward and inverse spin spherical
harmonic transforms for functions of arbitrary spin number. These algorithms
involve recasting the spin transform on the two-sphere S^2 as a Fourier
transform on the two-torus T^2. Fast Fourier transforms are then used to
compute Fourier coefficients, which are related to spherical harmonic
coefficients through a linear transform. By recasting the problem as a Fourier
transform on the torus we appeal to the usual Shannon sampling theorem to
develop spherical harmonic transforms that are theoretically exact for
band-limited functions, thereby providing an alternative sampling theorem on
the sphere. The computational complexity of our forward and inverse spin
spherical harmonic transforms scale as O(L^3) for any arbitrary spin number,
where L is the harmonic band-limit of the spin function on the sphere.
Numerical experiments are performed and unfortunately the forward transform is
found to be unstable for band-limits above L~32. The instability is due to the
poorly conditioned linear system relating Fourier and spherical harmonic
coefficients. The inverse transform is expected to be stable, although it is
not possible to verify this hypothesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4619</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4619</id><created>2008-07-29</created><authors><author><keyname>Shaiju</keyname><forenames>A. J.</forenames></author><author><keyname>Petersen</keyname><forenames>I. R.</forenames></author><author><keyname>James</keyname><forenames>M. R.</forenames></author></authors><title>Guaranteed Cost LQG Control of Uncertain Linear Quantum Stochastic
  Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>15 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulate and solve a guaranteed cost control problem for a
class of uncertain linear stochastic quantum systems. For these quantum
systems, a connection with an associated classical (non-quantum) system is
first established. Using this connection, the desired guaranteed cost results
are established. The theory presented is illustrated using an example from
quantum optics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4701</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4701</id><created>2008-07-29</created><authors><author><keyname>Sparavigna</keyname><forenames>A.</forenames></author><author><keyname>Marazzato</keyname><forenames>R.</forenames></author></authors><title>An image processing analysis of skin textures</title><categories>cs.CV</categories><journal-ref>Skin Research and Technology, Volume 16 Issue 2, Pages 161 - 167,
  2010</journal-ref><doi>10.1111/j.1600-0846.2009.00413.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colour and coarseness of skin are visually different. When image processing
is involved in the skin analysis, it is important to quantitatively evaluate
such differences using texture features. In this paper, we discuss a texture
analysis and measurements based on a statistical approach to the pattern
recognition. Grain size and anisotropy are evaluated with proper diagrams. The
possibility to determine the presence of pattern defects is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4753</identifier>
 <datestamp>2012-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4753</id><created>2008-07-30</created><authors><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author></authors><title>Counterexamples to the maximal p-norm multiplicativity conjecture for
  all p &gt; 1</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>Merger of arXiv:0707.0402 and arXiv:0707.3291 containing new and
  improved analysis of counterexamples. 17 pages</comments><journal-ref>Comm. Math. Phys. 284(1):263-280, 2008.</journal-ref><doi>10.1007/s00220-008-0624-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For all p &gt; 1, we demonstrate the existence of quantum channels with
non-multiplicative maximal output p-norms. Equivalently, for all p &gt;1, the
minimum output Renyi entropy of order p of a quantum channel is not additive.
The violations found are large; in all cases, the minimum output Renyi entropy
of order p for a product channel need not be significantly greater than the
minimum output entropy of its individual factors. Since p=1 corresponds to the
von Neumann entropy, these counterexamples demonstrate that if the additivity
conjecture of quantum information theory is true, it cannot be proved as a
consequence of any channel-independent guarantee of maximal p-norm
multiplicativity. We also show that a class of channels previously studied in
the context of approximate encryption lead to counterexamples for all p &gt; 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0807.4770</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0807.4770</id><created>2008-07-29</created><updated>2010-01-18</updated><authors><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Liew</keyname><forenames>Soung-Chang</forenames></author></authors><title>Channel Coding and Decoding in a Relay System Operated with Physical
  layer Network Coding</title><categories>cs.NI cs.IT math.IT</categories><journal-ref>IEEE journal on selection area in communications, Jun. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical-layer Network Coding (PNC) can significantly improve the throughput
of wireless two way relay channel (TWRC) by allowing the two end nodes to
transmit messages to the relay simultaneously. To achieve reliable
communication, channel coding could be applied on top of PNC. This paper
investigates link-by-link channel-coded PNC, in which a critical process at the
relay is to transform the superimposed channel-coded packets received from the
two end nodes plus noise, Y3=X1+X2+W3, to the network-coded combination of the
source packets, S1 XOR S2 . This is in distinct to the traditional
multiple-access problem, in which the goal is to obtain S1 and S2 separately.
The transformation from Y3 to (S1 XOR S2) is referred to as the
Channel-decoding-Network-Coding process (CNC) in that it involves both channel
decoding and network coding operations. A contribution of this paper is the
insight that in designing CNC, we should first (i) channel-decode Y3 to the
superimposed source symbols S1+S2 before (ii) transforming S1+S2 to the
network-coded packets (S1 XOR S2) . Compared with previously proposed
strategies for CNC, this strategy reduces the channel-coding network-coding
mismatch. It is not obvious, however, that an efficient decoder for step (i)
exists. A second contribution of this paper is to provide an explicit
construction of such a decoder based on the use of the Repeat Accumulate (RA)
code. Specifically, we redesign the belief propagation algorithm of the RA code
for traditional point-to-point channel to suit the need of the PNC
multiple-access channel. Simulation results show that our new scheme
outperforms the previously proposed schemes significantly in terms of BER
without added complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0111</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0111</id><created>2008-08-01</created><updated>2010-09-03</updated><authors><author><keyname>Hartig</keyname><forenames>Florian</forenames></author><author><keyname>Drechsler</keyname><forenames>Martin</forenames></author></authors><title>Stay by thy neighbor? Social organization determines the efficiency of
  biodiversity markets with spatial incentives</title><categories>physics.soc-ph cs.GT</categories><comments>11 pages, 6 figures</comments><journal-ref>Ecological Complexity, 2010, 7, 91-99</journal-ref><doi>10.1016/j.ecocom.2009.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Market-based conservation instruments, such as payments, auctions or tradable
permits, are environmental policies that create financial incentives for
landowners to engage in voluntary conservation on their land. But what if
ecological processes operate across property boundaries and land use decisions
on one property influence ecosystem functions on neighboring sites? This paper
examines how to account for such spatial externalities when designing
market-based conservation instruments. We use an agent-based model to analyze
different spatial metrics and their implications on land use decisions in a
dynamic cost environment. The model contains a number of alternative submodels
which differ in incentive design and social interactions of agents, the latter
including coordinating as well as cooperating behavior of agents. We find that
incentive design and social interactions have a strong influence on the spatial
allocation and the costs of the conservation market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0112</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0112</id><created>2008-08-01</created><updated>2010-10-28</updated><authors><author><keyname>Yukalov</keyname><forenames>V. I.</forenames></author><author><keyname>Sornette</keyname><forenames>D.</forenames></author></authors><title>Mathematical Structure of Quantum Decision Theory</title><categories>cs.AI math-ph math.MP quant-ph</categories><comments>40 pages</comments><journal-ref>Advances in Complex Systems 13, 659-698 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most complex systems is the human brain whose formalized
functioning is characterized by decision theory. We present a "Quantum Decision
Theory" of decision making, based on the mathematical theory of separable
Hilbert spaces. This mathematical structure captures the effect of
superposition of composite prospects, including many incorporated intentions,
which allows us to explain a variety of interesting fallacies and anomalies
that have been reported to particularize the decision making of real human
beings. The theory describes entangled decision making, non-commutativity of
subsequent decisions, and intention interference of composite prospects. We
demonstrate how the violation of the Savage's sure-thing principle (disjunction
effect) can be explained as a result of the interference of intentions, when
making decisions under uncertainty. The conjunction fallacy is also explained
by the presence of the interference terms. We demonstrate that all known
anomalies and paradoxes, documented in the context of classical decision
theory, are reducible to just a few mathematical archetypes, all of which
finding straightforward explanations in the frame of the developed quantum
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0284</identifier>
 <datestamp>2010-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0284</id><created>2008-08-02</created><updated>2010-03-31</updated><authors><author><keyname>Lebl</keyname><forenames>Jiri</forenames></author><author><keyname>Lichtblau</keyname><forenames>Daniel</forenames></author></authors><title>Uniqueness of certain polynomials constant on a line</title><categories>math.CV cs.CG math.NT</categories><comments>20 pages, latex; removed section 10 and address referee suggestions;
  accepted to Linear Algebra and its Applications</comments><msc-class>32H35, 68W30, 11C08, 05E99</msc-class><journal-ref>Linear Algebra and Its Applications 433 (2010) pp. 824-837</journal-ref><doi>10.1016/j.laa.2010.04.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a question with connections to linear algebra, real algebraic
geometry, combinatorics, and complex analysis. Let $p(x,y)$ be a polynomial of
degree $d$ with $N$ positive coefficients and no negative coefficients, such
that $p=1$ when $x+y=1$. A sharp estimate $d \leq 2N-3$ is known. In this paper
we study the $p$ for which equality holds. We prove some new results about the
form of these "sharp" polynomials. Using these new results and using two
independent computational methods we give a complete classification of these
polynomials up to $d=17$. The question is motivated by the problem of
classification of CR maps between spheres in different dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0298</identifier>
 <datestamp>2010-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0298</id><created>2008-08-03</created><authors><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Pasechnik</keyname><forenames>Dmitrii V.</forenames></author></authors><title>Computing the nucleolus of weighted voting games</title><categories>cs.GT cs.DS</categories><comments>LaTeX, 12 pages, COMSOC-2008 workshop</comments><acm-class>G.1.6; I.2.8</acm-class><journal-ref>Proceedings of SODA 2009, pp. 327-335</journal-ref><doi>10.1145/1496770.1496807</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted voting games (WVG) are coalitional games in which an agent's
contribution to a coalition is given by his it weight, and a coalition wins if
its total weight meets or exceeds a given quota. These games model
decision-making in political bodies as well as collaboration and surplus
division in multiagent domains. The computational complexity of various
solution concepts for weighted voting games received a lot of attention in
recent years. In particular, Elkind et al.(2007) studied the complexity of
stability-related solution concepts in WVGs, namely, of the core, the least
core, and the nucleolus. While they have completely characterized the
algorithmic complexity of the core and the least core, for the nucleolus they
have only provided an NP-hardness result. In this paper, we solve an open
problem posed by Elkind et al. by showing that the nucleolus of WVGs, and, more
generally, k-vector weighted voting games with fixed k, can be computed in
pseudopolynomial time, i.e., there exists an algorithm that correctly computes
the nucleolus and runs in time polynomial in the number of players and the
maximum weight. In doing so, we propose a general framework for computing the
nucleolus, which may be applicable to a wider of class of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0509</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0509</id><created>2008-08-04</created><authors><author><keyname>Bansal</keyname><forenames>Shweta</forenames></author><author><keyname>Khandelwal</keyname><forenames>Shashank</forenames></author><author><keyname>Meyers</keyname><forenames>Lauren Ancel</forenames></author></authors><title>Evolving Clustered Random Networks</title><categories>cs.DM physics.soc-ph</categories><journal-ref>BMC Bioinformatics, Vol 10: 405, 2009</journal-ref><doi>10.1186/1471-2105-10-405</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a Markov chain simulation method to generate simple connected
random graphs with a specified degree sequence and level of clustering. The
networks generated by our algorithm are random in all other respects and can
thus serve as generic models for studying the impacts of degree distributions
and clustering on dynamical processes as well as null models for detecting
other structural properties in empirical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.0549</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.0549</id><created>2008-08-05</created><updated>2010-02-26</updated><authors><author><keyname>Huang</keyname><forenames>Dong</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author><author><keyname>Leung</keyname><forenames>Cyril</forenames></author><author><keyname>Shen</keyname><forenames>Zhiqi</forenames></author></authors><title>Resource Allocation of MU-OFDM Based Cognitive Radio Systems Under
  Partial Channel State Information</title><categories>cs.IT cs.NE math.CO math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to some errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1000</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1000</id><created>2008-08-07</created><updated>2010-03-07</updated><authors><author><keyname>Huang</keyname><forenames>Dong</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author><author><keyname>Leung</keyname><forenames>Cyril</forenames></author></authors><title>Fitness Landscape Analysis for Dynamic Resource Allocation in Multiuser
  OFDM Based Cognitive Radio Systems</title><categories>cs.IT cs.NE math.CO math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1246</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1246</id><created>2008-08-08</created><updated>2013-01-21</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Romulus</forenames></author><author><keyname>Andreica</keyname><forenames>Angela</forenames></author></authors><title>Minimum Dissatisfaction Personnel Scheduling</title><categories>cs.DS</categories><comments>Some of the algorithmic techniques presented in this paper were later
  used by the first author for developing solutions to several algorithmic
  contest tasks (see the attached zip archive for some examples)</comments><proxy>ccsd</proxy><journal-ref>ARA Congress, Boston : United States (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider two problems regarding the scheduling of available
personnel in order to perform a given quantity of work, which can be
arbitrarily decomposed into a sequence of activities. We are interested in
schedules which minimize the overall dissatisfaction, where each employee's
dissatisfaction is modeled as a time-dependent linear function. For the two
situations considered we provide a detailed mathematical analysis, as well as
efficient algorithms for determining optimal schedules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.1549</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.1549</id><created>2008-08-11</created><updated>2008-11-19</updated><authors><author><keyname>Percus</keyname><forenames>Allon G.</forenames></author><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Sumi</keyname><forenames>Robert Z.</forenames></author><author><keyname>Boettcher</keyname><forenames>Stefan</forenames></author></authors><title>The Peculiar Phase Structure of Random Graph Bisection</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.DM</categories><comments>substantially revised section 2, changed figures 3, 4 and 6, made
  minor stylistic changes and added references</comments><report-no>LA-UR 08-5099</report-no><journal-ref>J. Math. Phys. 49, 125219 (2008)</journal-ref><doi>10.1063/1.3043666</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mincut graph bisection problem involves partitioning the n vertices of a
graph into disjoint subsets, each containing exactly n/2 vertices, while
minimizing the number of "cut" edges with an endpoint in each subset. When
considered over sparse random graphs, the phase structure of the graph
bisection problem displays certain familiar properties, but also some
surprises. It is known that when the mean degree is below the critical value of
2 log 2, the cutsize is zero with high probability. We study how the minimum
cutsize increases with mean degree above this critical threshold, finding a new
analytical upper bound that improves considerably upon previous bounds.
Combined with recent results on expander graphs, our bound suggests the unusual
scenario that random graph bisection is replica symmetric up to and beyond the
critical threshold, with a replica symmetry breaking transition possibly taking
place above the threshold. An intriguing algorithmic consequence is that
although the problem is NP-hard, we can find near-optimal cutsizes (whose ratio
to the optimal value approaches 1 asymptotically) in polynomial time for
typical instances near the phase transition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2089</identifier>
 <datestamp>2010-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2089</id><created>2008-08-14</created><updated>2010-10-07</updated><authors><author><keyname>Liu</keyname><forenames>Jialing</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Capacity-achieving Feedback Scheme for Gaussian Finite-State Markov
  Channels with Channel State Information</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory. 31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose capacity-achieving communication schemes for
Gaussian finite-state Markov channels (FSMCs) subject to an average channel
input power constraint, under the assumption that the transmitters can have
access to delayed noiseless output feedback as well as instantaneous or delayed
channel state information (CSI). We show that the proposed schemes reveals
connections between feedback communication and feedback control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2530</identifier>
 <datestamp>2010-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2530</id><created>2008-08-19</created><updated>2010-09-21</updated><authors><author><keyname>Jagabathula</keyname><forenames>Srikanth</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>Fair Scheduling in Networks Through Packet Election</title><categories>cs.IT math.IT</categories><comments>14 pages (double column), submitted to IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of designing a fair scheduling algorithm for
discrete-time constrained queuing networks. Each queue has dedicated exogenous
packet arrivals. There are constraints on which queues can be served
simultaneously. This model effectively describes important special instances
like network switches, interference in wireless networks, bandwidth sharing for
congestion control and traffic scheduling in road roundabouts. Fair scheduling
is required because it provides isolation to different traffic flows; isolation
makes the system more robust and enables providing quality of service. Existing
work on fairness for constrained networks concentrates on flow based fairness.
As a main result, we describe a notion of packet based fairness by establishing
an analogy with the ranked election problem: packets are voters, schedules are
candidates and each packet ranks the schedules based on its priorities. We then
obtain a scheduling algorithm that achieves the described notion of fairness by
drawing upon the seminal work of Goodman and Markowitz (1952). This yields the
familiar Maximum Weight (MW) style algorithm. As another important result we
prove that algorithm obtained is throughput optimal. There is no reason a
priori why this should be true, and the proof requires non-traditional methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2662</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2662</id><created>2008-08-20</created><updated>2010-01-12</updated><authors><author><keyname>Drucker</keyname><forenames>Andrew</forenames></author></authors><title>Multitask Efficiencies in the Decision Tree Model</title><categories>cs.CC</categories><comments>Improved exposition based on conference version</comments><acm-class>F.1.1; F.1.3</acm-class><journal-ref>24th Annual IEEE Conference on Computational Complexity, 2009, p.
  286-297</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Direct Sum problems [KRW], one tries to show that for a given
computational model, the complexity of computing a collection of finite
functions on independent inputs is approximately the sum of their individual
complexities. In this paper, by contrast, we study the diversity of ways in
which the joint computational complexity can behave when all the functions are
evaluated on a common input. We focus on the deterministic decision tree model,
with depth as the complexity measure; in this model we prove a result to the
effect that the 'obvious' constraints on joint computational complexity are
essentially the only ones.
  The proof uses an intriguing new type of cryptographic data structure called
a `mystery bin' which we construct using a small polynomial separation between
deterministic and unambiguous query complexity shown by Savicky. We also pose a
variant of the Direct Sum Conjecture of [KRW] which, if proved for a single
family of functions, could yield an analogous result for models such as the
communication model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2670</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2670</id><created>2008-08-19</created><updated>2010-03-12</updated><authors><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Kuscsik</keyname><forenames>Zoltan</forenames></author><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Wakeling</keyname><forenames>Joseph R.</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Solving the apparent diversity-accuracy dilemma of recommender systems</title><categories>cs.IR physics.soc-ph</categories><comments>10 pages, 9 figures, 4 tables (final version with supporting
  information included)</comments><journal-ref>PNAS 107, 4511-4515, 2010</journal-ref><doi>10.1073/pnas.1000488107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems use data on past user preferences to predict possible
future likes and interests. A key challenge is that while the most useful
individual recommendations are to be found among diverse niche objects, the
most reliably accurate results are obtained by methods that recommend objects
based on user or object similarity. In this paper we introduce a new algorithm
specifically to address the challenge of diversity and show how it can be used
to resolve this apparent dilemma when combined in an elegant hybrid with an
accuracy-focused algorithm. By tuning the hybrid appropriately we are able to
obtain, without relying on any semantic or context-specific information,
simultaneous gains in both accuracy and diversity of recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.2833</identifier>
 <datestamp>2015-01-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.2833</id><created>2008-08-20</created><updated>2010-11-04</updated><authors><author><keyname>Faigle</keyname><forenames>Ulrich</forenames></author><author><keyname>Schönhuth</keyname><forenames>Alexander</forenames></author></authors><title>Efficient tests for equivalence of hidden Markov processes and quantum
  random walks</title><categories>cs.IT math.IT</categories><comments>16 pages, requires llncs.cls</comments><journal-ref>IEEE Transactions on Information Theory, 57(3), 1746-1753, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While two hidden Markov process (HMP) resp. quantum random walk (QRW)
parametrizations can differ from one another, the stochastic processes arising
from them can be equivalent. Here a polynomial-time algorithm is presented
which can determine equivalence of two HMP parametrizations $\cM_1,\cM_2$ resp.
two QRW parametrizations $\cQ_1,\cQ_2$ in time $O(|\S|\max(N_1,N_2)^{4})$,
where $N_1,N_2$ are the number of hidden states in $\cM_1,\cM_2$ resp. the
dimension of the state spaces associated with $\cQ_1,\cQ_2$, and $\S$ is the
set of output symbols. Previously available algorithms for testing equivalence
of HMPs were exponential in the number of hidden states. In case of QRWs,
algorithms for testing equivalence had not yet been presented. The core
subroutines of this algorithm can also be used to efficiently test hidden
Markov processes and quantum random walks for ergodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3038</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3038</id><created>2008-08-22</created><updated>2011-06-09</updated><authors><author><keyname>Schicho</keyname><forenames>Josef</forenames></author><author><keyname>Sevilla</keyname><forenames>David</forenames></author></authors><title>Tschirnhaus-Weierstrass curves</title><categories>math.AG cs.SC</categories><comments>v2: 10 pages, major revision due to errors in the main result. v1: 14
  pages, submitted to Mathematics of Computation</comments><msc-class>14H99 (Primary) 14Q05, 68W30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the concept of Tschirnhaus-Weierstrass curve, named after the
Weierstrass form of an elliptic curve and Tschirnhaus transformations. Every
pointed curve has a Tschirnhaus-Weierstrass form, and this representation is
unique up to a scaling of variables. This is useful for computing isomorphisms
between curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3109</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3109</id><created>2008-08-22</created><updated>2008-11-18</updated><authors><author><keyname>Smarandache</keyname><forenames>Florentin</forenames></author><author><keyname>Christianto</keyname><forenames>V.</forenames></author></authors><title>n-ary Fuzzy Logic and Neutrosophic Logic Operators</title><categories>cs.AI</categories><comments>15 pages, 2 fuzzy and neutrosophic value tables, many diagrams</comments><acm-class>I.2.3</acm-class><journal-ref>Studies in Logic, Grammar and Rethoric [Belarus], 17 (30), pp.
  1-16, 2009.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend Knuth's 16 Boolean binary logic operators to fuzzy logic and
neutrosophic logic binary operators. Then we generalize them to n-ary fuzzy
logic and neutrosophic logic operators using the smarandache codification of
the Venn diagram and a defined vector neutrosophic law. In such way, new
operators in neutrosophic logic/set/probability are built.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3112</identifier>
 <datestamp>2012-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3112</id><created>2008-08-22</created><updated>2012-05-03</updated><authors><author><keyname>Cassaigne</keyname><forenames>Julien</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>On the decidability of semigroup freeness</title><categories>cs.DM</categories><comments>46 pages. 1 table. To appear in RAIRO</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the decidability of semigroup freeness. More precisely,
the freeness problem over a semigroup S is defined as: given a finite subset X
of S, decide whether each element of S has at most one factorization over X. To
date, the decidabilities of two freeness problems have been closely examined.
In 1953, Sardinas and Patterson proposed a now famous algorithm for the
freeness problem over the free monoid. In 1991, Klarner, Birget and Satterfield
proved the undecidability of the freeness problem over three-by-three integer
matrices. Both results led to the publication of many subsequent papers. The
aim of the present paper is three-fold: (i) to present general results
concerning freeness problems, (ii) to study the decidability of freeness
problems over various particular semigroups (special attention is devoted to
multiplicative matrix semigroups), and (iii) to propose precise, challenging
open questions in order to promote the study of the topic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3231</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3231</id><created>2008-08-24</created><updated>2011-10-23</updated><authors><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author><author><keyname>Zhang</keyname><forenames>Min-Ling</forenames></author><author><keyname>Huang</keyname><forenames>Sheng-Jun</forenames></author><author><keyname>Li</keyname><forenames>Yu-Feng</forenames></author></authors><title>Multi-Instance Multi-Label Learning</title><categories>cs.LG cs.AI</categories><comments>64 pages, 10 figures; Artificial Intelligence, 2011</comments><journal-ref>Artificial Intelligence, 2012, 176(1): 2291-2320</journal-ref><doi>10.1016/j.artint.2011.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose the MIML (Multi-Instance Multi-Label learning)
framework where an example is described by multiple instances and associated
with multiple class labels. Compared to traditional learning frameworks, the
MIML framework is more convenient and natural for representing complicated
objects which have multiple semantic meanings. To learn from MIML examples, we
propose the MimlBoost and MimlSvm algorithms based on a simple degeneration
strategy, and experiments show that solving problems involving complicated
objects with multiple semantic meanings in the MIML framework can lead to good
performance. Considering that the degeneration process may lose information, we
propose the D-MimlSvm algorithm which tackles MIML problems directly in a
regularization framework. Moreover, we show that even when we do not have
access to the real objects and thus cannot capture more information from real
objects by using the MIML representation, MIML is still useful. We propose the
InsDif and SubCod algorithms. InsDif works by transforming single-instances
into the MIML representation for learning, while SubCod works by transforming
single-label examples into the MIML representation for learning. Experiments
show that in some tasks they are able to achieve better performance than
learning the single-instances or single-label examples directly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3244</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3244</id><created>2008-08-24</created><authors><author><keyname>Kempner</keyname><forenames>Yulia</forenames></author><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author></authors><title>Duality between quasi-concave functions and monotone linkage functions</title><categories>math.CO cs.DM</categories><comments>12 pages, 2 figures</comments><msc-class>05B35 (Primary); 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A function $F$ defined on all subsets of a finite ground set $E$ is
quasi-concave if $F(X\cup Y)\geq\min\{F(X),F(Y)\}$ for all $X,Y\subset E$.
Quasi-concave functions arise in many fields of mathematics and computer
science such as social choice, theory of graph, data mining, clustering and
other fields.
  The maximization of quasi-concave function takes, in general, exponential
time. However, if a quasi-concave function is defined by associated monotone
linkage function then it can be optimized by the greedy type algorithm in a
polynomial time.
  Quasi-concave functions defined as minimum values of monotone linkage
functions were considered on antimatroids, where the correspondence between
quasi-concave and bottleneck functions was shown (Kempner &amp; Levit, 2003). The
goal of this paper is to analyze quasi-concave functions on different families
of sets and to investigate their relationships with monotone linkage functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3386</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3386</id><created>2008-08-25</created><updated>2014-03-18</updated><authors><author><keyname>Diaby</keyname><forenames>Moustapha</forenames></author></authors><title>Linear Programming Formulation of the Boolean Satisfiability Problem</title><categories>cs.DM cs.CC</categories><comments>This paper has been withdrawn because Theorem 38 and Corollary 39 are
  in error. The modeling needs 9-dimensional z-variables instead of the
  8-dimensional variables defined in notations 24.1</comments><acm-class>F.2.2; G.1.6; G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theorem 38 and Corollary 39 are in error. The modeling idea is sound, but it
needs 9-dimensional z-variables instead of the 8-dimensional variables defined
in notations 24.1.
  Examples of the correct model (with 9-index variables) are: (1) Diaby, M.,
"Linear Programming Formulation of the Set Partitioning Problem," International
Journal of Operational Research 8:4 (August 2010) pp. 399-427; (2) Diaby, M.,
"Linear Programming Formulation of the Vertex Coloring Problem," International
Journal of Mathematics in Operational Research 2:3 (May 2010) pp. 259-289; (3)
Diaby, M., "The Traveling Salesman Problem: A Linear Programming Formulation,"
WSEAS Transactions on Mathematics, 6:6 (June 2007) pp. 745-754.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.3884</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.3884</id><created>2008-08-28</created><updated>2010-08-23</updated><authors><author><keyname>Beyersdorff</keyname><forenames>Olaf</forenames></author><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The Complexity of Reasoning for Fragments of Default Logic</title><categories>cs.CC cs.LO</categories><comments>Corrected version</comments><acm-class>F.2.2; F.4.1; I.2.3; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Default logic was introduced by Reiter in 1980. In 1992, Gottlob classified
the complexity of the extension existence problem for propositional default
logic as $\SigmaPtwo$-complete, and the complexity of the credulous and
skeptical reasoning problem as SigmaP2-complete, resp. PiP2-complete.
Additionally, he investigated restrictions on the default rules, i.e.,
semi-normal default rules. Selman made in 1992 a similar approach with
disjunction-free and unary default rules. In this paper we systematically
restrict the set of allowed propositional connectives. We give a complete
complexity classification for all sets of Boolean functions in the meaning of
Post's lattice for all three common decision problems for propositional default
logic. We show that the complexity is a hexachotomy (SigmaP2-, DeltaP2-, NP-,
P-, NL-complete, trivial) for the extension existence problem, while for the
credulous and skeptical reasoning problem we obtain similar classifications
without trivial cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4050</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4050</id><created>2008-08-29</created><updated>2009-05-20</updated><authors><author><keyname>Burton</keyname><forenames>Benjamin A.</forenames></author></authors><title>Optimizing the double description method for normal surface enumeration</title><categories>math.GT cs.CG math.CO</categories><comments>27 pages, 12 figures; v2: Removed the 3^n bound from Section 3.3,
  fixed the projective equation in Lemma 4.4, clarified "most triangulations"
  in the introduction to section 5; v3: replace -ise with -ize for Mathematics
  of Computation (note that this changes the title of the paper)</comments><msc-class>52B55 (Primary) 57N10, 57N35 (Secondary)</msc-class><journal-ref>Mathematics of Computation 79 (2010), no. 269, 453-484</journal-ref><doi>10.1090/S0025-5718-09-02282-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many key algorithms in 3-manifold topology involve the enumeration of normal
surfaces, which is based upon the double description method for finding the
vertices of a convex polytope. Typically we are only interested in a small
subset of these vertices, thus opening the way for substantial optimization.
Here we give an account of the vertex enumeration problem as it applies to
normal surfaces, and present new optimizations that yield strong improvements
in both running time and memory consumption. The resulting algorithms are
tested using the freely available software package Regina.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4134</identifier>
 <datestamp>2010-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4134</id><created>2008-08-29</created><updated>2010-07-20</updated><authors><author><keyname>Spielman</keyname><forenames>Daniel A.</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Spectral Sparsification of Graphs</title><categories>cs.DS cs.DM</categories><comments>This revision addresses comments of the referees. In particular, we
  have completely re-written the proof of the main graph partitioning theorem
  in section 8</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new notion of graph sparsificaiton based on spectral
similarity of graph Laplacians: spectral sparsification requires that the
Laplacian quadratic form of the sparsifier approximate that of the original.
This is equivalent to saying that the Laplacian of the sparsifier is a good
preconditioner for the Laplacian of the original. We prove that every graph has
a spectral sparsifier of nearly linear size. Moreover, we present an algorithm
that produces spectral sparsifiers in time $\softO{m}$, where $m$ is the number
of edges in the original graph. This construction is a key component of a
nearly-linear time algorithm for solving linear equations in
diagonally-dominant matrcies. Our sparsification algorithm makes use of a
nearly-linear time algorithm for graph partitioning that satisfies a strong
guarantee: if the partition it outputs is very unbalanced, then the larger part
is contained in a subgraph of high conductance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0808.4156</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0808.4156</id><created>2008-08-29</created><updated>2010-05-07</updated><authors><author><keyname>Jalali</keyname><forenames>Shirin</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>Rate-Distortion via Markov Chain Monte Carlo</title><categories>cs.IT math.IT</categories><comments>35 pages, 16 figures, Submitted to IEEE Transactions on Information
  Theory</comments><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach to lossy source coding, utilizing ideas from Gibbs
sampling, simulated annealing, and Markov Chain Monte Carlo (MCMC). The idea is
to sample a reconstruction sequence from a Boltzmann distribution associated
with an energy function that incorporates the distortion between the source and
reconstruction, the compressibility of the reconstruction, and the point sought
on the rate-distortion curve. To sample from this distribution, we use a `heat
bath algorithm': Starting from an initial candidate reconstruction (say the
original source sequence), at every iteration, an index i is chosen and the
i-th sequence component is replaced by drawing from the conditional probability
distribution for that component given all the rest. At the end of this process,
the encoder conveys the reconstruction to the decoder using universal lossless
compression. The complexity of each iteration is independent of the sequence
length and only linearly dependent on a certain context parameter (which grows
sub-logarithmically with the sequence length). We show that the proposed
algorithms achieve optimum rate-distortion performance in the limits of large
number of iterations, and sequence length, when employed on any stationary
ergodic source. Experimentation shows promising initial results. Employing our
lossy compressors on noisy data, with appropriately chosen distortion measure
and level, followed by a simple de-randomization operation, results in a family
of denoisers that compares favorably (both theoretically and in practice) with
other MCMC-based schemes, and with the Discrete Universal Denoiser (DUDE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0009</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0009</id><created>2008-08-29</created><updated>2012-05-18</updated><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author><author><keyname>Ramanan</keyname><forenames>Kavita</forenames></author></authors><title>Distributed Parameter Estimation in Sensor Networks: Nonlinear
  Observation Models and Imperfect Communication</title><categories>cs.MA cs.IT math.IT</categories><comments>IEEE Transactions On Information Theory, Vol. 58, No. 6, June 2012</comments><doi>10.1109/TIT.2012.219450</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies distributed static parameter (vector) estimation in sensor
networks with nonlinear observation models and noisy inter-sensor
communication. It introduces \emph{separably estimable} observation models that
generalize the observability condition in linear centralized estimation to
nonlinear distributed estimation. It studies two distributed estimation
algorithms in separably estimable models, the $\mathcal{NU}$ (with its linear
counterpart $\mathcal{LU}$) and the $\mathcal{NLU}$. Their update rule combines
a \emph{consensus} step (where each sensor updates the state by weight
averaging it with its neighbors' states) and an \emph{innovation} step (where
each sensor processes its local current observation.) This makes the three
algorithms of the \textit{consensus + innovations} type, very different from
traditional consensus. The paper proves consistency (all sensors reach
consensus almost surely and converge to the true parameter value,) efficiency,
and asymptotic unbiasedness. For $\mathcal{LU}$ and $\mathcal{NU}$, it proves
asymptotic normality and provides convergence rate guarantees. The three
algorithms are characterized by appropriately chosen decaying weight sequences.
Algorithms $\mathcal{LU}$ and $\mathcal{NU}$ are analyzed in the framework of
stochastic approximation theory; algorithm $\mathcal{NLU}$ exhibits mixed
time-scale behavior and biased perturbations, and its analysis requires a
different approach that is developed in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0016</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0016</id><created>2008-08-29</created><updated>2010-03-30</updated><authors><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author></authors><title>An overview of the transmission capacity of wireless networks</title><categories>cs.IT math.IT</categories><comments>Submitted August 13, 2009 to IEEE Transactions on Communications.
  Revisions submitted December 14, 2009 and February 26, 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper surveys and unifies a number of recent contributions that have
collectively developed a metric for decentralized wireless network analysis
known as transmission capacity. Although it is notoriously difficult to derive
general end-to-end capacity results for multi-terminal or \adhoc networks, the
transmission capacity (TC) framework allows for quantification of achievable
single-hop rates by focusing on a simplified physical/MAC-layer model. By using
stochastic geometry to quantify the multi-user interference in the network, the
relationship between the optimal spatial density and success probability of
transmissions in the network can be determined, and expressed -- often fairly
simply -- in terms of the key network parameters. The basic model and
analytical tools are first discussed and applied to a simple network with path
loss only and we present tight upper and lower bounds on transmission capacity
(via lower and upper bounds on outage probability). We then introduce random
channels (fading/shadowing) and give TC and outage approximations for an
arbitrary channel distribution, as well as exact results for the special cases
of Rayleigh and Nakagami fading. We then apply these results to show how TC can
be used to better understand scheduling, power control, and the deployment of
multiple antennas in a decentralized network. The paper closes by discussing
shortcomings in the model as well as future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0063</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0063</id><created>2008-08-30</created><authors><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Fousse</keyname><forenames>Laurent</forenames><affiliation>LJK</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Simultaneous Modular Reduction and Kronecker Substitution for Small
  Finite Fields</title><categories>cs.SC math.NT</categories><proxy>ccsd hal-00315772</proxy><doi>10.1016/j.jsc.2010.08.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms to perform modular polynomial multiplication or modular
dot product efficiently in a single machine word. We pack polynomials into
integers and perform several modular operations with machine integer or
floating point arithmetic. The modular polynomials are converted into integers
using Kronecker substitution (evaluation at a sufficiently large integer). With
some control on the sizes and degrees, arithmetic operations on the polynomials
can be performed directly with machine integers or floating point numbers and
the number of conversions can be reduced. We also present efficient ways to
recover the modular values of the coefficients. This leads to practical gains
of quite large constant factors for polynomial multiplication, prime field
linear algebra and small extension field arithmetic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0073</identifier>
 <datestamp>2010-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0073</id><created>2008-08-30</created><updated>2010-07-22</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Languages recognized with unbounded error by quantum finite automata</title><categories>quant-ph cs.CC</categories><comments>This paper has been superseded by arXiv:1007.3624</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been superseded by arXiv:1007.3624
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0259</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0259</id><created>2008-09-01</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On Duality between Local Maximum Stable Sets of a Graph and its
  Line-Graph</title><categories>math.CO cs.DM</categories><comments>7 pages; 7 figures</comments><msc-class>05C69 (Primary) 05C70 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  G is a Koenig-Egervary graph provided alpha(G)+ mu(G)=|V(G)|, where mu(G) is
the size of a maximum matching and alpha(G) is the cardinality of a maximum
stable set. S is a local maximum stable set of G if S is a maximum stable set
of the closed neighborhood of S. Nemhauser and Trotter Jr. proved that any
local maximum stable set is a subset of a maximum stable set of G. In this
paper we demonstrate that if S is a local maximum stable set, the subgraph H
induced by the closed neighborhood of S is a Koenig-Egervary graph, and M is a
maximum matching in H, then M is a local maximum stable set in the line graph
of G.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0352</identifier>
 <datestamp>2010-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0352</id><created>2008-09-02</created><updated>2010-07-14</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Instruction sequences and non-uniform complexity theory</title><categories>cs.CC</categories><comments>31 pages; 31 pages, improvements of several proof outlines; 33 pages,
  presentation of section 7 improved</comments><report-no>PRG0812</report-no><acm-class>F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop theory concerning non-uniform complexity in a setting in which the
notion of single-pass instruction sequence considered in program algebra is the
central notion. We define counterparts of the complexity classes P/poly and
NP/poly and formulate a counterpart of the complexity theoretic conjecture that
NP is not included in P/poly. In addition, we define a notion of completeness
for the counterpart of NP/poly using a non-uniform reducibility relation and
formulate complexity hypotheses which concern restrictions on the instruction
sequences used for computation. We think that the theory developed opens up an
additional way of investigating issues concerning non-uniform complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0490</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0490</id><created>2008-09-02</created><updated>2011-05-09</updated><authors><author><keyname>Gorban</keyname><forenames>A. N.</forenames></author><author><keyname>Zinovyev</keyname><forenames>A. Y.</forenames></author></authors><title>Principal Graphs and Manifolds</title><categories>cs.LG cs.NE stat.ML</categories><comments>36 pages, 6 figures, minor corrections</comments><journal-ref>Handbook of Research on Machine Learning Applications and Trends:
  Algorithms, Methods and Techniques, Ch. 2, Information Science Reference,
  2009. 28-59</journal-ref><doi>10.4018/978-1-60566-766-9</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In many physical, statistical, biological and other investigations it is
desirable to approximate a system of points by objects of lower dimension
and/or complexity. For this purpose, Karl Pearson invented principal component
analysis in 1901 and found 'lines and planes of closest fit to system of
points'. The famous k-means algorithm solves the approximation problem too, but
by finite sets instead of lines and planes. This chapter gives a brief
practical introduction into the methods of construction of general principal
objects, i.e. objects embedded in the 'middle' of the multidimensional data
set. As a basis, the unifying framework of mean squared distance approximation
of finite datasets is selected. Principal graphs and manifolds are constructed
as generalisations of principal components and k-means principal points. For
this purpose, the family of expectation/maximisation algorithms with nearest
generalisations is presented. Construction of principal graphs with controlled
complexity is based on the graph grammar approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0522</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0522</id><created>2008-09-02</created><authors><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>The first-mover advantage in scientific publication</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>7 pages, 3 figures</comments><journal-ref>Europhys. Lett. 86, 68001 (2009)</journal-ref><doi>10.1209/0295-5075/86/68001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical models of the scientific citation process predict a strong
"first-mover" effect under which the first papers in a field will, essentially
regardless of content, receive citations at a rate enormously higher than
papers published later. Moreover papers are expected to retain this advantage
in perpetuity -- they should receive more citations indefinitely, no matter how
many other papers are published after them. We test this conjecture against
data from a selection of fields and in several cases find a first-mover effect
of a magnitude similar to that predicted by the theory. Were we wearing our
cynical hat today, we might say that the scientist who wants to become famous
is better off -- by a wide margin -- writing a modest paper in next year's
hottest field than an outstanding paper in this year's. On the other hand,
there are some papers, albeit only a small fraction, that buck the trend and
attract significantly more citations than theory predicts despite having
relatively late publication dates. We suggest that papers of this kind, though
they often receive comparatively few citations overall, are probably worthy of
our attention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0539</identifier>
 <datestamp>2011-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0539</id><created>2008-09-02</created><updated>2011-02-17</updated><authors><author><keyname>Santipach</keyname><forenames>Wiroonsak</forenames></author></authors><title>Signature Quantization in Fading CDMA With Limited Feedback</title><categories>cs.IT math.IT</categories><journal-ref>IEEE TRANSACTIONS ON COMMUNICATIONS, VOL. 59, NO. 2, PP. 569-577
  FEBRUARY 2011</journal-ref><doi>10.1109/TCOMM.2011.122110.090476</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we analyze the performance of a signature quantization scheme
for reverse-link Direct Sequence (DS)- Code Division Multiple Access (CDMA).
Assuming perfect estimates of the channel and interference covariance, the
receiver selects the signature that minimizes interference power or maximizes
signal-to-interference plus noise ratio (SINR) for a desired user from a
signature codebook. The codebook index corresponding to the optimal signature
is then relayed to the user with a finite number of bits via a feedback
channel. Here we are interested in the performance of a Random Vector
Quantization (RVQ) codebook, which contains independent isotropically
distributed vectors. Assuming arbitrary transmit power allocation, we consider
additive white Gaussian noise (AWGN) channel first with no fading and
subsequently, with multipath fading. We derive the corresponding SINR in a
large system limit at the output of matched filter and linear minimum mean
squared error (MMSE) receiver. Numerical examples show that the derived large
system results give a good approximation to the performance of finite-size
system and that the MMSE receiver achieves close to a single-user performance
with only one feedback bit per signature element.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0686</identifier>
 <datestamp>2010-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0686</id><created>2008-09-03</created><updated>2010-06-08</updated><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Yukich</keyname><forenames>Joseph E.</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Energy Scaling Laws for Distributed Inference in Random Fusion Networks</title><categories>cs.IT cs.NI math.IT math.ST stat.TH</categories><comments>IEEE JSAC on Stochastic Geometry and Random Graphs for Wireless
  Networks</comments><journal-ref>vol. 27, no. 7, pp.1203-1217, Sept. 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The energy scaling laws of multihop data fusion networks for distributed
inference are considered. The fusion network consists of randomly located
sensors distributed i.i.d. according to a general spatial distribution in an
expanding region. Among the class of data fusion schemes that enable optimal
inference at the fusion center for Markov random field (MRF) hypotheses, the
scheme with minimum average energy consumption is bounded below by average
energy of fusion along the minimum spanning tree, and above by a suboptimal
scheme, referred to as Data Fusion for Markov Random Fields (DFMRF). Scaling
laws are derived for the optimal and suboptimal fusion policies. It is shown
that the average asymptotic energy of the DFMRF scheme is finite for a class of
MRF models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0733</identifier>
 <datestamp>2012-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0733</id><created>2008-09-03</created><updated>2009-03-06</updated><authors><author><keyname>Harada</keyname><forenames>Masaaki</forenames></author><author><keyname>Munemasa</keyname><forenames>Akihiro</forenames></author></authors><title>There exists no self-dual [24,12,10] code over F5</title><categories>math.CO cs.IT math.IT</categories><comments>To appear in Designs, Codes and Cryptogr</comments><msc-class>94B05</msc-class><journal-ref>Designs, Codes and Cryptogr. 52 (2009), 125-127</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-dual codes over F5 exist for all even lengths. The smallest length for
which the largest minimum weight among self-dual codes has not been determined
is 24, and the largest minimum weight is either 9 or 10. In this note, we show
that there exists no self-dual [24,12,10] code over F5, using the
classification of 24-dimensional odd unimodular lattices due to Borcherds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0737</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0737</id><created>2008-09-03</created><updated>2011-05-09</updated><authors><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author><author><keyname>Kusuma</keyname><forenames>Julius</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>Malleable Coding with Fixed Reuse</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cloud computing, storage area networks, remote backup storage, and similar
settings, stored data is modified with updates from new versions. Representing
information and modifying the representation are both expensive. Therefore it
is desirable for the data to not only be compressed but to also be easily
modified during updates. A malleable coding scheme considers both compression
efficiency and ease of alteration, promoting codeword reuse. We examine the
trade-off between compression efficiency and malleability cost-the difficulty
of synchronizing compressed versions-measured as the length of a reused prefix
portion. Through a coding theorem, the region of achievable rates and
malleability is expressed as a single-letter optimization. Relationships to
common information problems are also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0835</identifier>
 <datestamp>2010-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0835</id><created>2008-09-04</created><updated>2010-03-13</updated><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames></author><author><keyname>Friedrich</keyname><forenames>Tobias</forenames></author></authors><title>Approximating the volume of unions and intersections of high-dimensional
  geometric objects</title><categories>cs.CG cs.NE</categories><comments>16 pages, To appear in Computational Geometry - Theory and
  Applications</comments><journal-ref>Computational Geometry: Theory and Applications, Vol. 43, No. 6-7,
  pages 601-610, 2010</journal-ref><doi>10.1016/j.comgeo.2010.03.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the computation of the volume of the union of high-dimensional
geometric objects. While showing that this problem is #P-hard already for very
simple bodies (i.e., axis-parallel boxes), we give a fast FPRAS for all objects
where one can: (1) test whether a given point lies inside the object, (2)
sample a point uniformly, (3) calculate the volume of the object in polynomial
time. All three oracles can be weak, that is, just approximate. This implies
that Klee's measure problem and the hypervolume indicator can be approximated
efficiently even though they are #P-hard and hence cannot be solved exactly in
time polynomial in the number of dimensions unless P=NP. Our algorithm also
allows to approximate efficiently the volume of the union of convex bodies
given by weak membership oracles.
  For the analogous problem of the intersection of high-dimensional geometric
objects we prove #P-hardness for boxes and show that there is no multiplicative
polynomial-time $2^{d^{1-\epsilon}}$-approximation for certain boxes unless
NP=BPP, but give a simple additive polynomial-time $\epsilon$-approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.0853</identifier>
 <datestamp>2011-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.0853</id><created>2008-09-04</created><updated>2009-04-22</updated><authors><author><keyname>Nguyen</keyname><forenames>XuanLong</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Estimating divergence functionals and the likelihood ratio by convex
  risk minimization</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>28 pages</comments><journal-ref>IEEE Transactions on Information Theory, 56(11), 5847--5861, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop and analyze $M$-estimation methods for divergence functionals and
the likelihood ratios of two probability distributions. Our method is based on
a non-asymptotic variational characterization of $f$-divergences, which allows
the problem of estimating divergences to be tackled via convex empirical risk
optimization. The resulting estimators are simple to implement, requiring only
the solution of standard convex programs. We present an analysis of consistency
and convergence for these estimators. Given conditions only on the ratios of
densities, we show that our estimators can achieve optimal minimax rates for
the likelihood ratio and the divergence functionals in certain regimes. We
derive an efficient optimization algorithm for computing our estimates, and
illustrate their convergence behavior and practical viability by simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1236</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1236</id><created>2008-09-07</created><updated>2010-01-17</updated><authors><author><keyname>Ganty</keyname><forenames>Pierre</forenames></author><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author><author><keyname>Monmege</keyname><forenames>Benjamin</forenames></author></authors><title>Bounded Underapproximations</title><categories>cs.LO</categories><comments>30 pages, 2 figures, v4 added complexity results, various
  improvements</comments><journal-ref>Formal Methods in System Design 40(2) (2012) 206-231</journal-ref><doi>10.1007/s10703-011-0136-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a new and constructive proof of the following language-theoretic
result: for every context-free language L, there is a bounded context-free
language L' included in L which has the same Parikh (commutative) image as L.
Bounded languages, introduced by Ginsburg and Spanier, are subsets of regular
languages of the form w1*w2*...wk* for some finite words w1,...,wk. In
particular bounded subsets of context-free languages have nice structural and
decidability properties. Our proof proceeds in two parts. First, using Newton's
iterations on the language semiring, we construct a context-free subset Ls of L
that can be represented as a sequence of substitutions on a linear language and
has the same Parikh image as L. Second, we inductively construct a
Parikh-equivalent bounded context-free subset of Ls.
  We show two applications of this result in model checking: to
underapproximate the reachable state space of multithreaded procedural programs
and to underapproximate the reachable state space of recursive counter
programs. The bounded language constructed above provides a decidable
underapproximation for the original problems. By iterating the construction, we
get a semi-algorithm for the original problems that constructs a sequence of
underapproximations such that no two underapproximations of the sequence can be
compared. This provides a progress guarantee: every word w in L is in some
underapproximation of the sequence. In addition, we show that our approach
subsumes context-bounded reachability for multithreaded programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1241</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1241</id><created>2008-09-08</created><updated>2012-12-04</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A New Framework of Multistage Estimation</title><categories>math.ST cs.LG math.PR stat.ME stat.TH</categories><comments>254 pages, no figure; added more references; main results appeared in
  Proceedings of SPIE, Orlando, Florida, USA, April 2010 and 2011</comments><doi>10.1103/PhysRevE.79.026307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have established a unified framework of multistage
parameter estimation. We demonstrate that a wide variety of statistical
problems such as fixed-sample-size interval estimation, point estimation with
error control, bounded-width confidence intervals, interval estimation
following hypothesis testing, construction of confidence sequences, can be cast
into the general framework of constructing sequential random intervals with
prescribed coverage probabilities. We have developed exact methods for the
construction of such sequential random intervals in the context of multistage
sampling. In particular, we have established inclusion principle and coverage
tuning techniques to control and adjust the coverage probabilities of
sequential random intervals. We have obtained concrete sampling schemes which
are unprecedentedly efficient in terms of sampling effort as compared to
existing procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1257</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1257</id><created>2008-09-07</created><authors><author><keyname>Daubechies</keyname><forenames>I.</forenames></author><author><keyname>Güntürk</keyname><forenames>C. S.</forenames></author><author><keyname>Wang</keyname><forenames>Y.</forenames></author><author><keyname>Yilmaz</keyname><forenames>Ö.</forenames></author></authors><title>The Golden Ratio Encoder</title><categories>cs.IT math.IT</categories><comments>24 pages, 9 figures</comments><msc-class>41A99, 94C99</msc-class><doi>10.1109/TIT.2010.2059750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel Nyquist-rate analog-to-digital (A/D) conversion
algorithm which achieves exponential accuracy in the bit-rate despite using
imperfect components. The proposed algorithm is based on a robust
implementation of a beta-encoder where the value of the base beta is equal to
golden mean. It was previously shown that beta-encoders can be implemented in
such a way that their exponential accuracy is robust against threshold offsets
in the quantizer element. This paper extends this result by allowing for
imperfect analog multipliers with imprecise gain values as well. A formal
computational model for algorithmic encoders and a general test bed for
evaluating their robustness is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1344</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1344</id><created>2008-09-08</created><updated>2010-01-21</updated><authors><author><keyname>Niesen</keyname><forenames>Urs</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author></authors><title>The Balanced Unicast and Multicast Capacity Regions of Large Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>37 pages, 7 figures, to appear in IEEE Transactions on Information
  Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, pp. 2249-2271,
  May 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the question of determining the scaling of the $n^2$-dimensional
balanced unicast and the $n 2^n$-dimensional balanced multicast capacity
regions of a wireless network with $n$ nodes placed uniformly at random in a
square region of area $n$ and communicating over Gaussian fading channels. We
identify this scaling of both the balanced unicast and multicast capacity
regions in terms of $\Theta(n)$, out of $2^n$ total possible, cuts. These cuts
only depend on the geometry of the locations of the source nodes and their
destination nodes and the traffic demands between them, and thus can be readily
evaluated. Our results are constructive and provide optimal (in the scaling
sense) communication schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1398</identifier>
 <datestamp>2010-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1398</id><created>2008-09-08</created><updated>2010-04-29</updated><authors><author><keyname>Mungan</keyname><forenames>Muhittin</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author></authors><title>Stability of Maximum likelihood based clustering methods: exploring the
  backbone of classifications (Who is keeping you in that community?)</title><categories>physics.soc-ph cond-mat.stat-mech cs.IT math.IT physics.comp-ph physics.data-an</categories><comments>19 pages, 9 figures</comments><journal-ref>J. Stat. Mech. (2010) P04028</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Components of complex systems are often classified according to the way they
interact with each other. In graph theory such groups are known as clusters or
communities. Many different techniques have been recently proposed to detect
them, some of which involve inference methods using either Bayesian or Maximum
Likelihood approaches. In this article, we study a statistical model designed
for detecting clusters based on connection similarity. The basic assumption of
the model is that the graph was generated by a certain grouping of the nodes
and an Expectation Maximization algorithm is employed to infer that grouping.
We show that the method admits further development to yield a stability
analysis of the groupings that quantifies the extent to which each node
influences its neighbors group membership. Our approach naturally allows for
the identification of the key elements responsible for the grouping and their
resilience to changes in the network. Given the generality of the assumptions
underlying the statistical model, such nodes are likely to play special roles
in the original system. We illustrate this point by analyzing several empirical
networks for which further information about the properties of the nodes is
available. The search and identification of stabilizing nodes constitutes thus
a novel technique to characterize the relevance of nodes in complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1489</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1489</id><created>2008-09-09</created><authors><author><keyname>Floréen</keyname><forenames>Patrik</forenames></author><author><keyname>Kaasinen</keyname><forenames>Joel</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>An optimal local approximation algorithm for max-min linear programs</title><categories>cs.DC</categories><comments>16 pages, 3 figures</comments><doi>10.1145/1583991.1584058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a local algorithm (constant-time distributed algorithm) for
approximating max-min LPs. The objective is to maximise $\omega$ subject to $Ax
\le 1$, $Cx \ge \omega 1$, and $x \ge 0$ for nonnegative matrices $A$ and $C$.
The approximation ratio of our algorithm is the best possible for any local
algorithm; there is a matching unconditional lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1552</identifier>
 <datestamp>2010-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1552</id><created>2008-09-08</created><updated>2010-06-03</updated><authors><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author><author><keyname>Spitters</keyname><forenames>Bas</forenames></author></authors><title>A computer verified, monadic, functional implementation of the integral</title><categories>cs.LO cs.NA</categories><journal-ref>Theoretical Computer Science, Volume 411, Issue 37, 7 August 2010,
  Pages 3386-3402</journal-ref><doi>10.1016/j.tcs.2010.05.031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a computer verified exact monadic functional implementation of the
Riemann integral in type theory. Together with previous work by O'Connor, this
may be seen as the beginning of the realization of Bishop's vision to use
constructive mathematics as a programming language for exact analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1590</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1590</id><created>2008-09-09</created><authors><author><keyname>Argyriou</keyname><forenames>Andreas</forenames></author><author><keyname>Micchelli</keyname><forenames>Charles</forenames></author><author><keyname>Pontil</keyname><forenames>Massimiliano</forenames></author></authors><title>When is there a representer theorem? Vector versus matrix regularizers</title><categories>cs.LG</categories><comments>22 pages 2 figures</comments><acm-class>G.1.1; G.1.2; G.1.6; G.1.10; G.3; I.2.6</acm-class><journal-ref>Journal of Machine Learning Research, 10:2507-2529, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a general class of regularization methods which learn a vector of
parameters on the basis of linear measurements. It is well known that if the
regularizer is a nondecreasing function of the inner product then the learned
vector is a linear combination of the input data. This result, known as the
{\em representer theorem}, is at the basis of kernel-based methods in machine
learning. In this paper, we prove the necessity of the above condition, thereby
completing the characterization of kernel methods based on regularization. We
further extend our analysis to regularization methods which learn a matrix, a
problem which is motivated by the application to multi-task learning. In this
context, we study a more general representer theorem, which holds for a larger
class of regularizers. We provide a necessary and sufficient condition for
these class of matrix regularizers and highlight them with some concrete
examples of practical importance. Our analysis uses basic principles from
matrix theory, especially the useful notion of matrix nondecreasing function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1593</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1593</id><created>2008-09-09</created><updated>2011-07-11</updated><authors><author><keyname>Ryabko</keyname><forenames>Boris</forenames></author><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Constructing Perfect Steganographic Systems</title><categories>cs.CR cs.IT math.IT</categories><journal-ref>Information and Computation, 2011, Vol. 209, No. 9, pp. 1223-1230</journal-ref><doi>10.1016/j.ic.2011.06.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose steganographic systems for the case when covertexts (containers)
are generated by a finite-memory source with possibly unknown statistics. The
probability distributions of covertexts with and without hidden information are
the same; this means that the proposed stegosystems are perfectly secure, i.e.
an observer cannot determine whether hidden information is being transmitted.
The speed of transmission of hidden information can be made arbitrary close to
the theoretical limit - the Shannon entropy of the source of covertexts. An
interesting feature of the suggested stegosystems is that they do not require
any (secret or public) key.
  At the same time, we outline some principled computational limitations on
steganography. We show that there are such sources of covertexts, that any
stegosystem that has linear (in the length of the covertext) speed of
transmission of hidden text must have an exponential Kolmogorov complexity.
This shows, in particular, that some assumptions on the sources of covertext
are necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1644</identifier>
 <datestamp>2010-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1644</id><created>2008-09-09</created><authors><author><keyname>Kaliszyk</keyname><forenames>Cezary</forenames></author><author><keyname>O'Connor</keyname><forenames>Russell</forenames></author></authors><title>Computing with Classical Real Numbers</title><categories>cs.LO</categories><journal-ref>Journal of Formalized Reasoning, 2(1):27-39, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two incompatible Coq libraries that have a theory of the real
numbers; the Coq standard library gives an axiomatic treatment of classical
real numbers, while the CoRN library from Nijmegen defines constructively valid
real numbers. Unfortunately, this means results about one structure cannot
easily be used in the other structure. We present a way interfacing these two
libraries by showing that their real number structures are isomorphic assuming
the classical axioms already present in the standard library reals. This allows
us to use O'Connor's decision procedure for solving ground inequalities present
in CoRN to solve inequalities about the reals from the Coq standard library,
and it allows theorems from the Coq standard library to apply to problem about
the CoRN reals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1681</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1681</id><created>2008-09-09</created><authors><author><keyname>Laufer</keyname><forenames>Rafael</forenames></author><author><keyname>Kleinrock</keyname><forenames>Leonard</forenames></author></authors><title>Multirate Anypath Routing in Wireless Mesh Networks</title><categories>cs.NI cs.DS</categories><comments>13 pages, 8 figures</comments><report-no>UCLA-CSD-TR080025</report-no><journal-ref>IEEE INFOCOM 2009</journal-ref><doi>10.1109/INFCOM.2009.5061904</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new routing paradigm that generalizes
opportunistic routing in wireless mesh networks. In multirate anypath routing,
each node uses both a set of next hops and a selected transmission rate to
reach a destination. Using this rate, a packet is broadcast to the nodes in the
set and one of them forwards the packet on to the destination. To date, there
is no theory capable of jointly optimizing both the set of next hops and the
transmission rate used by each node. We bridge this gap by introducing a
polynomial-time algorithm to this problem and provide the proof of its
optimality. The proposed algorithm runs in the same running time as regular
shortest-path algorithms and is therefore suitable for deployment in link-state
routing protocols. We conducted experiments in a 802.11b testbed network, and
our results show that multirate anypath routing performs on average 80% and up
to 6.4 times better than anypath routing with a fixed rate of 11 Mbps. If the
rate is fixed at 1 Mbps instead, performance improves by up to one order of
magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1806</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1806</id><created>2008-09-10</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Graph Operations that are Good for Greedoids</title><categories>math.CO cs.DM</categories><comments>8 pages, 4 figures</comments><msc-class>05C69 (Primary) 05B35, 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  S is a local maximum stable set of a graph G, if the set S is a maximum
stable set of the subgraph induced by its closed neighborhood. In (Levit,
Mandrescu, 2002) we have proved that the family of all local maximum stable
sets is a greedoid for every forest. The cases of bipartite graphs and
triangle-free graphs were analyzed in (Levit, Mandrescu, 2004) and (Levit,
Mandrescu, 2007), respectively. In this paper we give necessary and sufficient
conditions for the family of all local maximum stable sets of a graph G to form
a greedoid, where G is: (a) the disjoint union of a family of graphs; (b) the
Zykov sum of a family of graphs, or (c) the corona X*{H_1,H_2,...,H_n} obtained
by joining each vertex k of a graph X to all the vertices of a graph H_k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1810</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1810</id><created>2008-09-10</created><authors><author><keyname>Cruz</keyname><forenames>Felipe A.</forenames></author><author><keyname>Barba</keyname><forenames>L. A.</forenames></author></authors><title>Characterization of the errors of the FMM in particle simulations</title><categories>cs.DS physics.comp-ph</categories><comments>34 pages, 38 images</comments><journal-ref>Int. J. Num. Meth. Engrg., 79(13):1577-1604 (2009)</journal-ref><doi>10.1002/nme.2611</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Fast Multipole Method (FMM) offers an acceleration for pairwise
interaction calculation, known as $N$-body problems, from $\mathcal{O}(N^2)$ to
$\mathcal{O}(N)$ with $N$ particles. This has brought dramatic increase in the
capability of particle simulations in many application areas, such as
electrostatics, particle formulations of fluid mechanics, and others. Although
the literature on the subject provides theoretical error bounds for the FMM
approximation, there are not many reports of the measured errors in a suite of
computational experiments. We have performed such an experimental
investigation, and summarized the results of about 1000 calculations using the
FMM algorithm, to characterize the accuracy of the method in relation with the
different parameters available to the user. In addition to the more standard
diagnostic of the maximum error, we supply illustrations of the spatial
distribution of the errors, which offers visual evidence of all the
contributing factors to the overall approximation accuracy: multipole
expansion, local expansion, hierarchical spatial decomposition (interaction
lists, local domain, far domain). This presentation is a contribution to any
researcher wishing to incorporate the FMM acceleration to their application
code, as it aids in understanding where accuracy is gained or compromised.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.1949</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.1949</id><created>2008-09-11</created><updated>2011-05-14</updated><authors><author><keyname>Wendzel</keyname><forenames>Steffen</forenames></author></authors><title>Protocol Channels</title><categories>cs.CR</categories><comments>2 pages</comments><acm-class>K.6.5; D.4.6</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Covert channel techniques are used by attackers to transfer data in a way
prohibited by the security policy. There are two main categories of covert
channels: timing channels and storage channels. This paper introduces a new
storage channel technique called a protocol channel. A protocol channel
switches one of at least two protocols to send a bit combination to a
destination. The main goal of a protocol channel is that packets containing
covert information look equal to all other packets within a network, what makes
a protocol channel hard to detect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2083</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2083</id><created>2008-09-11</created><updated>2009-02-13</updated><authors><author><keyname>Baldoni</keyname><forenames>Velleda</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Berline</keyname><forenames>Nicole</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>De Loera</keyname><forenames>Jesus</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Köppe</keyname><forenames>Matthias</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Vergne</keyname><forenames>Michèle</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author></authors><title>How to Integrate a Polynomial over a Simplex</title><categories>math.MG cs.CC cs.SC</categories><comments>Tables added with new experimental results. References added</comments><proxy>ccsd hal-00320882</proxy><journal-ref>Mathematics of Computation 80, 273 (2011) 297-325</journal-ref><doi>10.1090/S0025-5718-2010-02378-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper settles the computational complexity of the problem of integrating
a polynomial function f over a rational simplex. We prove that the problem is
NP-hard for arbitrary polynomials via a generalization of a theorem of Motzkin
and Straus. On the other hand, if the polynomial depends only on a fixed number
of variables, while its degree and the dimension of the simplex are allowed to
vary, we prove that integration can be done in polynomial time. As a
consequence, for polynomials of fixed total degree, there is a polynomial time
algorithm as well. We conclude the article with extensions to other polytopes,
discussion of other available methods and experimental results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2136</identifier>
 <datestamp>2010-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2136</id><created>2008-09-12</created><updated>2009-12-16</updated><authors><author><keyname>Enumula</keyname><forenames>Prabodh K.</forenames></author><author><keyname>Rao</keyname><forenames>Shrisha</forenames></author></authors><title>The Potluck Problem</title><categories>cs.GT cs.MA</categories><comments>9 pages. Economics Letters, to appear</comments><acm-class>I.2.11; I.6.1</acm-class><journal-ref>Economics Letters 107 (1), pp. 10--12, April 2010</journal-ref><doi>10.1016/j.econlet.2009.12.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the Potluck Problem as a model for the behavior of
independent producers and consumers under standard economic assumptions, as a
problem of resource allocation in a multi-agent system in which there is no
explicit communication among the agents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2168</identifier>
 <datestamp>2010-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2168</id><created>2008-09-12</created><authors><author><keyname>Saini</keyname><forenames>Megha</forenames></author><author><keyname>Rao</keyname><forenames>Shrisha</forenames></author></authors><title>Fairness in Combinatorial Auctioning Systems</title><categories>cs.GT cs.MA</categories><comments>18 pages; AAAI Spring Symposium on Game Theoretic and Decision
  Theoretic Agents, Stanford University, CA, March 2007</comments><acm-class>I.2.11; J.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the Multi-Agent Systems that is widely used by various government
agencies, buyers and sellers in a market economy, in such a manner so as to
attain optimized resource allocation, is the Combinatorial Auctioning System
(CAS). We study another important aspect of resource allocations in CAS, namely
fairness. We present two important notions of fairness in CAS, extended
fairness and basic fairness. We give an algorithm that works by incorporating a
metric to ensure fairness in a CAS that uses the Vickrey-Clark-Groves (VCG)
mechanism, and uses an algorithm of Sandholm to achieve optimality.
Mathematical formulations are given to represent measures of extended fairness
and basic fairness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2386</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2386</id><created>2008-09-14</created><updated>2012-04-15</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Dalmau</keyname><forenames>Victor</forenames></author></authors><title>Datalog and Constraint Satisfaction with Infinite Templates</title><categories>cs.LO cs.CC</categories><comments>28 pages. This is an extended long version of a conference paper that
  appeared at STACS'06. In the third version in the arxiv we have revised the
  presentation again and added a section that relates our results to
  formalizations of CSPs using relation algebras</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  On finite structures, there is a well-known connection between the expressive
power of Datalog, finite variable logics, the existential pebble game, and
bounded hypertree duality. We study this connection for infinite structures.
This has applications for constraint satisfaction with infinite templates. If
the template Gamma is omega-categorical, we present various equivalent
characterizations of those Gamma such that the constraint satisfaction problem
(CSP) for Gamma can be solved by a Datalog program. We also show that
CSP(Gamma) can be solved in polynomial time for arbitrary omega-categorical
structures Gamma if the input is restricted to instances of bounded treewidth.
Finally, we characterize those omega-categorical templates whose CSP has
Datalog width 1, and those whose CSP has strict Datalog width k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2421</identifier>
 <datestamp>2011-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2421</id><created>2008-09-14</created><updated>2011-04-18</updated><authors><author><keyname>Sarmiento</keyname><forenames>Juan Ojeda</forenames></author></authors><title>Electricity Demand and Energy Consumption Management System</title><categories>cs.AI cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This project describes the electricity demand and energy consumption
management system and its application to Southern Peru smelter. It is composed
of an hourly demand-forecasting module and of a simulation component for a
plant electrical system. The first module was done using dynamic neural
networks with backpropagation training algorithm; it is used to predict the
electric power demanded every hour, with an error percentage below of 1%. This
information allows efficient management of energy peak demands before this
happen, distributing the raise of electric load to other hours or improving
those equipments that increase the demand. The simulation module is based in
advanced estimation techniques, such as: parametric estimation, neural network
modeling, statistic regression and previously developed models, which simulates
the electric behavior of the smelter plant. These modules facilitate
electricity demand and consumption proper planning, because they allow knowing
the behavior of the hourly demand and the consumption patterns of the plant,
including the bill components, but also energy deficiencies and opportunities
for improvement, based on analysis of information about equipments, processes
and production plans, as well as maintenance programs. Finally the results of
its application in Southern Peru smelter are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2651</identifier>
 <datestamp>2010-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2651</id><created>2008-09-16</created><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Putnam</keyname><forenames>Brian</forenames></author><author><keyname>Roy</keyname><forenames>Sasanka</forenames></author></authors><title>Largest Empty Circle Centered on a Query Line</title><categories>cs.CG</categories><comments>18 pages, 13 figures</comments><doi>10.1016/j.jda.2009.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Largest Empty Circle problem seeks the largest circle centered within the
convex hull of a set $P$ of $n$ points in $\mathbb{R}^2$ and devoid of points
from $P$. In this paper, we introduce a query version of this well-studied
problem. In our query version, we are required to preprocess $P$ so that when
given a query line $Q$, we can quickly compute the largest empty circle
centered at some point on $Q$ and within the convex hull of $P$.
  We present solutions for two special cases and the general case; all our
queries run in $O(\log n)$ time. We restrict the query line to be horizontal in
the first special case, which we preprocess in $O(n \alpha(n) \log n)$ time and
space, where $\alpha(n)$ is the slow growing inverse of the Ackermann's
function. When the query line is restricted to pass through a fixed point, the
second special case, our preprocessing takes $O(n \alpha(n)^{O(\alpha(n))} \log
n)$ time and space. We use insights from the two special cases to solve the
general version of the problem with preprocessing time and space in $O(n^3 \log
n)$ and $O(n^3)$ respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.2768</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.2768</id><created>2008-09-16</created><updated>2008-10-15</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Hubs and Clusters in the Evolving U. S. Internal Migration Network</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>38 pages, 16 figures, 2 tables. Additional analyses of the 1995-2000
  migration data and new figures are presented in Secs. V.C and V.D. To examine
  the four (searchable) master dendrograms (the first two [cardinal and
  ordinal] based on the doubly-stochastic table, and the next two, on its
  square), one must download the source</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most nations of the world periodically publish N x N origin-destination
tables, recording the number of people who lived in geographic subdivision i at
time t and j at t+1. We have developed and widely applied to such national
tables and other analogous (weighted, directed) socioeconomic networks, a
two-stage--double-standardization and (strong component) hierarchical
clustering--procedure. Previous applications of this methodology and related
analytical issues are discussed. Its use is illustrated in a large-scale study,
employing recorded United States internal migration flows between the 3,000+
county-level units of the nation for the periods 1965-1970 and 1995-2000.
Prominent, important features--such as ''cosmopolitan hubs'' and ``functional
regions''--are extracted from master dendrograms. The extent to which such
characteristics have varied over the intervening thirty years is evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3170</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3170</id><created>2008-09-18</created><updated>2012-12-04</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A New Framework of Multistage Hypothesis Tests</title><categories>math.ST cs.LG math.PR stat.ME stat.TH</categories><comments>77 pages, no figure; added more references; in Proceedings of SPIE
  Conferences, Orlando, Florida, April 5-10, 2010 and April 25-29, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have established a general framework of multistage
hypothesis tests which applies to arbitrarily many mutually exclusive and
exhaustive composite hypotheses. Within the new framework, we have constructed
specific multistage tests which rigorously control the risk of committing
decision errors and are more efficient than previous tests in terms of average
sample number and the number of sampling operations. Without truncation, the
sample numbers of our testing plans are absolutely bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3204</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3204</id><created>2008-09-18</created><authors><author><keyname>Järvisalo</keyname><forenames>Matti</forenames></author><author><keyname>Oikarinen</keyname><forenames>Emilia</forenames></author></authors><title>Extended ASP tableaux and rule redundancy in normal logic programs</title><categories>cs.AI</categories><comments>27 pages, 5 figures, 1 table</comments><journal-ref>Theory and Practice of Logic Programming, 8(5-6):691-716, 2008</journal-ref><doi>10.1017/S1471068408003578</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an extended tableau calculus for answer set programming (ASP).
The proof system is based on the ASP tableaux defined in [Gebser&amp;Schaub, ICLP
2006], with an added extension rule. We investigate the power of Extended ASP
Tableaux both theoretically and empirically. We study the relationship of
Extended ASP Tableaux with the Extended Resolution proof system defined by
Tseitin for sets of clauses, and separate Extended ASP Tableaux from ASP
Tableaux by giving a polynomial-length proof for a family of normal logic
programs P_n for which ASP Tableaux has exponential-length minimal proofs with
respect to n. Additionally, Extended ASP Tableaux imply interesting insight
into the effect of program simplification on the lengths of proofs in ASP.
Closely related to Extended ASP Tableaux, we empirically investigate the effect
of redundant rules on the efficiency of ASP solving.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3479</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3479</id><created>2008-09-19</created><updated>2008-11-20</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Fermions and Loops on Graphs. I. Loop Calculus for Determinant</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.IT hep-th math.IT</categories><comments>11 pages, 1 figure; misprints corrected</comments><report-no>LA-UR-08-05537</report-no><journal-ref>J.Stat.Mech.0812:P12011,2008</journal-ref><doi>10.1088/1742-5468/2008/12/P12011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is the first in the series devoted to evaluation of the partition
function in statistical models on graphs with loops in terms of the
Berezin/fermion integrals. The paper focuses on a representation of the
determinant of a square matrix in terms of a finite series, where each term
corresponds to a loop on the graph. The representation is based on a fermion
version of the Loop Calculus, previously introduced by the authors for
graphical models with finite alphabets. Our construction contains two levels.
First, we represent the determinant in terms of an integral over anti-commuting
Grassman variables, with some reparametrization/gauge freedom hidden in the
formulation. Second, we show that a special choice of the gauge, called BP
(Bethe-Peierls or Belief Propagation) gauge, yields the desired loop
representation. The set of gauge-fixing BP conditions is equivalent to the
Gaussian BP equations, discussed in the past as efficient (linear scaling)
heuristics for estimating the covariance of a sparse positive matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3481</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3481</id><created>2008-09-19</created><updated>2008-11-20</updated><authors><author><keyname>Chernyak</keyname><forenames>Vladimir Y.</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Fermions and Loops on Graphs. II. Monomer-Dimer Model as Series of
  Determinants</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC cs.IT hep-th math.IT</categories><comments>11 pages, 2 figures; misprints corrected</comments><report-no>LA-UR-08-05678</report-no><journal-ref>J.Stat.Mech.0812:P12012,2008</journal-ref><doi>10.1088/1742-5468/2008/12/P12012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue the discussion of the fermion models on graphs that started in
the first paper of the series. Here we introduce a Graphical Gauge Model (GGM)
and show that : (a) it can be stated as an average/sum of a determinant defined
on the graph over $\mathbb{Z}_{2}$ (binary) gauge field; (b) it is equivalent
to the Monomer-Dimer (MD) model on the graph; (c) the partition function of the
model allows an explicit expression in terms of a series over disjoint directed
cycles, where each term is a product of local contributions along the cycle and
the determinant of a matrix defined on the remainder of the graph (excluding
the cycle). We also establish a relation between the MD model on the graph and
the determinant series, discussed in the first paper, however, considered using
simple non-Belief-Propagation choice of the gauge. We conclude with a
discussion of possible analytic and algorithmic consequences of these results,
as well as related questions and challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3527</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3527</id><created>2008-09-20</created><updated>2012-12-23</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Angela</forenames></author><author><keyname>Andreica</keyname><forenames>Romulus</forenames></author></authors><title>Inferring Company Structure from Limited Available Information</title><categories>cs.DS</categories><comments>Some of the algorithmic techniques presented in this paper were used
  as part of the solutions for some of the tasks proposed in several
  programming contests in which the first author participated (see the related
  materials for several such tasks and their solutions)</comments><proxy>ccsd</proxy><journal-ref>International Symposium on Social Development and Economic
  Performance, Satu Mare : Romania (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present several algorithmic techniques for inferring the
structure of a company when only a limited amount of information is available.
We consider problems with two types of inputs: the number of pairs of employees
with a given property and restricted information about the hierarchical
structure of the company. We provide dynamic programming and greedy algorithms
for these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3528</identifier>
 <datestamp>2013-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3528</id><created>2008-09-20</created><updated>2013-01-30</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Cristina Teodora</forenames></author><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author></authors><title>Locating Restricted Facilities on Binary Maps</title><categories>cs.DS</categories><comments>The algorithmic techniques presented in this paper were used by the
  first author in the implementation of solutions to various algorithmic
  contest tasks (see the attached zip archive for some examples)</comments><proxy>ccsd</proxy><journal-ref>International Symposium on Social Development and Economic
  Performance, Satu Mare : Romania (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider several facility location problems with
applications to cost and social welfare optimization, when the area map is
encoded as a binary (0,1) mxn matrix. We present algorithmic solutions for all
the problems. Some cases are too particular to be used in practical situations,
but they are at least a starting point for more generic solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3546</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3546</id><created>2008-09-20</created><updated>2010-04-27</updated><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Universal Secure Network Coding via Rank-Metric Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>12 pages, 1 figure, substantially rewritten and improved. Submitted
  to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of securing a network coding communication system against an
eavesdropper adversary is considered. The network implements linear network
coding to deliver n packets from source to each receiver, and the adversary can
eavesdrop on \mu arbitrarily chosen links. The objective is to provide reliable
communication to all receivers, while guaranteeing that the source information
remains information-theoretically secure from the adversary. A coding scheme is
proposed that can achieve the maximum possible rate of n-\mu packets. The
scheme, which is based on rank-metric codes, has the distinctive property of
being universal: it can be applied on top of any communication network without
requiring knowledge of or any modifications on the underlying network code. The
only requirement of the scheme is that the packet length be at least n, which
is shown to be strictly necessary for universal communication at the maximum
rate. A further scenario is considered where the adversary is allowed not only
to eavesdrop but also to inject up to t erroneous packets into the network, and
the network may suffer from a rank deficiency of at most \rho. In this case,
the proposed scheme can be extended to achieve the rate of n-\rho-2t-\mu
packets. This rate is shown to be optimal under the assumption of zero-error
communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3565</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3565</id><created>2008-09-21</created><updated>2008-11-23</updated><authors><author><keyname>Vanetik</keyname><forenames>N.</forenames></author></authors><title>On fractionality of the path packing problem</title><categories>cs.DM</categories><comments>18 pages, 5 figures in .eps format, 2 latex files, main file is
  kc13.tex Resubmission due to incorrectly specified CS type of the article; no
  changes to the context have been made</comments><acm-class>G.2.2; F.2.2</acm-class><doi>10.1007/s10878-011-9405-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study fractional multiflows in undirected graphs. A
fractional multiflow in a graph G with a node subset T, called terminals, is a
collection of weighted paths with ends in T such that the total weights of
paths traversing each edge does not exceed 1. Well-known fractional path
packing problem consists of maximizing the total weight of paths with ends in a
subset S of TxT over all fractional multiflows. Together, G,T and S form a
network. A network is an Eulerian network if all nodes in N\T have even
degrees.
  A term "fractionality" was defined for the fractional path packing problem by
A. Karzanov as the smallest natural number D so that there exists a solution to
the problem that becomes integer-valued when multiplied by D. A. Karzanov has
defined the class of Eulerian networks in terms of T and S, outside which D is
infinite and proved that whithin this class D can be 1,2 or 4. He conjectured
that D should be 1 or 2 for this class of networks. In this paper we prove this
conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3577</identifier>
 <datestamp>2010-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3577</id><created>2008-09-21</created><updated>2010-01-13</updated><authors><author><keyname>Mohamed</keyname><forenames>Hanène</forenames></author><author><keyname>Robert</keyname><forenames>Philippe</forenames></author></authors><title>Dynamic tree algorithms</title><categories>math.PR cs.DS</categories><comments>Published in at http://dx.doi.org/10.1214/09-AAP617 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>ccsd inria-00323350</proxy><report-no>IMS-AAP-AAP617</report-no><msc-class>68W40, 60K20 (Primary), 90B15 (Secondary)</msc-class><journal-ref>Annals of Applied Probability 2010, Vol. 20, No. 1, 26-51</journal-ref><doi>10.1214/09-AAP617</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a general tree algorithm processing a random flow of arrivals
is analyzed. Capetanakis--Tsybakov--Mikhailov's protocol in the context of
communication networks with random access is an example of such an algorithm.
In computer science, this corresponds to a trie structure with a dynamic input.
Mathematically, it is related to a stopped branching process with exogeneous
arrivals (immigration). Under quite general assumptions on the distribution of
the number of arrivals and on the branching procedure, it is shown that there
exists a positive constant $\lambda_c$ so that if the arrival rate is smaller
than $\lambda_c$, then the algorithm is stable under the flow of requests, that
is, that the total size of an associated tree is integrable. At the same time,
a gap in the earlier proofs of stability in the literature is fixed. When the
arrivals are Poisson, an explicit characterization of $\lambda_c$ is given.
Under the stability condition, the asymptotic behavior of the average size of a
tree starting with a large number of individuals is analyzed. The results are
obtained with the help of a probabilistic rewriting of the functional equations
describing the dynamics of the system. The proofs use extensively this
stochastic background throughout the paper. In this analysis, two basic limit
theorems play a key role: the renewal theorem and the convergence to
equilibrium of an auto-regressive process with a moving average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3650</identifier>
 <datestamp>2011-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3650</id><created>2008-09-22</created><updated>2009-09-23</updated><authors><author><keyname>Dobigeon</keyname><forenames>Nicolas</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames></author><author><keyname>Tourneret</keyname><forenames>Jean-Yves</forenames></author></authors><title>Hierarchical Bayesian sparse image reconstruction with application to
  MRFM</title><categories>physics.data-an cs.IT math.IT stat.ME</categories><comments>v2: final version; IEEE Trans. Image Processing, 2009</comments><journal-ref>IEEE Trans. Image Processing, vol. 18, no. 9, pp. 2059-2070, Sept.
  2009</journal-ref><doi>10.1109/TIP.2009.2024067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a hierarchical Bayesian model to reconstruct sparse
images when the observations are obtained from linear transformations and
corrupted by an additive white Gaussian noise. Our hierarchical Bayes model is
well suited to such naturally sparse image applications as it seamlessly
accounts for properties such as sparsity and positivity of the image via
appropriate Bayes priors. We propose a prior that is based on a weighted
mixture of a positive exponential distribution and a mass at zero. The prior
has hyperparameters that are tuned automatically by marginalization over the
hierarchical Bayesian model. To overcome the complexity of the posterior
distribution, a Gibbs sampling strategy is proposed. The Gibbs samples can be
used to estimate the image to be recovered, e.g. by maximizing the estimated
posterior distribution. In our fully Bayesian approach the posteriors of all
the parameters are available. Thus our algorithm provides more information than
other previously proposed sparse reconstruction methods that only give a point
estimate. The performance of our hierarchical Bayesian sparse reconstruction
method is illustrated on synthetic and real data collected from a tobacco virus
sample using a prototype MRFM instrument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.3994</identifier>
 <datestamp>2010-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.3994</id><created>2008-09-23</created><updated>2010-01-23</updated><authors><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>Regularities of the distribution of abstract van der Corput sequences</title><categories>math.NT cs.DM</categories><proxy>ccsd hal-00323846</proxy><msc-class>11K38, 11K31, 11K16, 37B10, 68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarly to $\beta$-adic van der Corput sequences, abstract van der Corput
sequences can be defined for abstract numeration systems. Under some
assumptions, these sequences are low discrepancy sequences. The discrepancy
function is computed explicitely, and a characterization of bounded remainder
sets of the form $[0,y)$ is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4019</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4019</id><created>2008-09-23</created><updated>2010-02-22</updated><authors><author><keyname>Cui</keyname><forenames>Shengshan</forenames><affiliation>Shitz</affiliation></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Somekh</keyname><forenames>Oren</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Throughput Scaling of Wireless Networks With Random Connections</title><categories>cs.IT math.IT</categories><comments>13 pages, 4 figures, To appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies the throughput scaling laws of ad hoc wireless networks in
the limit of a large number of nodes. A random connections model is assumed in
which the channel connections between the nodes are drawn independently from a
common distribution. Transmitting nodes are subject to an on-off strategy, and
receiving nodes employ conventional single-user decoding. The following results
are proven:
  1) For a class of connection models with finite mean and variance, the
throughput scaling is upper-bounded by $O(n^{1/3})$ for single-hop schemes, and
$O(n^{1/2})$ for two-hop (and multihop) schemes.
  2) The $\Theta (n^{1/2})$ throughput scaling is achievable for a specific
connection model by a two-hop opportunistic relaying scheme, which employs
full, but only local channel state information (CSI) at the receivers, and
partial CSI at the transmitters.
  3) By relaxing the constraints of finite mean and variance of the connection
model, linear throughput scaling $\Theta (n)$ is achievable with Pareto-type
fading models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4086</identifier>
 <datestamp>2011-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4086</id><created>2008-09-24</created><updated>2011-01-07</updated><authors><author><keyname>Cybenko</keyname><forenames>George</forenames></author><author><keyname>Crespi</keyname><forenames>Valentino</forenames></author></authors><title>Learning Hidden Markov Models using Non-Negative Matrix Factorization</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory in September
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Baum-Welsh algorithm together with its derivatives and variations has
been the main technique for learning Hidden Markov Models (HMM) from
observational data. We present an HMM learning algorithm based on the
non-negative matrix factorization (NMF) of higher order Markovian statistics
that is structurally different from the Baum-Welsh and its associated
approaches. The described algorithm supports estimation of the number of
recurrent states of an HMM and iterates the non-negative matrix factorization
(NMF) algorithm to improve the learned HMM parameters. Numerical examples are
provided as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4093</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4093</id><created>2008-09-24</created><updated>2011-07-27</updated><authors><author><keyname>Vega-Paez</keyname><forenames>Ignacio</forenames></author><author><keyname>Ortega</keyname><forenames>Jose Angel</forenames></author><author><keyname>Pulido</keyname><forenames>Georgina G.</forenames></author></authors><title>Perspective Drawing of Surfaces with Line Hidden Line Elimination,
  Dibujando Superficies En Perspectiva Con Eliminacion De Lineas Ocultas</title><categories>cs.GR cs.CG</categories><report-no>IBP-TR2008-08</report-no><journal-ref>Proceedings in Technical Memory, XI Congreso Nacional de
  Ingenieria Electromecanica y de Sistemas, pp. 136-144, Mexico, DF., Nov 2009</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An efficient computer algorithm is described for the perspective drawing of a
wide class of surfaces. The class includes surfaces corresponding lo
single-valued, continuous functions which are defined over rectangular domains.
The algorithm automatically computes and eliminates hidden lines. The number of
computations in the algorithm grows linearly with the number of sample points
on the surface to be drawn. An analysis of the algorithm is presented, and
extensions lo certain multi-valued functions are indicated. The algorithm is
implemented and tested on .Net 2.0 platform that left interactive use. Running
times are found lo be exceedingly efficient for visualization, where
interaction on-line and view-point control, enables effective and rapid
examination of a surfaces from many perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4107</identifier>
 <datestamp>2010-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4107</id><created>2008-09-24</created><authors><author><keyname>Laprie</keyname><forenames>Jean-Claude</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kanoun</keyname><forenames>Karama</forenames><affiliation>LAAS</affiliation></author><author><keyname>Kaaniche</keyname><forenames>Mohamed</forenames><affiliation>LAAS</affiliation></author></authors><title>Modelling interdependencies between the electricity and information
  infrastructures</title><categories>cs.DC</categories><proxy>ccsd hal-00323999</proxy><journal-ref>26th International Conference on Computer Safety, Reliability and
  Security, SAFECOMP-2007, Nurenberg : Allemagne (2007)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to provide qualitative models characterizing
interdependencies related failures of two critical infrastructures: the
electricity infrastructure and the associated information infrastructure. The
interdependencies of these two infrastructures are increasing due to a growing
connection of the power grid networks to the global information infrastructure,
as a consequence of market deregulation and opening. These interdependencies
increase the risk of failures. We focus on cascading, escalating and
common-cause failures, which correspond to the main causes of failures due to
interdependencies. We address failures in the electricity infrastructure, in
combination with accidental failures in the information infrastructure, then we
show briefly how malicious attacks in the information infrastructure can be
addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4296</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4296</id><created>2008-09-24</created><authors><author><keyname>Rutishauser</keyname><forenames>Ueli</forenames></author><author><keyname>Douglas</keyname><forenames>Rodney J.</forenames></author></authors><title>State dependent computation using coupled recurrent networks</title><categories>q-bio.NC cs.NE</categories><comments>32 pages, 10 figures. Neural computation (in press)</comments><journal-ref>Neural computation, 21(2):478-509, 2009</journal-ref><doi>10.1162/neco.2008.03-08-734</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although conditional branching between possible behavioural states is a
hallmark of intelligent behavior, very little is known about the neuronal
mechanisms that support this processing. In a step toward solving this problem
we demonstrate by theoretical analysis and simulation how networks of richly
inter-connected neurons, such as those observed in the superficial layers of
the neocortex, can embed reliable robust finite state machines. We show how a
multi-stable neuronal network containing a number of states can be created very
simply, by coupling two recurrent networks whose synaptic weights have been
configured for soft winner-take-all (sWTA) performance. These two sWTAs have
simple, homogenous locally recurrent connectivity except for a small fraction
of recurrent cross-connections between them, which are used to embed the
required states. This coupling between the maps allows the network to continue
to express the current state even after the input that elicted that state is
withdrawn. In addition, a small number of 'transition neurons' implement the
necessary input-driven transitions between the embedded states. We provide
simple rules to systematically design and construct neuronal state machines of
this kind. The significance of our finding is that it offers a method whereby
the cortex could construct networks supporting a broad range of sophisticated
processing by applying only small specializations to the same generic neuronal
circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4317</identifier>
 <datestamp>2012-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4317</id><created>2008-09-24</created><updated>2010-12-23</updated><authors><author><keyname>Choi</keyname><forenames>Byung-Soo</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>On the Effect of Quantum Interaction Distance on Quantum Addition
  Circuits</title><categories>quant-ph cs.AR</categories><comments>accepted for ACM Journal on Emerging Technologies in Computing
  Systems</comments><acm-class>C.1.m; B.2.0; B.m</acm-class><doi>10.1145/2000502.2000504</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the theoretical limits of the effect of the quantum
interaction distance on the speed of exact quantum addition circuits. For this
study, we exploit graph embedding for quantum circuit analysis. We study a
logical mapping of qubits and gates of any $\Omega(\log n)$-depth quantum adder
circuit for two $n$-qubit registers onto a practical architecture, which limits
interaction distance to the nearest neighbors only and supports only one- and
two-qubit logical gates. Unfortunately, on the chosen $k$-dimensional practical
architecture, we prove that the depth lower bound of any exact quantum addition
circuits is no longer $\Omega(\log {n})$, but $\Omega(\sqrt[k]{n})$. This
result, the first application of graph embedding to quantum circuits and
devices, provides a new tool for compiler development, emphasizes the impact of
quantum computer architecture on performance, and acts as a cautionary note
when evaluating the time performance of quantum algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4747</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4747</id><created>2008-09-27</created><updated>2012-01-28</updated><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On parsimonious edge-colouring of graphs with maximum degree three</title><categories>cs.DM</categories><comments>Revised version submitted to Graphs and Combinatorics</comments><proxy>ccsd</proxy><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a graph $G$ of maximum degree $\Delta$ let $\gamma$ denote the largest
fraction of edges that can be $\Delta$ edge-coloured. Albertson and Haas showed
that $\gamma \geq 13/15$ when $G$ is cubic . We show here that this result can
be extended to graphs with maximum degree 3 with the exception of a graph on 5
vertices. Moreover, there are exactly two graphs with maximum degree 3 (one
being obviously the Petersen graph) for which $\gamma = 13/15$. This extends a
result given by Steffen. These results are obtained by using structural
properties of the so called $\delta$-minimum edge colourings for graphs with
maximum degree 3. Keywords : Cubic graph; Edge-colouring
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.4839</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.4839</id><created>2008-09-28</created><updated>2009-11-07</updated><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>M\'acajov\'a and \v{S}koviera Conjecture on Cubic Graphs</title><categories>cs.DM</categories><proxy>ccsd hal-00325255</proxy><journal-ref>Discussionnes Mathematicae on Graph Theory 30, 2 (2010) xxx-yyy</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A conjecture of M\'a\u{c}ajov\'a and \u{S}koviera asserts that every
bridgeless cubic graph has two perfect matchings whose intersection does not
contain any odd edge cut. We prove this conjecture for graphs with few vertices
and we give a stronger result for traceable graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5145</identifier>
 <datestamp>2010-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5145</id><created>2008-09-30</created><authors><author><keyname>Nasser</keyname><forenames>Youssef</forenames><affiliation>IETR</affiliation></author><author><keyname>Hélard</keyname><forenames>Jean-François</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussière</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>3D MIMO Scheme for Broadcasting Future Digital TV in Single Frequency
  Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00325605</proxy><journal-ref>Electronics Letters / IEE Electronics Letters 44, 13 (2008)
  829-830</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter introduces a 3D space-time-space block code for future digital TV
systems. The code is based on a double layer structure for inter-cell and
intra-cell transmission mode in single frequency networks. Without increasing
the complexity of the receiver, the proposed code is very efficient for
different transmission scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5191</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5191</id><created>2008-09-30</created><authors><author><keyname>Muhammad</keyname><forenames>Fahad Syed</forenames><affiliation>IETR</affiliation></author><author><keyname>Baudais</keyname><forenames>Jean-Yves</forenames><affiliation>IETR</affiliation></author><author><keyname>Hélard</keyname><forenames>Jean-François</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussière</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>A Coded Bit-Loading Linear Precoded Discrete Multitone Solution for
  Power Line Communication</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00325790</proxy><journal-ref>International Workshop on Signal Processing Advances in Wireless
  Communications, Recife, Pernambuco : Brazil (2008)</journal-ref><doi>10.1109/SPAWC.2008.4641669</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear precoded discrete multitone modulation (LP-DMT) system has been
already proved advantageous with adaptive resource allocation algorithm in a
power line communication (PLC) context. In this paper, we investigate the bit
and energy allocation algorithm of an adaptive LP-DMT system taking into
account the channel coding scheme. A coded adaptive LP-DMT system is presented
in the PLC context with a loading algorithm which ccommodates the channel
coding gains in bit and energy calculations. The performance of a concatenated
channel coding scheme, consisting of an inner Wei's 4-dimensional 16-states
trellis code and an outer Reed-Solomon code, in combination with the roposed
algorithm is analyzed. Simulation results are presented for a fixed target bit
error rate in a multicarrier scenario under power spectral density constraint.
Using a multipath model of PLC channel, it is shown that the proposed coded
adaptive LP-DMT system performs better than classical coded discrete multitone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0809.5275</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0809.5275</id><created>2008-09-30</created><authors><author><keyname>Muhammad</keyname><forenames>Fahad Syed</forenames><affiliation>IETR</affiliation></author><author><keyname>Baudais</keyname><forenames>Jean-Yves</forenames><affiliation>IETR</affiliation></author><author><keyname>Hélard</keyname><forenames>Jean-François</forenames><affiliation>IETR</affiliation></author><author><keyname>Crussière</keyname><forenames>Matthieu</forenames><affiliation>IETR</affiliation></author></authors><title>Coded Adaptive Linear Precoded Discrete Multitone Over PLC Channel</title><categories>cs.IT math.IT</categories><proxy>ccsd hal-00325789</proxy><journal-ref>International Symposium on Power-Line Communications and Its
  Applications, Jeju Island : Cor\'ee, R\'epublique de (2008)</journal-ref><doi>10.1109/ISPLC.2008.4510410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete multitone modulation (DMT) systems exploit the capabilities of
orthogonal subcarriers to cope efficiently with narrowband interference, high
frequency attenuations and multipath fadings with the help of simple
equalization filters. Adaptive linear precoded discrete multitone (LP-DMT)
system is based on classical DMT, combined with a linear precoding component.
In this paper, we investigate the bit and energy allocation algorithm of an
adaptive LP-DMT system taking into account the channel coding scheme. A coded
adaptive LPDMT system is presented in the power line communication (PLC)
context with a loading algorithm which accommodates the channel coding gains in
bit and energy calculations. The performance of a concatenated channel coding
scheme, consisting of an inner Wei's 4-dimensional 16-states trellis code and
an outer Reed-Solomon code, in combination with the proposed algorithm is
analyzed. Theoretical coding gains are derived and simulation results are
presented for a fixed target bit error rate in a multicarrier scenario under
power spectral density constraint. Using a multipath model of PLC channel, it
is shown that the proposed coded adaptive LP-DMT system performs better than
coded DMT and can achieve higher throughput for PLC applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0328</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0328</id><created>2008-10-01</created><updated>2011-12-26</updated><authors><author><keyname>Chan</keyname><forenames>Aldar C-F.</forenames></author></authors><title>Efficient Defence against Misbehaving TCP Receiver DoS Attacks</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The congestion control algorithm of TCP relies on correct feedback from the
receiver to determine the rate at which packets should be sent into the
network. Hence, correct receiver feedback (in the form of TCP acknowledgements)
is essential to the goal of sharing the scarce bandwidth resources fairly and
avoiding congestion collapse in the Internet. However, the assumption that a
TCP receiver can always be trusted (to generate feedback correctly) no longer
holds as there are plenty of incentives for a receiver to deviate from the
protocol. In fact, it has been shown that a misbehaving receiver (whose aim is
to bring about congestion collapse) can easily generate acknowledgements to
conceal packet loss, so as to drive a number of honest, innocent senders
arbitrarily fast to create a significant number of non-responsive packet flows,
leading to denial of service to other Internet users. We give the first formal
treatment to this problem. We also give an efficient, provably secure mechanism
to force a receiver to generate feedback correctly; any incorrect
acknowledgement will be detected at the sender and cheating TCP receivers would
be identified. The idea is as follows: for each packet sent, the sender
generates a tag using a secret key (known to himself only); the receiver could
generate a proof using the packet and the tag alone, and send it to the sender;
the sender can then verify the proof using the secret key; an incorrect proof
would indicate a cheating receiver. The scheme is very efficient in the sense
that the TCP sender does not need to store the packet or the tag, and the
proofs for multiple packets can be aggregated at the receiver. The scheme is
based on an aggregate authenticator. In addition, the proposed solution can be
applied to network-layer rate-limiting architectures requiring correct
feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0870</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0870</id><created>2008-10-05</created><updated>2009-05-19</updated><authors><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Lee</keyname><forenames>Chung-Pi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Cognitive Radio with Partial Channel State Information at the
  Transmitter</title><categories>cs.IT math.IT</categories><comments>resubmitted to IEEE Transaction on Wireless Communications, May 2009</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 9, no. 11, pp.
  3402-3413, Nov. 2010</journal-ref><doi>10.1109/TWC.2010.092410.090725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the cognitive radio system design with partial
channel state information known at the transmitter (CSIT).We replace the dirty
paper coding (DPC) used in the cognitive radio with full CSIT by the linear
assignment Gel'fand-Pinsker coding (LA-GPC), which can utilize the limited
knowledge of the channel more efficiently. Based on the achievable rate derived
from the LA-GPC, two optimization problems under the fast and slow fading
channels are formulated. We derive semianalytical solutions to find the
relaying ratios and precoding coefficients. The critical observation is that
the complex rate functions in these problems are closely related to ratios of
quadratic form. Simulation results show that the proposed semi-analytical
solutions perform close to the optimal solutions found by brute-force search,
and outperform the systems based on naive DPC. Asymptotic analysis also shows
that these solutions converge to the optimal ones solved with full CSIT when
the K-factor of Rician channel approaches infinity. Moreover, a new coding
scheme is proposed to implement the LA-GPC in practice. Simulation results show
that the proposed practical coding scheme can efficiently reach the theoretical
rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.0906</identifier>
 <datestamp>2010-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.0906</id><created>2008-10-06</created><updated>2010-11-24</updated><authors><author><keyname>Hasunuma</keyname><forenames>Toru</forenames></author><author><keyname>Ishii</keyname><forenames>Toshimasa</forenames></author><author><keyname>Ono</keyname><forenames>Hirotaka</forenames></author><author><keyname>Uno</keyname><forenames>Yushi</forenames></author></authors><title>A linear time algorithm for L(2,1)-labeling of trees</title><categories>cs.DS</categories><comments>23 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An L(2,1)-labeling of a graph $G$ is an assignment $f$ from the vertex set
$V(G)$ to the set of nonnegative integers such that $|f(x)-f(y)|\ge 2$ if $x$
and $y$ are adjacent and $|f(x)-f(y)|\ge 1$ if $x$ and $y$ are at distance 2,
for all $x$ and $y$ in $V(G)$. A $k$-L(2,1)-labeling is an assignment
$f:V(G)\to\{0,..., k\}$, and the L(2,1)-labeling problem asks the minimum $k$,
which we denote by $\lambda(G)$, among all possible assignments. It is known
that this problem is NP-hard even for graphs of treewidth 2, and tree is one of
a very few classes for which the problem is polynomially solvable. The running
time of the best known algorithm for trees had been $\mO(\Delta^{4.5} n)$ for
more than a decade, however, an $\mO(n^{1.75})$-time algorithm has been
proposed recently, which substantially improved the previous one, where
$\Delta$ is the maximum degree of $T$ and $n=|V(T)|$. In this paper, we finally
establish a linear time algorithm for L(2,1)-labeling of trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1106</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1106</id><created>2008-10-07</created><updated>2009-01-13</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>On the expressiveness of single-pass instruction sequences</title><categories>cs.PL</categories><comments>14 pages; error corrected, acknowledgement added; another error
  corrected, another acknowledgement added</comments><report-no>PRG0813</report-no><acm-class>D.1.4; D.3.3; F.1.1; F.3.3</acm-class><journal-ref>Theory of Computing Systems, 50(2):313--328, 2012</journal-ref><doi>10.1007/s00224-010-9301-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perceive programs as single-pass instruction sequences. A single-pass
instruction sequence under execution is considered to produce a behaviour to be
controlled by some execution environment. Threads as considered in basic thread
algebra model such behaviours. We show that all regular threads, i.e. threads
that can only be in a finite number of states, can be produced by single-pass
instruction sequences without jump instructions if use can be made of Boolean
registers. We also show that, in the case where goto instructions are used
instead of jump instructions, a bound to the number of labels restricts the
expressiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1151</identifier>
 <datestamp>2013-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1151</id><created>2008-10-07</created><updated>2013-04-16</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Ponse</keyname><forenames>Alban</forenames></author></authors><title>Periodic Single-Pass Instruction Sequences</title><categories>cs.PL</categories><comments>16 pages, 3 tables, New title</comments><acm-class>D.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A program is a finite piece of data that produces a (possibly infinite)
sequence of primitive instructions. From scratch we develop a linear notation
for sequential, imperative programs, using a familiar class of primitive
instructions and so-called repeat instructions, a particular type of control
instructions. The resulting mathematical structure is a semigroup. We relate
this set of programs to program algebra (PGA) and show that a particular
subsemigroup is a carrier for PGA by providing axioms for single-pass
congruence, structural congruence, and thread extraction. This subsemigroup
characterizes periodic single-pass instruction sequences and provides a direct
basis for PGA's toolset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1268</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1268</id><created>2008-10-07</created><updated>2010-09-09</updated><authors><author><keyname>Kim</keyname><forenames>Sang Joon</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Tarokh</keyname><forenames>Vahid</forenames></author></authors><title>Bi-directional half-duplex protocols with multiple relays</title><categories>cs.IT math.IT</categories><comments>44 pages, 17 figures, Submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a bi-directional relay channel, two nodes wish to exchange independent
messages over a shared wireless half-duplex channel with the help of relays.
Recent work has considered information theoretic limits of the bi-directional
relay channel with a single relay. In this work we consider bi-directional
relaying with multiple relays. We derive achievable rate regions and outer
bounds for half-duplex protocols with multiple decode and forward relays and
compare these to the same protocols with amplify and forward relays in an
additive white Gaussian noise channel. We consider three novel classes of
half-duplex protocols: the (m,2) 2 phase protocol with m relays, the (m,3) 3
phase protocol with m relays, and general (m, t) Multiple Hops and Multiple
Relays (MHMR) protocols, where m is the total number of relays and 3&lt;t&lt; m+3 is
the number of temporal phases in the protocol. The (m,2) and (m,3) protocols
extend previous bi-directional relaying protocols for a single m=1 relay, while
the new (m,t) protocol efficiently combines multi-hop routing with
message-level network coding. Finally, we provide a comprehensive treatment of
the MHMR protocols with decode and forward relaying and amplify and forward
relaying in the Gaussian noise, obtaining their respective achievable rate
regions, outer bounds and relative performance under different SNRs and relay
geometries, including an analytical comparison on the protocols at low and high
SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1571</identifier>
 <datestamp>2010-03-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1571</id><created>2008-10-09</created><authors><author><keyname>Bakhshi</keyname><forenames>Rena</forenames></author><author><keyname>Gavidia</keyname><forenames>Daniela</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>van Steen</keyname><forenames>Maarten</forenames></author></authors><title>An Analytical Model of Information Dissemination for a Gossip-based
  Protocol</title><categories>cs.DC cs.DM cs.IT cs.PF math.IT</categories><comments>20 pages, 8 figures, technical report</comments><doi>10.1016/j.comnet.2009.03.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an analytical model of information dissemination for a gossiping
protocol that combines both pull and push approaches. With this model we
analyse how fast an item is replicated through a network, and how fast the item
spreads in the network, and how fast the item covers the network. We also
determine the optimal size of the exchange buffer, to obtain fast replication.
Our results are confirmed by large-scale simulation experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1756</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1756</id><created>2008-10-09</created><updated>2012-02-13</updated><authors><author><keyname>Bradonjic</keyname><forenames>Milan</forenames></author><author><keyname>Kohler</keyname><forenames>Eddie</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author></authors><title>Near-Optimal Radio Use For Wireless Network Synchronization</title><categories>cs.DS cs.DM</categories><comments>23 pages</comments><doi>10.1016/j.tcs.2011.09.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the model of communication where wireless devices can either
switch their radios off to save energy, or switch their radios on and engage in
communication. We distill a clean theoretical formulation of this problem of
minimizing radio use and present near-optimal solutions. Our base model ignores
issues of communication interference, although we also extend the model to
handle this requirement. We assume that nodes intend to communicate
periodically, or according to some time-based schedule. Clearly, perfectly
synchronized devices could switch their radios on for exactly the minimum
periods required by their joint schedules. The main challenge in the deployment
of wireless networks is to synchronize the devices' schedules, given that their
initial schedules may be offset relative to one another (even if their clocks
run at the same speed). We significantly improve previous results, and show
optimal use of the radio for two processors and near-optimal use of the radio
for synchronization of an arbitrary number of processors. In particular, for
two processors we prove deterministically matching $\Theta(\sqrt{n})$ upper and
lower bounds on the number of times the radio has to be on, where $n$ is the
discretized uncertainty period of the clock shift between the two processors.
(In contrast, all previous results for two processors are randomized.) For
$m=n^\beta$ processors (for any $\beta &lt; 1$) we prove $\Omega(n^{(1-\beta)/2})$
is the lower bound on the number of times the radio has to be switched on (per
processor), and show a nearly matching (in terms of the radio use)
$\~{O}(n^{(1-\beta)/2})$ randomized upper bound per processor, with failure
probability exponentially close to 0. For $\beta \geq 1$ our algorithm runs
with at most $poly-log(n)$ radio invocations per processor. Our bounds also
hold in a radio-broadcast model where interference must be taken into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.1823</identifier>
 <datestamp>2011-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.1823</id><created>2008-10-10</created><updated>2011-04-18</updated><authors><author><keyname>Gioan</keyname><forenames>Emeric</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author></authors><title>Split decomposition and graph-labelled trees: characterizations and
  fully-dynamic algorithms for totally decomposable graphs</title><categories>cs.DM cs.DS</categories><comments>extended abstract appeared in ISAAC 2007: Dynamic distance hereditary
  graphs using split decompositon. In International Symposium on Algorithms and
  Computation - ISAAC. Number 4835 in Lecture Notes, pages 41-51, 2007</comments><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we revisit the split decomposition of graphs and give new
combinatorial and algorithmic results for the class of totally decomposable
graphs, also known as the distance hereditary graphs, and for two non-trivial
subclasses, namely the cographs and the 3-leaf power graphs. Precisely, we give
strutural and incremental characterizations, leading to optimal fully-dynamic
recognition algorithms for vertex and edge modifications, for each of these
classes. These results rely on a new framework to represent the split
decomposition, namely the graph-labelled trees, which also captures the modular
decomposition of graphs and thereby unify these two decompositions techniques.
The point of the paper is to use bijections between these graph classes and
trees whose nodes are labelled by cliques and stars. Doing so, we are also able
to derive an intersection model for distance hereditary graphs, which answers
an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2046</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2046</id><created>2008-10-11</created><authors><author><keyname>Owladeghaffari</keyname><forenames>Hamed</forenames></author><author><keyname>Pedrycz</keyname><forenames>Witold</forenames></author><author><keyname>Sharifzadeh</keyname><forenames>Mostafa</forenames></author></authors><title>Modeling of Social Transitions Using Intelligent Systems</title><categories>cs.AI</categories><doi>10.1109/CANS.2008.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we reproduce two new hybrid intelligent systems, involve three
prominent intelligent computing and approximate reasoning methods: Self
Organizing feature Map (SOM), Neruo-Fuzzy Inference System and Rough Set Theory
(RST),called SONFIS and SORST. We show how our algorithms can be construed as a
linkage of government-society interactions, where government catches various
states of behaviors: solid (absolute) or flexible. So, transition of society,
by changing of connectivity parameters (noise) from order to disorder is
inferred.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2150</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2150</id><created>2008-10-13</created><updated>2012-04-30</updated><authors><author><keyname>Task</keyname><forenames>Christine</forenames></author><author><keyname>Chauhan</keyname><forenames>Arun</forenames></author></authors><title>A Model for Communication in Clusters of Multi-core Machines</title><categories>cs.DC cs.DS</categories><comments>This paper has been withdrawn by the author because it was basically
  a short-hand write-up of an incompletely formed idea from her Masters, and
  she'd like to start using her ArXiv account for her formal PhD research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common paradigm for scientific computing is distributed message-passing
systems, and a common approach to these systems is to implement them across
clusters of high-performance workstations. As multi-core architectures become
increasingly mainstream, these clusters are very likely to include multi-core
machines. However, the theoretical models which are currently used to develop
communication algorithms across these systems do not take into account the
unique properties of processes running on shared-memory architectures,
including shared external network connections and communication via shared
memory locations. Because of this, existing algorithms are far from optimal for
modern clusters. Additionally, recent attempts to adapt these algorithms to
multicore systems have proceeded without the introduction of a more accurate
formal model and have generally neglected to capitalize on the full power these
systems offer. We propose a new model which simply and effectively captures the
strengths of multi-core machines in collective communications patterns and
suggest how it could be used to properly optimize these patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2279</identifier>
 <datestamp>2010-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2279</id><created>2008-10-13</created><updated>2010-03-05</updated><authors><author><keyname>Shtrakov</keyname><forenames>Slavcho</forenames></author><author><keyname>Koppitz</keyname><forenames>Joerg</forenames></author></authors><title>On finite functions with non-trivial arity gap</title><categories>cs.DM cs.CC</categories><comments>17 pages, Int. Conf. Algebraic and Combinatorial Coding Theory,
  ACCT2008, June 16 - Sunday 22, 2008, Pamporovo, BULGARIA</comments><acm-class>G.2.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Given an $n$-ary
  $k-$valued function $f$, $gap(f)$ denotes the minimal number of essential
variables in $f$ which become fictive when identifying any two distinct
essential variables in $f$.
  We particularly solve a problem concerning the explicit determination of
$n$-ary
  $k-$valued functions $f$ with $2\leq gap(f)\leq n\leq k$. Our methods yield
new combinatorial results about the number of such functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2336</identifier>
 <datestamp>2010-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2336</id><created>2008-10-13</created><updated>2010-07-30</updated><authors><author><keyname>Vance</keyname><forenames>Stephanie</forenames></author></authors><title>A Mordell Inequality for Lattices over Maximal Orders</title><categories>math.MG cs.IT math.IT math.NT</categories><comments>13 pages</comments><journal-ref>Trans. Amer. Math. Soc. 362 (2010), no. 7, 3827-3839</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we prove an analogue of Mordell's inequality for lattices in
finite-dimensional complex or quaternionic Hermitian space that are modules
over a maximal order in an imaginary quadratic number field or a totally
definite rational quaternion algebra. This inequality implies that the
16-dimensional Barnes-Wall lattice has optimal density among all 16-dimensional
lattices with Hurwitz structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2434</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2434</id><created>2008-10-14</created><authors><author><keyname>Rosten</keyname><forenames>Edward</forenames></author><author><keyname>Porter</keyname><forenames>Reid</forenames></author><author><keyname>Drummond</keyname><forenames>Tom</forenames></author></authors><title>Faster and better: a machine learning approach to corner detection</title><categories>cs.CV cs.LG</categories><comments>35 pages, 11 figures</comments><report-no>07-3912</report-no><journal-ref>IEEE Trans. PAMI, 32 (2010), 105--119</journal-ref><doi>10.1109/TPAMI.2008.275</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The repeatability and efficiency of a corner detector determines how likely
it is to be useful in a real-world application. The repeatability is importand
because the same scene viewed from different positions should yield features
which correspond to the same real-world 3D locations [Schmid et al 2000]. The
efficiency is important because this determines whether the detector combined
with further processing can operate at frame rate.
  Three advances are described in this paper. First, we present a new heuristic
for feature detection, and using machine learning we derive a feature detector
from this which can fully process live PAL video using less than 5% of the
available processing time. By comparison, most other detectors cannot even
operate at frame rate (Harris detector 115%, SIFT 195%). Second, we generalize
the detector, allowing it to be optimized for repeatability, with little loss
of efficiency. Third, we carry out a rigorous comparison of corner detectors
based on the above repeatability criterion applied to 3D scenes. We show that
despite being principally constructed for speed, on these stringent tests, our
heuristic detector significantly outperforms existing feature detectors.
Finally, the comparison demonstrates that using machine learning produces
significant improvements in repeatability, yielding a detector that is both
very fast and very high quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2513</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2513</id><created>2008-10-14</created><updated>2011-06-21</updated><authors><author><keyname>Sarwate</keyname><forenames>Anand D.</forenames></author><author><keyname>Dimakis</keyname><forenames>Alexandros G.</forenames></author></authors><title>The Impact of Mobility on Gossip Algorithms</title><categories>cs.NI cs.DC cs.IT math.IT</categories><comments>Revised version submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The influence of node mobility on the convergence time of averaging gossip
algorithms in networks is studied. It is shown that a small number of fully
mobile nodes can yield a significant decrease in convergence time. A method is
developed for deriving lower bounds on the convergence time by merging nodes
according to their mobility pattern. This method is used to show that if the
agents have one-dimensional mobility in the same direction the convergence time
is improved by at most a constant. Upper bounds are obtained on the convergence
time using techniques from the theory of Markov chains and show that simple
models of mobility can dramatically accelerate gossip as long as the mobility
paths significantly overlap. Simulations verify that different mobility
patterns can have significantly different effects on the convergence of
distributed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.2717</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.2717</id><created>2008-10-15</created><updated>2011-01-18</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>A Class of Graph-Geodetic Distances Generalizing the Shortest-Path and
  the Resistance Distances</title><categories>math.CO cs.DM math.MG</categories><comments>14 pages. Discrete Applied Mathematics</comments><msc-class>05C12, 05C50, 05C05, 15A48</msc-class><journal-ref>Discrete Applied Mathematics 159(2011) No. 5. 295-302</journal-ref><doi>10.1016/j.dam.2010.11.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of distances for graph vertices is proposed. This class contains
parametric families of distances which reduce to the shortest-path, weighted
shortest-path, and the resistance distances at the limiting values of the
family parameters. The main property of the class is that all distances it
comprises are graph-geodetic: $d(i,j)+d(j,k)=d(i,k)$ if and only if every path
from $i$ to $k$ passes through $j$. The construction of the class is based on
the matrix forest theorem and the transition inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3125</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3125</id><created>2008-10-17</created><updated>2011-02-07</updated><authors><author><keyname>D\kebowski</keyname><forenames>\Lukasz</forenames></author></authors><title>On the Vocabulary of Grammar-Based Codes and the Logical Consistency of
  Texts</title><categories>cs.IT cs.CL math.IT</categories><comments>24 pages, no figures</comments><msc-class>94A29, 60G10, 94A17</msc-class><acm-class>E.4; G.3; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article presents a new interpretation for Zipf-Mandelbrot's law in
natural language which rests on two areas of information theory. Firstly, we
construct a new class of grammar-based codes and, secondly, we investigate
properties of strongly nonergodic stationary processes. The motivation for the
joint discussion is to prove a proposition with a simple informal statement: If
a text of length $n$ describes $n^\beta$ independent facts in a repetitive way
then the text contains at least $n^\beta/\log n$ different words, under
suitable conditions on $n$. In the formal statement, two modeling postulates
are adopted. Firstly, the words are understood as nonterminal symbols of the
shortest grammar-based encoding of the text. Secondly, the text is assumed to
be emitted by a finite-energy strongly nonergodic source whereas the facts are
binary IID variables predictable in a shift-invariant way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3136</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3136</id><created>2008-10-17</created><updated>2010-09-06</updated><authors><author><keyname>Greco</keyname><forenames>Gianluigi</forenames></author><author><keyname>Malizia</keyname><forenames>Enrico</forenames></author><author><keyname>Palopoli</keyname><forenames>Luigi</forenames></author><author><keyname>Scarcello</keyname><forenames>Francesco</forenames></author></authors><title>On the Complexity of Core, Kernel, and Bargaining Set</title><categories>cs.GT cs.AI cs.CC</categories><comments>30 pages, 6 figures</comments><acm-class>F.2; J.4</acm-class><journal-ref>Artif. Intell. 175(12-13): 1877-1910 (2011)</journal-ref><doi>10.1016/j.artint.2011.06.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalitional games are mathematical models suited to analyze scenarios where
players can collaborate by forming coalitions in order to obtain higher worths
than by acting in isolation. A fundamental problem for coalitional games is to
single out the most desirable outcomes in terms of appropriate notions of worth
distributions, which are usually called solution concepts. Motivated by the
fact that decisions taken by realistic players cannot involve unbounded
resources, recent computer science literature reconsidered the definition of
such concepts by advocating the relevance of assessing the amount of resources
needed for their computation in terms of their computational complexity. By
following this avenue of research, the paper provides a complete picture of the
complexity issues arising with three prominent solution concepts for
coalitional games with transferable utility, namely, the core, the kernel, and
the bargaining set, whenever the game worth-function is represented in some
reasonable compact form (otherwise, if the worths of all coalitions are
explicitly listed, the input sizes are so large that complexity problems
are---artificially---trivial). The starting investigation point is the setting
of graph games, about which various open questions were stated in the
literature. The paper gives an answer to these questions, and in addition
provides new insights on the setting, by characterizing the computational
complexity of the three concepts in some relevant generalizations and
specializations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3283</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3283</id><created>2008-10-17</created><updated>2008-10-25</updated><authors><author><keyname>Dong</keyname><forenames>Daoyi</forenames></author><author><keyname>Chen</keyname><forenames>Chunlin</forenames></author><author><keyname>Zhang</keyname><forenames>Chenbin</forenames></author><author><keyname>Chen</keyname><forenames>Zonghai</forenames></author></authors><title>Quantum robot: structure, algorithms and applications</title><categories>cs.RO cs.AI quant-ph</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3294</identifier>
 <datestamp>2014-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3294</id><created>2008-10-18</created><updated>2014-01-30</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Burgess</keyname><forenames>Mark</forenames></author></authors><title>A static theory of promises</title><categories>cs.MA cs.SE</categories><comments>36 pages. Revision of v4. In v5 some remarks about the institution of
  promising in the philosophy of Law have been included as well as a comment
  concerning the anthropology of promising. Several minor mistakes were found
  and remedied</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss for the concept of promises within a framework that can be applied
to either humans or technology. We compare promises to the more established
notion of obligations and find promises to be both simpler and more effective
at reducing uncertainty in behavioural outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3434</identifier>
 <datestamp>2011-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3434</id><created>2008-10-19</created><updated>2011-08-31</updated><authors><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>Kalyana B.</forenames></author><author><keyname>Chaudhry</keyname><forenames>Jehanzeb H.</forenames></author></authors><title>Numerical method for Darcy flow derived using Discrete Exterior Calculus</title><categories>math.NA cs.NA math.DG</categories><comments>Added numerical experiment for flow on a surface. Other small changes
  in meshing related comments</comments><report-no>UIUCDCS-R-2008-2937</report-no><msc-class>65N30, 76S05 (Primary), 53-04, 55-04 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a numerical method for Darcy flow, hence also for Poisson's
equation in mixed (first order) form, based on discrete exterior calculus
(DEC). Exterior calculus is a generalization of vector calculus to smooth
manifolds and DEC is one of its discretizations on simplicial complexes such as
triangle and tetrahedral meshes. DEC is a coordinate invariant discretization,
in that it does not depend on the embedding of the simplices or the whole mesh.
We start by rewriting the governing equations of Darcy flow using the language
of exterior calculus. This yields a formulation in terms of flux differential
form and pressure. The numerical method is then derived by using the framework
provided by DEC for discretizing differential forms and operators that act on
forms. We also develop a discretization for spatially dependent Hodge star that
varies with the permeability of the medium. This also allows us to address
discontinuous permeability. The matrix representation for our discrete
non-homogeneous Hodge star is diagonal, with positive diagonal entries. The
resulting linear system of equations for flux and pressure are saddle type,
with a diagonal matrix as the top left block. The performance of the proposed
numerical method is illustrated on many standard test problems. These include
patch tests in two and three dimensions, comparison with analytically known
solution in two dimensions, layered medium with alternating permeability
values, and a test with a change in permeability along the flow direction. We
also show numerical evidence of convergence of the flux and the pressure. A
convergence experiment is also included for Darcy flow on a surface. A short
introduction to the relevant parts of smooth and discrete exterior calculus is
included in this paper. We also include a discussion of the boundary condition
in terms of exterior calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3605</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3605</id><created>2008-10-20</created><updated>2010-04-10</updated><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>A Minimum Relative Entropy Principle for Learning and Acting</title><categories>cs.AI cs.LG</categories><comments>36 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method to construct an adaptive agent that is universal
with respect to a given class of experts, where each expert is an agent that
has been designed specifically for a particular environment. This adaptive
control problem is formalized as the problem of minimizing the relative entropy
of the adaptive agent from the expert that is most suitable for the unknown
environment. If the agent is a passive observer, then the optimal solution is
the well-known Bayesian predictor. However, if the agent is active, then its
past actions need to be treated as causal interventions on the I/O stream
rather than normal probability conditions. Here it is shown that the solution
to this new variational problem is given by a stochastic controller called the
Bayesian control rule, which implements adaptive behavior as a mixture of
experts. Furthermore, it is shown that under mild assumptions, the Bayesian
control rule converges to the control law of the most suitable expert.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3695</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3695</id><created>2008-10-20</created><authors><author><keyname>Krovi</keyname><forenames>Hari</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>An Efficient Quantum Algorithm for the Hidden Subgroup Problem over
  Weyl-Heisenberg Groups</title><categories>quant-ph cs.CC</categories><comments>20 pages, 1 figure</comments><journal-ref>Proceedings of Mathematical Methods in Computer Science,
  (MMICS'08), pp.70-88, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many exponential speedups that have been achieved in quantum computing are
obtained via hidden subgroup problems (HSPs). We show that the HSP over
Weyl-Heisenberg groups can be solved efficiently on a quantum computer. These
groups are well-known in physics and play an important role in the theory of
quantum error-correcting codes. Our algorithm is based on non-commutative
Fourier analysis of coset states which are quantum states that arise from a
given black-box function. We use Clebsch-Gordan decompositions to combine and
reduce tensor products of irreducible representations. Furthermore, we use a
new technique of changing labels of irreducible representations to obtain
low-dimensional irreducible representations in the decomposition process. A
feature of the presented algorithm is that in each iteration of the algorithm
the quantum computer operates on two coset states simultaneously. This is an
improvement over the previously best known quantum algorithm for these groups
which required four coset states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3729</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3729</id><created>2008-10-20</created><updated>2010-03-22</updated><authors><author><keyname>Kim</keyname><forenames>Hyun Kwang</forenames></author><author><keyname>Lee</keyname><forenames>Joon Yop</forenames></author><author><keyname>Oh</keyname><forenames>Dong Yeol</forenames></author></authors><title>Optimal codes in deletion and insertion metric</title><categories>cs.IT cs.DM math.CO math.IT</categories><comments>19 pages,The material of this paper was presented in part at the 10th
  International Workshop on Algebraic and Combinatorial Coding Theory,
  Zvenigorod, Russia, September 2006</comments><msc-class>94B60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve the upper bound of Levenshtein for the cardinality of a code of
length 4 capable of correcting single deletions over an alphabet of even size.
We also illustrate that the new upper bound is sharp. Furthermore we will
construct an optimal perfect code capable of correcting single deletions for
the same parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3783</identifier>
 <datestamp>2010-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3783</id><created>2008-10-21</created><updated>2010-09-07</updated><authors><author><keyname>Wei</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Directed Transmission Method, A Fully Asynchronous approach to Solve
  Sparse Linear Systems in Parallel</title><categories>math.NA cs.DC</categories><comments>v1: poster presented in SPAA'08; v2: full paper; v3: rename EVS to
  GNBT; v4: reuse EVS. More info, see my web page at
  http://weifei00.googlepages.com</comments><msc-class>65F10, 65F50, 68M14</msc-class><doi>10.1145/1378533.1378598</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new distributed algorithm, called Directed
Transmission Method (DTM). DTM is a fully asynchronous and continuous-time
iterative algorithm to solve SPD sparse linear system. As an architecture-aware
algorithm, DTM could be freely running on all kinds of heterogeneous parallel
computer. We proved that DTM is convergent by making use of the final-value
theorem of Laplacian Transformation. Numerical experiments show that DTM is
stable and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3787</identifier>
 <datestamp>2014-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3787</id><created>2008-10-21</created><updated>2009-04-08</updated><authors><author><keyname>Guenther</keyname><forenames>Annika</forenames></author><author><keyname>Nebe</keyname><forenames>Gabriele</forenames></author></authors><title>Automorphisms of doubly-even self-dual binary codes</title><categories>math.NT cs.IT math.IT</categories><comments>Added a new proof for the main result</comments><msc-class>94B05; 20G25; 11E95</msc-class><doi>10.1112/blms/bdp026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The automorphism group of a binary doubly-even self-dual code is always
contained in the alternating group. On the other hand, given a permutation
group $G$ of degree $n$ there exists a doubly-even self-dual $G$-invariant code
if and only if $n$ is a multiple of 8, every simple self-dual $\F_2G$-module
occurs with even multiplicity in $\F_2^n$, and $G$ is contained in the
alternating group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.3836</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.3836</id><created>2008-10-21</created><updated>2010-10-11</updated><authors><author><keyname>Ducourthial</keyname><forenames>Bertrand</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Khalfallah</keyname><forenames>Sofiane</forenames><affiliation>HEUDIASYC</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author></authors><title>Best-effort Group Service in Dynamic Networks</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a group membership service for dynamic ad hoc networks. It
maintains as long as possible the existing groups and ensures that each group
diameter is always smaller than a constant, fixed according to the application
using the groups. The proposed protocol is self-stabilizing and works in
dynamic distributed systems. Moreover, it ensures a kind of continuity in the
service offer to the application while the system is converging, except if too
strong topology changes happen. Such a best effort behavior allows applications
to rely on the groups while the stabilization has not been reached, which is
very useful in dynamic ad hoc networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4112</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4112</id><created>2008-10-22</created><authors><author><keyname>Couvreur</keyname><forenames>Alain</forenames></author></authors><title>Sums of residues on algebraic surfaces and application to coding theory</title><categories>math.AG cs.IT math.IT</categories><comments>31 pages</comments><msc-class>14J99, 14J20, 14G50, 94B27</msc-class><journal-ref>Journal of Pure and Applied Algebra, vol 213 number 12, pages
  2201-2223, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study residues of differential 2-forms on a smooth
algebraic surface over an arbitrary field and give several statements about
sums of residues. Afterwards, using these results we construct
algebraic-geometric codes which are an extension to surfaces of the well-known
differential codes on curves. We also study some properties of these codes and
extend to them some known properties for codes on curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4187</identifier>
 <datestamp>2010-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4187</id><created>2008-10-22</created><authors><author><keyname>Kaltenbrunner</keyname><forenames>Andreas</forenames></author><author><keyname>Meza</keyname><forenames>Rodrigo</forenames></author><author><keyname>Grivolla</keyname><forenames>Jens</forenames></author><author><keyname>Codina</keyname><forenames>Joan</forenames></author><author><keyname>Banchs</keyname><forenames>Rafael</forenames></author></authors><title>Bicycle cycles and mobility patterns - Exploring and characterizing data
  from a community bicycle program</title><categories>cs.CY cs.HC</categories><comments>10 pages, 8 figures</comments><acm-class>G.3; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an analysis of human mobility data in an urban area using
the amount of available bikes in the stations of the community bicycle program
Bicing in Barcelona. The data was obtained by periodic mining of a KML-file
accessible through the Bicing website. Although in principle very noisy, after
some preprocessing and filtering steps the data allows to detect temporal
patterns in mobility as well as identify residential, university, business and
leisure areas of the city. The results lead to a proposal for an improvement of
the bicing website, including a prediction of the number of available bikes in
a certain station within the next minutes/hours. Furthermore a model for
identifying the most probable routes between stations is briefly sketched.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4423</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4423</id><created>2008-10-24</created><updated>2013-01-01</updated><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author></authors><title>Efficient Algorithmic Techniques for Several Multidimensional Geometric
  Data Management and Analysis Problems</title><categories>cs.CG cs.DM cs.DS</categories><comments>The algorithmic techniques presented in this paper were later used by
  the author in developing solutions for algorithmic tasks in several contests
  in which the author participated (see the attached zip archive for some
  examples of task statements and solutions). Knowledge Management - Projects,
  Systems and Technologies, Bucharest : Romania (2008)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I present several novel, efficient, algorithmic techniques for
solving some multidimensional geometric data management and analysis problems.
The techniques are based on several data structures from computational geometry
(e.g. segment tree and range tree) and on the well-known sweep-line method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4426</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4426</id><created>2008-10-24</created><updated>2009-01-04</updated><authors><author><keyname>Rosten</keyname><forenames>Edward</forenames></author><author><keyname>Loveland</keyname><forenames>Rohan</forenames></author></authors><title>Camera distortion self-calibration using the plumb-line constraint and
  minimal Hough entropy</title><categories>cs.CV</categories><comments>9 pages, 5 figures Corrected errors in equation 18</comments><report-no>08-2665</report-no><doi>10.1007/s00138-009-0196-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a simple and robust method for self-correction of
camera distortion using single images of scenes which contain straight lines.
Since the most common distortion can be modelled as radial distortion, we
illustrate the method using the Harris radial distortion model, but the method
is applicable to any distortion model. The method is based on transforming the
edgels of the distorted image to a 1-D angular Hough space, and optimizing the
distortion correction parameters which minimize the entropy of the
corresponding normalized histogram. Properly corrected imagery will have fewer
curved lines, and therefore less spread in Hough space. Since the method does
not rely on any image structure beyond the existence of edgels sharing some
common orientations and does not use edge fitting, it is applicable to a wide
variety of image types. For instance, it can be applied equally well to images
of texture with weak but dominant orientations, or images with strong vanishing
points. Finally, the method is performed on both synthetic and real data
revealing that it is particularly robust to noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4460</identifier>
 <datestamp>2014-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4460</id><created>2008-10-24</created><updated>2014-05-24</updated><authors><author><keyname>Geneves</keyname><forenames>Pierre</forenames></author></authors><title>Logics for XML</title><categories>cs.PL cs.DB cs.LO</categories><comments>Ph.D. dissertation, defended on December 4th, 2006</comments><acm-class>D.3.0; D.3.1; D.3.4; E.1; F.3.1; F.3.2; F.4.1; F.4.3; H.2.3; I.2.4;
  I.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis describes the theoretical and practical foundations of a system
for the static analysis of XML processing languages. The system relies on a
fixpoint temporal logic with converse, derived from the mu-calculus, where
models are finite trees. This calculus is expressive enough to capture regular
tree types along with multi-directional navigation in trees, while having a
single exponential time complexity. Specifically the decidability of the logic
is proved in time 2^O(n) where n is the size of the input formula.
  Major XML concepts are linearly translated into the logic: XPath navigation
and node selection semantics, and regular tree languages (which include DTDs
and XML Schemas). Based on these embeddings, several problems of major
importance in XML applications are reduced to satisfiability of the logic.
These problems include XPath containment, emptiness, equivalence, overlap,
coverage, in the presence or absence of regular tree type constraints, and the
static type-checking of an annotated query.
  The focus is then given to a sound and complete algorithm for deciding the
logic, along with a detailed complexity analysis, and crucial implementation
techniques for building an effective solver. Practical experiments using a full
implementation of the system are presented. The system appears to be efficient
in practice for several realistic scenarios.
  The main application of this work is a new class of static analyzers for
programming languages using both XPath expressions and XML type annotations
(input and output). Such analyzers allow to ensure at compile-time valuable
properties such as type-safety and optimizations, for safer and more efficient
XML processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4576</identifier>
 <datestamp>2011-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4576</id><created>2008-10-25</created><updated>2008-10-29</updated><authors><author><keyname>Itoh</keyname><forenames>Toshiya</forenames></author><author><keyname>Suzuki</keyname><forenames>Yasuhiro</forenames></author></authors><title>New Constructions for Query-Efficient Locally Decodable Codes of
  Subexponential Length</title><categories>cs.CC cs.CR</categories><comments>13 pages, 1 figure, 2 tables</comments><acm-class>F.1.2; F.2.2; G.2.1</acm-class><journal-ref>IEICE Trans. on Inf. and Syst. E93-D(2), pp.263-270, 2010</journal-ref><doi>10.1587/transinf.E93.D.263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $(k,\delta,\epsilon)$-locally decodable code $C: F_{q}^{n} \to F_{q}^{N}$
is an error-correcting code that encodes each message
$\vec{x}=(x_{1},x_{2},...,x_{n}) \in F_{q}^{n}$ to $C(\vec{x}) \in F_{q}^{N}$
and has the following property: For any $\vec{y} \in {\bf F}_{q}^{N}$ such that
$d(\vec{y},C(\vec{x})) \leq \delta N$ and each $1 \leq i \leq n$, the symbol
$x_{i}$ of $\vec{x}$ can be recovered with probability at least $1-\epsilon$ by
a randomized decoding algorithm looking only at $k$ coordinates of $\vec{y}$.
The efficiency of a $(k,\delta,\epsilon)$-locally decodable code $C: F_{q}^{n}
\to F_{q}^{N}$ is measured by the code length $N$ and the number $k$ of
queries. For any $k$-query locally decodable code $C: F_{q}^{n} \to F_{q}^{N}$,
the code length $N$ is conjectured to be exponential of $n$, however, this was
disproved. Yekhanin [In Proc. of STOC, 2007] showed that there exists a 3-query
locally decodable code $C: F_{2}^{n} \to F_{2}^{N}$ such that
$N=\exp(n^{(1/\log \log n)})$ assuming that the number of Mersenne primes is
infinite. For a 3-query locally decodable code $C: F_{q}^{n} \to F_{q}^{N}$,
Efremenko [ECCC Report No.69, 2008] reduced the code length further to
$N=\exp(n^{O((\log \log n/ \log n)^{1/2})})$, and also showed that for any
integer $r&gt;1$, there exists a $k$-query locally decodable code $C: F_{q}^{n}
\to F_{q}^{N}$ such that $k \leq 2^{r}$ and $N=\exp(n^{O((\log \log n/ \log
n)^{1-1/r})})$. In this paper, we present a query-efficient locally decodable
code and show that for any integer $r&gt;1$, there exists a $k$-query locally
decodable code $C: F_{q}^{n} \to F_{q}^{N}$ such that $k \leq 3 \cdot 2^{r-2}$
and $N=\exp(n^{O((\log \log n/ \log n)^{1-1/r})})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.4727</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.4727</id><created>2008-10-26</created><updated>2008-11-10</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>Robust Estimation of Mean Values</title><categories>math.ST cs.SY math.PR stat.CO stat.TH</categories><comments>12 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a computational approach for estimating the mean
value of a quantity in the presence of uncertainty. We demonstrate that, under
some mild assumptions, the upper and lower bounds of the mean value are
efficiently computable via a sample reuse technique, of which the computational
complexity is shown to posses a Poisson distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5157</identifier>
 <datestamp>2013-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5157</id><created>2008-10-28</created><authors><author><keyname>Pawling</keyname><forenames>Alec</forenames></author><author><keyname>Yan</keyname><forenames>Ping</forenames></author><author><keyname>Candia</keyname><forenames>Julián</forenames></author><author><keyname>Schoenharl</keyname><forenames>Tim</forenames></author><author><keyname>Madey</keyname><forenames>Greg</forenames></author></authors><title>Anomaly Detection in Streaming Sensor Data</title><categories>physics.data-an cs.NI physics.comp-ph</categories><comments>35 pages. Book chapter to appear in "Intelligent Techniques for
  Warehousing and Mining Sensor Network Data" (IGI Global), edited by A.
  Cuzzocrea</comments><doi>10.4018/978-1-60566-328-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter we consider a cell phone network as a set of automatically
deployed sensors that records movement and interaction patterns of the
population. We discuss methods for detecting anomalies in the streaming data
produced by the cell phone network. We motivate this discussion by describing
the Wireless Phone Based Emergency Response (WIPER) system, a proof-of-concept
decision support system for emergency response managers. We also discuss some
of the scientific work enabled by this type of sensor data and the related
privacy issues. We describe scientific studies that use the cell phone data set
and steps we have taken to ensure the security of the data. We describe the
overall decision support system and discuss three methods of anomaly detection
that we have applied to the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5399</identifier>
 <datestamp>2010-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5399</id><created>2008-10-29</created><updated>2010-12-26</updated><authors><author><keyname>Furuichi</keyname><forenames>Shigeru</forenames></author></authors><title>An axiomatic characterization of a two-parameter extended relative
  entropy</title><categories>cond-mat.stat-mech cs.IT math.IT</categories><comments>11 pages</comments><journal-ref>J. Math. Phys. Vol.51 (2010), 123302 (10 pages)</journal-ref><doi>10.1063/1.3525917</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The uniqueness theorem for a two-parameter extended relative entropy is
proven. This result extends our previous one, the uniqueness theorem for a
one-parameter extended relative entropy, to a two-parameter case. In addition,
the properties of a two-parameter extended relative entropy are studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5428</identifier>
 <datestamp>2010-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5428</id><created>2008-10-30</created><updated>2010-05-19</updated><authors><author><keyname>Bagchi</keyname><forenames>Amitabha</forenames></author><author><keyname>Lahoti</keyname><forenames>Garima</forenames></author></authors><title>Relating Web pages to enable information-gathering tasks</title><categories>cs.IR cs.DS</categories><comments>In Proceedings of ACM Hypertext 2009</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that relationships between Web pages are functions of the user's
intent. We identify a class of Web tasks - information-gathering - that can be
facilitated by a search engine that provides links to pages which are related
to the page the user is currently viewing. We define three kinds of intentional
relationships that correspond to whether the user is a) seeking sources of
information, b) reading pages which provide information, or c) surfing through
pages as part of an extended information-gathering process. We show that these
three relationships can be productively mined using a combination of textual
and link information and provide three scoring mechanisms that correspond to
them: {\em SeekRel}, {\em FactRel} and {\em SurfRel}. These scoring mechanisms
incorporate both textual and link information. We build a set of capacitated
subnetworks - each corresponding to a particular keyword - that mirror the
interconnection structure of the World Wide Web. The scores are computed by
computing flows on these subnetworks. The capacities of the links are derived
from the {\em hub} and {\em authority} values of the nodes they connect,
following the work of Kleinberg (1998) on assigning authority to pages in
hyperlinked environments. We evaluated our scoring mechanism by running
experiments on four data sets taken from the Web. We present user evaluations
of the relevance of the top results returned by our scoring mechanisms and
compare those to the top results returned by Google's Similar Pages feature,
and the {\em Companion} algorithm proposed by Dean and Henzinger (1999).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5517</identifier>
 <datestamp>2010-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5517</id><created>2008-10-30</created><updated>2010-01-18</updated><authors><author><keyname>Demri</keyname><forenames>Stephane</forenames></author><author><keyname>Lazic</keyname><forenames>Ranko</forenames></author><author><keyname>Sangnier</keyname><forenames>Arnaud</forenames></author></authors><title>Model checking memoryful linear-time logics over one-counter automata</title><categories>cs.LO</categories><comments>Substantially revised and extended version of "Model checking freeze
  LTL over one-counter automata" by the same authors in FoSSaCS 2008</comments><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study complexity of the model-checking problems for LTL with registers
(also known as freeze LTL) and for first-order logic with data equality tests
over one-counter automata. We consider several classes of one-counter automata
(mainly deterministic vs. nondeterministic) and several logical fragments
(restriction on the number of registers or variables and on the use of
propositional variables for control locations). The logics have the ability to
store a counter value and to test it later against the current counter value.
We show that model checking over deterministic one-counter automata is
PSPACE-complete with infinite and finite accepting runs. By constrast, we prove
that model checking freeze LTL in which the until operator is restricted to the
eventually operator over nondeterministic one-counter automata is undecidable
even if only one register is used and with no propositional variable. As a
corollary of our proof, this also holds for first-order logic with data
equality tests restricted to two variables. This makes a difference with the
facts that several verification problems for one-counter automata are known to
be decidable with relatively low complexity, and that finitary satisfiability
for the two logics are decidable. Our results pave the way for model-checking
memoryful (linear-time) logics over other classes of operational models, such
as reversal-bounded counter machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5551</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5551</id><created>2008-10-30</created><updated>2008-11-10</updated><authors><author><keyname>Chen</keyname><forenames>Xinjia</forenames></author></authors><title>A Theory of Truncated Inverse Sampling</title><categories>math.ST cs.LG math.PR stat.ME stat.TH</categories><comments>31 pages, no figure, revised proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have established a new framework of truncated inverse
sampling for estimating mean values of non-negative random variables such as
binomial, Poisson, hyper-geometrical, and bounded variables. We have derived
explicit formulas and computational methods for designing sampling schemes to
ensure prescribed levels of precision and confidence for point estimators.
Moreover, we have developed interval estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5663</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5663</id><created>2008-10-31</created><authors><author><keyname>Ay</keyname><forenames>Nihat</forenames></author><author><keyname>Mueller</keyname><forenames>Markus</forenames></author><author><keyname>Szkola</keyname><forenames>Arleta</forenames></author></authors><title>Effective Complexity and its Relation to Logical Depth</title><categories>cs.IT math.IT</categories><comments>14 pages, 2 figures</comments><journal-ref>IEEE Trans. Inf. Th., Vol. 56/9 pp. 4593-4607 (2010)</journal-ref><doi>10.1109/TIT.2010.2053892</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective complexity measures the information content of the regularities of
an object. It has been introduced by M. Gell-Mann and S. Lloyd to avoid some of
the disadvantages of Kolmogorov complexity, also known as algorithmic
information content. In this paper, we give a precise formal definition of
effective complexity and rigorous proofs of its basic properties. In
particular, we show that incompressible binary strings are effectively simple,
and we prove the existence of strings that have effective complexity close to
their lengths. Furthermore, we show that effective complexity is related to
Bennett's logical depth: If the effective complexity of a string $x$ exceeds a
certain explicit threshold then that string must have astronomically large
depth; otherwise, the depth can be arbitrarily small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0810.5685</identifier>
 <datestamp>2010-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0810.5685</id><created>2008-10-31</created><updated>2010-08-23</updated><authors><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Roche</keyname><forenames>Daniel S.</forenames></author></authors><title>Interpolation of Shifted-Lacunary Polynomials</title><categories>cs.SC cs.DS cs.MS</categories><comments>22 pages, to appear in Computational Complexity</comments><msc-class>68W30 (Primary), 12Y05 (Secondary)</msc-class><journal-ref>Computational Complexity, Vol. 19, No 3., pp. 333-354, 2010</journal-ref><doi>10.1007/s00037-010-0294-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a "black box" function to evaluate an unknown rational polynomial f in
Q[x] at points modulo a prime p, we exhibit algorithms to compute the
representation of the polynomial in the sparsest shifted power basis. That is,
we determine the sparsity t, the shift s (a rational), the exponents 0 &lt;= e1 &lt;
e2 &lt; ... &lt; et, and the coefficients c1,...,ct in Q\{0} such that f(x) =
c1(x-s)^e1+c2(x-s)^e2+...+ct(x-s)^et. The computed sparsity t is absolutely
minimal over any shifted power basis. The novelty of our algorithm is that the
complexity is polynomial in the (sparse) representation size, and in particular
is logarithmic in deg(f). Our method combines previous celebrated results on
sparse interpolation and computing sparsest shifts, and provides a way to
handle polynomials with extremely high degree which are, in some sense, sparse
in information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0037</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0037</id><created>2008-10-31</created><updated>2010-01-01</updated><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Jerrum</keyname><forenames>Mark</forenames></author></authors><title>A complexity dichotomy for hypergraph partition functions</title><categories>cs.CC cs.DM</categories><comments>21 pages</comments><acm-class>F.2.2; F.4.1; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the complexity of counting homomorphisms from an $r$-uniform
hypergraph $G$ to a symmetric $r$-ary relation $H$. We give a dichotomy theorem
for $r&gt;2$, showing for which $H$ this problem is in FP and for which $H$ it is
#P-complete. This generalises a theorem of Dyer and Greenhill (2000) for the
case $r=2$, which corresponds to counting graph homomorphisms. Our dichotomy
theorem extends to the case in which the relation $H$ is weighted, and the goal
is to compute the \emph{partition function}, which is the sum of weights of the
homomorphisms. This problem is motivated by statistical physics, where it
arises as computing the partition function for particle models in which certain
combinations of $r$ sites interact symmetrically. In the weighted case, our
dichotomy theorem generalises a result of Bulatov and Grohe (2005) for graphs,
where $r=2$. When $r=2$, the polynomial time cases of the dichotomy correspond
simply to rank-1 weights. Surprisingly, for all $r&gt;2$ the polynomial time cases
of the dichotomy have rather more structure. It turns out that the weights must
be superimposed on a combinatorial structure defined by solutions of an
equation over an Abelian group. Our result also gives a dichotomy for a closely
related constraint satisfaction problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0113</identifier>
 <datestamp>2012-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0113</id><created>2008-11-01</created><updated>2010-07-11</updated><authors><author><keyname>Martins</keyname><forenames>Andre C. R.</forenames></author></authors><title>A Bayesian Framework for Opinion Updates</title><categories>physics.soc-ph cs.MA nlin.AO</categories><comments>20 pages; major expansion and detailing</comments><report-no>In Liu Yijun and Zhou Tao, editors, Social Physics Catena (No.3),
  pages 146-157. Science Press, Beijing</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opinion Dynamics lacks a theoretical basis. In this article, I propose to use
a decision-theoretic framework, based on the updating of subjective
probabilities, as that basis. We will see we get a basic tool for a better
understanding of the interaction between the agents in Opinion Dynamics
problems and for creating new models. I will review the few existing
applications of Bayesian update rules to both discrete and continuous opinion
problems and show that several traditional models can be obtained as special
cases or approximations from these Bayesian models. The empirical basis and
useful properties of the framework will be discussed and examples of how the
framework can be used to describe different problems given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0359</identifier>
 <datestamp>2010-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0359</id><created>2008-11-03</created><updated>2010-06-11</updated><authors><author><keyname>de Bruijn</keyname><forenames>Jos</forenames></author><author><keyname>Eiter</keyname><forenames>Thomas</forenames></author><author><keyname>Polleres</keyname><forenames>Axel</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author></authors><title>Embedding Non-Ground Logic Programs into Autoepistemic Logic for
  Knowledge Base Combination</title><categories>cs.LO cs.AI</categories><comments>52 pages, submitted</comments><acm-class>I.2.4; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of the Semantic Web, several approaches to the combination of
ontologies, given in terms of theories of classical first-order logic and rule
bases, have been proposed. They either cast rules into classical logic or limit
the interaction between rules and ontologies. Autoepistemic logic (AEL) is an
attractive formalism which allows to overcome these limitations, by serving as
a uniform host language to embed ontologies and nonmonotonic logic programs
into it. For the latter, so far only the propositional setting has been
considered. In this paper, we present three embeddings of normal and three
embeddings of disjunctive non-ground logic programs under the stable model
semantics into first-order AEL. While the embeddings all correspond with
respect to objective ground atoms, differences arise when considering
non-atomic formulas and combinations with first-order theories. We compare the
embeddings with respect to stable expansions and autoepistemic consequences,
considering the embeddings by themselves, as well as combinations with
classical theories. Our results reveal differences and correspondences of the
embeddings and provide useful guidance in the choice of a particular embedding
for knowledge combination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0381</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0381</id><created>2008-11-03</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>On the dynamics of Social Balance on general networks (with an
  application to XOR-SAT)</title><categories>cs.DM math.CO math.PR physics.soc-ph</categories><journal-ref>Fundamenta Informaticae, 91 (2), pp. 341-356, 2009.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study nondeterministic and probabilistic versions of a discrete dynamical
system (due to T. Antal, P. L. Krapivsky, and S. Redner) inspired by Heider's
social balance theory. We investigate the convergence time of this dynamics on
several classes of graphs. Our contributions include:
  1. We point out the connection between the triad dynamics and a
generalization of annihilating walks to hypergraphs. In particular, this
connection allows us to completely characterize the recurrent states in graphs
where each edge belongs to at most two triangles.
  2. We also solve the case of hypergraphs that do not contain edges consisting
of one or two vertices.
  3. We show that on the so-called "triadic cycle" graph, the convergence time
is linear.
  4. We obtain a cubic upper bound on the convergence time on 2-regular triadic
simplexes G. This bound can be further improved to a quantity that depends on
the Cheeger constant of G. In particular this provides some rigorous
counterparts to previous experimental observations.
  We also point out an application to the analysis of the random walk algorithm
on certain instances of the 3-XOR-SAT problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0881</identifier>
 <datestamp>2010-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0881</id><created>2008-11-06</created><authors><author><keyname>Das</keyname><forenames>Arnab</forenames></author></authors><title>Non-classical Role of Potential Energy in Adiabatic Quantum Annealing</title><categories>quant-ph cond-mat.stat-mech cs.CC physics.comp-ph</categories><comments>10 pages, 2 figures (for the Proceedings of the International
  Workshop on Statis tical-Mechanical Informatics 2008, Sendai, Japan). Journal
  of Physics: Conference Series (to be publised)</comments><journal-ref>J. Phys.: Conf. Ser. vol. 143 012001 (2009)</journal-ref><doi>10.1088/1742-6596/143/1/012001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adiabatic quantum annealing is a paradigm of analog quantum computation,
where a given computational job is converted to the task of finding the global
minimum of some classical potential energy function and the search for the
global potential minimum is performed by employing external kinetic quantum
fluctuations and subsequent slow reduction (annealing) of them. In this method,
the entire potential energy landscape (PEL) may be accessed simultaneously
through a delocalized wave-function, in contrast to a classical search, where
the searcher has to visit different points in the landscape (i.e., individual
classical configurations) sequentially. Thus in such searches, the role of the
potential energy might be significantly different in the two cases. Here we
discuss this in the context of searching of a single isolated hole (potential
minimum) in a golf-course type gradient free PEL. We show, that the quantum
particle would be able to locate the hole faster if the hole is deeper, while
the classical particle of course would have no scope to exploit the depth of
the hole. We also discuss the effect of the underlying quantum phase transition
on the adiabatic dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0935</identifier>
 <datestamp>2011-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0935</id><created>2008-11-06</created><updated>2011-01-14</updated><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Kayran</keyname><forenames>Ahmet H.</forenames></author></authors><title>A New Training Protocol for Channel State Estimation in Wireless Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to technical flaws in
  SISO section</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The accuracy of channel state information (CSI) is critical for improving the
capacity of wireless networks. In this paper, we introduce a training protocol
for wireless relay networks that uses channel estimation and feedforwarding
methods. The feedforwarding method is the distinctive feature of the proposed
protocol. As we show, each relay feedforwards the imperfect CSI to the
destination in a way that provides a higher network capacity and a faster
transfer of the CSI than the existing protocols. In addition, we show the
importance of the effective CSI accuracy on the wireless relay network capacity
by comparing networks with the perfect effective CSI, imperfect effective CSI,
and noisy imperfect effective CSI available at the destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.0959</identifier>
 <datestamp>2010-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.0959</id><created>2008-11-06</created><updated>2009-08-12</updated><authors><author><keyname>Beyersdorff</keyname><forenames>Olaf</forenames></author><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author><author><keyname>Vollmer</keyname><forenames>Heribert</forenames></author></authors><title>The Complexity of Propositional Implication</title><categories>cs.CC cs.LO</categories><doi>10.1016/j.ipl.2009.06.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question whether a set of formulae G implies a formula f is fundamental.
The present paper studies the complexity of the above implication problem for
propositional formulae that are built from a systematically restricted set of
Boolean connectives. We give a complete complexity classification for all sets
of Boolean functions in the meaning of Post's lattice and show that the
implication problem is efficentily solvable only if the connectives are
definable using the constants {false,true} and only one of {and,or,xor}. The
problem remains coNP-complete in all other cases. We also consider the
restriction of G to singletons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1319</identifier>
 <datestamp>2010-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1319</id><created>2008-11-09</created><updated>2010-05-26</updated><authors><author><keyname>Plangprasopchok</keyname><forenames>Anon</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Modeling Social Annotation: a Bayesian Approach</title><categories>cs.AI</categories><comments>29 Pages, Accepted for publication at ACM Transactions on Knowledge
  Discovery from Data(TKDD) on March 2, 2010</comments><acm-class>H.2.8; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative tagging systems, such as Delicious, CiteULike, and others,
allow users to annotate resources, e.g., Web pages or scientific papers, with
descriptive labels called tags. The social annotations contributed by thousands
of users, can potentially be used to infer categorical knowledge, classify
documents or recommend new relevant information. Traditional text inference
methods do not make best use of social annotation, since they do not take into
account variations in individual users' perspectives and vocabulary. In a
previous work, we introduced a simple probabilistic model that takes interests
of individual annotators into account in order to find hidden topics of
annotated resources. Unfortunately, that approach had one major shortcoming:
the number of topics and interests must be specified a priori. To address this
drawback, we extend the model to a fully Bayesian framework, which offers a way
to automatically estimate these numbers. In particular, the model allows the
number of interests and topics to change as suggested by the structure of the
data. We evaluate the proposed model in detail on the synthetic and real-world
data by comparing its performance to Latent Dirichlet Allocation on the topic
extraction task. For the latter evaluation, we apply the model to infer topics
of Web resources from social annotations obtained from Delicious in order to
discover new resources similar to a specified one. Our empirical results
demonstrate that the proposed model is a promising method for exploiting social
knowledge contained in user-generated annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.1714</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.1714</id><created>2008-11-11</created><authors><author><keyname>Albrecht</keyname><forenames>Martin</forenames></author><author><keyname>Bard</keyname><forenames>Gregory</forenames></author><author><keyname>Hart</keyname><forenames>William</forenames></author></authors><title>Efficient Multiplication of Dense Matrices over GF(2)</title><categories>cs.MS</categories><acm-class>G.4</acm-class><doi>10.1145/1644001.1644010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an efficient implementation of a hierarchy of algorithms for
multiplication of dense matrices over the field with two elements (GF(2)). In
particular we present our implementation -- in the M4RI library -- of
Strassen-Winograd matrix multiplication and the "Method of the Four Russians"
multiplication (M4RM) and compare it against other available implementations.
Good performance is demonstrated on on AMD's Opteron and particulary good
performance on Intel's Core 2 Duo. The open-source M4RI library is available
stand-alone as well as part of the Sage mathematics software.
  In machine terms, addition in GF(2) is logical-XOR, and multiplication is
logical-AND, thus a machine word of 64-bits allows one to operate on 64
elements of GF(2) in parallel: at most one CPU cycle for 64 parallel additions
or multiplications. As such, element-wise operations over GF(2) are relatively
cheap. In fact, in this paper, we conclude that the actual bottlenecks are
memory reads and writes and issues of data locality. We present our empirical
findings in relation to minimizing these and give an analysis thereof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2180</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2180</id><created>2008-11-13</created><updated>2009-12-16</updated><authors><author><keyname>Chafai</keyname><forenames>Djalil</forenames><affiliation>LAMA</affiliation></author><author><keyname>Malrieu</keyname><forenames>Florent</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Paroux</keyname><forenames>Katy</forenames><affiliation>LM-Besançon, INRIA - IRISA</affiliation></author></authors><title>On the long time behavior of the TCP window size process</title><categories>math.PR cs.NI</categories><comments>Corrections</comments><proxy>ccsd hal-00338640</proxy><msc-class>68M12, 60K30, 60K25, 90B18</msc-class><journal-ref>Stochastic Processes and their Applications 120, 8 (2010)
  1518-1534</journal-ref><doi>10.1016/j.spa.2010.03.019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The TCP window size process appears in the modeling of the famous
Transmission Control Protocol used for data transmission over the Internet.
This continuous time Markov process takes its values in $[0,\infty)$, is
ergodic and irreversible. It belongs to the Additive Increase Multiplicative
Decrease class of processes. The sample paths are piecewise linear
deterministic and the whole randomness of the dynamics comes from the jump
mechanism. Several aspects of this process have already been investigated in
the literature. In the present paper, we mainly get quantitative estimates for
the convergence to equilibrium, in terms of the $W_1$ Wasserstein coupling
distance, for the process and also for its embedded chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2497</identifier>
 <datestamp>2010-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2497</id><created>2008-11-15</created><updated>2010-02-01</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Paterson</keyname><forenames>Mike</forenames></author></authors><title>Computing voting power in easy weighted voting games</title><categories>cs.GT cs.CC cs.DS</categories><comments>12 pages, Presented at the International Symposium on Combinatorial
  Optimization 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted voting games are ubiquitous mathematical models which are used in
economics, political science, neuroscience, threshold logic, reliability theory
and distributed systems. They model situations where agents with variable
voting weight vote in favour of or against a decision. A coalition of agents is
winning if and only if the sum of weights of the coalition exceeds or equals a
specified quota. The Banzhaf index is a measure of voting power of an agent in
a weighted voting game. It depends on the number of coalitions in which the
agent is the difference in the coalition winning or losing. It is well known
that computing Banzhaf indices in a weighted voting game is NP-hard. We give a
comprehensive classification of weighted voting games which can be solved in
polynomial time. Among other results, we provide a polynomial
($O(k{(\frac{n}{k})}^k)$) algorithm to compute the Banzhaf indices in weighted
voting games in which the number of weight values is bounded by $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2551</identifier>
 <datestamp>2013-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2551</id><created>2008-11-15</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author></authors><title>Modeling Cultural Dynamics</title><categories>cs.MA cs.AI q-bio.NC</categories><comments>8 pages</comments><journal-ref>Gabora, L. (2008). Modeling cultural dynamics. Proceedings of the
  Association for the Advancement of Artificial Intelligence (AAAI) Fall
  Symposium. Nov 7-9, Arlington VA, (pp. 18-25). Menlo Park, CA: AAAI Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EVOC (for EVOlution of Culture) is a computer model of culture that enables
us to investigate how various factors such as barriers to cultural diffusion,
the presence and choice of leaders, or changes in the ratio of innovation to
imitation affect the diversity and effectiveness of ideas. It consists of
neural network based agents that invent ideas for actions, and imitate
neighbors' actions. The model is based on a theory of culture according to
which what evolves through culture is not memes or artifacts, but the internal
models of the world that give rise to them, and they evolve not through a
Darwinian process of competitive exclusion but a Lamarckian process involving
exchange of innovation protocols. EVOC shows an increase in mean fitness of
actions over time, and an increase and then decrease in the diversity of
actions. Diversity of actions is positively correlated with population size and
density, and with barriers between populations. Slowly eroding borders increase
fitness without sacrificing diversity by fostering specialization followed by
sharing of fit actions. Introducing a leader that broadcasts its actions
throughout the population increases the fitness of actions but reduces
diversity of actions. Increasing the number of leaders reduces this effect.
Efforts are underway to simulate the conditions under which an agent
immigrating from one culture to another contributes new ideas while still
fitting in.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2572</identifier>
 <datestamp>2010-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2572</id><created>2008-11-17</created><updated>2009-12-01</updated><authors><author><keyname>Cardinal</keyname><forenames>Jean</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Joret</keyname><forenames>Gwenaël</forenames></author><author><keyname>Jungers</keyname><forenames>Raphaël M.</forenames></author><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author></authors><title>An Efficient Algorithm for Partial Order Production</title><categories>cs.DS</categories><comments>Referees' comments incorporated</comments><journal-ref>SIAM J. Comput. Volume 39, Issue 7, pp. 2927-2940 (2010)</journal-ref><doi>10.1137/090759860</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of partial order production: arrange the elements of
an unknown totally ordered set T into a target partially ordered set S, by
comparing a minimum number of pairs in T. Special cases include sorting by
comparisons, selection, multiple selection, and heap construction.
  We give an algorithm performing ITLB + o(ITLB) + O(n) comparisons in the
worst case. Here, n denotes the size of the ground sets, and ITLB denotes a
natural information-theoretic lower bound on the number of comparisons needed
to produce the target partial order.
  Our approach is to replace the target partial order by a weak order (that is,
a partial order with a layered structure) extending it, without increasing the
information theoretic lower bound too much. We then solve the problem by
applying an efficient multiple selection algorithm. The overall complexity of
our algorithm is polynomial. This answers a question of Yao (SIAM J. Comput.
18, 1989).
  We base our analysis on the entropy of the target partial order, a quantity
that can be efficiently computed and provides a good estimate of the
information-theoretic lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2690</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2690</id><created>2008-11-17</created><updated>2013-10-10</updated><authors><author><keyname>Lizier</keyname><forenames>Joseph T.</forenames></author><author><keyname>Prokopenko</keyname><forenames>Mikhail</forenames></author><author><keyname>Zomaya</keyname><forenames>Albert Y.</forenames></author></authors><title>A framework for the local information dynamics of distributed
  computation in complex systems</title><categories>nlin.CG cs.IT math.IT nlin.AO nlin.PS physics.data-an</categories><comments>44 pages, 8 figures</comments><report-no>ICT 08/320</report-no><msc-class>94A15</msc-class><journal-ref>in "Guided Self-Organization: Inception", edited by M. Prokopenko,
  pp. 115-158, Springer, Berlin/Heidelberg, 2014</journal-ref><doi>10.1007/978-3-642-53734-9_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nature of distributed computation has often been described in terms of
the component operations of universal computation: information storage,
transfer and modification. We review the first complete framework that
quantifies each of these individual information dynamics on a local scale
within a system, and describes the manner in which they interact to create
non-trivial computation where "the whole is greater than the sum of the parts".
We describe the application of the framework to cellular automata, a simple yet
powerful model of distributed computation. This is an important application,
because the framework is the first to provide quantitative evidence for several
important conjectures about distributed computation in cellular automata: that
blinkers embody information storage, particles are information transfer agents,
and particle collisions are information modification events. The framework is
also shown to contrast the computations conducted by several well-known
cellular automata, highlighting the importance of information coherence in
complex computation. The results reviewed here provide important quantitative
insights into the fundamental nature of distributed computation and the
dynamics of complex systems, as well as impetus for the framework to be applied
to the analysis and design of other systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2696</identifier>
 <datestamp>2010-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2696</id><created>2008-11-17</created><updated>2009-01-30</updated><authors><author><keyname>Ilten</keyname><forenames>Nathan</forenames></author><author><keyname>Süß</keyname><forenames>Hendrik</forenames></author></authors><title>AG Codes from Polyhedral Divisors</title><categories>math.AG cs.IT math.IT</categories><comments>30 pages, 9 figures; v2: replaced fansy cycles with fansy divisors</comments><msc-class>14G50, 94B27, 14L30, 14C20, 52B20</msc-class><journal-ref>Journal of Symbolic Computation 45 (2010) 734</journal-ref><doi>10.1016/j.jsc.2010.03.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A description of complete normal varieties with lower dimensional torus
action has been given by Altmann, Hausen, and Suess, generalizing the theory of
toric varieties. Considering the case where the acting torus T has codimension
one, we describe T-invariant Weil and Cartier divisors and provide formulae for
calculating global sections, intersection numbers, and Euler characteristics.
As an application, we use divisors on these so-called T-varieties to define new
evaluation codes called T-codes. We find estimates on their minimum distance
using intersection theory. This generalizes the theory of toric codes and
combines it with AG codes on curves. As the simplest application of our general
techniques we look at codes on ruled surfaces coming from decomposable vector
bundles. Already this construction gives codes that are better than the related
product code. Further examples show that we can improve these codes by
constructing more sophisticated T-varieties. These results suggest to look
further for good codes on T-varieties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.2827</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.2827</id><created>2008-11-17</created><updated>2011-11-02</updated><authors><author><keyname>Hayashi</keyname><forenames>Yukio</forenames></author></authors><title>Evolutionary Construction of Geographical Networks with Nearly Optimal
  Robustness and Efficient Routing Properties</title><categories>physics.data-an cs.CG cs.NI physics.soc-ph</categories><comments>14 pages, 10 figures, 1 table</comments><journal-ref>Physica A 388, pp.991-998, 2009</journal-ref><doi>10.1016/j.physa.2008.11.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust and efficient design of networks on a realistic geographical space is
one of the important issues for the realization of dependable communication
systems. In this paper, based on a percolation theory and a geometric graph
property, we investigate such a design from the following viewpoints: 1)
network evolution according to a spatially heterogeneous population, 2)
trimodal low degrees for the tolerant connectivity against both failures and
attacks, and 3) decentralized routing within short paths. Furthermore, we point
out the weakened tolerance by geographical constraints on local cycles, and
propose a practical strategy by adding a small fraction of shortcut links
between randomly chosen nodes in order to improve the robustness to a similar
level to that of the optimal bimodal networks with a larger degree
$O(\sqrt{N})$ for the network size $N$. These properties will be useful for
constructing future ad-hoc networks in wide-area communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3116</identifier>
 <datestamp>2010-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3116</id><created>2008-11-19</created><authors><author><keyname>Istrate</keyname><forenames>Gabriel</forenames></author></authors><title>Geometric properties of satisfying assignments of random
  $\epsilon$-1-in-k SAT</title><categories>cs.CC cs.DM</categories><acm-class>F.2.2; G.2</acm-class><journal-ref>International Journal of Computer Mathematics, 86(12), pp.
  2029-2039, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the geometric structure of the set of solutions of random
$\epsilon$-1-in-k SAT problem. For $l\geq 1$, two satisfying assignments $A$
and $B$ are $l$-connected if there exists a sequence of satisfying assignments
connecting them by changing at most $l$ bits at a time.
  We first prove that w.h.p. two assignments of a random $\epsilon$-1-in-$k$
SAT instance are $O(\log n)$-connected, conditional on being satisfying
assignments. Also, there exists $\epsilon_{0}\in (0,\frac{1}{k-2})$ such that
w.h.p. no two satisfying assignments at distance at least $\epsilon_{0}\cdot n$
form a "hole" in the set of assignments. We believe that this is true for all
$\epsilon &gt;0$, and thus satisfying assignments of a random 1-in-$k$ SAT
instance form a single cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3208</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3208</id><created>2008-11-19</created><updated>2009-11-24</updated><authors><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Quantum algorithms for highly non-linear Boolean functions</title><categories>quant-ph cs.CC</categories><comments>15 pages, 1 figure, to appear in Proceedings of the 21st Annual
  ACM-SIAM Symposium on Discrete Algorithms (SODA'10). This updated version of
  the paper contains a new exponential separation between classical and quantum
  query complexity</comments><journal-ref>Proceedings of the 21st Annual ACM-SIAM Symposium on Discrete
  Algorithms (SODA'10), pp. 448-457, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attempts to separate the power of classical and quantum models of computation
have a long history. The ultimate goal is to find exponential separations for
computational problems. However, such separations do not come a dime a dozen:
while there were some early successes in the form of hidden subgroup problems
for abelian groups--which generalize Shor's factoring algorithm perhaps most
faithfully--only for a handful of non-abelian groups efficient quantum
algorithms were found. Recently, problems have gotten increased attention that
seek to identify hidden sub-structures of other combinatorial and algebraic
objects besides groups. In this paper we provide new examples for exponential
separations by considering hidden shift problems that are defined for several
classes of highly non-linear Boolean functions. These so-called bent functions
arise in cryptography, where their property of having perfectly flat Fourier
spectra on the Boolean hypercube gives them resilience against certain types of
attack. We present new quantum algorithms that solve the hidden shift problems
for several well-known classes of bent functions in polynomial time and with a
constant number of queries, while the classical query complexity is shown to be
exponential. Our approach uses a technique that exploits the duality between
bent functions and their Fourier transforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3301</identifier>
 <datestamp>2012-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3301</id><created>2008-11-20</created><updated>2009-06-10</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>Faster Retrieval with a Two-Pass Dynamic-Time-Warping Lower Bound</title><categories>cs.DB cs.CV</categories><comments>Accepted in Pattern Recognition on November 20th, 2008</comments><journal-ref>Daniel Lemire, Faster Retrieval with a Two-Pass
  Dynamic-Time-Warping Lower Bound, Pattern Recognition 42(9): 2169-2180 (2009)</journal-ref><doi>10.1016/j.patcog.2008.11.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Dynamic Time Warping (DTW) is a popular similarity measure between time
series. The DTW fails to satisfy the triangle inequality and its computation
requires quadratic time. Hence, to find closest neighbors quickly, we use
bounding techniques. We can avoid most DTW computations with an inexpensive
lower bound (LB Keogh). We compare LB Keogh with a tighter lower bound (LB
Improved). We find that LB Improved-based search is faster. As an example, our
approach is 2-3 times faster over random-walk and shape time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3448</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3448</id><created>2008-11-20</created><updated>2011-05-17</updated><authors><author><keyname>Gilreath</keyname><forenames>William F.</forenames></author></authors><title>Binar Sort: A Linear Generalized Sorting Algorithm</title><categories>cs.DS</categories><comments>PDF from Word, 25-pages, 2-figures, 4-diagrams, version 2.0</comments><acm-class>B.2.4; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sorting is a common and ubiquitous activity for computers. It is not
surprising that there exist a plethora of sorting algorithms. For all the
sorting algorithms, it is an accepted performance limit that sorting algorithms
are linearithmic or O(N lg N). The linearithmic lower bound in performance
stems from the fact that the sorting algorithms use the ordering property of
the data. The sorting algorithm uses comparison by the ordering property to
arrange the data elements from an initial permutation into a sorted
permutation.
  Linear O(N) sorting algorithms exist, but use a priori knowledge of the data
to use a specific property of the data and thus have greater performance. In
contrast, the linearithmic sorting algorithms are generalized by using a
universal property of data-comparison, but have a linearithmic performance
lower bound. The trade-off in sorting algorithms is generality for performance
by the chosen property used to sort the data elements.
  A general-purpose, linear sorting algorithm in the context of the trade-off
of performance for generality at first consideration seems implausible. But,
there is an implicit assumption that only the ordering property is universal.
But, as will be discussed and examined, it is not the only universal property
for data elements. The binar sort is a general-purpose sorting algorithm that
uses this other universal property to sort linearly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3475</identifier>
 <datestamp>2010-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3475</id><created>2008-11-21</created><updated>2010-04-26</updated><authors><author><keyname>Wang</keyname><forenames>Da</forenames></author><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Robust Network Coding in the Presence of Untrusted Nodes</title><categories>cs.IT cs.NI math.IT</categories><comments>7 pages, 4 figures, to be published at the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While network coding can be an efficient means of information dissemination
in networks, it is highly susceptible to "pollution attacks," as the injection
of even a single erroneous packet has the potential to corrupt each and every
packet received by a given destination. Even when suitable error-control coding
is applied, an adversary can, in many interesting practical situations,
overwhelm the error-correcting capability of the code. To limit the power of
potential adversaries, a broadcast transformation is introduced, in which nodes
are limited to just a single (broadcast) transmission per generation. Under
this broadcast transformation, the multicast capacity of a network is changed
(in general reduced) from the number of edge-disjoint paths between source and
sink to the number of internally-disjoint paths. Exploiting this fact, we
propose a family of networks whose capacity is largely unaffected by a
broadcast transformation. This results in a significant achievable transmission
rate for such networks, even in the presence of adversaries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3476</identifier>
 <datestamp>2011-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3476</id><created>2008-11-21</created><updated>2010-01-16</updated><authors><author><keyname>Cousseau</keyname><forenames>Florent</forenames></author><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author><author><keyname>Okada</keyname><forenames>Masato</forenames></author></authors><title>Error correcting code using tree-like multilayer perceptron</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.IT math.IT</categories><comments>23 pages, 3 figures, Content has been extended and revised</comments><journal-ref>Phys. Rev. E, 81, 021104 (2010)</journal-ref><doi>10.1103/PhysRevE.81.021104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An error correcting code using a tree-like multilayer perceptron is proposed.
An original message $\mbi{s}^0$ is encoded into a codeword $\boldmath{y}_0$
using a tree-like committee machine (committee tree) or a tree-like parity
machine (parity tree). Based on these architectures, several schemes featuring
monotonic or non-monotonic units are introduced. The codeword $\mbi{y}_0$ is
then transmitted via a Binary Asymmetric Channel (BAC) where it is corrupted by
noise. The analytical performance of these schemes is investigated using the
replica method of statistical mechanics. Under some specific conditions, some
of the proposed schemes are shown to saturate the Shannon bound at the infinite
codeword length limit. The influence of the monotonicity of the units on the
performance is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3490</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3490</id><created>2008-11-21</created><updated>2011-03-17</updated><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author></authors><title>Faster Approximate String Matching for Short Patterns</title><categories>cs.DS</categories><comments>To appear in Theory of Computing Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the classical approximate string matching problem, that is, given
strings $P$ and $Q$ and an error threshold $k$, find all ending positions of
substrings of $Q$ whose edit distance to $P$ is at most $k$. Let $P$ and $Q$
have lengths $m$ and $n$, respectively. On a standard unit-cost word RAM with
word size $w \geq \log n$ we present an algorithm using time $$ O(nk \cdot
\min(\frac{\log^2 m}{\log n},\frac{\log^2 m\log w}{w}) + n) $$ When $P$ is
short, namely, $m = 2^{o(\sqrt{\log n})}$ or $m = 2^{o(\sqrt{w/\log w})}$ this
improves the previously best known time bounds for the problem. The result is
achieved using a novel implementation of the Landau-Vishkin algorithm based on
tabulation and word-level parallelism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3617</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3617</id><created>2008-11-21</created><updated>2011-05-12</updated><authors><author><keyname>Misra</keyname><forenames>Vinith</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author></authors><title>Distributed Scalar Quantization for Computing: High-Resolution Analysis
  and Extensions</title><categories>cs.IT math.IT</categories><comments>36 pages, 10 figures</comments><journal-ref>IEEE Trans. on Information Theory, vol. 57, no. 8, pp. 5298-5325,
  August 2011</journal-ref><doi>10.1109/TIT.2011.2158882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication of quantized information is frequently followed by a
computation. We consider situations of \emph{distributed functional scalar
quantization}: distributed scalar quantization of (possibly correlated) sources
followed by centralized computation of a function. Under smoothness conditions
on the sources and function, companding scalar quantizer designs are developed
to minimize mean-squared error (MSE) of the computed function as the quantizer
resolution is allowed to grow. Striking improvements over quantizers designed
without consideration of the function are possible and are larger in the
entropy-constrained setting than in the fixed-rate setting. As extensions to
the basic analysis, we characterize a large class of functions for which
regular quantization suffices, consider certain functions for which asymptotic
optimality is achieved without arbitrarily fine quantization, and allow limited
collaboration between source encoders. In the entropy-constrained setting, a
single bit per sample communicated between encoders can have an
arbitrarily-large effect on functional distortion. In contrast, such
communication has very little effect in the fixed-rate setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.3978</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.3978</id><created>2008-11-24</created><updated>2013-11-19</updated><authors><author><keyname>Gimbert</keyname><forenames>Hugo</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Horn</keyname><forenames>Florian</forenames><affiliation>LIAFA</affiliation></author></authors><title>Optimal Strategies in Perfect-Information Stochastic Games with Tail
  Winning Conditions</title><categories>cs.GT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that optimal strategies exist in every perfect-information
stochastic game with finitely many states and actions and a tail winning
condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4089</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4089</id><created>2008-11-25</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Interval greedoids and families of local maximum stable sets of graphs</title><categories>math.CO cs.DM</categories><comments>13 pages, 11 figures</comments><msc-class>05C69, 05B35 (Primary); 51D10, 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A maximum stable set in a graph G is a stable set of maximum cardinality. S
is a local maximum stable set of G, if S is a maximum stable set of the
subgraph induced by its closed neighborhood.
  Nemhauser and Trotter Jr. proved in 1975 that any local maximum stable set is
a subset of a maximum stable set of G. In 2002 we showed that the family of all
local maximum stable sets of a forest forms a greedoid on its vertex set. The
cases where G is bipartite, triangle-free, well-covered, while the family of
all local maximum stable sets is a greedoid, were analyzed in 2004, 2007, and
2008, respectively.
  In this paper we demonstrate that if the family of all local maximum stable
sets of the graph satisfies the accessibility property, then it is an interval
greedoid. We also characterize those graphs whose families of local maximum
stable sets are either antimatroids or matroids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4162</identifier>
 <datestamp>2011-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4162</id><created>2008-11-25</created><updated>2011-10-23</updated><authors><author><keyname>Xie</keyname><forenames>Bike</forenames></author><author><keyname>Courtade</keyname><forenames>Thomas</forenames></author><author><keyname>Wesel</keyname><forenames>Richard D.</forenames></author></authors><title>Optimal Encoding Schemes for Several Classes of Discrete Degraded
  Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>50 pages, 18 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a memoryless degraded broadcast channel (DBC) in which the channel
output is a single-letter function of the channel input and the channel noise.
As examples, for the Gaussian broadcast channel (BC) this single-letter
function is regular Euclidian addition and for the binary-symmetric BC this
single-letter function is Galois-Field-two addition. This paper identifies
several classes of discrete memoryless DBCs for which a relatively simple
encoding scheme, which we call natural encoding, achieves capacity. Natural
Encoding (NE) combines symbols from independent codebooks (one for each
receiver) using the same single-letter function that adds distortion to the
channel. The alphabet size of each NE codebook is bounded by that of the
channel input.
  Inspired by Witsenhausen and Wyner, this paper defines the conditional
entropy bound function $F^*$, studies its properties, and applies them to show
that NE achieves the boundary of the capacity region for the multi-receiver
broadcast Z channel. Then, this paper defines the input-symmetric DBC,
introduces permutation encoding for the input-symmetric DBC, and proves its
optimality. Because it is a special case of permutation encoding, NE is
capacity achieving for the two-receiver group-operation DBC. Combining the
broadcast Z channel and group-operation DBC results yields a proof that NE is
also optimal for the discrete multiplication DBC. Along the way, the paper also
provides explicit parametric expressions for the two-receiver binary-symmetric
DBC and broadcast Z channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4163</identifier>
 <datestamp>2010-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4163</id><created>2008-11-25</created><updated>2010-03-30</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Packing and Covering Properties of Subspace Codes for Error Control in
  Random Linear Network Coding</title><categories>cs.IT math.IT</categories><comments>12 pages, to appear in IEEE Transactions on Information Theory, May
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes in the projective space and codes in the Grassmannian over a finite
field - referred to as subspace codes and constant-dimension codes (CDCs),
respectively - have been proposed for error control in random linear network
coding. For subspace codes and CDCs, a subspace metric was introduced to
correct both errors and erasures, and an injection metric was proposed to
correct adversarial errors. In this paper, we investigate the packing and
covering properties of subspace codes with both metrics. We first determine
some fundamental geometric properties of the projective space with both
metrics. Using these properties, we then derive bounds on the cardinalities of
packing and covering subspace codes, and determine the asymptotic rates of
optimal packing and optimal covering subspace codes with both metrics. Our
results not only provide guiding principles for the code design for error
control in random linear network coding, but also illustrate the difference
between the two metrics from a geometric perspective. In particular, our
results show that optimal packing CDCs are optimal packing subspace codes up to
a scalar for both metrics if and only if their dimension is half of their
length (up to rounding). In this case, CDCs suffer from only limited rate loss
as opposed to subspace codes with the same minimum distance. We also show that
optimal covering CDCs can be used to construct asymptotically optimal covering
subspace codes with the injection metric only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4170</identifier>
 <datestamp>2010-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4170</id><created>2008-11-25</created><updated>2008-11-25</updated><authors><author><keyname>Barrat</keyname><forenames>Alain</forenames></author><author><keyname>Cattuto</keyname><forenames>Ciro</forenames></author><author><keyname>Colizza</keyname><forenames>Vittoria</forenames></author><author><keyname>Pinton</keyname><forenames>Jean-Francois</forenames></author><author><keyname>Broeck</keyname><forenames>Wouter Van den</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>High resolution dynamical mapping of social interactions with active
  RFID</title><categories>cs.CY cs.HC physics.soc-ph</categories><journal-ref>PLoS ONE 5(7): e11596 (2010)</journal-ref><doi>10.1371/journal.pone.0011596</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an experimental framework to gather data on
face-to-face social interactions between individuals, with a high spatial and
temporal resolution. We use active Radio Frequency Identification (RFID)
devices that assess contacts with one another by exchanging low-power radio
packets. When individuals wear the beacons as a badge, a persistent radio
contact between the RFID devices can be used as a proxy for a social
interaction between individuals. We present the results of a pilot study
recently performed during a conference, and a subsequent preliminary data
analysis, that provides an assessment of our method and highlights its
versatility and applicability in many areas concerned with human dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4227</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4227</id><created>2008-11-26</created><updated>2010-03-02</updated><authors><author><keyname>Hsieh</keyname><forenames>Min-Hsiu</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Entanglement-assisted communication of classical and quantum information</title><categories>quant-ph cs.IT math.IT</categories><comments>23 pages, 5 figures, 1 table, simplification of capacity region--it
  now has the simple interpretation as the unit resource capacity region
  translated along the classically-enhanced father trade-off curve</comments><journal-ref>IEEE Transactions on Information Theory, vol. 56, no. 9, pp.
  4682-4704, September 2010</journal-ref><doi>10.1109/TIT.2010.2053903</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of transmitting classical and quantum information
reliably over an entanglement-assisted quantum channel. Our main result is a
capacity theorem that gives a three-dimensional achievable rate region. Points
in the region are rate triples, consisting of the classical communication rate,
the quantum communication rate, and the entanglement consumption rate of a
particular coding scheme. The crucial protocol in achieving the boundary points
of the capacity region is a protocol that we name the classically-enhanced
father protocol. The classically-enhanced father protocol is more general than
other protocols in the family tree of quantum Shannon theoretic protocols, in
the sense that several previously known quantum protocols are now child
protocols of it. The classically-enhanced father protocol also shows an
improvement over a time-sharing strategy for the case of a qubit dephasing
channel--this result justifies the need for simultaneous coding of classical
and quantum information over an entanglement-assisted quantum channel. Our
capacity theorem is of a multi-letter nature (requiring a limit over many uses
of the channel), but it reduces to a single-letter characterization for at
least three channels: the completely depolarizing channel, the quantum erasure
channel, and the qubit dephasing channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4367</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4367</id><created>2008-11-26</created><updated>2010-05-26</updated><authors><author><keyname>Felty</keyname><forenames>Amy</forenames></author><author><keyname>Momigliano</keyname><forenames>Alberto</forenames></author></authors><title>Hybrid: A Definitional Two-Level Approach to Reasoning with Higher-Order
  Abstract Syntax</title><categories>cs.LO</categories><comments>58 pages, with 12 figures. To appear in the Journal of Automated
  Reasoning, accepted April 2010. For associated code, see
  http://hybrid.dsi.unimi.it/jar/index.html</comments><report-no>University of Ottawa Technical Report, number TR-2008-03</report-no><acm-class>F.4.1; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining higher-order abstract syntax and (co)induction in a logical
framework is well known to be problematic. Previous work described the
implementation of a tool called Hybrid, within Isabelle HOL, which aims to
address many of these difficulties. It allows object logics to be represented
using higher-order abstract syntax, and reasoned about using tactical theorem
proving and principles of (co)induction. In this paper we describe how to use
it in a multi-level reasoning fashion, similar in spirit to other meta-logics
such as Twelf. By explicitly referencing provability in a middle layer called a
specification logic, we solve the problem of reasoning by (co)induction in the
presence of non-stratifiable hypothetical judgments, which allow very elegant
and succinct specifications of object logic inference rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4413</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4413</id><created>2008-11-26</created><updated>2012-07-06</updated><authors><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author><author><keyname>Kakade</keyname><forenames>Sham M.</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>A Spectral Algorithm for Learning Hidden Markov Models</title><categories>cs.LG cs.AI</categories><comments>Published in JCSS Special Issue "Learning Theory 2009"</comments><journal-ref>Journal of Computer and System Sciences, 78(5):1460-1480, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov Models (HMMs) are one of the most fundamental and widely used
statistical tools for modeling discrete time series. In general, learning HMMs
from data is computationally hard (under cryptographic assumptions), and
practitioners typically resort to search heuristics which suffer from the usual
local optima issues. We prove that under a natural separation condition (bounds
on the smallest singular value of the HMM parameters), there is an efficient
and provably correct algorithm for learning HMMs. The sample complexity of the
algorithm does not explicitly depend on the number of distinct (discrete)
observations---it implicitly depends on this quantity through spectral
properties of the underlying HMM. This makes the algorithm particularly
applicable to settings with a large number of observations, such as those in
natural language processing where the space of observation is sometimes the
words in a language. The algorithm is also simple, employing only a singular
value decomposition and matrix multiplications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4489</identifier>
 <datestamp>2013-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4489</id><created>2008-11-27</created><updated>2009-03-10</updated><authors><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Xintao</forenames></author></authors><title>Automatic Generation of the Axial Lines of Urban Environments to Capture
  What We Perceive</title><categories>cs.CG cs.CV</categories><comments>13 pages, 9 figures submitted to International Journal of
  Geographical Information Science. With version 2, the concept of bucket has
  been explained and illustrated in more detail. With version 3, better
  formating and finetune</comments><journal-ref>International Journal of Geographical Information Science, 24(4),
  2010, 545-558</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the concepts of isovists and medial axes, we developed a set of
algorithms that can automatically generate axial lines for representing
individual linearly stretched parts of open space of an urban environment. Open
space is the space between buildings, where people can freely move around. The
generation of the axial lines has been a key aspect of space syntax research,
conventionally relying on hand-drawn axial lines of an urban environment, often
called axial map, for urban morphological analysis. Although various attempts
have been made towards an automatic solution, few of them can produce the axial
map that consists of the least number of longest visibility lines, and none of
them really works for different urban environments. Our algorithms provide a
better solution than existing ones. Throughout this paper, we have also argued
and demonstrated that the axial lines constitute a true skeleton, superior to
medial axes, in capturing what we perceive about the urban environment.
  Keywords: Visibility, space syntax, topological analysis, medial axes, axial
lines, isovists
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4699</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4699</id><created>2008-11-28</created><updated>2009-03-03</updated><authors><author><keyname>Sparavigna</keyname><forenames>A.</forenames></author><author><keyname>Marazzato</keyname><forenames>R.</forenames></author></authors><title>Mapping Images with the Coherence Length Diagrams</title><categories>cs.CV</categories><journal-ref>International Journal of Software Engineering and Computing, pp.
  53-57, 2009, Vol. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical pattern recognition methods based on the Coherence Length Diagram
(CLD) have been proposed for medical image analyses, such as quantitative
characterisation of human skin textures, and for polarized light microscopy of
liquid crystal textures. Further investigations are made on image maps
originated from such diagram and some examples related to irregularity of
microstructures are shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0811.4713</identifier>
 <datestamp>2014-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0811.4713</id><created>2008-11-28</created><updated>2014-07-08</updated><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames><affiliation>LaBRI, IUF</affiliation></author><author><keyname>Gavoille</keyname><forenames>Cyril</forenames><affiliation>LaBRI, INRIA Futurs</affiliation></author><author><keyname>Kanté</keyname><forenames>Mamadou Moustapha</forenames><affiliation>LaBRI</affiliation></author></authors><title>Compact Labelings For Efficient First-Order Model-Checking</title><categories>cs.DS cs.LO</categories><proxy>ccsd hal-00342668</proxy><msc-class>68R05, 68R10, 05C78, 05C85</msc-class><acm-class>F.0; G.2.2</acm-class><journal-ref>Journal of Combinatorial Optimisation 21(1):19-46(2011)</journal-ref><doi>10.1007/s10878-009-9260-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider graph properties that can be checked from labels, i.e., bit
sequences, of logarithmic length attached to vertices. We prove that there
exists such a labeling for checking a first-order formula with free set
variables in the graphs of every class that is \emph{nicely locally
cwd-decomposable}. This notion generalizes that of a \emph{nicely locally
tree-decomposable} class. The graphs of such classes can be covered by graphs
of bounded \emph{clique-width} with limited overlaps. We also consider such
labelings for \emph{bounded} first-order formulas on graph classes of
\emph{bounded expansion}. Some of these results are extended to counting
queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0038</identifier>
 <datestamp>2010-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0038</id><created>2008-11-28</created><updated>2010-11-14</updated><authors><author><keyname>Xie</keyname><forenames>Liang-Liang</forenames></author></authors><title>Omnidirectional Relay in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>Revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For wireless networks with multiple sources, an omnidirectional relay scheme
is developed, where each node can simultaneously relay different messages in
different directions. This is accomplished by the decode-and-forward relay
strategy, with each relay binning the multiple messages to be transmitted, in
the same spirit of network coding. Specially for the all-source all-cast
problem, where each node is an independent source to be transmitted to all the
other nodes, this scheme completely eliminates interference in the whole
network, and the signal transmitted by any node can be used by any other node.
For networks with some kind of symmetry, assuming no beamforming is to be
performed, this omnidirectional relay scheme is capable of achieving the
maximum achievable rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0146</identifier>
 <datestamp>2013-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0146</id><created>2008-11-30</created><updated>2012-02-24</updated><authors><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Lower Bounds on Performance of Metric Tree Indexing Schemes for Exact
  Similarity Search in High Dimensions</title><categories>cs.DS</categories><comments>21 pages, revised submission to Algorithmica, an improved and
  extended journal version of the conference paper arXiv:0812.0146v3 [cs.DS],
  with lower bounds strengthened, and the proof of the main Theorem 4
  simplified</comments><msc-class>68P10</msc-class><acm-class>H.3.3</acm-class><journal-ref>Algorithmica 66 (2013), 310-328</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within a mathematically rigorous model, we analyse the curse of
dimensionality for deterministic exact similarity search in the context of
popular indexing schemes: metric trees. The datasets $X$ are sampled randomly
from a domain $\Omega$, equipped with a distance, $\rho$, and an underlying
probability distribution, $\mu$. While performing an asymptotic analysis, we
send the intrinsic dimension $d$ of $\Omega$ to infinity, and assume that the
size of a dataset, $n$, grows superpolynomially yet subexponentially in $d$.
Exact similarity search refers to finding the nearest neighbour in the dataset
$X$ to a query point $\omega\in\Omega$, where the query points are subject to
the same probability distribution $\mu$ as datapoints. Let $\mathscr F$ denote
a class of all 1-Lipschitz functions on $\Omega$ that can be used as decision
functions in constructing a hierarchical metric tree indexing scheme. Suppose
the VC dimension of the class of all sets $\{\omega\colon f(\omega)\geq a\}$,
$a\in\R$ is $o(n^{1/4}/\log^2n)$. (In view of a 1995 result of Goldberg and
Jerrum, even a stronger complexity assumption $d^{O(1)}$ is reasonable.) We
deduce the $\Omega(n^{1/4})$ lower bound on the expected average case
performance of hierarchical metric-tree based indexing schemes for exact
similarity search in $(\Omega,X)$. In paricular, this bound is superpolynomial
in $d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0320</identifier>
 <datestamp>2011-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0320</id><created>2008-12-01</created><authors><author><keyname>Joret</keyname><forenames>Gwenaël</forenames></author></authors><title>Stackelberg Network Pricing is Hard to Approximate</title><categories>cs.DS cs.GT</categories><journal-ref>Networks, vol. 57, no. 2, pp. 117--120, 2011</journal-ref><doi>10.1002/net.20391</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Stackelberg Network Pricing problem, one has to assign tariffs to a
certain subset of the arcs of a given transportation network. The aim is to
maximize the amount paid by the user of the network, knowing that the user will
take a shortest st-path once the tariffs are fixed. Roch, Savard, and Marcotte
(Networks, Vol. 46(1), 57-67, 2005) proved that this problem is NP-hard, and
gave an O(log m)-approximation algorithm, where m denote the number of arcs to
be priced. In this note, we show that the problem is also APX-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0340</identifier>
 <datestamp>2013-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0340</id><created>2008-12-01</created><updated>2009-10-01</updated><authors><author><keyname>Morgan</keyname><forenames>Simon P.</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Vixie</keyname><forenames>Kevin R.</forenames></author></authors><title>A Matlab Implementation of a Flat Norm Motivated Polygonal Edge Matching
  Method using a Decomposition of Boundary into Four 1-Dimensional Currents</title><categories>cs.CV cs.CG</categories><comments>Contains Matlab code and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe and provide code and examples for a polygonal edge matching
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0372</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0372</id><created>2008-12-01</created><authors><author><keyname>Gravin</keyname><forenames>Nikolay</forenames></author></authors><title>Non-degenerate colorings in the Brook's Theorem</title><categories>math.CO cs.DM</categories><comments>18 pages, 10 figures</comments><report-no>MR2641023</report-no><journal-ref>Diskretnaya Matematika, 2009 N4 pp. 105-128</journal-ref><doi>10.1515/DMA.2009.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $c\geq 2$ and $p\geq c$ be two integers. We will call a proper coloring
of the graph $G$ a \textit{$(c,p)$-nondegenerate}, if for any vertex of $G$
with degree at least $p$ there are at least $c$ vertices of different colors
adjacent to it. In our work we prove the following result, which generalizes
Brook's Theorem. Let $D\geq 3$ and $G$ be a graph without cliques on $D+1$
vertices and the degree of any vertex in this graph is not greater than $D$.
Then for every integer $c\geq 2$ there is a proper $(c,p)$-nondegenerate vertex
$D$-coloring of $G$, where $p=(c^3+8c^2+19c+6)(c+1).$ During the primary proof,
some interesting corollaries are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0607</identifier>
 <datestamp>2010-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0607</id><created>2008-12-02</created><updated>2010-05-13</updated><authors><author><keyname>Dickerson</keyname><forenames>Matthew</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Wortman</keyname><forenames>Kevin A.</forenames></author></authors><title>Dilation, smoothed distance, and minimization diagrams of convex
  functions</title><categories>cs.CG</categories><comments>10 pages, 6 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Voronoi diagrams for distance functions that add together two convex
functions, each taking as its argument the difference between Cartesian
coordinates of two planar points. When the functions do not grow too quickly,
then the Voronoi diagram has linear complexity and can be constructed in
near-linear randomized expected time. Additionally, the level sets of the
distances from the sites form a family of pseudocircles in the plane, all cells
in the Voronoi diagram are connected, and the set of bisectors separating any
one cell in the diagram from each of the others forms an arrangement of
pseudolines in the plane. We apply these results to the smoothed distance or
biotope transform metric, a geometric analogue of the Jaccard distance whose
Voronoi diagrams can be used to determine the dilation of a star network with a
given hub. For sufficiently closely spaced points in the plane, the Voronoi
diagram of smoothed distance has linear complexity and can be computed
efficiently. We also experiment with a variant of Lloyd's algorithm, adapted to
smoothed distance, to find uniformly spaced point samples with exponentially
decreasing density around a given point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0852</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0852</id><created>2008-12-03</created><updated>2009-03-10</updated><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Yu</keyname><forenames>Sheng</forenames></author></authors><title>Hierarchy and equivalence of multi-letter quantum finite automata</title><categories>cs.CC</categories><comments>22 pages, 8 figures. The is a further revised version, and it has
  been accepted for publication in Theoretical Computer Science</comments><acm-class>F.1.1; F.1.2; F.4.3</acm-class><journal-ref>Theoretical Computer Science, 410 (30-32) (2009) 3006-3017.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-letter {\it quantum finite automata} (QFAs) were a new one-way QFA
model proposed recently by Belovs, Rosmanis, and Smotrovs (LNCS, Vol. 4588,
Springer, Berlin, 2007, pp. 60-71), and they showed that multi-letter QFAs can
accept with no error some regular languages ($(a+b)^{*}b$) that are
unacceptable by the one-way QFAs. In this paper, we continue to study
multi-letter QFAs. We mainly focus on two issues: (1) we show that
$(k+1)$-letter QFAs are computationally more powerful than $k$-letter QFAs,
that is, $(k+1)$-letter QFAs can accept some regular languages that are
unacceptable by any $k$-letter QFA. A comparison with the one-way QFAs is made
by some examples; (2) we prove that a $k_{1}$-letter QFA ${\cal A}_1$ and
another $k_{2}$-letter QFA ${\cal A}_2$ are equivalent if and only if they are
$(n_{1}+n_{2})^{4}+k-1$-equivalent, and the time complexity of determining the
equivalence of two multi-letter QFAs using this method is
$O(n^{12}+k^{2}n^{4}+kn^{8})$, where $n_{1}$ and $n_{2}$ are the numbers of
states of ${\cal A}_{1}$ and ${\cal A}_{2}$, respectively, and
$k=\max(k_{1},k_{2})$. Some other issues are addressed for further
consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0885</identifier>
 <datestamp>2013-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0885</id><created>2008-12-04</created><updated>2013-02-09</updated><authors><author><keyname>Horvat</keyname><forenames>Marko</forenames></author></authors><title>Elementary epistemological features of machine intelligence</title><categories>cs.AI</categories><comments>The paper needs to be redesigned</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Theoretical analysis of machine intelligence (MI) is useful for defining a
common platform in both theoretical and applied artificial intelligence (AI).
The goal of this paper is to set canonical definitions that can assist
pragmatic research in both strong and weak AI. Described epistemological
features of machine intelligence include relationship between intelligent
behavior, intelligent and unintelligent machine characteristics, observable and
unobservable entities and classification of intelligence. The paper also
establishes algebraic definitions of efficiency and accuracy of MI tests as
their quality measure. The last part of the paper addresses the learning
process with respect to the traditional epistemology and the epistemology of MI
described here. The proposed views on MI positively correlate to the Hegelian
monistic epistemology and contribute towards amalgamating idealistic
deliberations with the AI theory, particularly in a local frame of reference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0893</identifier>
 <datestamp>2010-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0893</id><created>2008-12-04</created><updated>2009-05-13</updated><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author></authors><title>Linear-Time Algorithms for Geometric Graphs with Sublinearly Many Edge
  Crossings</title><categories>cs.CG cs.DM cs.DS cs.GR</categories><comments>Expanded version of a paper appearing at the 20th ACM-SIAM Symposium
  on Discrete Algorithms (SODA09)</comments><acm-class>F.2.2; G.2.2; G.3</acm-class><journal-ref>SIAM J. Computing 39(8): 3814-3829, 2010</journal-ref><doi>10.1137/090759112</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide linear-time algorithms for geometric graphs with sublinearly many
crossings. That is, we provide algorithms running in O(n) time on connected
geometric graphs having n vertices and k crossings, where k is smaller than n
by an iterated logarithmic factor. Specific problems we study include Voronoi
diagrams and single-source shortest paths. Our algorithms all run in linear
time in the standard comparison-based computational model; hence, we make no
assumptions about the distribution or bit complexities of edge weights, nor do
we utilize unusual bit-level operations on memory words. Instead, our
algorithms are based on a planarization method that "zeroes in" on edge
crossings, together with methods for extending planar separator decompositions
to geometric graphs with sublinearly many crossings. Incidentally, our
planarization algorithm also solves an open computational geometry problem of
Chazelle for triangulating a self-intersecting polygonal chain having n
segments and k crossings in linear time, for the case when k is sublinear in n
by an iterated logarithmic factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.0956</identifier>
 <datestamp>2010-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.0956</id><created>2008-12-04</created><updated>2010-09-03</updated><authors><author><keyname>Hartig</keyname><forenames>Florian</forenames></author><author><keyname>Horn</keyname><forenames>Martin</forenames></author><author><keyname>Drechsler</keyname><forenames>Martin</forenames></author></authors><title>EcoTRADE - a multi player network game of a tradable permit market for
  biodiversity credits</title><categories>cs.GT</categories><comments>3 pages, 1 figure</comments><journal-ref>Environmental Modelling &amp; Software, 2010, 25, 1479-1480</journal-ref><doi>10.1016/j.envsoft.2009.01.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  EcoTRADE is a multi player network game of a virtual biodiversity credit
market. Each player controls the land use of a certain amount of parcels on a
virtual landscape. The biodiversity credits of a particular parcel depend on
neighboring parcels, which may be owned by other players. The game can be used
to study the strategies of players in experiments or classroom games and also
as a communication tool for stakeholders participating in credit markets that
include spatially interdependent credits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1012</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1012</id><created>2008-12-04</created><updated>2010-01-28</updated><authors><author><keyname>Guha</keyname><forenames>Sudipto</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author></authors><title>Adaptive Uncertainty Resolution in Bayesian Combinatorial Optimization
  Problems</title><categories>cs.DS</categories><comments>Journal version of the paper "Model-driven Optimization using
  Adaptive Probes" that appeared in the ACM-SIAM Symposium on Discrete
  Algorithms (SODA), 2007</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In several applications such as databases, planning, and sensor networks,
parameters such as selectivity, load, or sensed values are known only with some
associated uncertainty. The performance of such a system (as captured by some
objective function over the parameters) is significantly improved if some of
these parameters can be probed or observed. In a resource constrained
situation, deciding which parameters to observe in order to optimize system
performance itself becomes an interesting and important optimization problem.
This general problem is the focus of this paper.
  One of the most important considerations in this framework is whether
adaptivity is required for the observations. Adaptive observations introduce
blocking or sequential operations in the system whereas non-adaptive
observations can be performed in parallel. One of the important questions in
this regard is to characterize the benefit of adaptivity for probes and
observation.
  We present general techniques for designing constant factor approximations to
the optimal observation schemes for several widely used scheduling and metric
objective functions. We show a unifying technique that relates this
optimization problem to the outlier version of the corresponding deterministic
optimization. By making this connection, our technique shows constant factor
upper bounds for the benefit of adaptivity of the observation schemes. We show
that while probing yields significant improvement in the objective function,
being adaptive about the probing is not beneficial beyond constant factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1061</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1061</id><created>2008-12-04</created><updated>2010-10-24</updated><authors><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author><author><keyname>Zou</keyname><forenames>Xiangfu</forenames></author><author><keyname>Li</keyname><forenames>Lvzhou</forenames></author><author><keyname>Mateus</keyname><forenames>Paulo</forenames></author></authors><title>Decidability of the Equivalence of Multi-Letter Quantum Finite Automata</title><categories>cs.FL cs.CC</categories><comments>18 pages; this is a further revised version</comments><acm-class>F.1.1; F.1.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-letter {\it quantum finite automata} (QFAs) were a quantum variant of
classical {\it one-way multi-head finite automata} (J. Hromkovi\v{c}, Acta
Informatica 19 (1983) 377-384), and it has been shown that this new one-way
QFAs (multi-letter QFAs) can accept with no error some regular languages
$(a+b)^{*}b$ that are unacceptable by the previous one-way QFAs. In this paper,
we study the decidability of the equivalence of multi-letter QFAs, and the main
technical contributions are as follows: (1) We show that any two automata, a
$k_{1}$-letter QFA ${\cal A}_1$ and a $k_{2}$-letter QFA ${\cal A}_2$, over the
same input alphabet $\Sigma$ are equivalent if and only if they are
$(n^2m^{k-1}-m^{k-1}+k)$-equivalent, where $m=|\Sigma|$ is the cardinality of
$\Sigma$, $k=\max(k_{1},k_{2})$, and $n=n_{1}+n_{2}$, with $n_{1}$ and $n_{2}$
being the numbers of states of ${\cal A}_{1}$ and ${\cal A}_{2}$, respectively.
When $k=1$, we obtain the decidability of equivalence of measure-once QFAs in
the literature. It is worth mentioning that our technical method is essentially
different from that for the decidability of the case of single input alphabet
(i.e., $m=1$). (2) However, if we determine the equivalence of multi-letter
QFAs by checking all strings of length not more than $ n^2m^{k-1}-m^{k-1}+k$,
then the worst time complexity is exponential, i.e.,
$O(n^6m^{n^2m^{k-1}-m^{k-1}+2k-1})$. Therefore, we design a polynomial-time
$O(m^{2k-1}n^{8}+km^kn^{6})$ algorithm for determining the equivalence of any
two multi-letter QFAs. Here, the time complexity is concerning the number of
states in the multi-letter QFAs, and $k$ is thought of as a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1200</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1200</id><created>2008-12-05</created><updated>2010-01-09</updated><authors><author><keyname>Basu</keyname><forenames>Saugata</forenames></author><author><keyname>Zell</keyname><forenames>Thierry</forenames></author></authors><title>Polynomial hierarchy, Betti numbers and a real analogue of Toda's
  theorem</title><categories>cs.CC math.AT math.CO math.LO</categories><comments>Final version to appear in Found. Comput. Math</comments><journal-ref>Found. Comput. Math, 10:429-454, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Toda proved in 1989 that the (discrete) polynomial time hierarchy,
$\mathbf{PH}$, is contained in the class $\mathbf{P}^{#\mathbf{P}}$, namely the
class of languages that can be decided by a Turing machine in polynomial time
given access to an oracle with the power to compute a function in the counting
complexity class $#\mathbf{P}$. This result which illustrates the power of
counting is considered to be a seminal result in computational complexity
theory. An analogous result in the complexity theory over the reals (in the
sense of Blum-Shub-Smale real machines) has been missing so far. In this paper
we formulate and prove a real analogue of Toda's theorem. Unlike Toda's proof
in the discrete case, which relied on sophisticated combinatorial arguments,
our proof is topological in nature. As a consequence of our techniques we are
also able to relate the computational hardness of two extremely well-studied
problems in algorithmic semi-algebraic geometry -- namely the problem of
deciding sentences in the first order theory of the reals with a constant
number of quantifier alternations, and that of computing Betti numbers of
semi-algebraic sets. We obtain a polynomial time reduction of the compact
version of the first problem to the second. This latter result might be of
independent interest to researchers in algorithmic semi-algebraic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1364</identifier>
 <datestamp>2013-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1364</id><created>2008-12-07</created><authors><author><keyname>Godlin</keyname><forenames>Benny</forenames></author><author><keyname>Katz</keyname><forenames>Emilia</forenames></author><author><keyname>Makowsky</keyname><forenames>Johann A.</forenames></author></authors><title>Graph Polynomials: From Recursive Definitions To Subset Expansion
  Formulas</title><categories>cs.LO cs.DM</categories><comments>25 pages, 2 figures</comments><journal-ref>Journal of Logic and Computation, Volume 22(2), (2012) Pages
  237-265</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many graph polynomials, such as the Tutte polynomial, the interlace
polynomial and the matching polynomial, have both a recursive definition and a
defining subset expansion formula. In this paper we present a general,
logic-based framework which gives a precise meaning to recursive definitions of
graph polynomials. We then prove that in this framework every recursive
definition of a graph polynomial can be converted into a subset expansion
formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.1811</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.1811</id><created>2008-12-09</created><updated>2009-03-11</updated><authors><author><keyname>Delvenne</keyname><forenames>J. -C.</forenames></author><author><keyname>Yaliraki</keyname><forenames>S. N.</forenames></author><author><keyname>Barahona</keyname><forenames>M.</forenames></author></authors><title>Stability of graph communities across time scales</title><categories>physics.soc-ph cs.IR physics.data-an</categories><comments>submitted; updated bibliography from v3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of biological, social and engineering networks makes it
desirable to find natural partitions into communities that can act as
simplified descriptions and provide insight into the structure and function of
the overall system. Although community detection methods abound, there is a
lack of consensus on how to quantify and rank the quality of partitions. We
show here that the quality of a partition can be measured in terms of its
stability, defined in terms of the clustered autocovariance of a Markov process
taking place on the graph. Because the stability has an intrinsic dependence on
time scales of the graph, it allows us to compare and rank partitions at each
time and also to establish the time spans over which partitions are optimal.
Hence the Markov time acts effectively as an intrinsic resolution parameter
that establishes a hierarchy of increasingly coarser clusterings. Within our
framework we can then provide a unifying view of several standard partitioning
measures: modularity and normalized cut size can be interpreted as one-step
time measures, whereas Fiedler's spectral clustering emerges at long times. We
apply our method to characterize the relevance and persistence of partitions
over time for constructive and real networks, including hierarchical graphs and
social networks. We also obtain reduced descriptions for atomic level protein
structures over different time scales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2291</identifier>
 <datestamp>2013-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2291</id><created>2008-12-11</created><updated>2013-06-03</updated><authors><author><keyname>Babaioff</keyname><forenames>Moshe</forenames></author><author><keyname>Sharma</keyname><forenames>Yogeshwer</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Characterizing Truthful Multi-Armed Bandit Mechanisms</title><categories>cs.DS cs.GT cs.LG</categories><comments>This is the full version of a conference paper published in ACM EC
  2009. This revision is re-focused to emphasize the results that do not rely
  on the "IIA assumption" (see the paper for the definition)</comments><acm-class>F.2.2; K.4.4; F.1.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multi-round auction setting motivated by pay-per-click auctions
for Internet advertising. In each round the auctioneer selects an advertiser
and shows her ad, which is then either clicked or not. An advertiser derives
value from clicks; the value of a click is her private information. Initially,
neither the auctioneer nor the advertisers have any information about the
likelihood of clicks on the advertisements. The auctioneer's goal is to design
a (dominant strategies) truthful mechanism that (approximately) maximizes the
social welfare.
  If the advertisers bid their true private values, our problem is equivalent
to the "multi-armed bandit problem", and thus can be viewed as a strategic
version of the latter. In particular, for both problems the quality of an
algorithm can be characterized by "regret", the difference in social welfare
between the algorithm and the benchmark which always selects the same "best"
advertisement. We investigate how the design of multi-armed bandit algorithms
is affected by the restriction that the resulting mechanism must be truthful.
We find that truthful mechanisms have certain strong structural properties --
essentially, they must separate exploration from exploitation -- and they incur
much higher regret than the optimal multi-armed bandit algorithms. Moreover, we
provide a truthful mechanism which (essentially) matches our lower bound on
regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2298</identifier>
 <datestamp>2010-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2298</id><created>2008-12-12</created><authors><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author></authors><title>Efficient Isomorphism Testing for a Class of Group Extensions</title><categories>cs.DS cs.CC math.GR quant-ph</categories><comments>17 pages, accepted to the STACS 2009 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The group isomorphism problem asks whether two given groups are isomorphic or
not. Whereas the case where both groups are abelian is well understood and can
be solved efficiently, very little is known about the complexity of isomorphism
testing for nonabelian groups. In this paper we study this problem for a class
of groups corresponding to one of the simplest ways of constructing nonabelian
groups from abelian groups: the groups that are extensions of an abelian group
A by a cyclic group of order m. We present an efficient algorithm solving the
group isomorphism problem for all the groups of this class such that the order
of A is coprime with m. More precisely, our algorithm runs in time almost
linear in the orders of the input groups and works in the general setting where
the groups are given as black-boxes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2301</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2301</id><created>2008-12-12</created><updated>2010-10-18</updated><authors><author><keyname>Byun</keyname><forenames>Ilmu</forenames></author><author><keyname>Kim</keyname><forenames>Kwang Soon</forenames></author></authors><title>Cooperative Hybrid ARQ Protocols: Unified Frameworks for Protocol
  Analysis</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author for submission to another
  journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative hybrid-ARQ (HARQ) protocols, which can exploit the spatial and
temporal diversities, have been widely studied. The efficiency of cooperative
HARQ protocols is higher than that of cooperative protocols, because
retransmissions are only performed when necessary. We classify cooperative HARQ
protocols as three decode-and-forward based HARQ (DF-HARQ) protocols and two
amplified-and-forward based (AF-HARQ) protocols. To compare these protocols and
obtain the optimum parameters, two unified frameworks are developed for
protocol analysis. Using the frameworks, we can evaluate and compare the
maximum throughput and outage probabilities according to the SNR, the relay
location, and the delay constraint for the protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2379</identifier>
 <datestamp>2010-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2379</id><created>2008-12-12</created><updated>2010-03-31</updated><authors><author><keyname>Gadouleau</keyname><forenames>Maximilien</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>On the Decoder Error Probability of Rank Metric Codes and
  Constant-Dimension Codes</title><categories>cs.IT math.IT</categories><comments>19 pages, 2 figures, submitted to IEEE Transactions on Information
  Theory. Revised in May 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rank metric codes and constant-dimension codes (CDCs) have been considered
for error control in random network coding. Since decoder errors are more
detrimental to system performance than decoder failures, in this paper we
investigate the decoder error probability (DEP) of bounded distance decoders
(BDDs) for rank metric codes and CDCs. For rank metric codes, we consider a
channel motivated by network coding, where errors with the same row space are
equiprobable. Over such channels, we establish upper bounds on the DEPs of
BDDs, determine the exact DEP of BDDs for maximum rank distance (MRD) codes,
and show that MRD codes have the greatest DEPs up to a scalar. To evaluate the
DEPs of BDDs for CDCs, we first establish some fundamental geometric properties
of the projective space. Using these geometric properties, we then consider
BDDs in both subspace and injection metrics and derive analytical expressions
of their DEPs for CDCs, over a symmetric operator channel, as functions of
their distance distributions. Finally, we focus on CDCs obtained by lifting
rank metric codes and establish two important results: First, we derive
asymptotically tight upper bounds on the DEPs of BDDs in both metrics; Second,
we show that the DEPs for KK codes are the greatest up to a scalar among all
CDCs obtained by lifting rank metric codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2386</identifier>
 <datestamp>2010-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2386</id><created>2008-12-12</created><updated>2009-07-21</updated><authors><author><keyname>Alon</keyname><forenames>Noga</forenames></author><author><keyname>Ben-Shimon</keyname><forenames>Sonny</forenames></author><author><keyname>Krivelevich</keyname><forenames>Michael</forenames></author></authors><title>A note on regular Ramsey graphs</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><journal-ref>Journal of Graph Theory, 64 (3):244--249, 2010</journal-ref><doi>10.1002/jgt.20453</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that there is an absolute constant $C&gt;0$ so that for every natural
$n$ there exists a triangle-free \emph{regular} graph with no independent set
of size at least $C\sqrt{n\log n}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2567</identifier>
 <datestamp>2014-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2567</id><created>2008-12-13</created><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author></authors><title>An $O({\log n\over \log\log n})$ Upper Bound on the Price of Stability
  for Undirected Shapley Network Design Games</title><categories>cs.GT</categories><journal-ref>Information Processing Letters archive Volume 109 Issue 15, July,
  2009 Pages 876-878</journal-ref><doi>10.1016/j.ipl.2009.04.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the Shapley network design game on undirected
networks. In this game, we have an edge weighted undirected network $G(V,E)$
and $n$ selfish players where player $i$ wants to choose a path from source
vertex $s_i$ to destination vertex $t_i$. The cost of each edge is equally
split among players who pass it. The price of stability is defined as the ratio
of the cost of the best Nash equilibrium to that of the optimal solution. We
present an $O(\log n/\log\log n)$ upper bound on price of stability for the
single sink case, i.e, $t_i=t$ for all $i$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2851</identifier>
 <datestamp>2010-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2851</id><created>2008-12-15</created><updated>2010-02-11</updated><authors><author><keyname>Elmasry</keyname><forenames>Amr</forenames></author></authors><title>The Violation Heap: A Relaxed Fibonacci-Like Heap</title><categories>cs.DS</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a priority queue that achieves the same amortized bounds as Fibonacci
heaps. Namely, find-min requires O(1) worst-case time, insert, meld and
decrease-key require O(1) amortized time, and delete-min requires $O(\log n)$
amortized time. Our structure is simple and promises an efficient practical
behavior when compared to other known Fibonacci-like heaps. The main idea
behind our construction is to propagate rank updates instead of performing
cascaded cuts following a decrease-key operation, allowing for a relaxed
structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.2870</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.2870</id><created>2008-12-15</created><updated>2011-01-24</updated><authors><author><keyname>Knauer</keyname><forenames>Kolja</forenames></author><author><keyname>Micek</keyname><forenames>Piotr</forenames></author><author><keyname>Ueckerdt</keyname><forenames>Torsten</forenames></author></authors><title>How to eat 4/9 of a pizza</title><categories>cs.DM math.CO</categories><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two players alternately picking pieces of a pizza sliced by radial
cuts, in such a way that after the first piece is taken every subsequent chosen
piece is adjacent to some previously taken piece, we provide a strategy for the
starting player to get 4/9 of the pizza. This is best possible and settles a
conjecture of Peter Winkler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3429</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3429</id><created>2008-12-17</created><updated>2012-03-14</updated><authors><author><keyname>Gavinsky</keyname><forenames>Dmitry</forenames></author></authors><title>Quantum Predictive Learning and Communication Complexity with Single
  Input</title><categories>quant-ph cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a new model of quantum learning that we call Predictive Quantum
(PQ). This is a quantum analogue of PAC, where during the testing phase the
student is only required to answer a polynomial number of testing queries.
  We demonstrate a relational concept class that is efficiently learnable in
PQ, while in any "reasonable" classical model exponential amount of training
data would be required. This is the first unconditional separation between
quantum and classical learning.
  We show that our separation is the best possible in several ways; in
particular, there is no analogous result for a functional class, as well as for
several weaker versions of quantum learning. In order to demonstrate tightness
of our separation we consider a special case of one-way communication that we
call single-input mode, where Bob receives no input. Somewhat surprisingly,
this setting becomes nontrivial when relational communication tasks are
considered. In particular, any problem with two-sided input can be transformed
into a single-input relational problem of equal classical one-way cost. We show
that the situation is different in the quantum case, where the same
transformation can make the communication complexity exponentially larger. This
happens if and only if the original problem has exponential gap between quantum
and classical one-way communication costs. We believe that these auxiliary
results might be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3447</identifier>
 <datestamp>2011-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3447</id><created>2008-12-17</created><updated>2011-04-05</updated><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Completion Time Minimization and Robust Power Control in Wireless Packet
  Networks</title><categories>cs.IT math.IT</categories><comments>16 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless packet network is considered in which each user transmits a stream
of packets to its destination. The transmit power of each user interferes with
the transmission of all other users. A convex cost function of the completion
times of the user packets is minimized by optimally allocating the users'
transmission power subject to their respective power constraints. At all ranges
of SINR, completion time minimization can be formulated as a convex
optimization problem and hence can be efficiently solved. In particular,
although the feasible rate region of the wireless network is non-convex, its
corresponding completion time region is shown to be convex. When channel
knowledge is imperfect, robust power control is considered based on the channel
fading distribution subject to outage probability constraints. The problem is
shown to be convex when the fading distribution is log-concave in exponentiated
channel power gains; e.g., when each user is under independent Rayleigh,
Nakagami, or log-normal fading. Applying the optimization frameworks in a
wireless cellular network, the average completion time is significantly reduced
as compared to full power transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3465</identifier>
 <datestamp>2010-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3465</id><created>2008-12-18</created><updated>2010-02-24</updated><authors><author><keyname>Rusmevichientong</keyname><forenames>Paat</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Linearly Parameterized Bandits</title><categories>cs.LG</categories><comments>40 pages; updated results and references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider bandit problems involving a large (possibly infinite) collection
of arms, in which the expected reward of each arm is a linear function of an
$r$-dimensional random vector $\mathbf{Z} \in \mathbb{R}^r$, where $r \geq 2$.
The objective is to minimize the cumulative regret and Bayes risk. When the set
of arms corresponds to the unit sphere, we prove that the regret and Bayes risk
is of order $\Theta(r \sqrt{T})$, by establishing a lower bound for an
arbitrary policy, and showing that a matching upper bound is obtained through a
policy that alternates between exploration and exploitation phases. The
phase-based policy is also shown to be effective if the set of arms satisfies a
strong convexity condition. For the case of a general set of arms, we describe
a near-optimal policy whose regret and Bayes risk admit upper bounds of the
form $O(r \sqrt{T} \log^{3/2} T)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3632</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3632</id><created>2008-12-18</created><updated>2009-12-13</updated><authors><author><keyname>Sarnowski</keyname><forenames>Wojciech</forenames></author><author><keyname>Szajowski</keyname><forenames>Krzysztof</forenames></author></authors><title>Optimal detection of homogeneous segment of observations in stochastic
  sequence</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>13 pages</comments><report-no>Institute of Mathematics, Polish Academy of Science 696</report-no><msc-class>60G40 60K99, 90D60</msc-class><journal-ref>Stochastics An International Journal of Probability and Stochastic
  Processes, Vol. 83, Issue 4-6, 2011, pp. 569-581</journal-ref><doi>10.1080/17442508.2010.540015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Markov process is registered. At random moment $\theta$ the distribution of
observed sequence changes. Using probability maximizing approach the optimal
stopping rule for detecting the change is identified. Some explicit solution is
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.3709</identifier>
 <datestamp>2013-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.3709</id><created>2008-12-19</created><updated>2012-05-22</updated><authors><author><keyname>Ng</keyname><forenames>Chris T. K.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Tian</keyname><forenames>Chao</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Minimum Expected Distortion in Gaussian Source Coding with Fading Side
  Information</title><categories>cs.IT math.IT</categories><comments>24 pages, 10 figures</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 58, no. 9, pp. 5725-5739, Sep. 2012</journal-ref><doi>10.1109/TIT.2012.2204476</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encoder, subject to a rate constraint, wishes to describe a Gaussian
source under squared error distortion. The decoder, besides receiving the
encoder's description, also observes side information consisting of
uncompressed source symbol subject to slow fading and noise. The decoder knows
the fading realization but the encoder knows only its distribution. The
rate-distortion function that simultaneously satisfies the distortion
constraints for all fading states was derived by Heegard and Berger. A layered
encoding strategy is considered in which each codeword layer targets a given
fading state. When the side-information channel has two discrete fading states,
the expected distortion is minimized by optimally allocating the encoding rate
between the two codeword layers. For multiple fading states, the minimum
expected distortion is formulated as the solution of a convex optimization
problem with linearly many variables and constraints. Through a limiting
process on the primal and dual solutions, it is shown that single-layer rate
allocation is optimal when the fading probability density function is
continuous and quasiconcave (e.g., Rayleigh, Rician, Nakagami, and log-normal).
In particular, under Rayleigh fading, the optimal single codeword layer targets
the least favorable state as if the side information was absent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4235</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4235</id><created>2008-12-22</created><updated>2010-01-11</updated><authors><author><keyname>Dinuzzo</keyname><forenames>Francesco</forenames></author><author><keyname>Pillonetto</keyname><forenames>Gianluigi</forenames></author><author><keyname>De Nicolao</keyname><forenames>Giuseppe</forenames></author></authors><title>Client-server multi-task learning from distributed datasets</title><categories>cs.LG cs.AI</categories><doi>10.1109/TNN.2010.2095882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A client-server architecture to simultaneously solve multiple learning tasks
from distributed datasets is described. In such architecture, each client is
associated with an individual learning task and the associated dataset of
examples. The goal of the architecture is to perform information fusion from
multiple datasets while preserving privacy of individual data. The role of the
server is to collect data in real-time from the clients and codify the
information in a common database. The information coded in this database can be
used by all the clients to solve their individual learning task, so that each
client can exploit the informative content of all the datasets without actually
having access to private data of others. The proposed algorithmic framework,
based on regularization theory and kernel methods, uses a suitable class of
mixed effect kernels. The new method is illustrated through a simulated music
recommendation system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4279</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4279</id><created>2008-12-22</created><updated>2010-04-22</updated><authors><author><keyname>Stein</keyname><forenames>Noah D.</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author></authors><title>Correlated Equilibria in Continuous Games: Characterization and
  Computation</title><categories>cs.GT</categories><comments>Games and Economic Behavior, In Press, Accepted Manuscript, Available
  online 16 April 2010</comments><report-no>LIDS Technical Report 2805</report-no><journal-ref>Games and Economic Behavior, Vol. 71, No. 2, March 2011, Pages
  436-455</journal-ref><doi>10.1016/j.geb.2010.04.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several new characterizations of correlated equilibria in games
with continuous utility functions. These have the advantage of being more
computationally and analytically tractable than the standard definition in
terms of departure functions. We use these characterizations to construct
effective algorithms for approximating a single correlated equilibrium or the
entire set of correlated equilibria of a game with polynomial utility
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4322</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4322</id><created>2008-12-22</created><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author><author><keyname>Kynčl</keyname><forenames>Jan</forenames></author><author><keyname>Mészáros</keyname><forenames>Viola</forenames></author><author><keyname>Stolař</keyname><forenames>Rudolf</forenames></author><author><keyname>Valtr</keyname><forenames>Pavel</forenames></author></authors><title>Solution of Peter Winkler's Pizza Problem</title><categories>cs.DM</categories><comments>29 pages, 14 figures</comments><acm-class>G.2.1</acm-class><journal-ref>In: Fete of Combinatorics and Computer Science, Bolyai Society
  Mathematical Studies, vol. 20, pp. 63-93, Springer, 2010</journal-ref><doi>10.1007/978-3-642-13580-4_4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bob cuts a pizza into slices of not necessarily equal size and shares it with
Alice by alternately taking turns. One slice is taken in each turn. The first
turn is Alice's. She may choose any of the slices. In all other turns only
those slices can be chosen that have a neighbor slice already eaten. We prove a
conjecture of Peter Winkler by showing that Alice has a strategy for obtaining
4/9 of the pizza. This is best possible, that is, there is a cutting and a
strategy for Bob to get 5/9 of the pizza. We also give a characterization of
Alice's best possible gain depending on the number of slices. For a given
cutting of the pizza, we describe a linear time algorithm that computes Alice's
strategy gaining at least 4/9 of the pizza and another algorithm that computes
the optimal strategy for both players in any possible position of the game in
quadratic time. We distinguish two types of turns, shifts and jumps. We prove
that Alice can gain 4/9, 7/16 and 1/3 of the pizza if she is allowed to make at
most two jumps, at most one jump and no jump, respectively, and the three
constants are the best possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4346</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4346</id><created>2008-12-23</created><authors><author><keyname>Kaminski</keyname><forenames>Marcin</forenames></author><author><keyname>Medvedev</keyname><forenames>Paul</forenames></author><author><keyname>Milanic</keyname><forenames>Martin</forenames></author></authors><title>The Plane-Width of Graphs</title><categories>cs.DM</categories><journal-ref>Journal of Graph Theory 68 (2011) 229-245</journal-ref><doi>10.1002/jgt.20554</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Map vertices of a graph to (not necessarily distinct) points of the plane so
that two adjacent vertices are mapped at least a unit distance apart. The
plane-width of a graph is the minimum diameter of the image of the vertex set
over all such mappings. We establish a relation between the plane-width of a
graph and its chromatic number, and connect it to other well-known areas,
including the circular chromatic number and the problem of packing unit discs
in the plane. We also investigate how plane-width behaves under various
operations, such as homomorphism, disjoint union, complement, and the Cartesian
product.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4487</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4487</id><created>2008-12-24</created><updated>2011-05-13</updated><authors><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Gong</keyname><forenames>Guang</forenames></author></authors><title>New Sequences Design from Weil Representation with Low Two-Dimensional
  Correlation in Both Time and Phase Shifts</title><categories>cs.IT cs.DM math.IT math.RT</categories><comments>23 pages, accepted by IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a given prime $p$, a new construction of families of the complex valued
sequences of period $p$ with efficient implementation is given by applying both
multiplicative characters and additive characters of finite field
$\mathbb{F}_p$. Such a signal set consists of $p^2(p-2)$ time-shift distinct
sequences, the magnitude of the two-dimensional autocorrelation function (i.e.,
the ambiguity function) in both time and phase of each sequence is upper
bounded by $2\sqrt{p}$ at any shift not equal to $(0, 0)$, and the magnitude of
the ambiguity function of any pair of phase-shift distinct sequences is upper
bounded by $4\sqrt{p}$. Furthermore, the magnitude of their Fourier transform
spectrum is less than or equal to 2. A proof is given through finding a simple
elementary construction for the sequences constructed from the Weil
representation by Gurevich, Hadani and Sochen. An open problem for directly
establishing these assertions without involving the Weil representation is
addressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4706</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4706</id><created>2008-12-26</created><updated>2011-08-17</updated><authors><author><keyname>Busé</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Chèze</keyname><forenames>Guillaume</forenames><affiliation>IMT</affiliation></author></authors><title>On the total order of reducibility of a pencil of algebraic plane curves</title><categories>math.AC cs.SC math.AG</categories><proxy>ccsd</proxy><journal-ref>Journal of Algebra 341, 1 (2011) 256-278</journal-ref><doi>10.1016/j.jalgebra.2011.06.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of bounding the number of reducible curves in a
pencil of algebraic plane curves is addressed. Unlike most of the previous
related works, each reducible curve of the pencil is here counted with its
appropriate multiplicity. It is proved that this number of reducible curves,
counted with multiplicity, is bounded by d^2-1 where d is the degree of the
pencil. Then, a sharper bound is given by taking into account the Newton's
polygon of the pencil.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4710</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4710</id><created>2008-12-26</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Ghaïs El</forenames><affiliation>IETR</affiliation></author><author><keyname>Lostanlen</keyname><forenames>Yves</forenames><affiliation>IETR</affiliation></author></authors><title>Indoor Channel Measurements and Communications System Design at 60 GHz</title><categories>cs.NI</categories><comments>2 pages</comments><proxy>ccsd hal-00348803</proxy><journal-ref>XXIX URSI General Assembly, Chicago : \'Etats-Unis (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a brief overview of several studies concerning the indoor
wireless communications at 60 GHz performed by the IETR. The characterization
and the modeling of the radio propagation channel are based on several
measurement campaigns realized with the channel sounder developed at IETR. Some
typical residential environments were also simulated by ray tracing and
Gaussian Beam Tracking. The obtained results show a good agreement with the
similar experimental results. Currently, the IETR is developing a high data
rate wireless communication system operating at 60 GHz. The single-carrier
architecture of this system is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4835</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4835</id><created>2008-12-28</created><authors><author><keyname>Boyer</keyname><forenames>Michel</forenames></author><author><keyname>Gelles</keyname><forenames>Ran</forenames></author><author><keyname>Kenigsberg</keyname><forenames>Dan</forenames></author><author><keyname>Mor</keyname><forenames>Tal</forenames></author></authors><title>Semi-Quantum Key Distribution</title><categories>quant-ph cs.CR</categories><comments>13 pages, 2 figures</comments><doi>10.1103/PhysRevA.79.032341</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure key distribution among two remote parties is impossible when both are
classical, unless some unproven (and arguably unrealistic)
computation-complexity assumptions are made, such as the difficulty of
factorizing large numbers. On the other hand, a secure key distribution is
possible when both parties are quantum. What is possible when only one party
(Alice) is quantum, yet the other (Bob) has only classical capabilities?
Recently, a semi-quantum key distribution protocol was presented (Boyer,
Kenigsberg and Mor, Physical Review Letters, 2007), in which one of the parties
(Bob) is classical, and yet, the protocol is proven to be completely robust
against an eavesdropping attempt.
  Here we extend that result much further. We present two protocols with this
constraint, and prove their robustness against attacks: we prove that any
attempt of an adversary to obtain information (and even a tiny amount of
information) necessarily induces some errors that the legitimate parties could
notice. One protocol presented here is identical to the one referred to above,
however, its robustness is proven here in a much more general scenario. The
other protocol is very different as it is based on randomization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4893</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4893</id><created>2008-12-29</created><authors><author><keyname>Floréen</keyname><forenames>Patrik</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Polishchuk</keyname><forenames>Valentin</forenames></author><author><keyname>Suomela</keyname><forenames>Jukka</forenames></author></authors><title>Almost stable matchings in constant time</title><categories>cs.DS cs.DC</categories><comments>20 pages</comments><journal-ref>Algorithmica 58 (2010) 102-118</journal-ref><doi>10.1007/s00453-009-9353-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the ratio of matched individuals to blocking pairs grows
linearly with the number of propose--accept rounds executed by the
Gale--Shapley algorithm for the stable marriage problem. Consequently, the
participants can arrive at an almost stable matching even without full
information about the problem instance; for each participant, knowing only its
local neighbourhood is enough. In distributed-systems parlance, this means that
if each person has only a constant number of acceptable partners, an almost
stable matching emerges after a constant number of synchronous communication
rounds. This holds even if ties are present in the preference lists.
  We apply our results to give a distributed $(2+\epsilon)$-approximation
algorithm for maximum-weight matching in bicoloured graphs and a centralised
randomised constant-time approximation scheme for estimating the size of a
stable matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.4937</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.4937</id><created>2008-12-29</created><updated>2010-04-12</updated><authors><author><keyname>Trifonov</keyname><forenames>Peter</forenames></author></authors><title>Efficient Interpolation in the Guruswami-Sudan Algorithm</title><categories>cs.IT cs.DM math.AC math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel algorithm is proposed for the interpolation step of the
Guruswami-Sudan list decoding algorithm. The proposed method is based on the
binary exponentiation algorithm, and can be considered as an extension of the
Lee-O'Sullivan algorithm. The algorithm is shown to achieve both asymptotical
and practical performance gain compared to the case of iterative interpolation
algorithm. Further complexity reduction is achieved by integrating the proposed
method with re-encoding. The key contribution of the paper, which enables the
complexity reduction, is a novel randomized ideal multiplication algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5030</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5030</id><created>2008-12-30</created><updated>2010-01-03</updated><authors><author><keyname>Kane</keyname><forenames>Daniel</forenames></author><author><keyname>Price</keyname><forenames>Gregory N.</forenames></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author></authors><title>A Pseudopolynomial Algorithm for Alexandrov's Theorem</title><categories>cs.CG</categories><comments>25 pages; new Delaunay triangulation algorithm, minor other changes;
  an abbreviated v2 was at WADS 2009</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Alexandrov's Theorem states that every metric with the global topology and
local geometry required of a convex polyhedron is in fact the intrinsic metric
of a unique convex polyhedron. Recent work by Bobenko and Izmestiev describes a
differential equation whose solution leads to the polyhedron corresponding to a
given metric. We describe an algorithm based on this differential equation to
compute the polyhedron to arbitrary precision given the metric, and prove a
pseudopolynomial bound on its running time. Along the way, we develop
pseudopolynomial algorithms for computing shortest paths and weighted Delaunay
triangulations on a polyhedral surface, even when the surface edges are not
shortest paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5039</identifier>
 <datestamp>2013-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5039</id><created>2008-12-30</created><updated>2009-10-14</updated><authors><author><keyname>Bukh</keyname><forenames>Boris</forenames></author><author><keyname>Matoušek</keyname><forenames>Jiří</forenames></author><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author></authors><title>Lower bounds for weak epsilon-nets and stair-convexity</title><categories>math.CO cs.CG</categories><comments>To appear in Israel J. Math. 21 pages, 4 figures</comments><msc-class>52A30, 52C99, 68U05</msc-class><journal-ref>Israel Journal of Mathematics, 182:199-228, 2011</journal-ref><doi>10.1007/s11856-011-0029-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set N is called a "weak epsilon-net" (with respect to convex sets) for a
finite set X in R^d if N intersects every convex set that contains at least
epsilon*|X| points of X. For every fixed d&gt;=2 and every r&gt;=1 we construct sets
X in R^d for which every weak (1/r)-net has at least Omega(r log^{d-1} r)
points; this is the first superlinear lower bound for weak epsilon-nets in a
fixed dimension.
  The construction is a "stretched grid", i.e., the Cartesian product of d
suitable fast-growing finite sequences, and convexity in this grid can be
analyzed using "stair-convexity", a new variant of the usual notion of
convexity.
  We also consider weak epsilon-nets for the diagonal of our stretched grid in
R^d, d&gt;=3, which is an "intrinsically 1-dimensional" point set. In this case we
exhibit slightly superlinear lower bounds (involving the inverse Ackermann
function), showing that upper bounds by Alon, Kaplan, Nivasch, Sharir, and
Smorodinsky (2008) are not far from the truth in the worst case.
  Using the stretched grid we also improve the known upper bound for the
so-called "second selection lemma" in the plane by a logarithmic factor: We
obtain a set T of t triangles with vertices in an n-point set in the plane such
that no point is contained in more than O(t^2 / (n^3 log (n^3/t))) triangles of
T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0812.5064</identifier>
 <datestamp>2010-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0812.5064</id><created>2008-12-30</created><updated>2010-03-19</updated><authors><author><keyname>Li</keyname><forenames>Qiang</forenames></author><author><keyname>Chen</keyname><forenames>Zhuo</forenames></author><author><keyname>He</keyname><forenames>Yan</forenames></author><author><keyname>Jiang</keyname><forenames>Jing-ping</forenames></author></authors><title>A Novel Clustering Algorithm Based Upon Games on Evolving Network</title><categories>cs.LG cs.CV cs.GT nlin.AO</categories><comments>17 pages, 5 figures, 3 tables</comments><journal-ref>Expert Systems with Applications, 2010</journal-ref><doi>10.1016/j.eswa.2010.02.050</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper introduces a model based upon games on an evolving network, and
develops three clustering algorithms according to it. In the clustering
algorithms, data points for clustering are regarded as players who can make
decisions in games. On the network describing relationships among data points,
an edge-removing-and-rewiring (ERR) function is employed to explore in a
neighborhood of a data point, which removes edges connecting to neighbors with
small payoffs, and creates new edges to neighbors with larger payoffs. As such,
the connections among data points vary over time. During the evolution of
network, some strategies are spread in the network. As a consequence, clusters
are formed automatically, in which data points with the same evolutionarily
stable strategy are collected as a cluster, so the number of evolutionarily
stable strategies indicates the number of clusters. Moreover, the experimental
results have demonstrated that data points in datasets are clustered reasonably
and efficiently, and the comparison with other algorithms also provides an
indication of the effectiveness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0015</identifier>
 <datestamp>2010-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0015</id><created>2008-12-30</created><updated>2009-03-29</updated><authors><author><keyname>Harremoes</keyname><forenames>Peter</forenames></author></authors><title>Maximum Entropy on Compact Groups</title><categories>cs.IT math.IT math.PR</categories><journal-ref>Entropy 2009, 11(2), 222-237</journal-ref><doi>10.3390/e11020222</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  On a compact group the Haar probability measure plays the role of uniform
distribution. The entropy and rate distortion theory for this uniform
distribution is studied. New results and simplified proofs on convergence of
convolutions on compact groups are presented and they can be formulated as
entropy increases to its maximum. Information theoretic techniques and Markov
chains play a crucial role. The convergence results are also formulated via
rate distortion functions. The rate of convergence is shown to be exponential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0044</identifier>
 <datestamp>2010-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0044</id><created>2008-12-30</created><updated>2009-08-03</updated><authors><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Information Inequalities for Joint Distributions, with Interpretations
  and Applications</title><categories>cs.IT math.CO math.IT math.PR</categories><comments>15 pages, 1 figure. Originally submitted to the IEEE Transactions on
  Information Theory in May 2007, the current version incorporates reviewer
  comments including elimination of an error</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 56(6), pp.
  2699-2713, June 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upper and lower bounds are obtained for the joint entropy of a collection of
random variables in terms of an arbitrary collection of subset joint entropies.
These inequalities generalize Shannon's chain rule for entropy as well as
inequalities of Han, Fujishige and Shearer. A duality between the upper and
lower bounds for joint entropy is developed. All of these results are shown to
be special cases of general, new results for submodular functions-- thus, the
inequalities presented constitute a richly structured class of Shannon-type
inequalities. The new inequalities are applied to obtain new results in
combinatorics, such as bounds on the number of independent sets in an arbitrary
graph and the number of zero-error source-channel codes, as well as new
determinantal inequalities in matrix theory. A new inequality for relative
entropies is also developed, along with interpretations in terms of hypothesis
testing. Finally, revealing connections of the results to literature in
economics, computer science, and physics are explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0055</identifier>
 <datestamp>2012-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0055</id><created>2008-12-30</created><updated>2011-08-09</updated><authors><author><keyname>Madiman</keyname><forenames>Mokshay</forenames></author><author><keyname>Marcus</keyname><forenames>Adam</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Entropy and set cardinality inequalities for partition-determined
  functions</title><categories>cs.IT math.CO math.IT math.NT math.PR</categories><comments>26 pages. v2: Revised version incorporating referee feedback plus
  inclusion of some additional corollaries and discussion. v3: Final version
  with minor corrections. To appear in Random Structures and Algorithms</comments><journal-ref>Random Structures and Algorithms, Vol. 40, pp. 399-424, 2012</journal-ref><doi>10.1002/rsa.20385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new notion of partition-determined functions is introduced, and several
basic inequalities are developed for the entropy of such functions of
independent random variables, as well as for cardinalities of compound sets
obtained using these functions. Here a compound set means a set obtained by
varying each argument of a function of several variables over a set associated
with that argument, where all the sets are subsets of an appropriate algebraic
structure so that the function is well defined. On the one hand, the entropy
inequalities developed for partition-determined functions imply entropic
analogues of general inequalities of Pl\"unnecke-Ruzsa type. On the other hand,
the cardinality inequalities developed for compound sets imply several
inequalities for sumsets, including for instance a generalization of
inequalities proved by Gyarmati, Matolcsi and Ruzsa (2010). We also provide
partial progress towards a conjecture of Ruzsa (2007) for sumsets in nonabelian
groups. All proofs are elementary and rely on properly developing certain
information-theoretic inequalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0121</identifier>
 <datestamp>2011-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0121</id><created>2008-12-31</created><updated>2011-07-25</updated><authors><author><keyname>Khojabaghyan</keyname><forenames>Artur</forenames></author><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author></authors><title>On upper bounds for parameters related to construction of special
  maximum matchings</title><categories>cs.DM math.CO</categories><comments>11 pages, no figures</comments><journal-ref>Discrete Mathematics 312/2 (2012), pp. 213--220</journal-ref><doi>10.1016/j.disc.2011.08.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a graph $G$ let $L(G)$ and $l(G)$ denote the size of the largest and
smallest maximum matching of a graph obtained from $G$ by removing a maximum
matching of $G$. We show that $L(G)\leq 2l(G),$ and $L(G)\leq (3/2)l(G)$
provided that $G$ contains a perfect matching. We also characterize the class
of graphs for which $L(G)=2l(G)$. Our characterization implies the existence of
a polynomial algorithm for testing the property $L(G)=2l(G)$. Finally we show
that it is $NP$-complete to test whether a graph $G$ containing a perfect
matching satisfies $L(G)=(3/2)l(G)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0498</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0498</id><created>2009-01-05</created><authors><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author></authors><title>Towards the characterization of individual users through Web analytics</title><categories>cs.HC cs.CY physics.soc-ph</categories><comments>8 pages, 4 figures. To appear in Proceeding of Complex'09</comments><journal-ref>Complex Sciences, 2247-2254 (2009)</journal-ref><doi>10.1007/978-3-642-02469-6_102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We perform an analysis of the way individual users navigate in the Web. We
focus primarily in the temporal patterns of they return to a given page. The
return probability as a function of time as well as the distribution of time
intervals between consecutive visits are measured and found to be independent
of the level of activity of single users. The results indicate a rich variety
of individual behaviors and seem to preclude the possibility of defining a
characteristic frequency for each user in his/her visits to a single site.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0597</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0597</id><created>2009-01-06</created><updated>2010-09-13</updated><authors><author><keyname>Rastegar</keyname><forenames>Reza</forenames></author></authors><title>On the Optimal Convergence Probability of Univariate Estimation of
  Distribution Algorithms</title><categories>cs.NE cs.AI</categories><comments>evolutionary computation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we obtain bounds on the probability of convergence to the
optimal solution for the compact Genetic Algorithm (cGA) and the Population
Based Incremental Learning (PBIL). We also give a sufficient condition for
convergence of these algorithms to the optimal solution and compute a range of
possible values of the parameters of these algorithms for which they converge
to the optimal solution with a confidence level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0608</identifier>
 <datestamp>2010-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0608</id><created>2009-01-06</created><updated>2010-01-29</updated><authors><author><keyname>Han</keyname><forenames>Te Sun</forenames></author></authors><title>Multicasting correlated multi-source to multi-sink over a network</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of network coding with multicast of a single source to multisink
has first been studied by Ahlswede, Cai, Li and Yeung in 2000, in which they
have established the celebrated max-flow mini-cut theorem on non-physical
information flow over a network of independent channels. On the other hand, in
1980, Han has studied the case with correlated multisource and a single sink
from the viewpoint of polymatroidal functions in which a necessary and
sufficient condition has been demonstrated for reliable transmission over the
network. This paper presents an attempt to unify both cases, which leads to
establish a necessary and sufficient condition for reliable transmission over a
network multicasting correlated multisource to multisink. Here, the problem of
separation of source coding and channel coding is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0633</identifier>
 <datestamp>2012-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0633</id><created>2009-01-06</created><updated>2012-01-18</updated><authors><author><keyname>Kappen</keyname><forenames>B.</forenames></author><author><keyname>Gomez</keyname><forenames>V.</forenames></author><author><keyname>Opper</keyname><forenames>M.</forenames></author></authors><title>Optimal control as a graphical model inference problem</title><categories>math.OC cs.SY</categories><comments>26 pages, 12 Figures; Machine Learning Journal (2012)</comments><acm-class>F.1.2; G.3; I.2.8</acm-class><doi>10.1007/s10994-012-5278-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reformulate a class of non-linear stochastic optimal control problems
introduced by Todorov (2007) as a Kullback-Leibler (KL) minimization problem.
As a result, the optimal control computation reduces to an inference
computation and approximate inference methods can be applied to efficiently
compute approximate optimal controls. We show how this KL control theory
contains the path integral control method as a special case. We provide an
example of a block stacking task and a multi-agent cooperative game where we
demonstrate how approximate inference can be successfully applied to instances
that are too complex for exact computation. We discuss the relation of the KL
control approach to other inference approaches to control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0733</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0733</id><created>2009-01-06</created><updated>2011-05-06</updated><authors><author><keyname>Martin</keyname><forenames>Éric A.</forenames></author></authors><title>Contextual hypotheses and semantics of logic programs</title><categories>cs.LO cs.AI</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP) 46
  pages, 3 figures</comments><msc-class>03B70 (Primary) 68T27 (Secondary)</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming has developed as a rich field, built over a logical
substratum whose main constituent is a nonclassical form of negation, sometimes
coexisting with classical negation. The field has seen the advent of a number
of alternative semantics, with Kripke-Kleene semantics, the well-founded
semantics, the stable model semantics, and the answer-set semantics standing
out as the most successful. We show that all aforementioned semantics are
particular cases of a generic semantics, in a framework where classical
negation is the unique form of negation and where the literals in the bodies of
the rules can be `marked' to indicate that they can be the targets of
hypotheses. A particular semantics then amounts to choosing a particular
marking scheme and choosing a particular set of hypotheses. When a literal
belongs to the chosen set of hypotheses, all marked occurrences of that literal
in the body of a rule are assumed to be true, whereas the occurrences of that
literal that have not been marked in the body of the rule are to be derived in
order to contribute to the firing of the rule. Hence the notion of hypothetical
reasoning that is presented in this framework is not based on making global
assumptions, but more subtly on making local, contextual assumptions, taking
effect as indicated by the chosen marking scheme on the basis of the chosen set
of hypotheses. Our approach offers a unified view on the various semantics
proposed in logic programming, classical in that only classical negation is
used, and links the semantics of logic programs to mechanisms that endow
rule-based systems with the power to harness hypothetical reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0763</identifier>
 <datestamp>2010-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0763</id><created>2009-01-07</created><updated>2010-08-31</updated><authors><author><keyname>Ren</keyname><forenames>Shaolei</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Distributed Power Allocation in Multi-User Multi-Channel Relay Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors as they feel it inappropriate to
publish this paper for the time being.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0834</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0834</id><created>2009-01-07</created><updated>2010-07-28</updated><authors><author><keyname>Wang</keyname><forenames>Ligong</forenames></author><author><keyname>Colbeck</keyname><forenames>Roger</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Simple Channel Coding Bounds</title><categories>cs.IT math.IT</categories><comments>Presented at ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New channel coding converse and achievability bounds are derived for a single
use of an arbitrary channel. Both bounds are expressed using a quantity called
the "smooth 0-divergence", which is a generalization of Renyi's divergence of
order 0. The bounds are also studied in the limit of large block-lengths. In
particular, they combine to give a general capacity formula which is equivalent
to the one derived by Verdu and Han.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0858</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0858</id><created>2009-01-07</created><updated>2010-09-16</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Tankus</keyname><forenames>David</forenames></author></authors><title>Weighted Well-Covered Graphs without Cycles of Length 4, 5, 6 and 7</title><categories>cs.DM cs.CC</categories><comments>10 pages</comments><acm-class>G.2.2; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is well-covered if every maximal independent set has the same
cardinality. The recognition problem of well-covered graphs is known to be
co-NP-complete. Let w be a weight function defined on the vertices of G. Then G
is w-well-covered if all maximal independent sets of G are of the same weight.
The set of weight functions w for which a graph is w-well-covered is a vector
space. We prove that finding the vector space of weight functions under which
an input graph is w-well-covered can be done in polynomial time, if the input
graph does not contain cycles of length 4, 5, 6 and 7.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0869</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0869</id><created>2009-01-07</created><updated>2011-11-28</updated><authors><author><keyname>Durand</keyname><forenames>Irène</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Middeldorp</keyname><forenames>Aart</forenames></author></authors><title>On the Complexity of Deciding Call-by-Need</title><categories>cs.LO cs.PL</categories><proxy>ccsd hal-00344320</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent paper we introduced a new framework for the study of call by need
computations to normal form and root-stable form in term rewriting. Using
elementary tree automata techniques and ground tree transducers we obtained
simple decidability proofs for classes of rewrite systems that are much larger
than earlier classes defined using the complicated sequentiality concept. In
this paper we show that we can do without ground tree transducers in order to
arrive at decidability proofs that are phrased in direct tree automata
constructions. This allows us to derive better complexity bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.0911</identifier>
 <datestamp>2011-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.0911</id><created>2009-01-07</created><updated>2011-01-31</updated><authors><author><keyname>Berzati</keyname><forenames>Alexandre</forenames><affiliation>LETI, PRISM</affiliation></author><author><keyname>Canovas</keyname><forenames>Cécile</forenames><affiliation>LETI</affiliation></author><author><keyname>Dumas</keyname><forenames>Jean-Guillaume</forenames><affiliation>LJK</affiliation></author><author><keyname>Goubin</keyname><forenames>Louis</forenames><affiliation>PRISM</affiliation></author></authors><title>Fault Attacks on RSA Public Keys: Left-To-Right Implementations are also
  Vulnerable</title><categories>cs.CR</categories><proxy>ccsd</proxy><journal-ref>RSA Conference 2009, Cryptographers' Track, San Francisco : United
  States (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After attacking the RSA by injecting fault and corresponding countermeasures,
works appear now about the need for protecting RSA public elements against
fault attacks. We provide here an extension of a recent attack based on the
public modulus corruption. The difficulty to decompose the "Left-To-Right"
exponentiation into partial multiplications is overcome by modifying the public
modulus to a number with known factorization. This fault model is justified
here by a complete study of faulty prime numbers with a fixed size. The good
success rate of this attack combined with its practicability raises the
question of using faults for changing algebraic properties of finite field
based cryptosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1084</identifier>
 <datestamp>2010-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1084</id><created>2009-01-08</created><updated>2009-07-01</updated><authors><author><keyname>van Handel</keyname><forenames>Ramon</forenames></author></authors><title>When do nonlinear filters achieve maximal accuracy?</title><categories>math.PR cs.IT math.IT</categories><comments>18 pages</comments><msc-class>93E11, 60G10, 62M20, 93B07, 94A12</msc-class><journal-ref>SIAM J. Control Optim. 48, 3151-3168 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nonlinear filter for an ergodic signal observed in white noise is said to
achieve maximal accuracy if the stationary filtering error vanishes as the
signal to noise ratio diverges. We give a general characterization of the
maximal accuracy property in terms of various systems theoretic notions. When
the signal state space is a finite set explicit necessary and sufficient
conditions are obtained, while the linear Gaussian case reduces to a classic
result of Kwakernaak and Sivan (1972).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1155</identifier>
 <datestamp>2012-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1155</id><created>2009-01-08</created><updated>2012-09-12</updated><authors><author><keyname>Benjamini</keyname><forenames>Itai</forenames></author><author><keyname>Makarychev</keyname><forenames>Yury</forenames></author></authors><title>Balanced allocation: Memory performance tradeoffs</title><categories>cs.DS cs.DM math.PR</categories><comments>Published in at http://dx.doi.org/10.1214/11-AAP804 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP804</report-no><journal-ref>Annals of Applied Probability 2012, Vol. 22, No. 4, 1642-1649</journal-ref><doi>10.1214/11-AAP804</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we sequentially put $n$ balls into $n$ bins. If we put each ball into
a random bin then the heaviest bin will contain ${\sim}\log n/\log\log n$ balls
with high probability. However, Azar, Broder, Karlin and Upfal [SIAM J. Comput.
29 (1999) 180--200] showed that if each time we choose two bins at random and
put the ball in the least loaded bin among the two, then the heaviest bin will
contain only ${\sim}\log\log n$ balls with high probability. How much memory do
we need to implement this scheme? We need roughly $\log\log\log n$ bits per
bin, and $n\log\log\log n$ bits in total. Let us assume now that we have
limited amount of memory. For each ball, we are given two random bins and we
have to put the ball into one of them. Our goal is to minimize the load of the
heaviest bin. We prove that if we have $n^{1-\delta}$ bits then the heaviest
bin will contain at least $\Omega(\delta\log n/\log\log n)$ balls with high
probability. The bound is tight in the communication complexity model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1288</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1288</id><created>2009-01-09</created><updated>2010-01-29</updated><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>Power-Controlled Feedback and Training for Two-way MIMO Channels</title><categories>cs.IT math.IT</categories><comments>in IEEE Transactions on Information Theory, 2010</comments><journal-ref>IEEE Transactions on Information Theory, vol.56, no.7,
  pp.3310,3331, July 2010</journal-ref><doi>10.1109/TIT.2010.2048472</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most communication systems use some form of feedback, often related to
channel state information. The common models used in analyses either assume
perfect channel state information at the receiver and/or noiseless state
feedback links. However, in practical systems, neither is the channel estimate
known perfectly at the receiver and nor is the feedback link perfect. In this
paper, we study the achievable diversity multiplexing tradeoff using i.i.d.
Gaussian codebooks, considering the errors in training the receiver and the
errors in the feedback link for FDD systems, where the forward and the feedback
are independent MIMO channels.
  Our key result is that the maximum diversity order with one-bit of feedback
information is identical to systems with more feedback bits. Thus,
asymptotically in $\mathsf{SNR}$, more than one bit of feedback does not
improve the system performance at constant rates. Furthermore, the one-bit
diversity-multiplexing performance is identical to the system which has perfect
channel state information at the receiver along with noiseless feedback link.
This achievability uses novel concepts of power controlled feedback and
training, which naturally surface when we consider imperfect channel estimation
and noisy feedback links. In the process of evaluating the proposed training
and feedback protocols, we find an asymptotic expression for the joint
probability of the $\mathsf{SNR}$ exponents of eigenvalues of the actual
channel and the estimated channel which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1312</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1312</id><created>2009-01-09</created><updated>2010-05-28</updated><authors><author><keyname>Bui</keyname><forenames>Loc</forenames></author><author><keyname>Srikant</keyname><forenames>R.</forenames></author><author><keyname>Stolyar</keyname><forenames>Alexander</forenames></author></authors><title>Novel Architectures and Algorithms for Delay Reduction in Back-pressure
  Scheduling and Routing</title><categories>cs.NI</categories><comments>A short version of this paper is accepted to the INFOCOM 2009
  Mini-Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The back-pressure algorithm is a well-known throughput-optimal algorithm.
However, its delay performance may be quite poor even when the traffic load is
not close to network capacity due to the following two reasons. First, each
node has to maintain a separate queue for each commodity in the network, and
only one queue is served at a time. Second, the back-pressure routing algorithm
may route some packets along very long routes. In this paper, we present
solutions to address both of the above issues, and hence, improve the delay
performance of the back-pressure algorithm. One of the suggested solutions also
decreases the complexity of the queueing data structures to be maintained at
each node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1444</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1444</id><created>2009-01-11</created><updated>2011-12-15</updated><authors><author><keyname>Vasudevan</keyname><forenames>Dinkar</forenames></author><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author></authors><title>Algebraic gossip on Arbitrary Networks</title><categories>cs.IT math.IT</categories><comments>Paper has been withdrawn due to an error in the main proof</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a network of nodes where each node has a message to communicate to
all other nodes. For this communication problem, we analyze a gossip based
protocol where coded messages are exchanged. This problem was studied by Aoyama
and Shah where a bound to the dissemination time based on the spectral
properties of the underlying communication graph is provided. Our contribution
is a uniform bound that holds for arbitrary networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1473</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1473</id><created>2009-01-11</created><updated>2009-08-20</updated><authors><author><keyname>Lomnitz</keyname><forenames>Yuval</forenames></author><author><keyname>Feder</keyname><forenames>Meir</forenames></author></authors><title>Communication over Individual Channels</title><categories>cs.IT math.IT</categories><comments>Cleanup, Editorial changes, Additional commentary</comments><journal-ref>IEEE Trans. Information Theory, vol. 57, no. 11, pp. 7333 --7358,
  Nov. 2011</journal-ref><doi>10.1109/TIT.2011.2169130</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of communicating over a channel for which no
mathematical model is specified. We present achievable rates as a function of
the channel input and output known a-posteriori for discrete and continuous
channels, as well as a rate-adaptive scheme employing feedback which achieves
these rates asymptotically without prior knowledge of the channel behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1655</identifier>
 <datestamp>2010-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1655</id><created>2009-01-12</created><authors><author><keyname>Nobrega</keyname><forenames>Roberto W.</forenames></author><author><keyname>Uchoa-Filho</keyname><forenames>Bartolomeu F.</forenames></author></authors><title>Multishot Codes for Network Coding: Bounds and a Multilevel Construction</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to ISIT 2009</comments><doi>10.1109/ISIT.2009.5205750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subspace channel was introduced by Koetter and Kschischang as an adequate
model for the communication channel from the source node to a sink node of a
multicast network that performs random linear network coding. So far, attention
has been given to one-shot subspace codes, that is, codes that use the subspace
channel only once. In contrast, this paper explores the idea of using the
subspace channel more than once and investigates the so called multishot
subspace codes. We present definitions for the problem, a motivating example,
lower and upper bounds for the size of codes, and a multilevel construction of
codes based on block-coded modulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1703</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1703</id><created>2009-01-12</created><updated>2010-06-29</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Ashikhmin</keyname><forenames>Alexei</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Pilot Contamination and Precoding in Multi-Cell TDD Systems</title><categories>cs.IT math.IT</categories><comments>23 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a multi-cell multiple antenna system with precoding used
at the base stations for downlink transmission. For precoding at the base
stations, channel state information (CSI) is essential at the base stations. A
popular technique for obtaining this CSI in time division duplex (TDD) systems
is uplink training by utilizing the reciprocity of the wireless medium. This
paper mathematically characterizes the impact that uplink training has on the
performance of such multi-cell multiple antenna systems. When non-orthogonal
training sequences are used for uplink training, the paper shows that the
precoding matrix used by the base station in one cell becomes corrupted by the
channel between that base station and the users in other cells in an
undesirable manner. This paper analyzes this fundamental problem of pilot
contamination in multi-cell systems. Furthermore, it develops a new multi-cell
MMSE-based precoding method that mitigate this problem. In addition to being a
linear precoding method, this precoding method has a simple closed-form
expression that results from an intuitive optimization problem formulation.
Numerical results show significant performance gains compared to certain
popular single-cell precoding methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1705</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1705</id><created>2009-01-12</created><updated>2010-04-18</updated><authors><author><keyname>Timo</keyname><forenames>Roy</forenames></author><author><keyname>Chan</keyname><forenames>Terence</forenames></author><author><keyname>Grant</keyname><forenames>Alexander</forenames></author></authors><title>Rate-Distortion with Side-Information at Many Decoders</title><categories>cs.IT math.IT</categories><comments>36 pages. Submitted to IEEE Transactions on Information Theory. In
  proc. ISIT 2010.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new inner bound for the rate region of the $t$-stage
successive-refinement problem with side-information. We also present a new
upper bound for the rate-distortion function for lossy-source coding with
multiple decoders and side-information. Characterising this rate-distortion
function is a long-standing open problem, and it is widely believed that the
tightest upper bound is provided by Theorem 2 of Heegard and Berger's paper
"Rate Distortion when Side Information may be Absent", \emph{IEEE Trans.
Inform. Theory}, 1985. We give a counterexample to Heegard and Berger's result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1821</identifier>
 <datestamp>2011-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1821</id><created>2009-01-13</created><updated>2011-01-28</updated><authors><author><keyname>Henrion</keyname><forenames>Didier</forenames><affiliation>LAAS, CTU/FEE</affiliation></author></authors><title>Semidefinite representation of convex hulls of rational varieties</title><categories>math.OC cs.SY math.AG</categories><proxy>ccsd</proxy><report-no>Rapport LAAS No. 09001</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using elementary duality properties of positive semidefinite moment matrices
and polynomial sum-of-squares decompositions, we prove that the convex hull of
rationally parameterized algebraic varieties is semidefinite representable
(that is, it can be represented as a projection of an affine section of the
cone of positive semidefinite matrices) in the case of (a) curves; (b)
hypersurfaces parameterized by quadratics; and (c) hypersurfaces parameterized
by bivariate quartics; all in an ambient space of arbitrary dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1866</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1866</id><created>2009-01-13</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author></authors><title>Capacity Achieving Codes From Randomness Condensers</title><categories>cs.IT math.IT</categories><comments>Full version. A preliminary summary of this work appears (under the
  title "Capacity Achieving Codes From Randomness~Conductors") in proceedings
  of the 2009 IEEE International Symposium on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a general framework for construction of small ensembles of
capacity achieving linear codes for a wide range of (not necessarily
memoryless) discrete symmetric channels, and in particular, the binary erasure
and symmetric channels. The main tool used in our constructions is the notion
of randomness extractors and lossless condensers that are regarded as central
tools in theoretical computer science. Same as random codes, the resulting
ensembles preserve their capacity achieving properties under any change of
basis. Using known explicit constructions of condensers, we obtain specific
ensembles whose size is as small as polynomial in the block length. By applying
our construction to Justesen's concatenation scheme (Justesen, 1972) we obtain
explicit capacity achieving codes for BEC (resp., BSC) with almost linear time
encoding and almost linear time (resp., quadratic time) decoding and
exponentially small error probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1892</identifier>
 <datestamp>2014-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1892</id><created>2009-01-13</created><updated>2014-03-28</updated><authors><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>A New Achievable Rate Region for the Discrete Memoryless Multiple-Access
  Channel with Noiseless Feedback</title><categories>cs.IT math.IT</categories><comments>appeared in IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 57, no.12, pp.
  8038-8054, Dec. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new single-letter achievable rate region is proposed for the two-user
discrete memoryless multiple-access channel(MAC) with noiseless feedback. The
proposed region includes the Cover-Leung rate region [1], and it is shown that
the inclusion is strict. The proof uses a block-Markov superposition strategy
based on the observation that the messages of the two users are correlated
given the feedback. The rates of transmission are too high for each encoder to
decode the other's message directly using the feedback, so they transmit
correlated information in the next block to learn the message of one another.
They then cooperate in the following block to resolve the residual uncertainty
of the decoder. The coding scheme may be viewed as a natural generalization of
the Cover-Leung scheme with a delay of one extra block and a pair of additional
auxiliary random variables. We compute the proposed rate region for two
different MACs and compare the results with other known rate regions for the
MAC with feedback. Finally, we show how the coding scheme can be extended to
obtain larger rate regions with more auxiliary random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1908</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1908</id><created>2009-01-13</created><authors><author><keyname>Collette</keyname><forenames>Sebastien</forenames></author><author><keyname>Dujmovic</keyname><forenames>Vida</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Entropy, Triangulation, and Point Location in Planar Subdivisions</title><categories>cs.CG cs.DS</categories><comments>19 pages, 4 figures, lots of formulas</comments><acm-class>I.3.5; E.1</acm-class><journal-ref>ACM Transactions on Algorithms (TALG), Volume 8 Issue 3, July 2012
  Article No. 29</journal-ref><doi>10.1145/2229163.2229173</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data structure is presented for point location in connected planar
subdivisions when the distribution of queries is known in advance. The data
structure has an expected query time that is within a constant factor of
optimal. More specifically, an algorithm is presented that preprocesses a
connected planar subdivision G of size n and a query distribution D to produce
a point location data structure for G. The expected number of point-line
comparisons performed by this data structure, when the queries are distributed
according to D, is H + O(H^{2/3}+1) where H=H(G,D) is a lower bound on the
expected number of point-line comparisons performed by any linear decision tree
for point location in G under the query distribution D. The preprocessing
algorithm runs in O(n log n) time and produces a data structure of size O(n).
These results are obtained by creating a Steiner triangulation of G that has
near-minimum entropy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.1924</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.1924</id><created>2009-01-13</created><updated>2010-03-22</updated><authors><author><keyname>Jing</keyname><forenames>Zhenhai</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Li</keyname><forenames>Ying</forenames></author></authors><title>Interference Avoidance Game in the Gaussian Interference Channel:
  Sub-Optimal and Optimal Schemes</title><categories>cs.IT math.IT</categories><comments>18 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper considers a distributed interference avoidance problem employing
frequency assignment in the Gaussian interference channel (IC). We divide the
common channel into several subchannels and each user chooses the subchannel
with less amount of interference from other users as the transmit channel. This
mechanism named interference avoidance in this paper can be modeled as a
competitive game model. And a completely autonomous distributed iterative
algorithm called Tdistributed interference avoidance algorithm (DIA) is adopted
to achieve the Nash equilibriumT (NE) of the game. Due to the self-optimum, DIA
is a sub-optimal algorithm. Therefore, through introducing an optimal
compensation into the competitive game model, we successfully develop a
compensation-based game model to approximate the optimal interference avoidance
problem. Moreover, an optimal algorithm called iterative optimal interference
avoidance algorithm (IOIA) is proposed to reach the optimality of the
interference avoidance scheme. We analyze the implementation complexities of
the two algorithms. We also give the proof on the convergence of the proposed
algorithms. The performance upper bound and lower bound are also derived for
the proposed algorithms. The simulation results show that IOIA does reach the
optimality under condition of interference avoidance mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2120</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2120</id><created>2009-01-14</created><updated>2011-07-22</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Didier</keyname><forenames>Frederic</forenames></author><author><keyname>Shokrollahi</keyname><forenames>Amin</forenames></author></authors><title>Invertible Extractors and Wiretap Protocols</title><categories>cs.IT math.IT</categories><comments>Full version. A preliminary summary of this work appears (under the
  same title) in proceedings of the 2009 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wiretap protocol is a pair of randomized encoding and decoding functions
such that knowledge of a bounded fraction of the encoding of a message reveals
essentially no information about the message, while knowledge of the entire
encoding reveals the message using the decoder. In this paper we study the
notion of efficiently invertible extractors and show that a wiretap protocol
can be constructed from such an extractor. We will then construct invertible
extractors for symbol-fixing, affine, and general sources and apply them to
create wiretap protocols with asymptotically optimal trade-offs between their
rate (ratio of the length of the message versus its encoding) and resilience
(ratio of the observed positions of the encoding and the length of the
encoding). We will then apply our results to create wiretap protocols for
challenging communication problems, such as active intruders who change
portions of the encoding, network coding, and intruders observing arbitrary
boolean functions of the encoding.
  As a by-product of our constructions we obtain new explicit extractors for a
restricted family of affine sources over large fields (that in particular
generalizes the notion of symbol-fixing sources) which is of independent
interest. These extractors are able to extract the entire source entropy with
zero error.
  Keywords: Wiretap Channel, Extractors, Network Coding, Active Intrusion,
Exposure Resilient Cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2140</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2140</id><created>2009-01-14</created><authors><author><keyname>Elkouss</keyname><forenames>David</forenames></author><author><keyname>Leverrier</keyname><forenames>Anthony</forenames></author><author><keyname>Alléaume</keyname><forenames>Romain</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph</forenames></author></authors><title>Efficient reconciliation protocol for discrete-variable quantum key
  distribution</title><categories>cs.IT math.IT quant-ph</categories><doi>10.1109/ISIT.2009.5205475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconciliation is an essential part of any secret-key agreement protocol and
hence of a Quantum Key Distribution (QKD) protocol, where two legitimate
parties are given correlated data and want to agree on a common string in the
presence of an adversary, while revealing a minimum amount of information.
  In this paper, we show that for discrete-variable QKD protocols, this problem
can be advantageously solved with Low Density Parity Check (LDPC) codes
optimized for the BSC. In particular, we demonstrate that our method leads to a
significant improvement of the achievable secret key rate, with respect to
earlier interactive reconciliation methods used in QKD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2224</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2224</id><created>2009-01-15</created><updated>2010-08-02</updated><authors><author><keyname>Savinov</keyname><forenames>Alexandr</forenames></author></authors><title>Concept-Oriented Model and Query Language</title><categories>cs.DB</categories><comments>45 pages, 18 figures, Submitted to ACM Transactions on Database
  Systems (TODS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new approach to data modeling, called the concept-oriented
model (COM), and a novel concept-oriented query language (COQL). The model is
based on three principles: duality principle postulates that any element is a
couple consisting of one identity and one entity, inclusion principle
postulates that any element has a super-element, and order principle assumes
that any element has a number of greater elements within a partially ordered
set. Concept-oriented query language is based on a new data modeling construct,
called concept, inclusion relation between concepts, and concept partial
ordering in which greater concepts are represented by their field types. It is
demonstrated how COM and COQL can be used to solve three general data modeling
tasks: logical navigation, multidimensional analysis and inference. Logical
navigation is based on two operations of projection and de-projection.
Multidimensional analysis uses product operation for producing a cube from
level concepts chosen along the chosen dimension paths. Inference is defined as
a two-step procedure where input constraints are first propagated downwards
using de-projection and then the constrained result is propagated upwards using
projection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2410</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2410</id><created>2009-01-16</created><updated>2011-08-18</updated><authors><author><keyname>Goseling</keyname><forenames>Jasper</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ruytaroh</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author><author><keyname>Weber</keyname><forenames>Jos H.</forenames></author></authors><title>On the Energy Benefit of Network Coding for Wireless Multiple Unicast</title><categories>cs.IT math.IT</categories><journal-ref>EURASIP Journal on Wireless Communications and Networking, Vol.
  2010 (2010), Art.ID 605421</journal-ref><doi>10.1155/2010/605421</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the energy savings that can be obtained by employing network
coding instead of plain routing in wireless multiple unicast problems. We
establish lower bounds on the benefit of network coding, defined as the maximum
of the ratio of the minimum energy required by routing and network coding
solutions, where the maximum is over all configurations. It is shown that if
coding and routing solutions are using the same transmission range, the benefit
in $d$-dimensional networks is at least $2d/\lfloor\sqrt{d}\rfloor$. Moreover,
it is shown that if the transmission range can be optimized for routing and
coding individually, the benefit in 2-dimensional networks is at least 3. Our
results imply that codes following a \emph{decode-and-recombine} strategy are
not always optimal regarding energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2684</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2684</id><created>2009-01-18</created><updated>2009-05-09</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Tock</keyname><forenames>Yoav</forenames></author><author><keyname>Zymnis</keyname><forenames>Argyris</forenames></author><author><keyname>Boyd</keyname><forenames>Stephen</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Distributed Large Scale Network Utility Maximization</title><categories>cs.IT cs.DC math.IT math.OC</categories><comments>In the International Symposium on Information Theory (ISIT) 2009</comments><doi>10.1109/ISIT.2009.5205655</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work by Zymnis et al. proposes an efficient primal-dual interior-point
method, using a truncated Newton method, for solving the network utility
maximization (NUM) problem. This method has shown superior performance relative
to the traditional dual-decomposition approach. Other recent work by Bickson et
al. shows how to compute efficiently and distributively the Newton step, which
is the main computational bottleneck of the Newton method, utilizing the
Gaussian belief propagation algorithm.
  In the current work, we combine both approaches to create an efficient
distributed algorithm for solving the NUM problem. Unlike the work of Zymnis,
which uses a centralized approach, our new algorithm is easily distributed.
Using an empirical evaluation we show that our new method outperforms previous
approaches, including the truncated Newton method and dual-decomposition
methods. As an additional contribution, this is the first work that evaluates
the performance of the Gaussian belief propagation algorithm vs. the
preconditioned conjugate gradient method, for a large scale problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2687</identifier>
 <datestamp>2010-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2687</id><created>2009-01-18</created><updated>2010-04-12</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Hoch</keyname><forenames>Ezra N.</forenames></author><author><keyname>Naaman</keyname><forenames>Nir</forenames></author><author><keyname>Tock</keyname><forenames>Yoav</forenames></author></authors><title>A Hybrid Multicast-Unicast Infrastructure for Efficient
  Publish-Subscribe in Enterprise Networks</title><categories>cs.NI cs.DC</categories><journal-ref>SYSTOR 2010 - The 3rd Annual Haifa Experimental Systems
  Conference, Haifa, Israel, May 24-26, 2010</journal-ref><doi>10.1145/1815695.1815722</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main challenges in building a large scale publish-subscribe
infrastructure in an enterprise network, is to provide the subscribers with the
required information, while minimizing the consumed host and network resources.
Typically, previous approaches utilize either IP multicast or point-to-point
unicast for efficient dissemination of the information.
  In this work, we propose a novel hybrid framework, which is a combination of
both multicast and unicast data dissemination. Our hybrid framework allows us
to take the advantages of both multicast and unicast, while avoiding their
drawbacks. We investigate several algorithms for computing the best mapping of
publishers' transmissions into multicast and unicast transport.
  Using extensive simulations, we show that our hybrid framework reduces
consumed host and network resources, outperforming traditional solutions. To
insure the subscribers interests closely resemble those of real-world settings,
our simulations are based on stock market data and on recorded IBM WebShpere
subscriptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2689</identifier>
 <datestamp>2010-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2689</id><created>2009-01-18</created><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Reinman</keyname><forenames>Tzachy</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Pinkas</keyname><forenames>Benny</forenames></author></authors><title>Peer-to-Peer Secure Multi-Party Numerical Computation Facing Malicious
  Adversaries</title><categories>cs.CR cs.NI</categories><comments>Submitted to Peer-to-Peer Networking and Applications Journal (PPNA)
  2009</comments><doi>10.1007/s12083-009-0051-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient framework for enabling secure multi-party numerical
computations in a Peer-to-Peer network. This problem arises in a range of
applications such as collaborative filtering, distributed computation of trust
and reputation, monitoring and other tasks, where the computing nodes is
expected to preserve the privacy of their inputs while performing a joint
computation of a certain function. Although there is a rich literature in the
field of distributed systems security concerning secure multi-party
computation, in practice it is hard to deploy those methods in very large scale
Peer-to-Peer networks. In this work, we try to bridge the gap between
theoretical algorithms in the security domain, and a practical Peer-to-Peer
deployment.
  We consider two security models. The first is the semi-honest model where
peers correctly follow the protocol, but try to reveal private information. We
provide three possible schemes for secure multi-party numerical computation for
this model and identify a single light-weight scheme which outperforms the
others. Using extensive simulation results over real Internet topologies, we
demonstrate that our scheme is scalable to very large networks, with up to
millions of nodes. The second model we consider is the malicious peers model,
where peers can behave arbitrarily, deliberately trying to affect the results
of the computation as well as compromising the privacy of other peers. For this
model we provide a fourth scheme to defend the execution of the computation
against the malicious peers. The proposed scheme has a higher complexity
relative to the semi-honest model. Overall, we provide the Peer-to-Peer network
designer a set of tools to choose from, based on the desired level of security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2703</identifier>
 <datestamp>2010-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2703</id><created>2009-01-18</created><updated>2010-09-17</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Language recognition by generalized quantum finite automata with
  unbounded error (abstract &amp; poster)</title><categories>cs.CC</categories><comments>2 pages, poster presented at the 4th Workshop on Theory of Quantum
  Computation, Communication, and Cryptography (TQC2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we generalize the results of arXiv:0901.2703v1 We show that all
one-way quantum finite automaton (QFA) models that are at least as general as
Kondacs-Watrous QFA's are equivalent in power to classical probabilistic finite
automata in this setting. Unlike their probabilistic counterparts, allowing the
tape head to stay put for some steps during its traversal of the input does
enlarge the class of languages recognized by such QFA's with unbounded error.
(Note that, the proof of Theorem 1 in the abstract was presented in the
previous version (arXiv:0901.2703v1).)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2778</identifier>
 <datestamp>2011-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2778</id><created>2009-01-19</created><authors><author><keyname>Janovitz-Freireich</keyname><forenames>Itnuit</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ronayi</keyname><forenames>Lajos</forenames></author><author><keyname>Szanto</keyname><forenames>Agnes</forenames></author></authors><title>On the Computation of Matrices of Traces and Radicals of Ideals</title><categories>cs.SC math.AC</categories><proxy>ccsd inria-00354120</proxy><journal-ref>Journal of Symbolic Computation 47, 1 (2012) 102-122</journal-ref><doi>10.1016/j.jsc.2011.08.020</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $f_1,...,f_s \in \mathbb{K}[x_1,...,x_m]$ be a system of polynomials
generating a zero-dimensional ideal $\I$, where $\mathbb{K}$ is an arbitrary
algebraically closed field. We study the computation of "matrices of traces"
for the factor algebra $\A := \CC[x_1, ..., x_m]/ \I$, i.e. matrices with
entries which are trace functions of the roots of $\I$. Such matrices of traces
in turn allow us to compute a system of multiplication matrices
$\{M_{x_i}|i=1,...,m\}$ of the radical $\sqrt{\I}$. We first propose a method
using Macaulay type resultant matrices of $f_1,...,f_s$ and a polynomial $J$ to
compute moment matrices, and in particular matrices of traces for $\A$. Here
$J$ is a polynomial generalizing the Jacobian. We prove bounds on the degrees
needed for the Macaulay matrix in the case when $\I$ has finitely many
projective roots in $\mathbb{P}^m_\CC$. We also extend previous results which
work only for the case where $\A$ is Gorenstein to the non-Gorenstein case. The
second proposed method uses Bezoutian matrices to compute matrices of traces of
$\A$. Here we need the assumption that $s=m$ and $f_1,...,f_m$ define an affine
complete intersection. This second method also works if we have higher
dimensional components at infinity. A new explicit description of the
generators of $\sqrt{\I}$ are given in terms of Bezoutians.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2864</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2864</id><created>2009-01-19</created><authors><author><keyname>Duursma</keyname><forenames>Iwan</forenames></author><author><keyname>Kirov</keyname><forenames>Radoslav</forenames></author></authors><title>An extension of the order bound for AG codes</title><categories>math.NT cs.IT math.AG math.IT</categories><comments>11 pages</comments><msc-class>14G50, 11T71, 94B</msc-class><doi>10.1007/978-3-642-02181-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most successful method to obtain lower bounds for the minimum distance of
an algebraic geometric code is the order bound, which generalizes the Feng-Rao
bound. We provide a significant extension of the bound that improves the order
bounds by Beelen and by Duursma and Park. We include an exhaustive numerical
comparison of the different bounds for 10168 two-point codes on the Suzuki
curve of genus g=124 over the field of 32 elements. Keywords: algebraic
geometric code, order bound, Suzuki curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.2903</identifier>
 <datestamp>2010-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.2903</id><created>2009-01-19</created><updated>2010-06-02</updated><authors><author><keyname>Teixeira</keyname><forenames>Andreia</forenames></author><author><keyname>Souto</keyname><forenames>Andre</forenames></author><author><keyname>Matos</keyname><forenames>Armando</forenames></author><author><keyname>Antunes</keyname><forenames>Luis</forenames></author></authors><title>Entropy Measures vs. Algorithmic Information</title><categories>cs.IT cs.CC math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algorithmic entropy and Shannon entropy are two conceptually different
information measures, as the former is based on size of programs and the later
in probability distributions. However, it is known that, for any recursive
probability distribution, the expected value of algorithmic entropy equals its
Shannon entropy, up to a constant that depends only on the distribution. We
study if a similar relationship holds for R\'{e}nyi and Tsallis entropies of
order $\alpha$, showing that it only holds for R\'{e}nyi and Tsallis entropies
of order 1 (i.e., for Shannon entropy). Regarding a time bounded analogue
relationship, we show that, for distributions such that the cumulative
probability distribution is computable in time $t(n)$, the expected value of
time-bounded algorithmic entropy (where the alloted time is $nt(n)\log
(nt(n))$) is in the same range as the unbounded version. So, for these
distributions, Shannon entropy captures the notion of computationally
accessible information. We prove that, for universal time-bounded distribution
$\m^t(x)$, Tsallis and R\'{e}nyi entropies converge if and only if $\alpha$ is
greater than 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3003</identifier>
 <datestamp>2013-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3003</id><created>2009-01-20</created><updated>2013-07-19</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Timed tuplix calculus and the Wesseling and van den Bergh equation</title><categories>q-fin.GN cs.LO</categories><comments>17 pages; phrasing improved, references updated; substantially
  improved; remarks added</comments><report-no>PRG0901</report-no><journal-ref>Scientific Annals of Computer Science 23(2):169--190, 2013</journal-ref><doi>10.7561/SACS.2013.2.169</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an algebraic framework for the description and analysis of
financial behaviours, that is, behaviours that consist of transferring certain
amounts of money at planned times. To a large extent, analysis of financial
products amounts to analysis of such behaviours. We formalize the cumulative
interest compliant conservation requirement for financial products proposed by
Wesseling and van den Bergh by an equation in the framework developed and
define a notion of financial product behaviour using this formalization. We
also present some properties of financial product behaviours. The development
of the framework has been influenced by previous work on the process algebra
ACP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3119</identifier>
 <datestamp>2011-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3119</id><created>2009-01-20</created><updated>2009-09-10</updated><authors><author><keyname>Cibulka</keyname><forenames>Josef</forenames></author></authors><title>Average number of flips in pancake sorting</title><categories>cs.DM</categories><comments>21 pages, new computational results for unburnt pancakes (up to n=19)</comments><journal-ref>Theor. Comput. Sci. 412, pp. 822-834 (2011)</journal-ref><doi>10.1016/j.tcs.2010.11.028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given a stack of pancakes of different sizes and the only allowed
operation is to take several pancakes from top and flip them. The unburnt
version requires the pancakes to be sorted by their sizes at the end, while in
the burnt version they additionally need to be oriented burnt-side down. We
present an algorithm with the average number of flips, needed to sort a stack
of n burnt pancakes, equal to 7n/4+O(1) and a randomized algorithm for the
unburnt version with at most 17n/12+O(1) flips on average.
  In addition, we show that in the burnt version, the average number of flips
of any algorithm is at least n+\Omega(n/log n) and conjecture that some
algorithm can reach n+\Theta(n/log n).
  We also slightly increase the lower bound on g(n), the minimum number of
flips needed to sort the worst stack of n burnt pancakes. This bound, together
with the upper bound found by Heydari and Sudborough in 1997, gives the exact
number of flips to sort the previously conjectured worst stack -I_n for n=3 mod
4 and n&gt;=15. Finally we present exact values of f(n) up to n=19 and of g(n) up
to n=17 and disprove a conjecture of Cohen and Blum by showing that the burnt
stack -I_{15} is not the worst one for n=15.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3170</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3170</id><created>2009-01-21</created><updated>2009-10-29</updated><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>On linear balancing sets</title><categories>cs.IT cs.DM math.IT</categories><comments>The abstract of this paper appeared in the proc. of 2009
  International Symposium on Information Theory</comments><journal-ref>Advances in Mathematics of Communications (AMC), Vol. 4, Issue 3,
  pp. 345 - 361, August, 2010</journal-ref><doi>10.3934/amc.2010.4.345</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let n be an even positive integer and F be the field \GF(2). A word in F^n is
called balanced if its Hamming weight is n/2. A subset C \subseteq F^n$ is
called a balancing set if for every word y \in F^n there is a word x \in C such
that y + x is balanced. It is shown that most linear subspaces of F^n of
dimension slightly larger than 3/2\log_2(n) are balancing sets. A
generalization of this result to linear subspaces that are "almost balancing"
is also presented. On the other hand, it is shown that the problem of deciding
whether a given set of vectors in F^n spans a balancing set, is NP-hard. An
application of linear balancing sets is presented for designing efficient
error-correcting coding schemes in which the codewords are balanced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3197</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3197</id><created>2009-01-21</created><updated>2009-10-07</updated><authors><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Ihler</keyname><forenames>Alexander T.</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>A Low Density Lattice Decoder via Non-Parametric Belief Propagation</title><categories>cs.IT math.IT</categories><comments>Submitted for publication</comments><doi>10.1109/ALLERTON.2009.5394798</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent work of Sommer, Feder and Shalvi presented a new family of codes
called low density lattice codes (LDLC) that can be decoded efficiently and
approach the capacity of the AWGN channel. A linear time iterative decoding
scheme which is based on a message-passing formulation on a factor graph is
given.
  In the current work we report our theoretical findings regarding the relation
between the LDLC decoder and belief propagation. We show that the LDLC decoder
is an instance of non-parametric belief propagation and further connect it to
the Gaussian belief propagation algorithm. Our new results enable borrowing
knowledge from the non-parametric and Gaussian belief propagation domains into
the LDLC domain. Specifically, we give more general convergence conditions for
convergence of the LDLC decoder (under the same assumptions of the original
LDLC convergence analysis). We discuss how to extend the LDLC decoder from
Latin square to full rank, non-square matrices. We propose an efficient
construction of sparse generator matrix and its matching decoder. We report
preliminary experimental results which show our decoder has comparable symbol
to error rate compared to the original LDLC decoder.%
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3299</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3299</id><created>2009-01-21</created><updated>2010-05-28</updated><authors><author><keyname>van Iersel</keyname><forenames>Leo</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author></authors><title>Computing Rooted and Unrooted Maximum Consistent Supertrees</title><categories>cs.DM cs.DS</categories><comments>This paper has been withdrawn by the authors due to an error</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A chief problem in phylogenetics and database theory is the computation of a
maximum consistent tree from a set of rooted or unrooted trees. A standard
input are triplets, rooted binary trees on three leaves, or quartets, unrooted
binary trees on four leaves. We give exact algorithms constructing rooted and
unrooted maximum consistent supertrees in time O(2^n n^5 m^2 log(m)) for a set
of m triplets (quartets), each one distinctly leaf-labeled by some subset of n
labels. The algorithms extend to weighted triplets (quartets). We further
present fast exact algorithms for constructing rooted and unrooted maximum
consistent trees in polynomial space. Finally, for a set T of m rooted or
unrooted trees with maximum degree D and distinctly leaf-labeled by some subset
of a set L of n labels, we compute, in O(2^{mD} n^m m^5 n^6 log(m)) time, a
tree distinctly leaf-labeled by a maximum-size subset X of L that all trees in
T, when restricted to X, are consistent with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3384</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3384</id><created>2009-01-21</created><authors><author><keyname>Ham</keyname><forenames>Michael I.</forenames></author><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>A Boundary Approximation Algorithm for Distributed Sensor Networks</title><categories>cs.DC</categories><report-no>LA-UR-09-00111</report-no><acm-class>C.2.1</acm-class><journal-ref>International Journal of Sensor Networks, 8(1), pp. 41-46,
  ISSN:1748-1279, 2010</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present an algorithm for boundary approximation in locally-linked sensor
networks that communicate with a remote monitoring station. Delaunay
triangulations and Voronoi diagrams are used to generate a sensor communication
network and define boundary segments between sensors, respectively. The
proposed algorithm reduces remote station communication by approximating
boundaries via a decentralized computation executed within the sensor network.
Moreover, the algorithm identifies boundaries based on differences between
neighboring sensor readings, and not absolute sensor values. An analysis of the
bandwidth consumption of the algorithm is presented and compared to two naive
approaches. The proposed algorithm reduces the amount of remote communication
(compared to the naive approaches) and becomes increasingly useful in networks
with more nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3590</identifier>
 <datestamp>2014-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3590</id><created>2009-01-22</created><updated>2009-12-27</updated><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Li</keyname><forenames>Hanxi</forenames></author></authors><title>On the Dual Formulation of Boosting Algorithms</title><categories>cs.LG cs.CV</categories><comments>16 pages. To publish/Published in IEEE Transactions on Pattern
  Analysis and Machine Intelligence, 2010</comments><doi>10.1109/TPAMI.2010.47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study boosting algorithms from a new perspective. We show that the
Lagrange dual problems of AdaBoost, LogitBoost and soft-margin LPBoost with
generalized hinge loss are all entropy maximization problems. By looking at the
dual problems of these boosting algorithms, we show that the success of
boosting algorithms can be understood in terms of maintaining a better margin
distribution by maximizing margins and at the same time controlling the margin
variance.We also theoretically prove that, approximately, AdaBoost maximizes
the average margin, instead of the minimum margin. The duality formulation also
enables us to develop column generation based optimization algorithms, which
are totally corrective. We show that they exhibit almost identical
classification results to that of standard stage-wise additive boosting
algorithms but with much faster convergence rates. Therefore fewer weak
classifiers are needed to build the ensemble using our proposed optimization
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3706</identifier>
 <datestamp>2010-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3706</id><created>2009-01-23</created><updated>2009-01-25</updated><authors><author><keyname>Brachat</keyname><forenames>Jerome</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Comon</keyname><forenames>Pierre</forenames><affiliation>I3S</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Tsigaridas</keyname><forenames>Elias</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Symmetric tensor decomposition</title><categories>cs.SC math.AG</categories><proxy>ccsd inria-00355713</proxy><journal-ref>Linear Algebra and Applications 433, 11-12 (2010) 851?1872</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for decomposing a symmetric tensor, of dimension n
and order d as a sum of rank-1 symmetric tensors, extending the algorithm of
Sylvester devised in 1886 for binary forms. We recall the correspondence
between the decomposition of a homogeneous polynomial in n variables of total
degree d as a sum of powers of linear forms (Waring's problem), incidence
properties on secant varieties of the Veronese Variety and the representation
of linear forms as a linear combination of evaluations at distinct points. Then
we reformulate Sylvester's approach from the dual point of view. Exploiting
this duality, we propose necessary and sufficient conditions for the existence
of such a decomposition of a given rank, using the properties of Hankel (and
quasi-Hankel) matrices, derived from multivariate polynomials and normal form
computations. This leads to the resolution of polynomial equations of small
degree in non-generic cases. We propose a new algorithm for symmetric tensor
decomposition, based on this characterization and on linear algebra
computations with these Hankel matrices. The impact of this contribution is
two-fold. First it permits an efficient computation of the decomposition of any
tensor of sub-generic rank, as opposed to widely used iterative algorithms with
unproved global convergence (e.g. Alternate Least Squares or gradient
descents). Second, it gives tools for understanding uniqueness conditions, and
for detecting the rank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3795</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3795</id><created>2009-01-23</created><updated>2010-01-26</updated><authors><author><keyname>Szajowski</keyname><forenames>Krzysztof</forenames></author></authors><title>On a random number of disorders</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>in Institute of Mathematics, Polish Academy of Science, Preprint no.
  702, 25 references, 34 pages</comments><msc-class>60G40, 60K99, 90D60</msc-class><journal-ref>Probability and Mathematical Statistics, vol. 31, Fasc. 1 (2011),
  pp. 17-45</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We register a random sequence which has the following properties: it has
three segments being the homogeneous Markov processes. Each segment has his own
one step transition probability law and the length of the segment is unknown
and random. It means that at two random successive moments (they can be equal
also and equal zero too) the source of observations is changed and the first
observation in new segment is chosen according to new transition probability
starting from the last state of the previous segment. In effect the number of
homogeneous segments is random. The transition probabilities of each process
are known and a priori distribution of the disorder moments is given. The
former research on such problem has been devoted to various questions
concerning the distribution changes. The random number of distributional
segments creates new problems in solutions with relation to analysis of the
model with deterministic number of segments. Two cases are presented in
details. In the first one the objectives is to stop on or between the disorder
moments while in the second one our objective is to find the strategy which
immediately detects the distribution changes. Both problems are reformulated to
optimal stopping of the observed sequences. The detailed analysis of the
problem is presented to show the form of optimal decision function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3839</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3839</id><created>2009-01-24</created><authors><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Meiss</keyname><forenames>Mark R.</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author><author><keyname>Flammini</keyname><forenames>Alessandro</forenames></author><author><keyname>Menczer</keyname><forenames>Filippo</forenames></author></authors><title>Remembering what we like: Toward an agent-based model of Web traffic</title><categories>cs.HC cs.CY cs.IR cs.MA physics.soc-ph</categories><comments>4 pages, 4 figures. Accepted in WSDM 2009 Late Breaking Results</comments><journal-ref>WSDM 2009 Late Breaking Results</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of aggregate Web traffic has shown that PageRank is a poor model of
how people actually navigate the Web. Using the empirical traffic patterns
generated by a thousand users over the course of two months, we characterize
the properties of Web traffic that cannot be reproduced by Markovian models, in
which destinations are independent of past decisions. In particular, we show
that the diversity of sites visited by individual users is smaller and more
broadly distributed than predicted by the PageRank model; that link traffic is
more broadly distributed than predicted; and that the time between consecutive
visits to the same site by a user is less broadly distributed than predicted.
To account for these discrepancies, we introduce a more realistic navigation
model in which agents maintain individual lists of bookmarks that are used as
teleportation targets. The model can also account for branching, a traffic
property caused by browser features such as tabs and the back button. The model
reproduces aggregate traffic patterns such as site popularity, while also
generating more accurate predictions of diversity, link traffic, and return
time distributions. This model for the first time allows us to capture the
extreme heterogeneity of aggregate traffic measurements while explaining the
more narrowly focused browsing patterns of individual users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.3880</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.3880</id><created>2009-01-25</created><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Capacity Scaling of Single-source Wireless Networks: Effect of Multiple
  Antennas</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 11, pp.
  6870-6878, Nov. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless network in which a single source node located at the
center of a unit area having $m$ antennas transmits messages to $n$ randomly
located destination nodes in the same area having a single antenna each. To
achieve the sum-rate proportional to $m$ by transmit beamforming, channel state
information (CSI) is essentially required at the transmitter (CSIT), which is
hard to obtain in practice because of the time-varying nature of the channels
and feedback overhead. We show that, even without CSIT, the achievable sum-rate
scales as $\Theta(m\log m)$ if a cooperation between receivers is allowed. By
deriving the cut-set upper bound, we also show that $\Theta(m\log m)$ scaling
is optimal. Specifically, for $n=\omega(m^2)$, the simple TDMA-based
quantize-and-forward is enough to achieve the capacity scaling. For
$n=\omega(m)$ and $n=\operatorname{O}(m^2)$, on the other hand, we apply the
hierarchical cooperation to achieve the capacity scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4012</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4012</id><created>2009-01-26</created><updated>2009-11-28</updated><authors><author><keyname>Fontanari</keyname><forenames>José F.</forenames></author><author><keyname>Cangelosi</keyname><forenames>Angelo</forenames></author></authors><title>Cross-situational and supervised learning in the emergence of
  communication</title><categories>cs.LG</categories><journal-ref>Interaction Studies: Social Behaviour and Communication in
  Biological and Artificial Systems, 12, 119-133 (2011)</journal-ref><doi>10.1075/is.12.1.05fon</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scenarios for the emergence or bootstrap of a lexicon involve the repeated
interaction between at least two agents who must reach a consensus on how to
name N objects using H words. Here we consider minimal models of two types of
learning algorithms: cross-situational learning, in which the individuals
determine the meaning of a word by looking for something in common across all
observed uses of that word, and supervised operant conditioning learning, in
which there is strong feedback between individuals about the intended meaning
of the words. Despite the stark differences between these learning schemes, we
show that they yield the same communication accuracy in the realistic limits of
large N and H, which coincides with the result of the classical occupancy
problem of randomly assigning N objects to H words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4032</identifier>
 <datestamp>2014-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4032</id><created>2009-01-26</created><authors><author><keyname>Mishra</keyname><forenames>Siddhartha</forenames><affiliation>University of Oslo</affiliation></author><author><keyname>Jaffré</keyname><forenames>Jérôme</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>On the upstream mobility scheme for two-phase flow in porous media</title><categories>cs.NA math.AP math.NA physics.class-ph</categories><comments>A preprint to be published in Computational Geosciences</comments><proxy>ccsd inria-00353627</proxy><report-no>RR-6789</report-no><journal-ref>Computational Geosciences 14 (2010) 105-124</journal-ref><doi>10.1007/s10596-009-9135-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When neglecting capillarity, two-phase incompressible flow in porous media is
modelled as a scalar nonlinear hyperbolic conservation law. A change in the
rock type results in a change of the flux function. Discretizing in
one-dimensional with a finite volume method, we investigate two numerical
fluxes, an extension of the Godunov flux and the upstream mobility flux, the
latter being widely used in hydrogeology and petroleum engineering. Then, in
the case of a changing rock type, one can give examples when the upstream
mobility flux does not give the right answer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4129</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4129</id><created>2009-01-26</created><updated>2011-08-20</updated><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Quasi-Cyclic LDPC Codes: Influence of Proto- and Tanner-Graph Structure
  on Minimum Hamming Distance Upper Bounds</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in IEEE Transactions on Information Theory. Changes
  compared to v1: some convolutional code results have been added; some
  incompleteness issues with some of the proofs have been corrected; a typo in
  one of the parity-check matrices has been corrected (i.e., an entry of H"(x)
  in Example 28 of v1 needs to be changed so that d_min=56 as written there,
  cf. \hat H(x) in Example 29 of v2)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quasi-cyclic (QC) low-density parity-check (LDPC) codes are an important
instance of proto-graph-based LDPC codes. In this paper we present upper bounds
on the minimum Hamming distance of QC LDPC codes and study how these upper
bounds depend on graph structure parameters (like variable degrees, check node
degrees, girth) of the Tanner graph and of the underlying proto-graph.
Moreover, for several classes of proto-graphs we present explicit QC LDPC code
constructions that achieve (or come close to) the respective minimum Hamming
distance upper bounds. Because of the tight algebraic connection between QC
codes and convolutional codes, we can state similar results for the free
Hamming distance of convolutional codes. In fact, some QC code statements are
established by first proving the corresponding convolutional code statements
and then using a result by Tanner that says that the minimum Hamming distance
of a QC code is upper bounded by the free Hamming distance of the convolutional
code that is obtained by "unwrapping" the QC code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4134</identifier>
 <datestamp>2010-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4134</id><created>2009-01-26</created><updated>2010-03-02</updated><authors><author><keyname>Su</keyname><forenames>Han-I</forenames></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames></author></authors><title>Distributed Lossy Averaging</title><categories>cs.IT math.IT</categories><comments>25 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An information theoretic formulation of the distributed averaging problem
previously studied in computer science and control is presented. We assume a
network with m nodes each observing a WGN source. The nodes communicate and
perform local processing with the goal of computing the average of the sources
to within a prescribed mean squared error distortion. The network rate
distortion function R^*(D) for a 2-node network with correlated Gaussian
sources is established. A general cutset lower bound on R^*(D) is established
and shown to be achievable to within a factor of 2 via a centralized protocol
over a star network. A lower bound on the network rate distortion function for
distributed weighted-sum protocols, which is larger in order than the cutset
bound by a factor of log m is established. An upper bound on the network rate
distortion function for gossip-base weighted-sum protocols, which is only log
log m larger in order than the lower bound for a complete graph network, is
established. The results suggest that using distributed protocols results in a
factor of log m increase in order relative to centralized protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4180</identifier>
 <datestamp>2015-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4180</id><created>2009-01-27</created><updated>2015-01-28</updated><authors><author><keyname>Kjos-Hanssen</keyname><forenames>Bjørn</forenames></author><author><keyname>Evangelista</keyname><forenames>Alberto J.</forenames></author></authors><title>Google distance between words</title><categories>cs.CL</categories><comments>Presented at Frontiers in Undergraduate Research, University of
  Connecticut, 2006</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cilibrasi and Vitanyi have demonstrated that it is possible to extract the
meaning of words from the world-wide web. To achieve this, they rely on the
number of webpages that are found through a Google search containing a given
word and they associate the page count to the probability that the word appears
on a webpage. Thus, conditional probabilities allow them to correlate one word
with another word's meaning. Furthermore, they have developed a similarity
distance function that gauges how closely related a pair of words is. We
present a specific counterexample to the triangle inequality for this
similarity distance function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4192</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4192</id><created>2009-01-27</created><updated>2009-07-03</updated><authors><author><keyname>Johnson</keyname><forenames>Jason K.</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Dolev</keyname><forenames>Danny</forenames></author></authors><title>Fixing Convergence of Gaussian Belief Propagation</title><categories>cs.IT cs.LG math.IT stat.CO</categories><comments>In the IEEE International Symposium on Information Theory (ISIT)
  2009, Seoul, South Korea, July 2009</comments><doi>10.1109/ISIT.2009.5205777</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian belief propagation (GaBP) is an iterative message-passing algorithm
for inference in Gaussian graphical models. It is known that when GaBP
converges it converges to the correct MAP estimate of the Gaussian random
vector and simple sufficient conditions for its convergence have been
established. In this paper we develop a double-loop algorithm for forcing
convergence of GaBP. Our method computes the correct MAP estimate even in cases
where standard GaBP would not have converged. We further extend this
construction to compute least-squares solutions of over-constrained linear
systems. We believe that our construction has numerous applications, since the
GaBP algorithm is linked to solution of linear systems of equations, which is a
fundamental problem in computer science and engineering. As a case study, we
discuss the linear detection problem. We show that using our new construction,
we are able to force convergence of Montanari's linear detection algorithm, in
cases where it would originally fail. As a consequence, we are able to increase
significantly the number of users that can transmit concurrently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4379</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4379</id><created>2009-01-27</created><updated>2012-06-16</updated><authors><author><keyname>Nazer</keyname><forenames>Bobak</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Ergodic Interference Alignment</title><categories>cs.IT math.IT</categories><comments>16 pages, 6 figure, To appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a new communication strategy, ergodic interference
alignment, for the K-user interference channel with time-varying fading. At any
particular time, each receiver will see a superposition of the transmitted
signals plus noise. The standard approach to such a scenario results in each
transmitter-receiver pair achieving a rate proportional to 1/K its
interference-free ergodic capacity. However, given two well-chosen time
indices, the channel coefficients from interfering users can be made to exactly
cancel. By adding up these two observations, each receiver can obtain its
desired signal without any interference. If the channel gains have independent,
uniform phases, this technique allows each user to achieve at least 1/2 its
interference-free ergodic capacity at any signal-to-noise ratio. Prior
interference alignment techniques were only able to attain this performance as
the signal-to-noise ratio tended to infinity. Extensions are given for the case
where each receiver wants a message from more than one transmitter as well as
the "X channel" case (with two receivers) where each transmitter has an
independent message for each receiver. Finally, it is shown how to generalize
this strategy beyond Gaussian channel models. For a class of finite field
interference channels, this approach yields the ergodic capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4400</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4400</id><created>2009-01-28</created><updated>2009-01-28</updated><authors><author><keyname>Bihan</keyname><forenames>Frederic</forenames></author><author><keyname>Rojas</keyname><forenames>J. Maurice</forenames></author><author><keyname>Stella</keyname><forenames>Casey</forenames></author></authors><title>Faster Real Feasibility via Circuit Discriminants</title><categories>math.AG cs.CC math.OC</categories><comments>12 pages in double column ACM format. Submitted to a conference.
  Significantly improves and simplifies the algorithms and complexity lower
  bounds of arXiv:math/0411107 . Also presents a new complexity lower bound for
  A-discriminants. This version fixes many annoying typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that detecting real roots for honestly n-variate (n+2)-nomials (with
integer exponents and coefficients) can be done in time polynomial in the
sparse encoding for any fixed n. The best previous complexity bounds were
exponential in the sparse encoding, even for n fixed. We then give a
characterization of those functions k(n) such that the complexity of detecting
real roots for n-variate (n+k(n))-nomials transitions from P to NP-hardness as
n tends to infinity. Our proofs follow in large part from a new complexity
threshold for deciding the vanishing of A-discriminants of n-variate
(n+k(n))-nomials. Diophantine approximation, through linear forms in
logarithms, also arises as a key tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4417</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4417</id><created>2009-01-28</created><updated>2010-02-12</updated><authors><author><keyname>Wild</keyname><forenames>Marcel</forenames></author></authors><title>A novel type of branch and bound for maximum independent set</title><categories>cs.DS cs.DM cs.MS</categories><comments>The section break up in v2 is improved, parts are trimmed, other
  parts added (e.g graphs with up to 3000 vertices are handled), the new title
  is more diplomatic. See the last page of version 1 for the missing figure on
  page 2 of version 2 (technical problems)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several algorithms are presented. The standard algorithm generates all N
anticliques of a graph with v vertices in time O(N^v2). It can e.g. be adapted
to calculate the independence polynomial of G, to generate all maximum
cardinality anticliques, or just one maximum anticlique. The latter was
programmed using the Mathematica 6.0 code. For a random (45, 92)-graph G a
maximum anticlique of size 21 was found in 1.344 sec, whereas the "hardwired"
Mathematica command MaximumIndependentSet[G] clocked in at 155838 sec, which is
five orders of magnitude slower.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4466</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4466</id><created>2009-01-28</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Physarum boats: If plasmodium sailed it would never leave a port</title><categories>cs.RO q-bio.CB</categories><acm-class>I.2.9; J.3</acm-class><journal-ref>Applied Bionics and Biomechanics, Volume 7, Issue 1 March 2010 ,
  pages 31 - 39</journal-ref><doi>10.1080/11762320902863890</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plasmodium of \emph{Physarum polycephalum} is a single huge (visible by naked
eye) cell with myriad of nuclei. The plasmodium is a promising substrate for
non-classical, nature-inspired, computing devices. It is capable for
approximation of shortest path, computation of planar proximity graphs and
plane tessellations, primitive memory and decision-making. The unique
properties of the plasmodium make it an ideal candidate for a role of amorphous
biological robots with massive parallel information processing and distributed
inputs and outputs. We show that when adhered to light-weight object resting on
a water surface the plasmodium can propel the object by oscillating its
protoplasmic pseudopodia. In experimental laboratory conditions and
computational experiments we study phenomenology of the plasmodium-floater
system, and possible mechanisms of controlling motion of objects propelled by
on board plasmodium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4467</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4467</id><created>2009-01-28</created><updated>2011-10-07</updated><authors><author><keyname>Braunstein</keyname><forenames>Alfredo</forenames></author><author><keyname>Kayhan</keyname><forenames>Farbod</forenames></author><author><keyname>Zecchina</keyname><forenames>Riccardo</forenames></author></authors><title>Efficient LDPC Codes over GF(q) for Lossy Data Compression</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures</comments><journal-ref>In: IEEE International Symposium on Information Theory, 2009. ISIT
  2009. Seul, Korea; 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the lossy compression of a binary symmetric source.
We present a scheme that provides a low complexity lossy compressor with near
optimal empirical performance. The proposed scheme is based on b-reduced
ultra-sparse LDPC codes over GF(q). Encoding is performed by the Reinforced
Belief Propagation algorithm, a variant of Belief Propagation. The
computational complexity at the encoder is O(&lt;d&gt;.n.q.log q), where &lt;d&gt; is the
average degree of the check nodes. For our code ensemble, decoding can be
performed iteratively following the inverse steps of the leaf removal
algorithm. For a sparse parity-check matrix the number of needed operations is
O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4643</identifier>
 <datestamp>2012-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4643</id><created>2009-01-29</created><updated>2009-12-27</updated><authors><author><keyname>Grossu</keyname><forenames>I. V.</forenames></author><author><keyname>Besliu</keyname><forenames>C.</forenames></author><author><keyname>Rusu</keyname><forenames>M. V.</forenames></author><author><keyname>Jipa</keyname><forenames>Al.</forenames></author><author><keyname>Bordeianu</keyname><forenames>C. C.</forenames></author><author><keyname>Felea</keyname><forenames>D.</forenames></author><author><keyname>Stan</keyname><forenames>E.</forenames></author><author><keyname>Esanu</keyname><forenames>T.</forenames></author></authors><title>Visual tool for estimating the fractal dimension of images</title><categories>physics.comp-ph cs.GR nlin.PS</categories><comments>A new version was accepted to Computer Physics Communications
  doi:10.1016/j.cpc.2009.12.005</comments><journal-ref>Computer Physics Communications 180 (2009) p.1999-2001; CPC,
  Volume 181, Issue 4, April 2010, Pages 831-832</journal-ref><doi>10.1016/j.cpc.2009.05.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents a new Visual Basic 6.0 application for estimating the
fractal dimension of images, based on an optimized version of the box-counting
algorithm. Following the attempt to separate the real information from noise,
we considered also the family of all band-pass filters with the same band-width
(specified as parameter). The fractal dimension can be thus represented as a
function of the pixel color code. The program was used for the study of
paintings cracks, as an additional tool which can help the critic to decide if
an artistic work is original or not. In its second version, the application was
extended for working also with csv files and three-dimensional images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4784</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4784</id><created>2009-01-29</created><authors><author><keyname>Guerrero</keyname><forenames>Fabio G.</forenames></author></authors><title>On the Entropy of Written Spanish</title><categories>cs.CL cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><journal-ref>Revista Colombiana de Estadistica (RCE), Vol. 35, No. 3, Dec.
  2012, pp 423-440</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reports on results on the entropy of the Spanish language. They
are based on an analysis of natural language for n-word symbols (n = 1 to 18),
trigrams, digrams, and characters. The results obtained in this work are based
on the analysis of twelve different literary works in Spanish, as well as a
279917 word news file provided by the Spanish press agency EFE. Entropy values
are calculated by a direct method using computer processing and the probability
law of large numbers. Three samples of artificial Spanish language produced by
a first-order model software source are also analyzed and compared with natural
Spanish language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4798</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4798</id><created>2009-01-29</created><updated>2009-02-18</updated><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Space Efficient Secret Sharing</title><categories>cs.CR</categories><comments>5 pages; with corrections</comments><journal-ref>4th Annual Computer Science Research Conference at the University
  of Oklahoma, April 18, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note proposes a method of space efficient secret sharing in which k
secrets are mapped into n shares (n&gt;=k) of the same size. Since, n can be
chosen to be equal to k, the method is space efficient. This method may be
compared with conventional secret sharing schemes that divide a single secret
into n shares.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4814</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4814</id><created>2009-01-29</created><authors><author><keyname>Parakh</keyname><forenames>Abhishek</forenames></author><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Space Efficient Secret Sharing: A Recursive Approach</title><categories>cs.CR</categories><comments>8 pages</comments><report-no>Cryptology ePrint Archive: Report 2009/365</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a recursive secret sharing technique that distributes k-1
secrets of length b each into n shares such that each share is effectively of
length (n/(k-1))*b and any k pieces suffice for reconstructing all the k-1
secrets. Since n/(k-1) is near the optimal factor of n/k, and can be chosen to
be close to 1, the proposed technique is space efficient. Furthermore, each
share is information theoretically secure, i.e. it does not depend on any
unproven assumption of computational intractability. Such a recursive technique
has potential applications in secure and reliable storage of information on the
Web and in sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4835</identifier>
 <datestamp>2010-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4835</id><created>2009-01-30</created><updated>2010-02-09</updated><authors><author><keyname>Chung</keyname><forenames>Yoo</forenames></author><author><keyname>Lee</keyname><forenames>Dongman</forenames></author></authors><title>A Mathematical Basis for the Chaining of Lossy Interface Adapters</title><categories>cs.DM cs.DC cs.SE</categories><comments>22 pages, 6 figures</comments><acm-class>D.2.12; F.2.2</acm-class><journal-ref>IET Software, 4(1):54-54, February 2010</journal-ref><doi>10.1049/iet-sen.2009.0019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite providing similar functionality, multiple network services may
require the use of different interfaces to access the functionality, and this
problem will only get worse with the widespread deployment of ubiquitous
computing environments. One way around this problem is to use interface
adapters that adapt one interface into another. Chaining these adapters allows
flexible interface adaptation with fewer adapters, but the loss incurred due to
imperfect interface adaptation must be considered. This paper outlines a
mathematical basis for analyzing the chaining of lossy interface adapters. We
also show that the problem of finding an optimal interface adapter chain is
NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4904</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4904</id><created>2009-01-30</created><updated>2014-04-13</updated><authors><author><keyname>Nair</keyname><forenames>Rajiv</forenames></author><author><keyname>Nagarjuna</keyname><forenames>G.</forenames></author><author><keyname>Ray</keyname><forenames>Arnab K.</forenames></author></authors><title>Finite-size effects in the dependency networks of free and open-source
  software</title><categories>cs.OH physics.soc-ph</categories><comments>ReVTeX, 9 pages, 7 figures. Major revisions in Sections III and IV of
  this version. The bibliography has been updated</comments><journal-ref>Complex Systems, 23, 71, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a continuum model for the degree distribution of directed networks
in free and open-source software. The degree distributions of links in both the
in-directed and out-directed dependency networks follow Zipf's law for the
intermediate nodes, but the heavily linked nodes and the poorly linked nodes
deviate from this trend and exhibit finite-size effects. The finite-size
parameters make a quantitative distinction between the in-directed and
out-directed networks. For the out-degree distribution, the initial condition
for a dynamic evolution corresponds to the limiting count of the most heavily
liked nodes that the out-directed network can finally have. The number of nodes
contributing out-directed links grows with every generation of software
release, but this growth ultimately saturates towards a terminal value due to
the finiteness of semantic possibilities in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0901.4934</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0901.4934</id><created>2009-01-30</created><updated>2010-10-04</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>A historical perspective on developing foundations iInfo(TM) information
  systems: iConsult(TM) and iEntertain(TM) apps using iDescribers(TM)
  information integration for iOrgs(TM) information systems</title><categories>cs.DC cs.DB cs.LO</categories><comments>updated title and abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Technology now at hand can integrate all kinds of digital information for
individuals, groups, and organizations so their information usefully links
together. iInfo(TM) information integration works by making connections
including examples like the following:
  - A statistical connection between "being in a traffic jam" and "driving in
downtown Trenton between 5PM and 6PM on a weekday."
  - A terminological connection between "MSR" and "Microsoft Research."
  - A causal connection between "joining a group" and "being a member of the
group."
  - A syntactic connection between "a pin dropped" and "a dropped pin."
  - A biological connection between "a dolphin" and "a mammal".
  - A demographic connection between "undocumented residents of California" and
"7% of the population of California."
  - A geographical connection between "Leeds" and "England."
  - A temporal connection between "turning on a computer" and "joining an
on-line discussion."
  By making these connections, iInfo offers tremendous value for individuals,
families, groups, and organizations in making more effective use of information
technology.
  In practice, integrated information is invariably pervasively inconsistent.
Therefore iInfo must be able to make connections even in the face of
inconsistency. The business of iInfo is not to make difficult decisions like
deciding the ultimate truth or probability of propositions. Instead it provides
means for processing information and carefully recording its provenance
including arguments (including arguments about arguments) for and against
propositions that is used by iConsult(TM) and iEntertain(TM) apps in iOrgs(TM)
Information Systems.
  A historical perspective on the above questions is highly pertinent to the
current quest to develop foundations for privacy-friendly client-cloud
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0026</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0026</id><created>2009-01-31</created><updated>2009-09-21</updated><authors><author><keyname>Tropp</keyname><forenames>Joel A.</forenames></author><author><keyname>Laska</keyname><forenames>Jason N.</forenames></author><author><keyname>Duarte</keyname><forenames>Marco F.</forenames></author><author><keyname>Romberg</keyname><forenames>Justin K.</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard G.</forenames></author></authors><title>Beyond Nyquist: Efficient Sampling of Sparse Bandlimited Signals</title><categories>cs.IT math.IT</categories><comments>24 pages, 8 figures</comments><journal-ref>IEEE Trans. Inform. Theory, Vol.56, num. 1, pp. 520-544, Jan. 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wideband analog signals push contemporary analog-to-digital conversion
systems to their performance limits. In many applications, however, sampling at
the Nyquist rate is inefficient because the signals of interest contain only a
small number of significant frequencies relative to the bandlimit, although the
locations of the frequencies may not be known a priori. For this type of sparse
signal, other sampling strategies are possible. This paper describes a new type
of data acquisition system, called a random demodulator, that is constructed
from robust, readily available components. Let K denote the total number of
frequencies in the signal, and let W denote its bandlimit in Hz. Simulations
suggest that the random demodulator requires just O(K log(W/K)) samples per
second to stably reconstruct the signal. This sampling rate is exponentially
lower than the Nyquist rate of W Hz. In contrast with Nyquist sampling, one
must use nonlinear methods, such as convex programming, to recover the signal
from the samples taken by the random demodulator. This paper provides a
detailed theoretical analysis of the system's performance that supports the
empirical observations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0101</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0101</id><created>2009-02-02</created><updated>2009-04-10</updated><authors><author><keyname>Ummels</keyname><forenames>Michael</forenames></author><author><keyname>Wojtczak</keyname><forenames>Dominik</forenames></author></authors><title>The Complexity of Nash Equilibria in Simple Stochastic Multiplayer Games</title><categories>cs.GT cs.CC cs.LO</categories><comments>23 pages; revised version</comments><report-no>EDI-INF-RR-1323</report-no><doi>10.1007/978-3-642-02930-1_25</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the computational complexity of finding Nash equilibria in simple
stochastic multiplayer games. We show that restricting the search space to
equilibria whose payoffs fall into a certain interval may lead to
undecidability. In particular, we prove that the following problem is
undecidable: Given a game G, does there exist a pure-strategy Nash equilibrium
of G where player 0 wins with probability 1. Moreover, this problem remains
undecidable if it is restricted to strategies with (unbounded) finite memory.
However, if mixed strategies are allowed, decidability remains an open problem.
One way to obtain a provably decidable variant of the problem is restricting
the strategies to be positional or stationary. For the complexity of these two
problems, we obtain a common lower bound of NP and upper bounds of NP and
PSPACE respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0261</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0261</id><created>2009-02-02</created><updated>2011-07-20</updated><authors><author><keyname>Yamakami</keyname><forenames>Tomoyuki</forenames></author></authors><title>Immunity and Pseudorandomness of Context-Free Languages</title><categories>cs.CC cs.FL</categories><comments>A4, 23 pages, 10 pt. A complete revision of the initial version that
  was posted in February 2009</comments><acm-class>F.4.3; F.1.1; F.1.3</acm-class><journal-ref>Theoretical Computer Science, vol. 412, pp.6432-6450, 2011</journal-ref><doi>10.1016/j.tcs.2011.07.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the computational complexity of context-free languages,
concentrating on two well-known structural properties---immunity and
pseudorandomness. An infinite language is REG-immune (resp., CFL-immune) if it
contains no infinite subset that is a regular (resp., context-free) language.
We prove that (i) there is a context-free REG-immune language outside REG/n and
(ii) there is a REG-bi-immune language that can be computed deterministically
using logarithmic space. We also show that (iii) there is a CFL-simple set,
where a CFL-simple language is an infinite context-free language whose
complement is CFL-immune. Similar to the REG-immunity, a REG-primeimmune
language has no polynomially dense subsets that are also regular. We further
prove that (iv) there is a context-free language that is REG/n-bi-primeimmune.
Concerning pseudorandomness of context-free languages, we show that (v) CFL
contains REG/n-pseudorandom languages. Finally, we prove that (vi) against
REG/n, there exists an almost 1-1 pseudorandom generator computable in
nondeterministic pushdown automata equipped with a write-only output tape and
(vii) against REG, there is no almost 1-1 weakly pseudorandom generator
computable deterministically in linear time by a single-tape Turing machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0392</identifier>
 <datestamp>2011-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0392</id><created>2009-02-02</created><updated>2011-09-21</updated><authors><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Tree Exploration for Bayesian RL Exploration</title><categories>stat.ML cs.LG</categories><comments>13 pages, 1 figure. Slightly extended and corrected version (notation
  errors and lower bound calculation) of homonymous paper presented at the
  conference of Computational Intelligence for Modelling, Control and
  Automation 2008 (CIMCA'08)</comments><report-no>IAS-08-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research in reinforcement learning has produced algorithms for optimal
decision making under uncertainty that fall within two main types. The first
employs a Bayesian framework, where optimality improves with increased
computational time. This is because the resulting planning task takes the form
of a dynamic programming problem on a belief tree with an infinite number of
states. The second type employs relatively simple algorithm which are shown to
suffer small regret within a distribution-free framework. This paper presents a
lower bound and a high probability upper bound on the optimal value function
for the nodes in the Bayesian belief tree, which are analogous to similar
bounds in POMDPs. The bounds are then used to create more efficient strategies
for exploring the tree. The resulting algorithms are compared with the
distribution-free algorithm UCB1, as well as a simpler baseline algorithm on
multi-armed bandit problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0465</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0465</id><created>2009-02-03</created><updated>2011-04-07</updated><authors><author><keyname>Jiang</keyname><forenames>Bin</forenames></author><author><keyname>Liu</keyname><forenames>Xintao</forenames></author></authors><title>AxialGen: A Research Prototype for Automatically Generating the Axial
  Map</title><categories>cs.RO cs.CG</categories><comments>9 pages, 4 figures</comments><journal-ref>Proceedings of CUPUM 2009, the 11th International Conference on
  Computers in Urban Planning and Urban Management, Hong Kong, 16-18 June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AxialGen is a research prototype for automatically generating the axial map,
which consists of the least number of the longest visibility lines (or axial
lines) for representing individual linearly stretched parts of open space of an
urban environment. Open space is the space between closed spaces such as
buildings and street blocks. This paper aims to provide an accessible guide to
software AxialGen, and the underlying concepts and ideas. We concentrate on the
explanation and illustration of the key concept of bucket: its definition,
formation and how it is used in generating the axial map.
  Keywords: Bucket, visibility, medial axes, axial lines, isovists, axial map
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0524</identifier>
 <datestamp>2010-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0524</id><created>2009-02-03</created><updated>2010-04-24</updated><authors><author><keyname>Gujar</keyname><forenames>Sujit</forenames></author><author><keyname>Narahari</keyname><forenames>Y</forenames></author></authors><title>An Optimal Multi-Unit Combinatorial Procurement Auction with Single
  Minded Bidders</title><categories>cs.GT</categories><comments>8 Pages, Managing Complexity in Distributed World, MCDES 2008: IISc
  Centenary Conference of Division of Electrical Sciences Added 2 references in
  newer version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current art in optimal combinatorial auctions is limited to handling the
case of single units of multiple items, with each bidder bidding on exactly one
bundle (single minded bidders). This paper extends the current art by proposing
an optimal auction for procuring multiple units of multiple items when the
bidders are single minded. The auction minimizes the cost of procurement while
satisfying Bayesian incentive compatibility and interim individual rationality.
Under appropriate regularity conditions, this optimal auction also satisfies
dominant strategy incentive compatibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0562</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0562</id><created>2009-02-03</created><updated>2010-08-02</updated><authors><author><keyname>Cappellari</keyname><forenames>Lorenzo</forenames></author><author><keyname>De Giusti</keyname><forenames>Andrea</forenames></author></authors><title>A Unified Perspective on Parity- and Syndrome-Based Binary Data
  Compression Using Off-the-Shelf Turbo Codecs</title><categories>cs.IT math.IT</categories><comments>10 pages, 10 figures (11 graphic files organized with subfigures), 1
  table; completely reviewed with a focus on non-uniform sources; submitted to
  IEEE Trans. Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of compressing memoryless binary data with or without
side information at the decoder. We review the parity- and the syndrome-based
approaches and discuss their theoretical limits, assuming that there exists a
virtual binary symmetric channel between the source and the side information,
and that the source is not necessarily uniformly distributed. We take a
factor-graph-based approach in order to devise how to take full advantage of
the ready-available iterative decoding procedures when turbo codes are
employed, in both a parity- or a syndrome-based fashion. We end up obtaining a
unified decoder formulation that holds both for error-free and for error-prone
encoder-to-decoder transmission over generic channels. To support the
theoretical results, the different compression systems analyzed in the paper
are also experimentally tested. They are compared against several different
approaches proposed in literature and shown to be competitive in a variety of
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0746</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0746</id><created>2009-02-04</created><updated>2010-01-06</updated><authors><author><keyname>Jaffrès-Runser</keyname><forenames>Katia</forenames></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames></author></authors><title>Interference and Congestion Aware Gradient Broadcasting Routing for
  Wireless Sensor Networks</title><categories>cs.NI</categories><comments>submitted to Eurasip Journal on Wireless Communications and
  Networking, special issue on Interference Management in Wireless
  Communication Systems: Theory and Applications in November 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of reliable transmission of data through a
sensor network. We focus on networks rapidly deployed in harsh environments.
For these networks, important design requirements are fast data transmission
and rapid network setup, as well as minimized energy consumption for increased
network lifetime. We propose a novel broadcasting solution that accounts for
the interference impact and the congestion level of the channel, in order to
improve robustness, energy consumption and delay performance, compared to a
benchmark routing protocol, the GRAB algorithm. Three solutions are proposed:
P-GRAB, a probabilistic routing algorithm for interference mitigation, U-GRAB,
a utility-based algorithm that adjusts to real-time congestion and UP-GRAB, a
combination of P-GRAB and U-GRAB. It is shown that P-GRAB provides the best
performance for geometry-aware networks while the U-GRAB approach is the best
option for unreliable and unstable networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0782</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0782</id><created>2009-02-04</created><updated>2010-01-06</updated><authors><author><keyname>Jaffrès-Runser</keyname><forenames>Katia</forenames></author><author><keyname>Comaniciu</keyname><forenames>Cristina</forenames></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames></author></authors><title>A Multiobjective Optimization Framework for Routing in Wireless Ad Hoc
  Networks</title><categories>cs.NI cs.PF</categories><journal-ref>IEEE International Symposium on Conference Modeling and
  Optimization in Mobile, Ad Hoc, and Wireless Networks (WiOpt) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless ad hoc networks are seldom characterized by one single performance
metric, yet the current literature lacks a flexible framework to assist in
characterizing the design tradeoffs in such networks. In this work, we address
this problem by proposing a new modeling framework for routing in ad hoc
networks, which used in conjunction with metaheuristic multiobjective search
algorithms, will result in a better understanding of network behavior and
performance when multiple criteria are relevant. Our approach is to take a
holistic view of the network that captures the cross-interactions among
interference management techniques implemented at various layers of the
protocol stack. The resulting framework is a complex multiobjective
optimization problem that can be efficiently solved through existing
multiobjective search techniques. In this contribution, we present the Pareto
optimal sets for an example sensor network when delay, robustness and energy
are considered. The aim of this paper is to present the framework and hence for
conciseness purposes, the multiobjective optimization search is not developed
herein.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0838</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0838</id><created>2009-02-04</created><updated>2012-03-10</updated><authors><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>The Ergodic Capacity of Phase-Fading Interference Networks</title><categories>cs.IT math.IT</categories><comments>19 pages</comments><journal-ref>IEEE Transactions on Information Theory, Vol. 57, No. 12, Pages:
  7685-7694, December 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify the role of equal strength interference links as bottlenecks on
the ergodic sum capacity of a $K$ user phase-fading interference network, i.e.,
an interference network where the fading process is restricted primarily to
independent and uniform phase variations while the channel magnitudes are held
fixed across time. It is shown that even though there are $K(K-1)$ cross-links,
only about $K/2$ disjoint and equal strength interference links suffice to
determine the capacity of the network regardless of the strengths of the rest
of the cross channels. This scenario is called a \emph{minimal bottleneck
state}. It is shown that ergodic interference alignment is capacity optimal for
a network in a minimal bottleneck state. The results are applied to large
networks. It is shown that large networks are close to bottleneck states with a
high probability, so that ergodic interference alignment is close to optimal
for large networks. Limitations of the notion of bottleneck states are also
highlighted for channels where both the phase and the magnitudes vary with
time. It is shown through an example that for these channels, joint coding
across different bottleneck states makes it possible to circumvent the capacity
bottlenecks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0892</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0892</id><created>2009-02-05</created><updated>2011-08-16</updated><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author></authors><title>A Unified Framework for Linear-Programming Based Communication Receivers</title><categories>cs.IT math.IT</categories><comments>13 pages, 6 figures. To appear in the IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that a large class of communication systems which admit a
sum-product algorithm (SPA) based receiver also admit a corresponding
linear-programming (LP) based receiver. The two receivers have a relationship
defined by the local structure of the underlying graphical model, and are
inhibited by the same phenomenon, which we call 'pseudoconfigurations'. This
concept is a generalization of the concept of 'pseudocodewords' for linear
codes. It is proved that the LP receiver has the 'maximum likelihood
certificate' property, and that the receiver output is the lowest cost
pseudoconfiguration. Equivalence of graph-cover pseudoconfigurations and
linear-programming pseudoconfigurations is also proved. A concept of 'system
pseudodistance' is defined which generalizes the existing concept of
pseudodistance for binary and nonbinary linear codes. It is demonstrated how
the LP design technique may be applied to the problem of joint equalization and
decoding of coded transmissions over a frequency selective channel, and a
simulation-based analysis of the error events of the resulting LP receiver is
also provided. For this particular application, the proposed LP receiver is
shown to be competitive with other receivers, and to be capable of
outperforming turbo equalization in bit and frame error rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.0947</identifier>
 <datestamp>2010-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.0947</id><created>2009-02-05</created><updated>2010-04-12</updated><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Wigger</keyname><forenames>Michele A.</forenames></author></authors><title>On the Gaussian MAC with Imperfect Feedback</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New achievable rate regions are derived for the two-user additive white
Gaussian multiple-access channel with noisy feedback. The regions exhibit the
following two properties. Irrespective of the (finite) Gaussian feedback-noise
variances, the regions include rate points that lie outside the no-feedback
capacity region, and when the feedback-noise variances tend to 0 the regions
converge to the perfect-feedback capacity region. The new achievable regions
also apply to the partial-feedback setting where one of the transmitters has a
noisy feedback link and the other transmitter has no feedback at all. Again,
irrespective of the (finite) noise variance on the feedback link, the regions
include rate points that lie outside the no-feedback capacity region. Moreover,
in the case of perfect partial feedback, i.e., where the only feedback link is
noise-free, for certain channel parameters the new regions include rate points
that lie outside the Cover-Leung region. This answers in the negative the
question posed by van der Meulen as to whether the Cover-Leung region equals
the capacity region of the Gaussian multiple-access channel with perfect
partial feedback. Finally, we propose new achievable regions also for a setting
where the receiver is cognizant of the realizations of the noise sequences on
the feedback links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1043</identifier>
 <datestamp>2011-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1043</id><created>2009-02-06</created><updated>2011-03-01</updated><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames><affiliation>MIT</affiliation></author><author><keyname>Demaine</keyname><forenames>Erik D.</forenames><affiliation>MIT</affiliation></author><author><keyname>Tazari</keyname><forenames>Siamak</forenames></author></authors><title>Polynomial-Time Approximation Schemes for Subset-Connectivity Problems
  in Bounded-Genus Graphs</title><categories>cs.DM cs.DS</categories><comments>Updated version from the conference (STACS) version</comments><proxy>ccsd inria-00359068</proxy><journal-ref>26th International Symposium on Theoretical Aspects of Computer
  Science STACS 2009 (2009) 171-182</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the first polynomial-time approximation schemes (PTASes) for the
following subset-connectivity problems in edge-weighted graphs of bounded
genus: Steiner tree, low-connectivity survivable-network design, and subset
TSP. The schemes run in O(n log n) time for graphs embedded on both orientable
and non-orientable surfaces. This work generalizes the PTAS frameworks of
Borradaile, Klein, and Mathieu from planar graphs to bounded-genus graphs: any
future problems shown to admit the required structure theorem for planar graphs
will similarly extend to bounded-genus graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1257</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1257</id><created>2009-02-07</created><authors><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LM-Savoie</affiliation></author><author><keyname>Leroy</keyname><forenames>Xavier</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Wells</keyname><forenames>J. B.</forenames></author></authors><title>Compilation of extended recursion in call-by-value functional languages</title><categories>cs.PL</categories><comments>62 pages, uses pic</comments><proxy>ccsd hal-00359213</proxy><journal-ref>Higher-Order and Symbolic Computation 22, 1 (2009) 3-66</journal-ref><doi>10.1007/s10990-009-9042-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formalizes and proves correct a compilation scheme for
mutually-recursive definitions in call-by-value functional languages. This
scheme supports a wider range of recursive definitions than previous methods.
We formalize our technique as a translation scheme to a lambda-calculus
featuring in-place update of memory blocks, and prove the translation to be
correct.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1299</identifier>
 <datestamp>2013-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1299</id><created>2009-02-08</created><authors><author><keyname>Kobayashi</keyname><forenames>Hirotada</forenames></author><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author><author><keyname>Roetteler</keyname><forenames>Martin</forenames></author></authors><title>Perfect Quantum Network Communication Protocol Based on Classical
  Network Coding</title><categories>quant-ph cs.IT math.IT</categories><comments>LaTeX2e, 10 pages, 2 figures</comments><journal-ref>Proceedings 2010 IEEE International Symposium on Information
  Theory (ISIT 2010), pp. 2686-2690</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a problem of quantum communication between parties that
are connected through a network of quantum channels. The model in this paper
assumes that there is no prior entanglement shared among any of the parties,
but that classical communication is free. The task is to perfectly transfer an
unknown quantum state from a source subsystem to a target subsystem, where both
source and target are formed by ordered sets of some of the nodes. It is proved
that a lower bound of the rate at which this quantum communication task is
possible is given by the classical min-cut max-flow theorem of network coding,
where the capacities in question are the quantum capacities of the edges of the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1394</identifier>
 <datestamp>2010-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1394</id><created>2009-02-09</created><updated>2010-02-01</updated><authors><author><keyname>Bianchi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Melazzi</keyname><forenames>Nicola Blefari</forenames></author><author><keyname>Bracciale</keyname><forenames>Lorenzo</forenames></author><author><keyname>Piccolo</keyname><forenames>Francesca Lo</forenames></author><author><keyname>Salsano</keyname><forenames>Stefano</forenames></author></authors><title>Fundamental delay bounds in peer-to-peer chunk-based real-time streaming
  systems</title><categories>cs.PF cs.MM</categories><comments>8 pages, 5 figures</comments><journal-ref>Proceedings of 21st International Teletraffic Congress (ITC 21),
  2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper addresses the following foundational question: what is the maximum
theoretical delay performance achievable by an overlay peer-to-peer streaming
system where the streamed content is subdivided into chunks? As shown in this
paper, when posed for chunk-based systems, and as a consequence of the
store-and-forward way in which chunks are delivered across the network, this
question has a fundamentally different answer with respect to the case of
systems where the streamed content is distributed through one or more flows
(sub-streams). To circumvent the complexity emerging when directly dealing with
delay, we express performance in term of a convenient metric, called "stream
diffusion metric". We show that it is directly related to the end-to-end
minimum delay achievable in a P2P streaming network. In a homogeneous scenario,
we derive a performance bound for such metric, and we show how this bound
relates to two fundamental parameters: the upload bandwidth available at each
node, and the number of neighbors a node may deliver chunks to. In this bound,
k-step Fibonacci sequences do emerge, and appear to set the fundamental laws
that characterize the optimal operation of chunk-based systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1505</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1505</id><created>2009-02-09</created><updated>2009-05-21</updated><authors><author><keyname>Ye</keyname><forenames>Deping</forenames></author></authors><title>On the Bures Volume of Separable Quantum States</title><categories>quant-ph cs.IT math.FA math.IT math.MG</categories><comments>27 pages. To appear in the Journal of Mathematical Physics</comments><journal-ref>JOURNAL OF MATHEMATICAL PHYSICS 50, 083502 (2009)</journal-ref><doi>10.1063/1.3187216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We obtain two sided estimates for the Bures volume of an arbitrary subset of
the set of $N\times N$ density matrices, in terms of the Hilbert-Schmidt volume
of that subset. For general subsets, our results are essentially optimal (for
large $N$). As applications, we derive in particular nontrivial lower and upper
bounds for the Bures volume of sets of separable states and for sets of states
with positive partial transpose.
  PACS numbers: 02.40.Ft, 03.65.Db, 03.65.Ud, 03.67.Mn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1634</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1634</id><created>2009-02-10</created><updated>2012-06-27</updated><authors><author><keyname>Guerrini</keyname><forenames>Eleonora</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>A bound on the size of linear codes</title><categories>cs.IT math.IT</categories><comments>A new version of this article is now available</comments><msc-class>11T71,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a bound on the size of linear codes. This bound is independent of
other known bounds, e.g. the Griesmer bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1700</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1700</id><created>2009-02-10</created><updated>2010-06-28</updated><authors><author><keyname>Charbit</keyname><forenames>Pierre</forenames></author><author><keyname>de Montgolfier</keyname><forenames>Fabien</forenames></author><author><keyname>Raffinot</keyname><forenames>Mathieu</forenames></author></authors><title>Linear Time Split Decomposition Revisited</title><categories>cs.DM cs.DS</categories><comments>18 pages, submitted</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a family F of subsets of a ground set V, its orthogonal is defined to
be the family of subsets that do not overlap any element of F.
  Using this tool we revisit the problem of designing a simple linear time
algorithm for undirected graph split (also known as 1-join) decomposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.1942</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.1942</id><created>2009-02-11</created><updated>2009-02-19</updated><authors><author><keyname>Elkies</keyname><forenames>Noam D.</forenames></author><author><keyname>Kominers</keyname><forenames>Scott D.</forenames></author></authors><title>On the Classification of Type II Codes of Length 24</title><categories>math.NT cs.DM cs.IT math.CO math.IT</categories><comments>5 pages; v2: fixed minor typos</comments><msc-class>94B05, 11H71</msc-class><journal-ref>SIAM Journal on Discrete Mathematics 23(4), (2010), 2173-2177</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new, purely coding-theoretic proof of Koch's criterion on the
tetrad systems of Type II codes of length 24 using the theory of harmonic
weight enumerators. This approach is inspired by Venkov's approach to the
classification of the root systems of Type II lattices in R^{24}, and gives a
new instance of the analogy between lattices and codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2081</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2081</id><created>2009-02-12</created><updated>2010-02-12</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Languages recognized by nondeterministic quantum finite automata</title><categories>cs.CC</categories><comments>A new version with major revisions, 24 pages, latex</comments><journal-ref>Quantum Information &amp; Computation, Volume 10 Issue 9, September
  2010, Pages 747-770</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The nondeterministic quantum finite automaton (NQFA) is the only known case
where a one-way quantum finite automaton (QFA) model has been shown to be
strictly superior in terms of language recognition power to its probabilistic
counterpart. We give a characterization of the class of languages recognized by
NQFA's, demonstrating that it is equal to the class of exclusive stochastic
languages. We also characterize the class of languages that are recognized
necessarily by two-sided error by QFA's. It is shown that these classes remain
the same when the QFA's used in their definitions are replaced by several
different model variants that have appeared in the literature. We prove several
closure properties of the related classes. The ramifications of these results
about classical and quantum sublogarithmic space complexity classes are
examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2108</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2108</id><created>2009-02-12</created><updated>2011-08-30</updated><authors><author><keyname>Gripon</keyname><forenames>Vincent</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Serre</keyname><forenames>Olivier</forenames><affiliation>LIAFA</affiliation></author></authors><title>Qualitative Concurrent Stochastic Games with Imperfect Information</title><categories>cs.FL cs.GT cs.LO</categories><comments>Automata, Languages and Programming, 36th International Colloquium,
  ICALP 2009, Rhodes: Greece (2009)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a model of games that combines concurrency, imperfect information
and stochastic aspects. Those are finite states games in which, at each round,
the two players choose, simultaneously and independently, an action. Then a
successor state is chosen accordingly to some fixed probability distribution
depending on the previous state and on the pair of actions chosen by the
players. Imperfect information is modeled as follows: both players have an
equivalence relation over states and, instead of observing the exact state,
they only know to which equivalence class it belongs. Therefore, if two partial
plays are indistinguishable by some player, he should behave the same in both
of them. We consider reachability (does the play eventually visit a final
state?) and B\"uchi objective (does the play visit infinitely often a final
state?). Our main contribution is to prove that the following problem is
complete for 2-ExpTime: decide whether the first player has a strategy that
ensures her to almost-surely win against any possible strategy of her oponent.
We also characterise those strategies needed by the first player to
almost-surely win.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2206</identifier>
 <datestamp>2010-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2206</id><created>2009-02-12</created><updated>2010-02-27</updated><authors><author><keyname>Weinberger</keyname><forenames>Kilian</forenames></author><author><keyname>Dasgupta</keyname><forenames>Anirban</forenames></author><author><keyname>Attenberg</keyname><forenames>Josh</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Smola</keyname><forenames>Alex</forenames></author></authors><title>Feature Hashing for Large Scale Multitask Learning</title><categories>cs.AI</categories><comments>Fixed broken theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Empirical evidence suggests that hashing is an effective strategy for
dimensionality reduction and practical nonparametric estimation. In this paper
we provide exponential tail bounds for feature hashing and show that the
interaction between random subspaces is negligible with high probability. We
demonstrate the feasibility of this approach with experimental results for a
new use case -- multitask learning with hundreds of thousands of tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2415</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2415</id><created>2009-02-14</created><updated>2011-11-22</updated><authors><author><keyname>Danila</keyname><forenames>Bogdan</forenames></author><author><keyname>Sun</keyname><forenames>Yudong</forenames></author><author><keyname>Bassler</keyname><forenames>Kevin E.</forenames></author></authors><title>Collectively optimal routing for congested traffic limited by link
  capacity</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.NI physics.comp-ph</categories><comments>7 pages, 4 figures</comments><journal-ref>Phys Rev E 80 (6) 066116, 2009</journal-ref><doi>10.1103/PhysRevE.80.066116</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the capacity of a complex network that models a city street grid
to support congested traffic can be optimized by using routes that collectively
minimize the maximum ratio of betweenness to capacity in any link. Networks
with a heterogeneous distribution of link capacities and with a heterogeneous
transport load are considered. We find that overall traffic congestion and
average travel times can be significantly reduced by a judicious use of slower,
smaller capacity links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2420</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2420</id><created>2009-02-13</created><updated>2011-07-20</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Self-Assembly as Graph Grammar as Distributed System</title><categories>cs.DC cs.NE</categories><comments>Withdrawn as I would like to polish it before making it public again.
  A two-page announcement of these results will appear in the proceedings of
  PODC 2009</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2004, Klavins et al. introduced the use of graph grammars to describe --
and to program -- systems of self-assembly. It turns out that these graph
grammars are a "dual notion" of a graph rewriting characterization of
distributed systems that was proposed by Degano and Montanari over twenty years
ago. By applying techniques obtained from this observation, we prove a
generalized version of Soloveichik and Winfree's theorem on local determinism,
and we also present a canonical method to simulate asynchronous
constant-size-message-passing models of distributed computing with systems of
self-assembly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2446</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2446</id><created>2009-02-14</created><updated>2009-07-17</updated><authors><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Mason</keyname><forenames>Paolo</forenames></author><author><keyname>Piccoli</keyname><forenames>Benedetto</forenames></author></authors><title>Detection of Gaussian signals via hexagonal sensor networks</title><categories>math.OC cs.SY</categories><comments>16 pages, 4 figures. Accepted. v1-current: corrected typos, added
  clarifications, updated and added references, extended intro and final
  remarks</comments><msc-class>93A14 (Primary) 94C15 68M14</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a special case of the problem of identifying a static
scalar signal, depending on the location, using a planar network of sensors in
a distributed fashion. Motivated by the application to monitoring wild-fires
spreading and pollutants dispersion, we assume the signal to be Gaussian in
space. Using a network of sensors positioned to form a regular hexagonal
tessellation, we prove that each node can estimate the parameters of the
Gaussian from local measurements. Moreover, we study the sensitivity of these
estimates to additive errors affecting the measurements. Finally, we show how a
consensus algorithm can be designed to fuse the local estimates into a shared
global estimate, effectively compensating the measurement errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2501</identifier>
 <datestamp>2012-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2501</id><created>2009-02-14</created><authors><author><keyname>Hayes</keyname><forenames>Tom</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>The Forgiving Graph: A distributed data structure for low stretch under
  adversarial attack</title><categories>cs.DS cs.DC</categories><comments>Submitted to Principles of Distributed Computing (PODC) 2009</comments><acm-class>C.2.1; C.2.3; C.2.4; C.4; H.3.4</acm-class><journal-ref>Distributed Computing, 2012, Volume 25, Number 4, Pages 261-278</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of self-healing in peer-to-peer networks that are
under repeated attack by an omniscient adversary. We assume that, over a
sequence of rounds, an adversary either inserts a node with arbitrary
connections or deletes an arbitrary node from the network. The network responds
to each such change by quick "repairs," which consist of adding or deleting a
small number of edges.
  These repairs essentially preserve closeness of nodes after adversarial
deletions, without increasing node degrees by too much, in the following sense.
At any point in the algorithm, nodes $v$ and $w$ whose distance would have been
$\ell$ in the graph formed by considering only the adversarial insertions (not
the adversarial deletions), will be at distance at most $\ell \log n$ in the
actual graph, where $n$ is the total number of vertices seen so far. Similarly,
at any point, a node $v$ whose degree would have been $d$ in the graph with
adversarial insertions only, will have degree at most 3d in the actual graph.
Our algorithm is completely distributed and has low latency and bandwidth
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2537</identifier>
 <datestamp>2011-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2537</id><created>2009-02-15</created><updated>2010-04-12</updated><authors><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Schwartz</keyname><forenames>Oded</forenames></author></authors><title>Communication-optimal Parallel and Sequential Cholesky Decomposition</title><categories>cs.NA cs.CC cs.DS math.NA</categories><comments>29 pages, 2 tables, 6 figures</comments><acm-class>F.2.1</acm-class><journal-ref>SIAM J. Sci. Comput. 32, (2010) pp. 3495-3523</journal-ref><doi>10.1137/090760969</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical algorithms have two kinds of costs: arithmetic and communication,
by which we mean either moving data between levels of a memory hierarchy (in
the sequential case) or over a network connecting processors (in the parallel
case). Communication costs often dominate arithmetic costs, so it is of
interest to design algorithms minimizing communication. In this paper we first
extend known lower bounds on the communication cost (both for bandwidth and for
latency) of conventional (O(n^3)) matrix multiplication to Cholesky
factorization, which is used for solving dense symmetric positive definite
linear systems. Second, we compare the costs of various Cholesky decomposition
implementations to these lower bounds and identify the algorithms and data
structures that attain them. In the sequential case, we consider both the
two-level and hierarchical memory models. Combined with prior results in [13,
14, 15], this gives a set of communication-optimal algorithms for O(n^3)
implementations of the three basic factorizations of dense linear algebra: LU
with pivoting, QR and Cholesky. But it goes beyond this prior work on
sequential LU by optimizing communication for any number of levels of memory
hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2674</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2674</id><created>2009-02-16</created><updated>2010-02-03</updated><authors><author><keyname>Fortnow</keyname><forenames>Lance</forenames></author><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author><author><keyname>Mayordomo</keyname><forenames>Elvira</forenames></author></authors><title>Inseparability and Strong Hypotheses for Disjoint NP Pairs</title><categories>cs.CC</categories><acm-class>F.1.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper investigates the existence of inseparable disjoint pairs of NP
languages and related strong hypotheses in computational complexity. Our main
theorem says that, if NP does not have measure 0 in EXP, then there exist
disjoint pairs of NP languages that are P-inseparable, in fact
TIME(2^(n^k))-inseparable. We also relate these conditions to strong hypotheses
concerning randomness and genericity of disjoint pairs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2783</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2783</id><created>2009-02-16</created><updated>2010-01-08</updated><authors><author><keyname>Pourmohammad</keyname><forenames>Ali</forenames></author><author><keyname>Ahadi</keyname><forenames>Seyed Mohammad</forenames></author></authors><title>New Ica-Beamforming Method to Under-Determined BSS</title><categories>cs.SD</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author ali pourmohammad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2788</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2788</id><created>2009-02-16</created><updated>2010-01-08</updated><authors><author><keyname>Pourmohammad</keyname><forenames>Ali</forenames></author><author><keyname>Ahadi</keyname><forenames>Seyed Mohammad</forenames></author></authors><title>Using SLP Neural Network to Persian Handwritten Digits Recognition</title><categories>cs.CV</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author ali pourmohammad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2851</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2851</id><created>2009-02-17</created><updated>2012-02-29</updated><authors><author><keyname>Dieudonné</keyname><forenames>Yoann</forenames><affiliation>MIS</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author><author><keyname>Villain</keyname><forenames>Vincent</forenames><affiliation>MIS</affiliation></author></authors><title>Leader Election Problem Versus Pattern Formation Problem</title><categories>cs.DC cs.MA</categories><proxy>ccsd inria-00361916</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leader election and arbitrary pattern formation are funda- mental tasks for a
set of autonomous mobile robots. The former consists in distinguishing a unique
robot, called the leader. The latter aims in arranging the robots in the plane
to form any given pattern. The solv- ability of both these tasks turns out to
be necessary in order to achieve more complex tasks. In this paper, we study
the relationship between these two tasks in a model, called CORDA, wherein the
robots are weak in several aspects. In particular, they are fully asynchronous
and they have no direct means of communication. They cannot remember any
previous observation nor computation performed in any previous step. Such
robots are said to be oblivious. The robots are also uniform and anonymous,
i.e, they all have the same program using no global parameter (such as an
identity) allowing to differentiate any of them. Moreover, we assume that none
of them share any kind of common coordinate mechanism or common sense of
direction and we discuss the influence of a common handedness (i.e.,
chirality). In such a system, Flochini et al. proved in [11] that it is
possible to elect a leader for n \geq 3 robots if it is possible to form any
pattern for n \geq 3. In this paper, we show that the converse is true for n
\geq 4 when the robots share a common handedness and for n \geq 5 when they do
not. Thus, we deduce that with chirality (resp. without chirality) both
problems are equivalent for n \geq 4 (resp. n \geq 5) in CORDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2853</identifier>
 <datestamp>2010-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2853</id><created>2009-02-17</created><updated>2010-03-04</updated><authors><author><keyname>Poinsot</keyname><forenames>Laurent</forenames><affiliation>LIPN</affiliation></author><author><keyname>Duchamp</keyname><forenames>Gérard</forenames><affiliation>LIPN</affiliation></author></authors><title>A formal calculus on the Riordan near algebra</title><categories>cs.SC math.CO</categories><comments>29 p</comments><proxy>ccsd hal-00361379</proxy><journal-ref>Advances and Applications in Discrete Mathematics 6, 1 (2010)
  11-44</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Riordan group is the semi-direct product of a multiplicative group of
invertible series and a group, under substitution, of non units. The Riordan
near algebra, as introduced in this paper, is the Cartesian product of the
algebra of formal power series and its principal ideal of non units, equipped
with a product that extends the multiplication of the Riordan group. The later
is naturally embedded as a subgroup of units into the former. In this paper, we
prove the existence of a formal calculus on the Riordan algebra. This formal
calculus plays a role similar to those of holomorphic calculi in the Banach or
Fr\'echet algebras setting, but without the constraint of a radius of
convergence. Using this calculus, we define \emph{en passant} a notion of
generalized powers in the Riordan group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.2969</identifier>
 <datestamp>2013-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.2969</id><created>2009-02-17</created><updated>2010-02-26</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Ptarithmetic</title><categories>cs.LO cs.AI cs.CC</categories><comments>Substantially better versions are on their way. Hence the present
  article probably will not be published</comments><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>The Baltic International Yearbook on Cognition, Logic and
  Communication 8 (2013), Article 5, pp. 1-186</journal-ref><doi>10.4148/1944-3676.1074</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present article introduces ptarithmetic (short for "polynomial time
arithmetic") -- a formal number theory similar to the well known Peano
arithmetic, but based on the recently born computability logic (see
http://www.cis.upenn.edu/~giorgi/cl.html) instead of classical logic. The
formulas of ptarithmetic represent interactive computational problems rather
than just true/false statements, and their "truth" is understood as existence
of a polynomial time solution. The system of ptarithmetic elaborated in this
article is shown to be sound and complete. Sound in the sense that every
theorem T of the system represents an interactive number-theoretic
computational problem with a polynomial time solution and, furthermore, such a
solution can be effectively extracted from a proof of T. And complete in the
sense that every interactive number-theoretic problem with a polynomial time
solution is represented by some theorem T of the system.
  The paper is self-contained, and can be read without any previous familiarity
with computability logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3176</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3176</id><created>2009-02-18</created><updated>2010-02-03</updated><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author></authors><title>Error-Correcting Tournaments</title><categories>cs.AI cs.LG</categories><comments>Minor wording improvements</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a family of pairwise tournaments reducing $k$-class classification
to binary classification. These reductions are provably robust against a
constant fraction of binary errors. The results improve on the PECOC
construction \cite{SECOC} with an exponential improvement in computation, from
$O(k)$ to $O(\log_2 k)$, and the removal of a square root in the regret
dependence, matching the best possible computation and regret up to a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3294</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3294</id><created>2009-02-17</created><updated>2010-09-01</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Progress in Computer-Assisted Inductive Theorem Proving by
  Human-Orientedness and Descente Infinie?</title><categories>cs.AI cs.LO</categories><comments>ii + 35 pages</comments><report-no>SEKI Working-Paper SR-2006-01</report-no><journal-ref>Logic Journal of the IGPL, 2012, Volume 20, Pp. 1046-1063</journal-ref><doi>10.1093/jigpal/jzr048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short position paper we briefly review the development history of
automated inductive theorem proving and computer-assisted mathematical
induction. We think that the current low expectations on progress in this field
result from a faulty narrow-scope historical projection. Our main motivation is
to explain--on an abstract but hopefully sufficiently descriptive level--why we
believe that future progress in the field is to result from human-orientedness
and descente infinie.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3548</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3548</id><created>2009-02-20</created><authors><author><keyname>Zlatić</keyname><forenames>Vinko</forenames></author><author><keyname>Štefančić</keyname><forenames>Hrvoje</forenames></author></authors><title>Model of Wikipedia growth based on information exchange via reciprocal
  arcs</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY</categories><comments>4 pages, 4 figures, companion paper of our paper "Influence of
  reciprocal arcs on the degree distribution and degree correlations"</comments><journal-ref>EPL 93 (2011) 58005</journal-ref><doi>10.1209/0295-5075/93/58005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how reciprocal arcs significantly influence the structural
organization of Wikipedias, online encyclopedias. It is shown that random
addition of reciprocal arcs in the static network cannot explain the observed
reciprocity of Wikipedias. A model of Wikipedia growth based on preferential
attachment and on information exchange via reciprocal arcs is presented. An
excellent agreement between in-degree distributions of our model and real
Wikipedia networks is achieved without fitting the distributions, but by merely
extracting a small number of model parameters from the measurement of real
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3595</identifier>
 <datestamp>2010-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3595</id><created>2009-02-20</created><updated>2010-01-14</updated><authors><author><keyname>Chen</keyname><forenames>Jinhui</forenames></author><author><keyname>Slock</keyname><forenames>Dirk T. M.</forenames></author></authors><title>On Optimum End-to-End Distortion in MIMO Systems</title><categories>cs.IT math.IT</categories><comments>35 pages, 10 figures, submitted to EURASIP Journal on Wireless
  Communications and Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the joint impact of the numbers of antennas,
source-to-channel bandwidth ratio and spatial correlation on the optimum
expected end-to-end distortion in an outage-free MIMO system. In particular,
based on an analytical expression valid for any SNR, a closed-form expression
of the optimum asymptotic expected end-to-end distortion valid for high SNR is
derived. It is comprised of the optimum distortion exponent and the
multiplicative optimum distortion factor. Demonstrated by the simulation
results, the analysis on the joint impact of the optimum distortion exponent
and the optimum distortion factor explains the behavior of the optimum expected
end-to-end distortion varying with the numbers of antennas, source-to-channel
bandwidth ratio and spatial correlation. It is also proved that as the
correlation tends to zero, the optimum asymptotic expected end-to-end
distortion in the setting of correlated channel approaches that in the setting
of uncorrelated channel. The results in this paper could be performance
objectives for analog-source transmission systems. To some extend, they are
instructive for system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3623</identifier>
 <datestamp>2010-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3623</id><created>2009-02-20</created><updated>2010-12-14</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>A Self-Contained and Easily Accessible Discussion of the Method of
  Descente Infinie and Fermat's Only Explicitly Known Proof by Descente Infinie</title><categories>cs.AI cs.LO</categories><comments>ii + 36 pages, French abstract (R\'esum\'e) included in paper</comments><report-no>SEKI Working-Paper SWP-2006-02, Second edition</report-no><msc-class>03-03, 01A45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the only proof of Pierre Fermat by descente infinie that is known
to exist today. As the text of its Latin original requires active mathematical
interpretation, it is more a proof sketch than a proper mathematical proof. We
discuss descente infinie from the mathematical, logical, historical,
linguistic, and refined logic-historical points of view. We provide the
required preliminaries from number theory and develop a self-contained proof in
a modern form, which nevertheless is intended to follow Fermat's ideas closely.
We then annotate an English translation of Fermat's original proof with terms
from the modern proof. Including all important facts, we present a concise and
self-contained discussion of Fermat's proof sketch, which is easily accessible
to laymen in number theory as well as to laymen in the history of mathematics,
and which provides new clarification of the Method of Descente Infinie to the
experts in these fields. Last but not least, this paper fills a gap regarding
the easy accessibility of the subject.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3631</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3631</id><created>2009-02-20</created><updated>2010-07-16</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Distributed Agreement in Tile Self-Assembly</title><categories>cs.DC cs.NE</categories><comments>The extended abstract of this paper won the Best Student Paper Award
  at DNA 15. The current version has been accepted for publication in Natural
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Laboratory investigations have shown that a formal theory of fault-tolerance
will be essential to harness nanoscale self-assembly as a medium of
computation. Several researchers have voiced an intuition that self-assembly
phenomena are related to the field of distributed computing. This paper
formalizes some of that intuition. We construct tile assembly systems that are
able to simulate the solution of the wait-free consensus problem in some
distributed systems. (For potential future work, this may allow binding errors
in tile assembly to be analyzed, and managed, with positive results in
distributed computing, as a "blockage" in our tile assembly model is analogous
to a crash failure in a distributed computing model.) We also define a
strengthening of the "traditional" consensus problem, to make explicit an
expectation about consensus algorithms that is often implicit in distributed
computing literature. We show that solution of this strengthened consensus
problem can be simulated by a two-dimensional tile assembly model only for two
processes, whereas a three-dimensional tile assembly model can simulate its
solution in a distributed system with any number of processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3635</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3635</id><created>2009-02-20</created><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>lim+, delta+, and Non-Permutability of beta-Steps</title><categories>cs.AI cs.LO</categories><comments>ii + 36 pages</comments><report-no>SEKI Report SR-2005-01</report-no><journal-ref>Journal of Symbolic Computation, 2012, Volume 47, Pp. 1109-1135</journal-ref><doi>10.1016/j.jsc.2011.12.035</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a human-oriented formal example proof of the (lim+) theorem, i.e. that
the sum of limits is the limit of the sum, which is of value for reference on
its own, we exhibit a non-permutability of beta-steps and delta+-steps
(according to Smullyan's classification), which is not visible with
non-liberalized delta-rules and not serious with further liberalized
delta-rules, such as the delta++-rule. Besides a careful presentation of the
search for a proof of (lim+) with several pedagogical intentions, the main
subject is to explain why the order of beta-steps plays such a practically
important role in some calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3749</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3749</id><created>2009-02-21</created><updated>2012-01-16</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author></authors><title>Hilbert's epsilon as an Operator of Indefinite Committed Choice</title><categories>cs.AI cs.LO</categories><comments>ii + 73 pages. arXiv admin note: substantial text overlap with
  arXiv:1104.2444</comments><report-no>SEKI Report SR-2006-02</report-no><journal-ref>Journal of Applied Logic 6 (2008), pp. 287-317</journal-ref><doi>10.1016/j.jal.2007.07.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paul Bernays and David Hilbert carefully avoided overspecification of
Hilbert's epsilon-operator and axiomatized only what was relevant for their
proof-theoretic investigations. Semantically, this left the epsilon-operator
underspecified. In the meanwhile, there have been several suggestions for
semantics of the epsilon as a choice operator. After reviewing the literature
on semantics of Hilbert's epsilon operator, we propose a new semantics with the
following features: We avoid overspecification (such as right-uniqueness), but
admit indefinite choice, committed choice, and classical logics. Moreover, our
semantics for the epsilon supports proof search optimally and is natural in the
sense that it does not only mirror some cases of referential interpretation of
indefinite articles in natural language, but may also contribute to philosophy
of language. Finally, we ask the question whether our epsilon within our
free-variable framework can serve as a paradigm useful in the specification and
computation of semantics of discourses in natural language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3780</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3780</id><created>2009-02-22</created><updated>2010-02-03</updated><authors><author><keyname>Marx</keyname><forenames>Dániel</forenames><affiliation>Budapest University of Technology and Economics</affiliation></author><author><keyname>O'Sullivan</keyname><forenames>Barry</forenames><affiliation>Cork Constraint Computation Centre, University College Cork</affiliation></author><author><keyname>Razgon</keyname><forenames>Igor</forenames><affiliation>Cork Constraint Computation Centre, University College Cork</affiliation></author></authors><title>Treewidth reduction for constrained separation and bipartization
  problems</title><categories>cs.DS cs.DM</categories><comments>STACS final version of our result. For the complete description of
  the result please see version 1</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a method for reducing the treewidth of a graph while preserving
all the minimal $s-t$ separators. This technique turns out to be very useful
for establishing the fixed-parameter tractability of constrained separation and
bipartization problems. To demonstrate the power of this technique, we prove
the fixed-parameter tractability of a number of well-known separation and
bipartization problems with various additional restrictions (e.g., the vertices
being removed from the graph form an independent set). These results answer a
number of open questions in the area of parameterized complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3883</identifier>
 <datestamp>2011-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3883</id><created>2009-02-23</created><updated>2009-12-15</updated><authors><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author></authors><title>Directed Graph Representation of Half-Rate Additive Codes over GF(4)</title><categories>math.CO cs.IT math.IT</categories><comments>Presented at International Workshop on Coding and Cryptography (WCC
  2009), 10-15 May 2009, Ullensvang, Norway. (14 pages, 2 figures)</comments><msc-class>94B60, 05C90</msc-class><journal-ref>Des. Codes Cryptogr. 59, pp. 119-130, 2011</journal-ref><doi>10.1007/s10623-010-9469-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that (n,2^n) additive codes over GF(4) can be represented as directed
graphs. This generalizes earlier results on self-dual additive codes over
GF(4), which correspond to undirected graphs. Graph representation reduces the
complexity of code classification, and enables us to classify additive (n,2^n)
codes over GF(4) of length up to 7. From this we also derive classifications of
isodual and formally self-dual codes. We introduce new constructions of
circulant and bordered circulant directed graph codes, and show that these
codes will always be isodual. A computer search of all such codes of length up
to 26 reveals that these constructions produce many codes of high minimum
distance. In particular, we find new near-extremal formally self-dual codes of
length 11 and 13, and isodual codes of length 24, 25, and 26 with better
minimum distance than the best known self-dual codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.3979</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.3979</id><created>2009-02-23</created><authors><author><keyname>Giovanidis</keyname><forenames>Anastasios</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author><author><keyname>Buehler</keyname><forenames>Joerg</forenames></author></authors><title>Optimal Control of a Single Queue with Retransmissions: Delay-Dropping
  Tradeoffs</title><categories>cs.MM</categories><comments>29 pages, 8 figures, submitted to IEEE Transactions on Wireless
  Communications</comments><journal-ref>IEEE Transactions on Wireless Communications (Volume:8 , Issue: 7
  ), pp. 3736 - 3746,. July 2009</journal-ref><doi>10.1109/TWC.2009.080959</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single queue incorporating a retransmission protocol is investigated,
assuming that the sequence of per effort success probabilities in the Automatic
Retransmission reQuest (ARQ) chain is a priori defined and no channel state
information at the transmitter is available. A Markov Decision Problem with an
average cost criterion is formulated where the possible actions are to either
continue the retransmission process of an erroneous packet at the next time
slot or to drop the packet and move on to the next packet awaiting for
transmission. The cost per slot is a linear combination of the current queue
length and a penalty term in case dropping is chosen as action. The
investigation seeks policies that provide the best possible average packet
delay-dropping trade-off for Quality of Service guarantees. An optimal
deterministic stationary policy is shown to exist, several structural
properties of which are obtained. Based on that, a class of suboptimal
&lt;L,K&gt;-policies is introduced. These suggest that it is almost optimal to use a
K-truncated ARQ protocol as long as the queue length is lower than L, else send
all packets in one shot. The work concludes with an evaluation of the optimal
delay-dropping tradeoff using dynamic programming and a comparison between the
optimal and suboptimal policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4060</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4060</id><created>2009-02-23</created><authors><author><keyname>Yamamoto</keyname><forenames>Ken</forenames></author><author><keyname>Yamazaki</keyname><forenames>Yoshihiro</forenames></author></authors><title>Network of two-Chinese-character compound words in Japanese language</title><categories>cs.CL physics.soc-ph</categories><journal-ref>Physica A 388, 2555-2560 (2009)</journal-ref><doi>10.1016/j.physa.2009.02.032</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some statistical properties of a network of two-Chinese-character compound
words in Japanese language are reported. In this network, a node represents a
Chinese character and an edge represents a two-Chinese-character compound word.
It is found that this network has properties of "small-world" and "scale-free."
A network formed by only Chinese characters for common use ({\it joyo-kanji} in
Japanese), which is regarded as a subclass of the original network, also has
small-world property. However, a degree distribution of the network exhibits no
clear power law. In order to reproduce disappearance of the power-law property,
a model for a selecting process of the Chinese characters for common use is
proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4095</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4095</id><created>2009-02-24</created><authors><author><keyname>Blümlein</keyname><forenames>J.</forenames></author><author><keyname>Kauers</keyname><forenames>M.</forenames></author><author><keyname>Klein</keyname><forenames>S.</forenames></author><author><keyname>Schneider</keyname><forenames>C.</forenames></author></authors><title>From Moments to Functions in Quantum Chromodynamics</title><categories>hep-ph cs.SC math-ph math.AG math.CO math.MP</categories><comments>7 pages, 2 subsidiary files</comments><report-no>DESY 09-011, SFB-CPP-09/17</report-no><journal-ref>PoS ACAT08:106,2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Single-scale quantities, like the QCD anomalous dimensions and Wilson
coefficients, obey difference equations. Therefore their analytic form can be
determined from a finite number of moments. We demonstrate this in an explicit
calculation by establishing and solving large scale recursions by means of
computer algebra for the anomalous dimensions and Wilson coefficients in
unpolarized deeply inelastic scattering from their Mellin moments to 3-loop
order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4106</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4106</id><created>2009-02-24</created><authors><author><keyname>Lin</keyname><forenames>Shih-Chun</forenames></author><author><keyname>Lin</keyname><forenames>Pin-Hsun</forenames></author><author><keyname>Lee</keyname><forenames>Chung-Pi</forenames></author><author><keyname>Su</keyname><forenames>Hsuan-Jung</forenames></author></authors><title>Filter and nested-lattice code design for fading MIMO channels with
  side-information</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Communications, Feb, 2009</comments><journal-ref>IEEE Transactions on Communications, vol. 59. No. 6, pp. 1489 -
  1494, June 2011</journal-ref><doi>10.1109/TCOMM.2011.050211.090113A</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear-assignment Gel'fand-Pinsker coding (LA-GPC) is a coding technique for
channels with interference known only at the transmitter, where the known
interference is treated as side-information (SI). As a special case of LA-GPC,
dirty paper coding has been shown to be able to achieve the optimal
interference-free rate for interference channels with perfect channel state
information at the transmitter (CSIT). In the cases where only the channel
distribution information at the transmitter (CDIT) is available, LA-GPC also
has good (sometimes optimal) performance in a variety of fast and slow fading
SI channels. In this paper, we design the filters in nested-lattice based
coding to make it achieve the same rate performance as LA-GPC in multiple-input
multiple-output (MIMO) channels. Compared with the random Gaussian codebooks
used in previous works, our resultant coding schemes have an algebraic
structure and can be implemented in practical systems. A simulation in a
slow-fading channel is also provided, and near interference-free error
performance is obtained. The proposed coding schemes can serve as the
fundamental building blocks to achieve the promised rate performance of MIMO
Gaussian broadcast channels with CDIT or perfect CSIT
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4185</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4185</id><created>2009-02-24</created><updated>2010-07-28</updated><authors><author><keyname>Zdeborová</keyname><forenames>Lenka</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author></authors><title>Quiet Planting in the Locked Constraint Satisfaction Problems</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.CC</categories><comments>21 pages, revised version</comments><journal-ref>SIAM J. Discrete Math. 25, 750-770 (2011)</journal-ref><doi>10.1137/090750755</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the planted ensemble of locked constraint satisfaction problems. We
describe the connection between the random and planted ensembles. The use of
the cavity method is combined with arguments from reconstruction on trees and
first and second moment considerations; in particular the connection with the
reconstruction on trees appears to be crucial. Our main result is the location
of the hard region in the planted ensemble. In a part of that hard region
instances have with high probability a single satisfying assignment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4218</identifier>
 <datestamp>2010-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4218</id><created>2009-02-24</created><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>On graph theoretic results underlying the analysis of consensus in
  multi-agent systems</title><categories>cs.MA cs.DM math.CO math.OC</categories><comments>3 pages, 13 references. Submitted</comments><journal-ref>Proceedings of the IEEE, Vol. 98, No. 7, July 2010</journal-ref><doi>10.1109/JPROC.2010.2049911</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note corrects a pretty serious mistake and some inaccuracies in
"Consensus and cooperation in networked multi-agent systems" by R.
Olfati-Saber, J.A. Fax, and R.M. Murray, published in Vol. 95 of the
Proceedings of the IEEE (2007, No. 1, P. 215-233). It also mentions several
stronger results applicable to the class of problems under consideration and
addresses the issue of priority whose interpretation in the above-mentioned
paper is not exact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4246</identifier>
 <datestamp>2012-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4246</id><created>2009-02-24</created><updated>2009-06-24</updated><authors><author><keyname>Kurmaev</keyname><forenames>Oleg</forenames></author></authors><title>Constant-Weight and Constant-Charge Binary Run-Length Limited Codes</title><categories>cs.IT math.IT</categories><comments>29 pages, submitted to IEEE Transactions on Information Theory. This
  paper is a corrected version of a paper with the same title that appeared on
  the arXiv in Feb. 2009. The major change is in Section VI, in which
  Subsection D is now well defined</comments><doi>10.1109/TIT.2011.2145490</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant-weight and constant-charge binary sequences with constrained run
length of zeros are introduced. For these sequences, the weight and the charge
distribution are found. Then, recurrent and direct formulas for calculating the
number of these sequences are obtained. With considering these numbers of
constant-weight and constant-charge RLL sequences as coefficients of convergent
power series, generating functions are derived. The fact, that generating
function for enumerating constant-charge RLL sequences does not have a closed
form, is proved. Implementation of encoding and decoding procedures using
Cover's enumerative scheme is shown. On the base of obtained results, some
examples, such as enumeration of running-digital-sum (RDS) constrained RLL
sequences or peak-shifts control capability are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4348</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4348</id><created>2009-02-25</created><updated>2012-09-07</updated><authors><author><keyname>Vagvolgyi</keyname><forenames>Sandor</forenames></author></authors><title>On ground word problem of term equation systems</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give semi-decision procedures for the ground word problem of variable
preserving term equation systems and term equation systems. They are natural
improvements of two well known trivial semi-decision procedures. We show the
correctness of our procedures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4514</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4514</id><created>2009-02-26</created><updated>2009-02-26</updated><authors><author><keyname>Chebotarev</keyname><forenames>Pavel</forenames></author></authors><title>Analytical Expression of the Expected Values of Capital at Voting in the
  Stochastic Environment</title><categories>math.OC cs.MA cs.SI cs.SY math.PR</categories><comments>13 pages, 5 figures, translated from Russian by M.A. Kasner</comments><msc-class>91B12; 91B70</msc-class><journal-ref>Automation and Remote Control, 2006, Vol. 67, No. 2, pp. 480-492.
  Original Russian text published in Avtomatika i Telemekhanika, 2006, No. 3,
  pp. 152-165</journal-ref><doi>10.1134/S000511790603012X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the simplest version of the model of group decision making in the
stochastic environment, the participants are segregated into egoists and a
group of collectivists. A "proposal of the environment" is a stochastically
generated vector of algebraic increments of participants' capitals. The social
dynamics is determined by the sequence of proposals accepted by a majority
voting (with a threshold) of the participants. In this paper, we obtain
analytical expressions for the expected values of capitals for all the
participants, including collectivists and egoists. In addition, distinctions
between some principles of group voting are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4577</identifier>
 <datestamp>2010-03-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4577</id><created>2009-02-26</created><updated>2010-03-22</updated><authors><author><keyname>Jing</keyname><forenames>Zhenhai</forenames></author><author><keyname>Bai</keyname><forenames>Baoming</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author></authors><title>Using Distributed Rate-Splitting Game to Approach Rate Region Boundary
  of the Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>29 pages, 10 figures, submitted to IEEE Trans on Information
  Theory,Feb.,2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining how to approach the rate boundary of the Gaussian interference
channel in practical system is a big concern. In this paper, a distributed
rate-splitting (DRS) scheme is proposed to approach the rate region boundary of
the Gaussian interference channel. It is shown that the DRS scheme can be
formulated as a non-cooperative game. We introduce the Stackelberg equilibrium
(SE) with multiple leaders as the equilibrium point of the non-cooperative
game. Therefore, an iterative multiple waterlevels water-filling algorithm
(IML-WFA) is developed to efficiently reach the SE of the non-cooperative game.
The existence of SE is established for the game. Numerical examples show that
the rate-tuples achieved by the DRS are very close to the boundary of the
well-known HK region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0902.4682</identifier>
 <datestamp>2014-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0902.4682</id><created>2009-02-26</created><updated>2014-05-27</updated><authors><author><keyname>Wirth</keyname><forenames>Claus-Peter</forenames></author><author><keyname>Siekmann</keyname><forenames>Joerg</forenames></author><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author><author><keyname>Autexier</keyname><forenames>Serge</forenames></author></authors><title>Lectures on Jacques Herbrand as a Logician</title><categories>cs.LO cs.AI</categories><comments>ii + 82 pages</comments><report-no>SEKI Report SR-2009-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give some lectures on the work on formal logic of Jacques Herbrand, and
sketch his life and his influence on automated theorem proving. The intended
audience ranges from students interested in logic over historians to logicians.
Besides the well-known correction of Herbrand's False Lemma by Goedel and
Dreben, we also present the hardly known unpublished correction of Heijenoort
and its consequences on Herbrand's Modus Ponens Elimination. Besides Herbrand's
Fundamental Theorem and its relation to the Loewenheim-Skolem-Theorem, we
carefully investigate Herbrand's notion of intuitionism in connection with his
notion of falsehood in an infinite domain. We sketch Herbrand's two proofs of
the consistency of arithmetic and his notion of a recursive function, and last
but not least, present the correct original text of his unification algorithm
with a new translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0050</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0050</id><created>2009-02-28</created><updated>2009-12-22</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Succinctness of two-way probabilistic and quantum finite automata</title><categories>cs.CC</categories><comments>A new version, 21 pages, latex</comments><journal-ref>Discrete Mathematics &amp; Theoretical Computer Science, Vol 12, No 4
  (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that two-way probabilistic and quantum finite automata (2PFA's and
2QFA's) can be considerably more concise than both their one-way versions
(1PFA's and 1QFA's), and two-way nondeterministic finite automata (2NFA's). For
this purpose, we demonstrate several infinite families of regular languages
which can be recognized with some fixed probability greater than $ {1/2} $ by
just tuning the transition amplitudes of a 2QFA (and, in one case, a 2PFA) with
a constant number of states, whereas the sizes of the corresponding 1PFA's,
1QFA's and 2NFA's grow without bound. We also show that 2QFA's with mixed
states can support highly efficient probability amplification. The weakest
known model of computation where quantum computers recognize more languages
with bounded error than their classical counterparts is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0134</identifier>
 <datestamp>2010-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0134</id><created>2009-03-01</created><updated>2010-01-08</updated><authors><author><keyname>Eskandari</keyname><forenames>Ahmad Reza</forenames></author><author><keyname>Pourmohammad</keyname><forenames>Ali</forenames></author></authors><title>Recognition of Regular Shapes in Satelite Images</title><categories>cs.CV</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author ali pourmohammad.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0200</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0200</id><created>2009-03-01</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author></authors><title>Faith in the Algorithm, Part 1: Beyond the Turing Test</title><categories>cs.CY cs.AI</categories><report-no>LA-UR-09-00052</report-no><journal-ref>Proceedings of the AISB Symposium on Computing and Philosophy, The
  Society for the Study of Artificial Intelligence and Simulation of Behaviour,
  Edinburgh, Scotland, April 2009.</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Since the Turing test was first proposed by Alan Turing in 1950, the primary
goal of artificial intelligence has been predicated on the ability for
computers to imitate human behavior. However, the majority of uses for the
computer can be said to fall outside the domain of human abilities and it is
exactly outside of this domain where computers have demonstrated their greatest
contribution to intelligence. Another goal for artificial intelligence is one
that is not predicated on human mimicry, but instead, on human amplification.
This article surveys various systems that contribute to the advancement of
human and social intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0443</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0443</id><created>2009-03-02</created><authors><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Lamahewa</keyname><forenames>Tharaka A.</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author></authors><title>Design Guidelines for Training-based MIMO Systems with Feedback</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Signal Processing</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 57, no. 10, pp.
  4014-4026, Oct. 2009</journal-ref><doi>10.1109/TSP.2009.2023930</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the optimal training and data transmission strategies
for block fading multiple-input multiple-output (MIMO) systems with feedback.
We consider both the channel gain feedback (CGF) system and the channel
covariance feedback (CCF) system. Using an accurate capacity lower bound as a
figure of merit, we investigate the optimization problems on the temporal power
allocation to training and data transmission as well as the training length.
For CGF systems without feedback delay, we prove that the optimal solutions
coincide with those for non-feedback systems. Moreover, we show that these
solutions stay nearly optimal even in the presence of feedback delay. This
finding is important for practical MIMO training design. For CCF systems, the
optimal training length can be less than the number of transmit antennas, which
is verified through numerical analysis. Taking this fact into account, we
propose a simple yet near optimal transmission strategy for CCF systems, and
derive the optimal temporal power allocation over pilot and data transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0696</identifier>
 <datestamp>2011-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0696</id><created>2009-03-03</created><updated>2011-06-06</updated><authors><author><keyname>Owen</keyname><forenames>Megan</forenames></author></authors><title>Computing Geodesic Distances in Tree Space</title><categories>math.CO cs.CG cs.DM math.MG q-bio.PE</categories><comments>24 pages, 7 figures; v2: substantially revised for clarity</comments><msc-class>68R05 (primary), 92D15 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two algorithms for computing the geodesic distance between
phylogenetic trees in tree space, as introduced by Billera, Holmes, and
Vogtmann (2001). We show that the possible combinatorial types of shortest
paths between two trees can be compactly represented by a partially ordered
set. We calculate the shortest distance along each candidate path by converting
the problem into one of finding the shortest path through a certain region of
Euclidean space. In particular, we show there is a linear time algorithm for
finding the shortest path between a point in the all positive orthant and a
point in the all negative orthant of R^k contained in the subspace of R^k
consisting of all orthants with the first i coordinates non-positive and the
remaining coordinates non-negative for 0 &lt;= i &lt;= k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.0748</identifier>
 <datestamp>2010-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.0748</id><created>2009-03-04</created><updated>2009-10-14</updated><authors><author><keyname>Trisetyarso</keyname><forenames>Agung</forenames></author><author><keyname>Van Meter</keyname><forenames>Rodney</forenames></author></authors><title>Circuit Design for A Measurement-Based Quantum Carry-Lookahead Adder</title><categories>quant-ph cs.AR</categories><comments>28 pages and 14 figures</comments><journal-ref>Int. J. Quantum Inf. 8, 843 (2010)</journal-ref><doi>10.1142/S0219749910006496</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the design and evaluation of a quantum carry-lookahead adder
(QCLA) using measurement-based quantum computation (MBQC), called MBQCLA. QCLA
was originally designed for an abstract, concurrent architecture supporting
long-distance communication, but most realistic architectures heavily constrain
communication distances. The quantum carry-lookahead adder is faster than a
quantum ripple-carry adder; QCLA has logarithmic depth while ripple adders have
linear depth. MBQCLA utilizes MBQC's ability to transfer quantum states in unit
time to accelerate addition. MBQCLA breaks the latency limit of addition
circuits in nearest neighbor-only architectures : compared to the $\Theta(n)$
limit on circuit depth for linear nearest-neighbor architectures, it can reach
$\Theta(log n)$ depth. MBQCLA is an order of magnitude faster than a
ripple-carry adder when adding registers longer than 100 qubits, but requires a
cluster state that is an order of magnitude larger. The cluster state resources
can be classified as computation and communication; for the unoptimized form,
$\approx$ 88 % of the resources are used for communication. Hand optimization
of horizontal communication costs results in a $\approx$ 12% reduction in
spatial resources for the in-place MBQCLA circuit. For comparison, a graph
state quantum carry-lookahead adder (GSQCLA) uses only $\approx$ 9 % of the
spatial resources of the MBQCLA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1095</identifier>
 <datestamp>2014-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1095</id><created>2009-03-05</created><updated>2009-03-20</updated><authors><author><keyname>Burke</keyname><forenames>Edmund K.</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author><author><keyname>Parkes</keyname><forenames>Andrew J.</forenames></author><author><keyname>Rudova</keyname><forenames>Hana</forenames></author></authors><title>Decomposition, Reformulation, and Diving in University Course
  Timetabling</title><categories>cs.DS cs.AI</categories><comments>45 pages, 7 figures. Improved typesetting of figures and tables</comments><report-no>NOTTCS-TR-2008-02</report-no><acm-class>G.2.3; I.2.8; F.2.2</acm-class><journal-ref>Computers and Operations Research (2010) 37(3), 582-597</journal-ref><doi>10.1016/j.cor.2009.02.023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real-life optimisation problems, there are multiple interacting
components in a solution. For example, different components might specify
assignments to different kinds of resource. Often, each component is associated
with different sets of soft constraints, and so with different measures of soft
constraint violation. The goal is then to minimise a linear combination of such
measures. This paper studies an approach to such problems, which can be thought
of as multiphase exploitation of multiple objective-/value-restricted
submodels. In this approach, only one computationally difficult component of a
problem and the associated subset of objectives is considered at first. This
produces partial solutions, which define interesting neighbourhoods in the
search space of the complete problem. Often, it is possible to pick the initial
component so that variable aggregation can be performed at the first stage, and
the neighbourhoods to be explored next are guaranteed to contain feasible
solutions. Using integer programming, it is then easy to implement heuristics
producing solutions with bounds on their quality.
  Our study is performed on a university course timetabling problem used in the
2007 International Timetabling Competition, also known as the Udine Course
Timetabling Problem. In the proposed heuristic, an objective-restricted
neighbourhood generator produces assignments of periods to events, with
decreasing numbers of violations of two period-related soft constraints. Those
are relaxed into assignments of events to days, which define neighbourhoods
that are easier to search with respect to all four soft constraints. Integer
programming formulations for all subproblems are given and evaluated using ILOG
CPLEX 11. The wider applicability of this approach is analysed and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1137</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1137</id><created>2009-03-05</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Complexity of Terminating Preference Elicitation</title><categories>cs.AI cs.CC cs.MA</categories><comments>7th International Joint Conference on Autonomous Agents and
  Multiagent Systems (AAMAS 2008)</comments><acm-class>I.2.4</acm-class><journal-ref>AAMAS 2008: 967-974</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complexity theory is a useful tool to study computational issues surrounding
the elicitation of preferences, as well as the strategic manipulation of
elections aggregating together preferences of multiple agents. We study here
the complexity of determining when we can terminate eliciting preferences, and
prove that the complexity depends on the elicitation strategy. We show, for
instance, that it may be better from a computational perspective to elicit all
preferences from one agent at a time than to elicit individual preferences from
multiple agents. We also study the connection between the strategic
manipulation of an election and preference elicitation. We show that what we
can manipulate affects the computational complexity of manipulation. In
particular, we prove that there are voting rules which are easy to manipulate
if we can change all of an agent's vote, but computationally intractable if we
can change only some of their preferences. This suggests that, as with
preference elicitation, a fine-grained view of manipulation may be informative.
Finally, we study the connection between predicting the winner of an election
and preference elicitation. Based on this connection, we identify a voting rule
where it is computationally difficult to decide the probability of a candidate
winning given a probability distribution over the votes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1147</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1147</id><created>2009-03-05</created><authors><author><keyname>Takenaga</keyname><forenames>Yasuhiko</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Tetravex is NP-complete</title><categories>cs.CC cs.AI</categories><acm-class>F.1.3</acm-class><journal-ref>Inf. Process. Lett. 99(5): 171-174 (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tetravex is a widely played one person computer game in which you are given
$n^2$ unit tiles, each edge of which is labelled with a number. The objective
is to place each tile within a $n$ by $n$ square such that all neighbouring
edges are labelled with an identical number. Unfortunately, playing Tetravex is
computationally hard. More precisely, we prove that deciding if there is a
tiling of the Tetravex board is NP-complete. Deciding where to place the tiles
is therefore NP-hard. This may help to explain why Tetravex is a good puzzle.
This result compliments a number of similar results for one person games
involving tiling. For example, NP-completeness results have been shown for: the
offline version of Tetris, KPlumber (which involves rotating tiles containing
drawings of pipes to make a connected network), and shortest sliding puzzle
problems. It raises a number of open questions. For example, is the infinite
version Turing-complete? How do we generate Tetravex problems which are truly
puzzling as random NP-complete problems are often surprising easy to solve? Can
we observe phase transition behaviour? What about the complexity of the problem
when it is guaranteed to have an unique solution? How do we generate puzzles
with unique solutions?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1204</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1204</id><created>2009-03-06</created><authors><author><keyname>Vlasov</keyname><forenames>Alexander Yu.</forenames></author></authors><title>Quantum Information Science and Nanotechnology</title><categories>quant-ph cs.OH</categories><comments>LaTeX, 12pt, 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note is touched upon an application of quantum information science
(QIS) in nanotechnology area. The laws of quantum mechanics may be very
important for nano-scale objects. A problem with simulating of quantum systems
is well known and quantum computer was initially suggested by R. Feynman just
as the way to overcome such difficulties. Mathematical methods developed in QIS
also may be applied for description of nano-devices. Few illustrative examples
are mentioned and they may be related with so-called fourth generation of
nanotechnology products.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1291</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1291</id><created>2009-03-06</created><updated>2014-10-06</updated><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Childs</keyname><forenames>Andrew M.</forenames></author><author><keyname>Gall</keyname><forenames>François Le</forenames></author><author><keyname>Tani</keyname><forenames>Seiichiro</forenames></author></authors><title>The quantum query complexity of certification</title><categories>quant-ph cs.CC</categories><comments>8 pages; Updated to reflect changes in final journal version and to
  point out that the main result only applies for k&gt;1</comments><journal-ref>Quantum Information and Computation 10, 181-188 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the quantum query complexity of finding a certificate for a
d-regular, k-level balanced NAND formula. Up to logarithmic factors, we show
that the query complexity is Theta(d^{(k+1)/2}) for 0-certificates, and
Theta(d^{k/2}) for 1-certificates. In particular, this shows that the
zero-error quantum query complexity of evaluating such formulas is
O(d^{(k+1)/2}) (again neglecting a logarithmic factor). Our lower bound relies
on the fact that the quantum adversary method obeys a direct sum theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1337</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1337</id><created>2009-03-07</created><authors><author><keyname>Carli</keyname><forenames>Ruggero</forenames></author><author><keyname>Fagnani</keyname><forenames>Fabio</forenames></author><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author><author><keyname>Zampieri</keyname><forenames>Sandro</forenames></author></authors><title>Efficient quantization for average consensus</title><categories>math.OC cs.SY</categories><comments>Based on material from the third author's PhD thesis, and on a 2007
  conference paper</comments><msc-class>93A14, 93D21</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algorithm which solves exponentially fast the average
consensus problem on strongly connected network of digital links. The algorithm
is based on an efficient zooming-in/zooming-out quantization scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1450</identifier>
 <datestamp>2011-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1450</id><created>2009-03-08</created><updated>2011-03-02</updated><authors><author><keyname>Hafalir</keyname><forenames>I.</forenames></author><author><keyname>Ravi</keyname><forenames>R.</forenames></author><author><keyname>Sayedi</keyname><forenames>A.</forenames></author></authors><title>Multi-unit Auctions with Budget Constraints</title><categories>cs.GT</categories><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Motivated by sponsored search auctions, we study multi-unit auctions with
budget constraints. In the mechanism we propose, Sort-Cut, understating budgets
or values is weakly dominated. Since Sort-Cut's revenue is increasing in
budgets and values, all kinds of equilibrium deviations from true valuations
turn out to be beneficial to the auctioneer. We show that the revenue of
Sort-Cut can be an order of magnitude greater than that of the natural Market
Clearing Price mechanism, and we discuss the efficiency properties of its
ex-post Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1502</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1502</id><created>2009-03-09</created><updated>2011-03-28</updated><authors><author><keyname>Duyck</keyname><forenames>Dieter</forenames></author><author><keyname>Boutros</keyname><forenames>Joseph J.</forenames></author><author><keyname>Moeneclaey</keyname><forenames>Marc</forenames></author></authors><title>Low-Density Graph Codes for slow fading Relay Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Information Theory</comments><msc-class>68Pxx</msc-class><journal-ref>IEEE Transactions on Information theory, vol 57, no 7, pp. 4202 -
  4218, 2011</journal-ref><doi>10.1109/TIT.2011.2145470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Low-Density Parity-Check (LDPC) codes with iterative decoding on
block-fading (BF) Relay Channels. We consider two users that employ coded
cooperation, a variant of decode-and-forward with a smaller outage probability
than the latter. An outage probability analysis for discrete constellations
shows that full diversity can be achieved only when the coding rate does not
exceed a maximum value that depends on the level of cooperation. We derive a
new code structure by extending the previously published full-diversity
root-LDPC code, designed for the BF point-to-point channel, to exhibit a
rate-compatibility property which is necessary for coded cooperation. We
estimate the asymptotic performance through a new density evolution analysis
and the word error rate performance is determined for finite length codes. We
show that our code construction exhibits near-outage limit performance for all
block lengths and for a range of coding rates up to 0.5, which is the highest
possible coding rate for two cooperating users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1588</identifier>
 <datestamp>2010-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1588</id><created>2009-03-09</created><updated>2010-05-04</updated><authors><author><keyname>Flanagan</keyname><forenames>Mark F.</forenames></author><author><keyname>Paolini</keyname><forenames>Enrico</forenames></author><author><keyname>Chiani</keyname><forenames>Marco</forenames></author><author><keyname>Fossorier</keyname><forenames>Marc</forenames></author></authors><title>On the Growth Rate of the Weight Distribution of Irregular
  Doubly-Generalized LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Revision of the journal paper. 37 pages, 2 figures. Submitted</comments><report-no>UCD-01-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an expression for the asymptotic growth rate of the number of
small linear-weight codewords of irregular doubly-generalized LDPC (D-GLDPC)
codes is derived. The expression is compact and generalizes existing results
for LDPC and generalized LDPC (GLDPC) codes. Ensembles with check or variable
node minimum distance greater than 2 are shown to be have good growth rate
behavior, while for other ensembles a fundamental parameter is identified which
discriminates between an asymptotically small and an asymptotically large
expected number of small linear-weight codewords. Also, in the latter case it
is shown that the growth rate depends only on the check and variable nodes with
minimum distance 2. An important connection between this new result and the
stability condition of D-GLDPC codes over the BEC is highlighted. Such a
connection, previously observed for LDPC and GLDPC codes, is now extended to
the case of D-GLDPC codes. Finally, it is shown that the analysis may be
extended to include the growth rate of the stopping set size distribution of
irregular D-GLDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1621</identifier>
 <datestamp>2010-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1621</id><created>2009-03-09</created><authors><author><keyname>Higuchi</keyname><forenames>Saburo</forenames></author><author><keyname>Mézard</keyname><forenames>Marc</forenames></author></authors><title>Susceptibility Propagation for Constraint Satisfaction Problems</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT</categories><comments>17 pages, 5 figures</comments><journal-ref>J. Phys.: Conf. Ser. 233(2010)012003</journal-ref><doi>10.1088/1742-6596/233/1/012003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the susceptibility propagation, a message-passing algorithm to
compute correlation functions. It is applied to constraint satisfaction
problems and its accuracy is examined. As a heuristic method to find a
satisfying assignment, we propose susceptibility-guided decimation where
correlations among the variables play an important role. We apply this novel
decimation to locked occupation problems, a class of hard constraint
satisfaction problems exhibited recently. It is shown that the present method
performs better than the standard belief-guided decimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1627</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1627</id><created>2009-03-09</created><updated>2012-02-01</updated><authors><author><keyname>Cassaigne</keyname><forenames>Julien</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>On the Morse-Hedlund complexity gap</title><categories>cs.FL cs.DM</categories><comments>7 pages. Not intended to be submitted. New proof of an old result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1938, Morse and Hedlund proved that the subword complexity function of an
infinite word is either bounded or at least linearly growing. In 1982,
Ehrenfeucht and Rozenberg proved that this gap property holds for the subword
complexity function of any language. The aim of the present paper is to present
a self-contained, compact proof of Ehrenfeucht and Rozenberg's result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1680</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1680</id><created>2009-03-10</created><updated>2010-10-05</updated><authors><author><keyname>Zhuge</keyname><forenames>H.</forenames></author><author><keyname>He</keyname><forenames>C.</forenames></author></authors><title>Faceted Exploration of Emerging Resource Spaces</title><categories>cs.DB cs.DL cs.HC</categories><comments>20 pages, 18 figures</comments><acm-class>H.2.1; H.2.8; H.3.1; H.3.7; H.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans have the ability to regcognize the real world from different facets.
Faceted exploration is a mechanism for browsing and understanding large-scale
resources in information network by multiple facets. This paper proposes an
Emerging Resource Space Model, whose schema is a partially ordered set of
concepts with subclassOf relation and each resource is categorized by multiple
concepts. Emering Resource Space (ERS) is a class of resources characterized by
a concept set. ERSes compose a lattice (ERSL) via concept association. A series
of exploration operations is proposed to guide users to explore through ERSL
with more demanding and richer semantics than current faceted navigation. To
fulfill instant response during faceted exploration, we devise an efficient
algorithm for mining and indexing ERSL. The proposed model can effectively
support faceted exploration in various applications from personal information
management to large-scale information sharing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.1904</identifier>
 <datestamp>2010-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.1904</id><created>2009-03-11</created><authors><author><keyname>Laumann</keyname><forenames>C. R.</forenames></author><author><keyname>Moessner</keyname><forenames>R.</forenames></author><author><keyname>Scardicchio</keyname><forenames>A.</forenames></author><author><keyname>Sondhi</keyname><forenames>S. L.</forenames></author></authors><title>Phase transitions and random quantum satisfiability</title><categories>quant-ph cond-mat.dis-nn cond-mat.stat-mech cs.CC</categories><comments>9 pages, 3 figures</comments><journal-ref>Quant. Inf. and Comp. (2010) vol. 10 (1) 1 pp. 0001-0015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alongside the effort underway to build quantum computers, it is important to
better understand which classes of problems they will find easy and which
others even they will find intractable. We study random ensembles of the
QMA$_1$-complete quantum satisfiability (QSAT) problem introduced by Bravyi.
QSAT appropriately generalizes the NP-complete classical satisfiability (SAT)
problem. We show that, as the density of clauses/projectors is varied, the
ensembles exhibit quantum phase transitions between phases that are satisfiable
and unsatisfiable. Remarkably, almost all instances of QSAT for any hypergraph
exhibit the same dimension of the satisfying manifold. This establishes the
QSAT decision problem as equivalent to a, potentially new, graph theoretic
problem and that the hardest typical instances are likely to be localized in a
bounded range of clause density.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2071</identifier>
 <datestamp>2014-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2071</id><created>2009-03-12</created><updated>2009-06-29</updated><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author></authors><title>Notes on Recent Approaches Concerning the
  Kirchhoff-Law-Johnson-Noise-based Secure Key Exchange</title><categories>physics.gen-ph cs.CR physics.class-ph</categories><comments>Accepted for publication in Physics Letters A on May 29, 2009. In the
  present version, DOI and acceptance info is added in the pdf file, too</comments><journal-ref>Physics Letters A 373 (2009) 2858-2868</journal-ref><doi>10.1016/j.physleta.2009.05.077</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We critically analyze the results and claims in [Physics Letters A 373 (2009)
901-904].
  We show that the strong security leak appeared in the simulations is only an
artifact and not caused by "multiple reflections". Since no wave modes exist at
cable length of 5% of the shortest wavelength of the signal, no wave is present
to reflect it.
  In the high wave impedance limit, the conditions used in the simulations are
heavily unphysical (requiring cable diameters up to 28000 times greater than
the measured size of the known universe) and the results are modeling artifacts
due to the unphysical values.
  At the low cable impedance limit, the observed artifacts are due to violating
the recommended (and tested) conditions by neglecting the cable capacitance
restrictions and using about 100 times longer cable than recommended without
cable capacitance compensation arrangement.
  We implement and analyze the general circuitry of Liu's circulator and
confirm that they are conceptually secure against passive attacks. We introduce
an asymmetric, more robust version without feedback loop. Then we crack all
these systems by an active attack: a circulator-based man-in-the middle attack.
  Finally, we analyze the proposed method to increase security by dropping only
high-risk bits. We point out the differences between different types of
high-risk bits and show the shortage of this strategy for some simple key
exchange protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2101</identifier>
 <datestamp>2010-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2101</id><created>2009-03-12</created><updated>2010-08-27</updated><authors><author><keyname>Duchamp</keyname><forenames>Gérard Henry Edmond</forenames><affiliation>LIPN</affiliation></author><author><keyname>Tollu</keyname><forenames>Christophe</forenames><affiliation>LIPN</affiliation></author><author><keyname>Penson</keyname><forenames>K. A.</forenames><affiliation>LPTMC</affiliation></author><author><keyname>Koshevoy</keyname><forenames>Gleb</forenames><affiliation>CEMI</affiliation></author></authors><title>Combinatorial Deformations of Algebras: Twisting and Perturbations</title><categories>cs.SC math-ph math.CO math.MP</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The framework used to prove the multiplicative law deformation of the algebra
of Feynman-Bender diagrams is a \textit{twisted shifted dual law} (in fact,
twice). We give here a clear interpretation of its two parameters. The crossing
parameter is a deformation of the tensor structure whereas the superposition
parameters is a perturbation of the shuffle coproduct of Hoffman type which, in
turn, can be interpreted as the diagonal restriction of a superproduct. Here,
we systematically detail these constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2174</identifier>
 <datestamp>2010-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2174</id><created>2009-03-12</created><authors><author><keyname>Leshem</keyname><forenames>Amir</forenames></author><author><keyname>Zehavi</keyname><forenames>Ephi</forenames></author></authors><title>Game theory and the frequency selective interference channel - A
  tutorial</title><categories>cs.IT cs.GT math.IT</categories><journal-ref>IEEE Signal Processing Magazine. Special issue on applications of
  game theory in signal processing and communications. Volume 26, Issue 4,
  pages 28-40. Sep. 2009</journal-ref><doi>10.1109/MSP.2009.933372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a tutorial overview of game theoretic techniques used for
communication over frequency selective interference channels. We discuss both
competitive and cooperative techniques.
  Keywords: Game theory, competitive games, cooperative games, Nash
Equilibrium, Nash bargaining solution, Generalized Nash games, Spectrum
optimization, distributed coordination, interference channel, multiple access
channel, iterative water-filling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2177</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2177</id><created>2009-03-12</created><updated>2010-10-21</updated><authors><author><keyname>Pauly</keyname><forenames>Arno</forenames></author></authors><title>On the (semi)lattices induced by continuous reducibilities</title><categories>cs.LO</categories><comments>this version of the paper is outdated, please consult the journal
  version</comments><acm-class>F.4.1</acm-class><journal-ref>Mathematical Logic Quarterly, 56(5): 488--502, 2010</journal-ref><doi>10.1002/malq.200910104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Continuous reducibilities are a proven tool in computable analysis, and have
applications in other fields such as constructive mathematics or reverse
mathematics. We study the order-theoretic properties of several variants of the
two most important definitions, and especially introduce suprema for them. The
suprema are shown to commutate with several characteristic numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2232</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2232</id><created>2009-03-12</created><updated>2012-01-30</updated><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>On the Iterative Decoding of High-Rate LDPC Codes With Applications in
  Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Trans. on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the performance of $(j,k)$-regular low-density
parity-check (LDPC) codes with message-passing (MP) decoding algorithms in the
high-rate regime. In particular, we derive the high-rate scaling law for MP
decoding of LDPC codes on the binary erasure channel (BEC) and the $q$-ary
symmetric channel ($q$-SC). For the BEC, the density evolution (DE) threshold
of iterative decoding scales like $\Theta(k^{-1})$ and the critical stopping
ratio scales like $\Theta(k^{-j/(j-2)})$. For the $q$-SC, the DE threshold of
verification decoding depends on the details of the decoder and scales like
$\Theta(k^{-1})$ for one decoder.
  Using the fact that coding over large finite alphabets is very similar to
coding over the real numbers, the analysis of verification decoding is also
extended to the the compressed sensing (CS) of strictly-sparse signals. A DE
based approach is used to analyze the CS systems with randomized-reconstruction
guarantees. This leads to the result that strictly-sparse signals can be
reconstructed efficiently with high-probability using a constant oversampling
ratio (i.e., when the number of measurements scales linearly with the sparsity
of the signal). A stopping-set based approach is also used to get stronger
(e.g., uniform-in-probability) reconstruction guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2243</identifier>
 <datestamp>2014-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2243</id><created>2009-03-12</created><updated>2014-09-22</updated><authors><author><keyname>Weinberger</keyname><forenames>Edward D.</forenames></author></authors><title>Pragmatic Information Rates, Generalizations of the Kelly Criterion, and
  Financial Market Efficiency</title><categories>cs.IT math.IT q-fin.PM q-fin.TR</categories><comments>Revised to clarify the text</comments><msc-class>94A17, 91G80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is part of an ongoing investigation of "pragmatic information",
defined in Weinberger (2002) as "the amount of information actually used in
making a decision". Because a study of information rates led to the Noiseless
and Noisy Coding Theorems, two of the most important results of Shannon's
theory, we begin the paper by defining a pragmatic information rate, showing
that all of the relevant limits make sense, and interpreting them as the
improvement in compression obtained from using the correct distribution of
transmitted symbols.
  The first of two applications of the theory extends the information theoretic
analysis of the Kelly Criterion, and its generalization, the horse race, to a
series of races where the stochastic process of winning horses, payoffs, and
strategies depend on some stationary process, including, but not limited to the
history of previous races. If the bettor is receiving messages (side
information) about the probability distribution of winners, the doubling rate
of the bettor's winnings is bounded by the pragmatic information of the
messages.
  A second application is to the question of market efficiency. An efficient
market is, by definition, a market in which the pragmatic information of the
"tradable past" with respect to current prices is zero. Under this definition,
markets whose returns are characterized by a GARCH(1,1) process cannot be
efficient.
  Finally, a pragmatic informational analogue to Shannon's Noisy Coding Theorem
suggests that a cause of market inefficiency is that the underlying
fundamentals are changing so fast that the price discovery mechanism simply
cannot keep up. This may happen most readily in the run-up to a financial
bubble, where investors' willful ignorance degrade the information processing
capabilities of the market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2299</identifier>
 <datestamp>2013-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2299</id><created>2009-03-13</created><updated>2013-07-08</updated><authors><author><keyname>McAllester</keyname><forenames>David</forenames></author></authors><title>Differential Contrastive Divergence</title><categories>cs.LG</categories><comments>This paper was a rediscovery of known material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been retracted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2310</identifier>
 <datestamp>2010-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2310</id><created>2009-03-13</created><authors><author><keyname>Ning</keyname><forenames>Kang</forenames></author><author><keyname>Ng</keyname><forenames>Hoong Kee</forenames></author><author><keyname>Leong</keyname><forenames>Hon Wai</forenames></author></authors><title>Analysis of the Relationships among Longest Common Subsequences,
  Shortest Common Supersequences and Patterns and its application on Pattern
  Discovery in Biological Sequences</title><categories>cs.DS cs.DM cs.IR cs.OH q-bio.QM</categories><comments>Extended version of paper presented in IEEE BIBE 2006 submitted to
  journal for review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a set of mulitple sequences, their patterns,Longest Common Subsequences
(LCS) and Shortest Common Supersequences (SCS) represent different aspects of
these sequences profile, and they can all be used for biological sequence
comparisons and analysis. Revealing the relationship between the patterns and
LCS,SCS might provide us with a deeper view of the patterns of biological
sequences, in turn leading to better understanding of them. However, There is
no careful examinaton about the relationship between patterns, LCS and SCS. In
this paper, we have analyzed their relation, and given some lemmas. Based on
their relations, a set of algorithms called the PALS (PAtterns by Lcs and Scs)
algorithms are propsoed to discover patterns in a set of biological sequences.
These algorithms first generate the results for LCS and SCS of sequences by
heuristic, and consequently derive patterns from these results. Experiments
show that the PALS algorithms perform well (both in efficiency and in accuracy)
on a variety of sequences. The PALS approach also provides us with a solution
for transforming between the heuristic results of SCS and LCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2554</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2554</id><created>2009-03-14</created><updated>2013-07-31</updated><authors><author><keyname>Durand</keyname><forenames>Irene</forenames></author><author><keyname>Senizergues</keyname><forenames>Geraud</forenames></author></authors><title>Bottom-up rewriting for words and terms</title><categories>cs.FL</categories><comments>86 pages; long version to be cut into pieces for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the whole class of linear term rewriting systems, we define
\emph{bottom-up rewriting} which is a restriction of the usual notion of
rewriting. We show that bottom-up rewriting effectively inverse-preserves
recognizability and analyze the complexity of the underlying construction. The
Bottom-Up class (BU) is, by definition, the set of linear systems for which
every derivation can be replaced by a bottom-up derivation. Membership to BU
turns out to be undecidable, we are thus lead to define more restricted
classes: the classes SBU(k), k in N of Strongly Bottom-Up(k) systems for which
we show that membership is decidable. We define the class of Strongly Bottom-Up
systems by SBU = U_{k in \} SBU(k). We give a polynomial sufficient condition
for a system to be in $\SBU$. The class SBU contains (strictly) several classes
of systems which were already known to inverse preserve recognizability: the
inverse left-basic semi-Thue systems (viewed as unary term rewriting systems),
the linear growing term rewriting systems, the inverse
Linear-Finite-Path-Ordering systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2693</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2693</id><created>2009-03-16</created><authors><author><keyname>Ning</keyname><forenames>Kang</forenames></author></authors><title>A Pseudo DNA Cryptography Method</title><categories>cs.CR cs.DM</categories><comments>A small work that quite some people asked about</comments><doi>10.1016/j.compeleceng.2012.02.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The DNA cryptography is a new and very promising direction in cryptography
research. DNA can be used in cryptography for storing and transmitting the
information, as well as for computation. Although in its primitive stage, DNA
cryptography is shown to be very effective. Currently, several DNA computing
algorithms are proposed for quite some cryptography, cryptanalysis and
steganography problems, and they are very powerful in these areas. However, the
use of the DNA as a means of cryptography has high tech lab requirements and
computational limitations, as well as the labor intensive extrapolation means
so far. These make the efficient use of DNA cryptography difficult in the
security world now. Therefore, more theoretical analysis should be performed
before its real applications.
  In this project, We do not intended to utilize real DNA to perform the
cryptography process; rather, We will introduce a new cryptography method based
on central dogma of molecular biology. Since this method simulates some
critical processes in central dogma, it is a pseudo DNA cryptography method.
The theoretical analysis and experiments show this method to be efficient in
computation, storage and transmission; and it is very powerful against certain
attacks. Thus, this method can be of many uses in cryptography, such as an
enhancement insecurity and speed to the other cryptography methods. There are
also extensions and variations to this method, which have enhanced security,
effectiveness and applicability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2711</identifier>
 <datestamp>2010-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2711</id><created>2009-03-16</created><updated>2010-12-04</updated><authors><author><keyname>Fertl</keyname><forenames>Peter</forenames></author><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author></authors><title>Performance Assessment of MIMO-BICM Demodulators based on System
  Capacity</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, Oct. 20010
  (paper was presented in part at IEEE SPAWC 2008, Recife, Brazil, July 2008)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a comprehensive performance comparison of soft-output and
hard-output demodulators in the context of non-iterative multiple-input
multiple-output bit-interleaved coded modulation (MIMO-BICM). Coded bit error
rate (BER), widely used in literature for demodulator comparison, has the
drawback of depending strongly on the error correcting code being used. This
motivates us to propose a code-independent performance measure in terms of
system capacity, i.e., mutual information of the equivalent modulation channel
that comprises modulator, wireless channel, and demodulator. We present
extensive numerical results for ergodic and quasi-static fading channels under
perfect and imperfect channel state information. These results reveal that the
performance ranking of MIMO demodulators is rate-dependent. Furthermore, they
provide new insights regarding MIMO-BICM system design, i.e., the choice of
antenna configuration, symbol constellation, and demodulator for a given target
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2749</identifier>
 <datestamp>2010-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2749</id><created>2009-03-16</created><updated>2010-01-10</updated><authors><author><keyname>Östergård</keyname><forenames>Patric R. J.</forenames></author><author><keyname>Pottonen</keyname><forenames>Olli</forenames></author><author><keyname>Phelps</keyname><forenames>Kevin T.</forenames></author></authors><title>The Perfect Binary One-Error-Correcting Codes of Length 15: Part
  II--Properties</title><categories>cs.IT math.IT</categories><comments>v2: fixed two errors (extension of nonsystematic codes, table of
  coordinates fixed by symmetries of codes), added and extended many other
  results</comments><journal-ref>IEEE Trans. Inform. Theory vol. 56, pp. 2571-2582, 2010</journal-ref><doi>10.1109/TIT.2010.2046197</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A complete classification of the perfect binary one-error-correcting codes of
length 15 as well as their extensions of length 16 was recently carried out in
[P. R. J. \"Osterg{\aa}rd and O. Pottonen, "The perfect binary
one-error-correcting codes of length 15: Part I--Classification," IEEE Trans.
Inform. Theory vol. 55, pp. 4657--4660, 2009]. In the current accompanying
work, the classified codes are studied in great detail, and their main
properties are tabulated. The results include the fact that 33 of the 80
Steiner triple systems of order 15 occur in such codes. Further understanding
is gained on full-rank codes via switching, as it turns out that all but two
full-rank codes can be obtained through a series of such transformations from
the Hamming code. Other topics studied include (non)systematic codes, embedded
one-error-correcting codes, and defining sets of codes. A classification of
certain mixed perfect codes is also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2774</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2774</id><created>2009-03-16</created><updated>2010-05-07</updated><authors><author><keyname>Tauboeck</keyname><forenames>Georg</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author><author><keyname>Eiwen</keyname><forenames>Daniel</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Compressive estimation of doubly selective channels in multicarrier
  systems: Leakage effects and sparsity-enhancing processing</title><categories>cs.IT math.IT</categories><comments>18 pages, 6 figures; content is identical to published paper version
  (in IEEE Journal of Selected Topics in Signal Processing - Special Issue on
  Compressed Sensing), only format is different; this revision contains
  substantially new material compared with previous (arXiv) revision, also
  title and author list have changed</comments><journal-ref>IEEE J. Sel. Top. Sig. Process., vol. 4, no. 2, pp. 255-271, April
  2010</journal-ref><doi>10.1109/JSTSP.2010.2042410</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the application of compressed sensing (CS) to the estimation of
doubly selective channels within pulse-shaping multicarrier systems (which
include OFDM systems as a special case). By exploiting sparsity in the
delay-Doppler domain, CS-based channel estimation allows for an increase in
spectral efficiency through a reduction of the number of pilot symbols. For
combating leakage effects that limit the delay-Doppler sparsity, we propose a
sparsity-enhancing basis expansion and a method for optimizing the basis with
or without prior statistical information about the channel. We also present an
alternative CS-based channel estimator for (potentially) strongly
time-frequency dispersive channels, which is capable of estimating the
"off-diagonal" channel coefficients characterizing intersymbol and intercarrier
interference (ISI/ICI). For this estimator, we propose a basis construction
combining Fourier (exponential) and prolate spheroidal sequences. Simulation
results assess the performance gains achieved by the proposed
sparsity-enhancing processing techniques and by explicit estimation of ISI/ICI
channel coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2792</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2792</id><created>2009-03-16</created><updated>2011-02-27</updated><authors><author><keyname>Koroutchev</keyname><forenames>Kostadin</forenames></author><author><keyname>Shen</keyname><forenames>Jian</forenames></author><author><keyname>Koroutcheva</keyname><forenames>Elka</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author></authors><title>Thermodynamics of Information Retrieval</title><categories>cs.IT cs.CL cs.SI math.IT</categories><comments>12 pages, 7 figures</comments><acm-class>E.4; G.3; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we suggest a parameterized statistical model (the gamma
distribution) for the frequency of word occurrences in long strings of English
text and use this model to build a corresponding thermodynamic picture by
constructing the partition function. We then use our partition function to
compute thermodynamic quantities such as the free energy and the specific heat.
In this approach, the parameters of the word frequency model vary from word to
word so that each word has a different corresponding thermodynamics and we
suggest that differences in the specific heat reflect differences in how the
words are used in language, differentiating keywords from common and function
words. Finally, we apply our thermodynamic picture to the problem of retrieval
of texts based on keywords and suggest some advantages over traditional
information retrieval methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2851</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2851</id><created>2009-03-16</created><updated>2010-01-18</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Freund</keyname><forenames>Yoav</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author></authors><title>A parameter-free hedging algorithm</title><categories>cs.LG cs.AI</categories><comments>Updated Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of decision-theoretic online learning (DTOL). Motivated
by practical applications, we focus on DTOL when the number of actions is very
large. Previous algorithms for learning in this framework have a tunable
learning rate parameter, and a barrier to using online-learning in practical
applications is that it is not understood how to set this parameter optimally,
particularly when the number of actions is large.
  In this paper, we offer a clean solution by proposing a novel and completely
parameter-free algorithm for DTOL. We introduce a new notion of regret, which
is more natural for applications with a large number of actions. We show that
our algorithm achieves good performance with respect to this new notion of
regret; in addition, it also achieves performance close to that of the best
bounds achieved by previous algorithms with optimally-tuned parameters,
according to previous notions of regret.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2862</identifier>
 <datestamp>2010-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2862</id><created>2009-03-16</created><updated>2010-01-18</updated><authors><author><keyname>Chaudhuri</keyname><forenames>Kamalika</forenames></author><author><keyname>Freund</keyname><forenames>Yoav</forenames></author><author><keyname>Hsu</keyname><forenames>Daniel</forenames></author></authors><title>Tracking using explanation-based modeling</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the tracking problem, namely, estimating the hidden state of an
object over time, from unreliable and noisy measurements. The standard
framework for the tracking problem is the generative framework, which is the
basis of solutions such as the Bayesian algorithm and its approximation, the
particle filters. However, the problem with these solutions is that they are
very sensitive to model mismatches. In this paper, motivated by online
learning, we introduce a new framework -- an {\em explanatory} framework -- for
tracking. We provide an efficient tracking algorithm for this framework. We
provide experimental results comparing our algorithm to the Bayesian algorithm
on simulated data. Our experiments show that when there are slight model
mismatches, our algorithm vastly outperforms the Bayesian algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2890</identifier>
 <datestamp>2010-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2890</id><created>2009-03-16</created><updated>2010-05-28</updated><authors><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Sinopoli</keyname><forenames>Bruno</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Kalman Filtering with Intermittent Observations: Weak Convergence to a
  Stationary Distribution</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the asymptotic behavior of Random Algebraic Riccati
Equations (RARE) arising in Kalman filtering when the arrival of the
observations is described by a Bernoulli i.i.d. process. We model the RARE as
an order-preserving, strongly sublinear random dynamical system (RDS). Under a
sufficient condition, stochastic boundedness, and using a limit-set dichotomy
result for order-preserving, strongly sublinear RDS, we establish the
asymptotic properties of the RARE: the sequence of random prediction error
covariance matrices converges weakly to a unique invariant distribution, whose
support exhibits fractal behavior. In particular, this weak convergence holds
under broad conditions and even when the observations arrival rate is below the
critical probability for mean stability. We apply the weak-Feller property of
the Markov process governing the RARE to characterize the support of the
limiting invariant distribution as the topological closure of a countable set
of points, which, in general, is not dense in the set of positive semi-definite
matrices. We use the explicit characterization of the support of the invariant
distribution and the almost sure ergodicity of the sample paths to easily
compute the moments of the invariant distribution. A one dimensional example
illustrates that the support is a fractured subset of the non-negative reals
with self-similarity properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2914</identifier>
 <datestamp>2013-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2914</id><created>2009-03-17</created><updated>2013-03-28</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>A process calculus with finitary comprehended terms</title><categories>cs.LO math.RA</categories><comments>25 pages, combined with arXiv:0901.3012 [math.RA]; presentation
  improved, mistakes in Table 5 corrected</comments><acm-class>D.1.3; F.1.2; F.4.1</acm-class><journal-ref>Theory of Computing Systems, 53(4):645--668, 2013</journal-ref><doi>10.1007/s00224-013-9468-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of an ACP process algebra and the notion of a meadow
enriched ACP process algebra. The former notion originates from the models of
the axiom system ACP. The latter notion is a simple generalization of the
former notion to processes in which data are involved, the mathematical
structure of data being a meadow. Moreover, for all associative operators from
the signature of meadow enriched ACP process algebras that are not of an
auxiliary nature, we introduce variable-binding operators as generalizations.
These variable-binding operators, which give rise to comprehended terms, have
the property that they can always be eliminated. Thus, we obtain a process
calculus whose terms can be interpreted in all meadow enriched ACP process
algebras. Use of the variable-binding operators can have a major impact on the
size of terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.2923</identifier>
 <datestamp>2010-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.2923</id><created>2009-03-17</created><updated>2010-09-09</updated><authors><author><keyname>Ghobber</keyname><forenames>Saifallah</forenames><affiliation>MAPMO</affiliation></author><author><keyname>Jaming</keyname><forenames>Philippe</forenames><affiliation>MAPMO, IMB</affiliation></author></authors><title>On uncertainty principles in the finite dimensional setting</title><categories>math.CA cs.IT math.IT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove an uncertainty principle for the
representation of a vector in two bases. Our result extends previously known
qualitative uncertainty principles into quantitative estimates. We then show
how to transfer this result to the discrete version of the Short Time Fourier
Transform. An application to trigonometric polynomials is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3127</identifier>
 <datestamp>2010-06-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3127</id><created>2009-03-18</created><updated>2010-06-28</updated><authors><author><keyname>Hazan</keyname><forenames>Tamir</forenames></author><author><keyname>Shashua</keyname><forenames>Amnon</forenames></author></authors><title>Norm-Product Belief Propagation: Primal-Dual Message-Passing for
  Approximate Inference</title><categories>cs.AI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we treat both forms of probabilistic inference, estimating
marginal probabilities of the joint distribution and finding the most probable
assignment, through a unified message-passing algorithm architecture. We
generalize the Belief Propagation (BP) algorithms of sum-product and
max-product and tree-rewaighted (TRW) sum and max product algorithms (TRBP) and
introduce a new set of convergent algorithms based on "convex-free-energy" and
Linear-Programming (LP) relaxation as a zero-temprature of a
convex-free-energy. The main idea of this work arises from taking a general
perspective on the existing BP and TRBP algorithms while observing that they
all are reductions from the basic optimization formula of $f + \sum_i h_i$
where the function $f$ is an extended-valued, strictly convex but non-smooth
and the functions $h_i$ are extended-valued functions (not necessarily convex).
We use tools from convex duality to present the "primal-dual ascent" algorithm
which is an extension of the Bregman successive projection scheme and is
designed to handle optimization of the general type $f + \sum_i h_i$. Mapping
the fractional-free-energy variational principle to this framework introduces
the "norm-product" message-passing. Special cases include sum-product and
max-product (BP algorithms) and the TRBP algorithms. When the
fractional-free-energy is set to be convex (convex-free-energy) the
norm-product is globally convergent for estimating of marginal probabilities
and for approximating the LP-relaxation. We also introduce another branch of
the norm-product, the "convex-max-product". The convex-max-product is
convergent (unlike max-product) and aims at solving the LP-relaxation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3278</identifier>
 <datestamp>2010-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3278</id><created>2009-03-19</created><updated>2009-06-15</updated><authors><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author><author><keyname>Chiu</keyname><forenames>Dah-Ming</forenames></author></authors><title>On Oligopoly Spectrum Allocation Game in Cognitive Radio Networks with
  Capacity Constraints</title><categories>cs.NI cs.GT</categories><comments>40 pages, 22 figures</comments><journal-ref>Elsevier, Computer Networks, 2010</journal-ref><doi>10.1016/j.comnet.2009.11.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic spectrum sharing is a promising technology to improve spectrum
utilization in the future wireless networks. The flexible spectrum management
provides new opportunities for licensed primary user and unlicensed secondary
users to reallocate the spectrum resource efficiently. In this paper, we
present an oligopoly pricing framework for dynamic spectrum allocation in which
the primary users sell excessive spectrum to the secondary users for monetary
return. We present two approaches, the strict constraints (type-I) and the QoS
penalty (type-II), to model the realistic situation that the primary users have
limited capacities. In the oligopoly model with strict constraints, we propose
a low-complexity searching method to obtain the Nash Equilibrium and prove its
uniqueness. When reduced to a duopoly game, we analytically show the
interesting gaps in the leader-follower pricing strategy. In the QoS penalty
based oligopoly model, a novel variable transformation method is developed to
derive the unique Nash Equilibrium. When the market information is limited, we
provide three myopically optimal algorithms "StrictBEST", "StrictBR" and
"QoSBEST" that enable price adjustment for duopoly primary users based on the
Best Response Function (BRF) and the bounded rationality (BR) principles.
Numerical results validate the effectiveness of our analysis and demonstrate
the fast convergence of "StrictBEST" as well as "QoSBEST" to the Nash
Equilibrium. For the "StrictBR" algorithm, we reveal the chaotic behaviors of
dynamic price adaptation in response to the learning rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3623</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3623</id><created>2009-03-20</created><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>Matrix plots of reordered bistochastized transaction flow tables: A
  United States intercounty migration example</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a number of variously rearranged matrix plots of the $3, 107
\times 3, 107$ 1995-2000 (asymmetric) intercounty migration table for the
United States, principally in its bistochasticized form (all 3,107 row and
column sums iteratively proportionally fitted to equal 1). In one set of plots,
the counties are seriated on the bases of the subdominant (left and right)
eigenvectors of the bistochastic matrix. In another set, we use the ordering of
counties in the dendrogram generated by the associated strong component
hierarchical clustering. Interesting, diverse features of U. S. intercounty
migration emerge--such as a contrast in centralized, hub-like
(cosmopolitan/provincial) properties between cosmopolitan "Sunbelt" and
provincial "Black Belt" counties. The methodologies employed should also be
insightful for the many other diverse forms of interesting transaction
flow-type data--interjournal citations being an obvious, much-studied example,
where one might expect that the journals Science, Nature and PNAS would display
"cosmopolitan" characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3667</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3667</id><created>2009-03-21</created><updated>2011-01-02</updated><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>How random are a learner's mistakes?</title><categories>cs.LG cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a random binary sequence $X^{(n)}$ of random variables, $X_{t},$
$t=1,2,...,n$, for instance, one that is generated by a Markov source (teacher)
of order $k^{*}$ (each state represented by $k^{*}$ bits). Assume that the
probability of the event $X_{t}=1$ is constant and denote it by $\beta$.
Consider a learner which is based on a parametric model, for instance a Markov
model of order $k$, who trains on a sequence $x^{(m)}$ which is randomly drawn
by the teacher. Test the learner's performance by giving it a sequence
$x^{(n)}$ (generated by the teacher) and check its predictions on every bit of
$x^{(n)}.$ An error occurs at time $t$ if the learner's prediction $Y_{t}$
differs from the true bit value $X_{t}$. Denote by $\xi^{(n)}$ the sequence of
errors where the error bit $\xi_{t}$ at time $t$ equals 1 or 0 according to
whether the event of an error occurs or not, respectively. Consider the
subsequence $\xi^{(\nu)}$ of $\xi^{(n)}$ which corresponds to the errors of
predicting a 0, i.e., $\xi^{(\nu)}$ consists of the bits of $\xi^{(n)}$ only at
times $t$ such that $Y_{t}=0.$ In this paper we compute an estimate on the
deviation of the frequency of 1s of $\xi^{(\nu)}$ from $\beta$. The result
shows that the level of randomness of $\xi^{(\nu)}$ decreases relative to an
increase in the complexity of the learner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3676</identifier>
 <datestamp>2010-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3676</id><created>2009-03-23</created><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author><author><keyname>Appleboilm</keyname><forenames>Eli</forenames></author><author><keyname>Wolansky</keyname><forenames>Gershon</forenames></author><author><keyname>Zeevi</keyname><forenames>Yehoshua Y.</forenames></author></authors><title>Combinatorial Ricci Curvature and Laplacians for Image Processing</title><categories>cs.CV cs.CG</categories><comments>12 pages, 8 figures (some of the these may be of lesser quality than
  those in the Technical report version)</comments><report-no>CCIT Report # 722 March 2009 (EE Pub. No. 1679)</report-no><journal-ref>Proceedings of CISP'09, Vol. 2, 992-997, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new Combinatorial Ricci curvature and Laplacian operators for grayscale
images are introduced and tested on 2D synthetic, natural and medical images.
Analogue formulae for voxels are also obtained. These notions are based upon
more general concepts developed by R. Forman. Further applications, in
particular a fitting Ricci flow, are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.3696</identifier>
 <datestamp>2014-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.3696</id><created>2009-03-23</created><updated>2014-11-06</updated><authors><author><keyname>Bell</keyname><forenames>George I.</forenames></author></authors><title>Notes on solving and playing peg solitaire on a computer</title><categories>math.CO cs.DM math.HO</categories><comments>25 pages, 11 figures, 8 tables. Some text rewritten, more ancillary
  material added</comments><msc-class>00A08, 97A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the one-person game of peg solitaire played on a computer. Two
popular board shapes are the 33-hole cross-shaped board, and the 15-hole
triangle board---we use them as examples throughout. The basic game begins from
a full board with one peg missing and the goal is to finish at a board position
with one peg. First, we discuss ways to solve the basic game on a computer.
Then we consider the problem of quickly distinguishing board positions where
the goal can still be reached ("winning" board positions) from those where it
cannot. This enables a computer to alert the player if a jump under
consideration leads to a dead end. On the 15-hole triangle board, it is
possible to identify all winning board positions (from any single vacancy
start) by storing a key set of 437 board positions. For the "central game" on
the 33-hole cross-shaped board, we can identify all winning board positions by
storing 839,536 board positions. By viewing a successful game as a traversal of
a directed graph of winning board positions, we apply a simple algorithm to
count the number of ways to traverse this graph, and calculate that the total
number of solutions to the central game is 40,861,647,040,079,968. Our analysis
can also determine how quickly we can reach a "dead board position", where a
one peg finish is no longer possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4014</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4014</id><created>2009-03-24</created><updated>2010-04-09</updated><authors><author><keyname>Muramatsu</keyname><forenames>Jun</forenames></author><author><keyname>Miyake</keyname><forenames>Shigeki</forenames></author></authors><title>Construction of Codes for Wiretap Channel and Secret Key Agreement from
  Correlated Source Outputs by Using Sparse Matrices</title><categories>cs.IT cs.CR math.IT</categories><comments>A part of this paper is presented in part at 2009 IEEE Information
  Theory Workshop (ITW2009), Taormina, Italy, pp.105-109, 2009. This paper is
  submitted to IEEE Transactions on Information Theory. 34 pages</comments><journal-ref>IEEE Transactions on Information Theory, vol. 58, no. 2, pp.
  671-692, Feb. 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove coding theorems for the wiretap channel
coding problem and secret key agreement problem based on the the notion of a
hash property for an ensemble of functions. These theorems imply that codes
using sparse matrices can achieve the optimal rate. Furthermore, fixed-rate
universal coding theorems for a wiretap channel and a secret key agreement are
also proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4132</identifier>
 <datestamp>2010-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4132</id><created>2009-03-24</created><authors><author><keyname>Goñi</keyname><forenames>Joaquín</forenames></author><author><keyname>Martincorena</keyname><forenames>Iñigo</forenames></author><author><keyname>Corominas-Murtra</keyname><forenames>Bernat</forenames></author><author><keyname>Arrondo</keyname><forenames>Gonzalo</forenames></author><author><keyname>Ardanza-Trevijano</keyname><forenames>Sergio</forenames></author><author><keyname>Villoslada</keyname><forenames>Pablo</forenames></author></authors><title>Switcher-random-walks: a cognitive-inspired mechanism for network
  exploration</title><categories>cs.AI cond-mat.dis-nn physics.soc-ph</categories><comments>9 pages, 3 figures. Accepted in "International Journal of
  Bifurcations and Chaos": Special issue on "Modelling and Computation on
  Complex Networks"</comments><journal-ref>International Journal of Bifurcation and Chaos 20, 913-922 (2010)</journal-ref><doi>10.1142/S0218127410026204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic memory is the subsystem of human memory that stores knowledge of
concepts or meanings, as opposed to life specific experiences. The organization
of concepts within semantic memory can be understood as a semantic network,
where the concepts (nodes) are associated (linked) to others depending on
perceptions, similarities, etc. Lexical access is the complementary part of
this system and allows the retrieval of such organized knowledge. While
conceptual information is stored under certain underlying organization (and
thus gives rise to a specific topology), it is crucial to have an accurate
access to any of the information units, e.g. the concepts, for efficiently
retrieving semantic information for real-time needings. An example of an
information retrieval process occurs in verbal fluency tasks, and it is known
to involve two different mechanisms: -clustering-, or generating words within a
subcategory, and, when a subcategory is exhausted, -switching- to a new
subcategory. We extended this approach to random-walking on a network
(clustering) in combination to jumping (switching) to any node with certain
probability and derived its analytical expression based on Markov chains.
Results show that this dual mechanism contributes to optimize the exploration
of different network models in terms of the mean first passage time.
Additionally, this cognitive inspired dual mechanism opens a new framework to
better understand and evaluate exploration, propagation and transport phenomena
in other complex systems where switching-like phenomena are feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4237</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4237</id><created>2009-03-25</created><updated>2010-02-17</updated><authors><author><keyname>Kramer</keyname><forenames>Josh Brown</forenames></author><author><keyname>Sabalka</keyname><forenames>Lucas</forenames></author></authors><title>Projection-Forcing Multisets of Weight Changes</title><categories>math.CO cs.IT math.IT</categories><comments>11 Pages</comments><msc-class>05E99, 94B05</msc-class><journal-ref>Journal of Combinatorial Theory, Series A, 117(8): 1136-1142, 2010</journal-ref><doi>10.1016/j.jcta.2010.01.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $F$ be a finite field. A multiset $S$ of integers is projection-forcing
if for every linear function $\phi : F^n \to F^m$ whose multiset of weight
changes is $S$, $\phi$ is a coordinate projection up to permutation and scaling
of entries. The MacWilliams Extension Theorem from coding theory says that $S =
\{0, 0, ..., 0\}$ is projection-forcing. We give a (super-polynomial) algorithm
to determine whether or not a given $S$ is projection-forcing. We also give a
condition that can be checked in polynomial time that implies that $S$ is
projection-forcing. This result is a generalization of the MacWilliams
Extension Theorem and work by the first author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4258</identifier>
 <datestamp>2010-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4258</id><created>2009-03-25</created><updated>2010-02-16</updated><authors><author><keyname>Burkhart</keyname><forenames>Martin</forenames></author><author><keyname>Strasser</keyname><forenames>Mario</forenames></author><author><keyname>Many</keyname><forenames>Dilip</forenames></author><author><keyname>Dimitropoulos</keyname><forenames>Xenofontas</forenames></author></authors><title>SEPIA: Security through Private Information Aggregation</title><categories>cs.NI cs.CR</categories><report-no>TIK-Report No. 298</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Secure multiparty computation (MPC) allows joint privacy-preserving
computations on data of multiple parties. Although MPC has been studied
substantially, building solutions that are practical in terms of computation
and communication cost is still a major challenge. In this paper, we
investigate the practical usefulness of MPC for multi-domain network security
and monitoring. We first optimize MPC comparison operations for processing high
volume data in near real-time. We then design privacy-preserving protocols for
event correlation and aggregation of network traffic statistics, such as
addition of volume metrics, computation of feature entropy, and distinct item
count. Optimizing performance of parallel invocations, we implement our
protocols along with a complete set of basic operations in a library called
SEPIA. We evaluate the running time and bandwidth requirements of our protocols
in realistic settings on a local cluster as well as on PlanetLab and show that
they work in near real-time for up to 140 input providers and 9 computation
nodes. Compared to implementations using existing general-purpose MPC
frameworks, our protocols are significantly faster, requiring, for example, 3
minutes for a task that takes 2 days with general-purpose frameworks. This
improvement paves the way for new applications of MPC in the area of
networking. Finally, we run SEPIA's protocols on real traffic traces of 17
networks and show how they provide new possibilities for distributed
troubleshooting and early anomaly detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0903.4513</identifier>
 <datestamp>2011-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0903.4513</id><created>2009-03-26</created><updated>2011-10-13</updated><authors><author><keyname>Vishnevskaya</keyname><forenames>Elena S.</forenames></author></authors><title>Building the information kernel and the problem of recognition</title><categories>cs.CV cs.AI</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At this point in time there is a need for a new representation of different
information, to identify and organize descending its characteristics. Today,
science is a powerful tool for the description of reality - the numbers. Why
the most important property of numbers. Suppose we have a number 0.2351734, it
is clear that the figures are there in order of importance. If necessary, we
can round the number up to some value, eg 0.235. Arguably, the 0,235 - the most
important information of 0.2351734. Thus, we can reduce the size of numbers is
not losing much with the accuracy. Clearly, if learning to provide a graphical
or audio information kernel, we can provide the most relevant information,
discarding the rest. Introduction of various kinds of information in an
information kernel, is an important task, to solve many problems in artificial
intelligence and information theory.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="0" completeListSize="55406">1150333|1001</resumptionToken>
</ListRecords>
</OAI-PMH>